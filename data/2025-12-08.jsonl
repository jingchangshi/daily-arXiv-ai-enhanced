{"id": "2512.05372", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05372", "abs": "https://arxiv.org/abs/2512.05372", "authors": ["Chengjie Ma", "Seungeun Oh", "Jihong Park", "Seong-Lyun Kim"], "title": "FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity", "comment": null, "summary": "Federated learning (FL) holds strong potential for distributed machine learning, but in heterogeneous environments, Bandwidth-Constrained Clients (BCCs) often struggle to participate effectively due to limited communication capacity. Their small sub-models learn quickly at first but become under-parameterized in later stages, leading to slow convergence and degraded generalization. We propose FedGMR - Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity. FedGMR progressively increases each client's sub-model density during training, enabling BCCs to remain effective contributors throughout the process. In addition, we develop a mask-aware aggregation rule tailored for asynchronous MHFL and provide convergence guarantees showing that aggregated error scales with the average sub-model density across clients and rounds, while GMR provably shrinks this gap toward full-model FL. Extensive experiments on FEMNIST, CIFAR-10, and ImageNet-100 demonstrate that FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID settings."}
{"id": "2512.05543", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05543", "abs": "https://arxiv.org/abs/2512.05543", "authors": ["Xuezhi Li", "Jiancong He", "Ming Xie", "Xuyang Chen", "Le Chang", "Li Jiang", "Gui Gui"], "title": "Are Bus-Mounted Edge Servers Feasible?", "comment": null, "summary": "Placement of edge servers is the prerequisite of provisioning edge computing services for Internet of Vehicles (IoV). Fixed-site edge servers at Road Side Units (RSUs) or base stations are able to offer basic service coverage for end users, i.e., vehicles on road. However, the server locations and capacity are fixed after deployment, rendering their inefficiency in handling spationtemporal user dynamics. Mobile servers such as buses, on the other hand, have the potential of adding computation elasticity to such system. To this end, this paper studies the feasibility of bus-mounted edge servers based on real traces. First, we investigate the coverage of the buses and base stations using the Shanghai bus/taxi/Telecom datasets, which shows a great potential of bus-based edge servers as they cover a great portion of geographic area and demand points. Next, we build a mathematical model and design a simple greedy heuristic algorithm to select a limited number of buses that maximizes the coverage of demand points, i.e., with a limited purchase budget. We perform trace-driven simulations to verify the performance of the proposed bus selection algorithm. The results show that our approach effectively handles the dynamic user demand under realistic constraints such as server capacity and purchase quantity. Thus, we claim: bus-mounted edge servers for vehicular networks in urban areas are feasible, beneficial, and valuable."}
{"id": "2512.05224", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05224", "abs": "https://arxiv.org/abs/2512.05224", "authors": ["Miguel de Oliveira Guerreiro"], "title": "NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM", "comment": "4 figures, 2 tables", "summary": "Actor-based systems like Erlang/OTP power critical infrastructure -- from telecommunications to messaging platforms -- handling millions of concurrent connections with legendary reliability. Yet these systems lack static guarantees about message protocols: processes communicate by sending arbitrary messages that pattern-matched at runtime, deferring protocol violations to production failures.\n  We present NVLang, a statically typed functional language that brings comprehensive type safety to the BEAM virtual machine while preserving actor model's simplicity and power. NVLang's central contribution that algebraic data types (ADTs) naturally encode actor message protocols: each actor declares the sum type representing its message vocabulary, and the type system enforces protocol conformance at compile time. We introduce typed process identifiers (Pid[T]) that encode the protocol an actor expects, and typed futures (Future[T]) that provide type-safe request-reply patterns.\n  By extending Hindley-Milner type inference to track message protocols, NVLang eliminates an entire class of message-passing errors while maintaining clean syntax that rivals dynamically typed alternatives. Our implementation compiles to Core Erlang, enabling seamless interoperability with the existing Erlang ecosystem. We formalize the type system and provide proof sketches for type soundness, demonstrating that well-typed NVLang programs cannot send messages that violate actor protocols."}
{"id": "2512.05516", "categories": ["cs.PL", "cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2512.05516", "abs": "https://arxiv.org/abs/2512.05516", "authors": ["Pawel K. Radtke", "Tobias Weinzierl"], "title": "Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware", "comment": null, "summary": "This study evaluates AoS-to-SoA transformations over reduced-precision data layouts for a particle simulation code on several GPU platforms: We hypothesize that SoA fits particularly well to SIMT, while AoS is the preferred storage format for many Lagrangian codes. Reduced-precision (below IEEE accuracy) is an established tool to address bandwidth constraints, although it remains unclear whether AoS and precision conversions should execute on a CPU or be deployed to a GPU if the compute kernel itself must run on an accelerator. On modern superchips where CPUs and GPUs share (logically) one data space, it is also unclear whether it is advantageous to stream data to the accelerator prior to the calculation, or whether we should let the accelerator transform data on demand, i.e.~work in-place logically. We therefore introduce compiler annotations to facilitate such conversions and to give the programmer the option to orchestrate the conversions in combination with GPU offloading. For some of our compute kernels of interest, Nvidia's G200 platforms yield a speedup of around 2.6 while AMD's MI300A exhibits more robust performance yet profits less. We assume that our compiler-based techniques are applicable to a wide variety of Lagrangian codes and beyond."}
{"id": "2512.05224", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05224", "abs": "https://arxiv.org/abs/2512.05224", "authors": ["Miguel de Oliveira Guerreiro"], "title": "NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM", "comment": "4 figures, 2 tables", "summary": "Actor-based systems like Erlang/OTP power critical infrastructure -- from telecommunications to messaging platforms -- handling millions of concurrent connections with legendary reliability. Yet these systems lack static guarantees about message protocols: processes communicate by sending arbitrary messages that pattern-matched at runtime, deferring protocol violations to production failures.\n  We present NVLang, a statically typed functional language that brings comprehensive type safety to the BEAM virtual machine while preserving actor model's simplicity and power. NVLang's central contribution that algebraic data types (ADTs) naturally encode actor message protocols: each actor declares the sum type representing its message vocabulary, and the type system enforces protocol conformance at compile time. We introduce typed process identifiers (Pid[T]) that encode the protocol an actor expects, and typed futures (Future[T]) that provide type-safe request-reply patterns.\n  By extending Hindley-Milner type inference to track message protocols, NVLang eliminates an entire class of message-passing errors while maintaining clean syntax that rivals dynamically typed alternatives. Our implementation compiles to Core Erlang, enabling seamless interoperability with the existing Erlang ecosystem. We formalize the type system and provide proof sketches for type soundness, demonstrating that well-typed NVLang programs cannot send messages that violate actor protocols."}
{"id": "2512.05262", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.05262", "abs": "https://arxiv.org/abs/2512.05262", "authors": ["Daniel Nezamabadi", "Magnus O. Myreen", "Yong Kiam Tan"], "title": "Verified VCG and Verified Compiler for Dafny", "comment": "16 pages, 4 figures. To be published in CPP 2026. For mechanization, see https://github.com/CakeML/cakeml/tree/751ecd45c16b11ee0c3fd1280be7a6d798b5c457/compiler/dafny", "summary": "Dafny is a verification-aware programming language that comes with a compiler and static program verifier. However, neither the compiler nor the verifier is proved correct; in fact, soundness bugs have been found in both tools. This paper shows that the aforementioned Dafny tools can be developed with foundational correctness guarantees. We present a functional big-step semantics for an imperative subset of Dafny and, based on this semantics, a verified verification condition generator (VCG) and a verified compiler for Dafny. The subset of Dafny we have formalized includes mutually recursive method calls, while loops, and arrays -- these language features are significant enough to cover challenging examples such as McCarthy's 91 function and array-based programs that are used when teaching Dafny. The verified VCG allows one to prove functional correctness of annotated Dafny programs, while the verified compiler can be used to compile verified Dafny programs to CakeML programs. From there, one can obtain executable machine code via the (already verified) CakeML compiler, all while provably maintaining the functional correctness guarantees that were proved for the source-level Dafny programs. Our work has been mechanized in the HOL4 theorem prover."}
{"id": "2512.05516", "categories": ["cs.PL", "cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2512.05516", "abs": "https://arxiv.org/abs/2512.05516", "authors": ["Pawel K. Radtke", "Tobias Weinzierl"], "title": "Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware", "comment": null, "summary": "This study evaluates AoS-to-SoA transformations over reduced-precision data layouts for a particle simulation code on several GPU platforms: We hypothesize that SoA fits particularly well to SIMT, while AoS is the preferred storage format for many Lagrangian codes. Reduced-precision (below IEEE accuracy) is an established tool to address bandwidth constraints, although it remains unclear whether AoS and precision conversions should execute on a CPU or be deployed to a GPU if the compute kernel itself must run on an accelerator. On modern superchips where CPUs and GPUs share (logically) one data space, it is also unclear whether it is advantageous to stream data to the accelerator prior to the calculation, or whether we should let the accelerator transform data on demand, i.e.~work in-place logically. We therefore introduce compiler annotations to facilitate such conversions and to give the programmer the option to orchestrate the conversions in combination with GPU offloading. For some of our compute kernels of interest, Nvidia's G200 platforms yield a speedup of around 2.6 while AMD's MI300A exhibits more robust performance yet profits less. We assume that our compiler-based techniques are applicable to a wide variety of Lagrangian codes and beyond."}
{"id": "2512.05555", "categories": ["cs.PL", "cs.OS", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05555", "abs": "https://arxiv.org/abs/2512.05555", "authors": ["Alexey Paznikov", "Andrey Kogutenko", "Yaroslav Osipov", "Michael Schwarz", "Umang Mathur"], "title": "Compiling Away the Overhead of Race Detection", "comment": "35 pages", "summary": "Dynamic data race detectors are indispensable for flagging concurrency errors in software, but their high runtime overhead limits their adoption. This overhead stems primarily from pervasive instrumentation of memory accesses - a significant fraction of which is redundant. We addresses this inefficiency through a static, compiler-integrated approach that identifies and eliminates redundant instrumentation, drastically reducing the runtime cost of dynamic data race detectors. We introduce a suite of interprocedural static analyses reasoning about memory access patterns, synchronization, and thread creation to eliminate instrumentation for provably race-free accesses and show that the completeness properties of the data race detector are preserved. We further observe that many inserted checks flag a race if and only if a preceding check has already flagged an equivalent race for the same memory location - albeit potentially at a different access. We characterize this notion of equivalence and show that, when limiting reporting to at least one representative for each equivalence class, a further class of redundant checks can be eliminated. We identify such accesses using a novel dominance-based elimination analysis. Based on these two insights, we have implemented five static analyses within the LLVM, integrated with the instrumentation pass of the race detector ThreadSanitizer. Our experimental evaluation on a diverse suite of real-world applications demonstrates that our approach significantly reduces race detection overhead, achieving a geomean speedup of 1.34x, with peak speedups reaching 2.5x under high thread contention. This performance is achieved with a negligible increase in compilation time and, being fully automatic, places no additional burden on developers. Our optimizations have been accepted by the ThreadSanitizer maintainers and are in the process of being upstreamed."}
