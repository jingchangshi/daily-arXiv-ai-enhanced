{"id": "2508.01199", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.01199", "abs": "https://arxiv.org/abs/2508.01199", "authors": ["Avinash Malik"], "title": "Efficient compilation and execution of synchronous programs via type-state programming", "comment": null, "summary": "Synchronous programs are used extensively in implementation of safety\ncritical embedded software. Imperative synchronous programming languages model\nmultiple Finite State Machines (FSMs) executing in lockstep at logical clock\nticks. The synchronous view of time along with the FSM based design enables\neasier formal verification. The synchronous composition of multiple FSMs,\nduring compilation, results in the well known state space explosion problem.\nHence, efficiently compiling imperative synchronous programs into small and\nfast executables is challenging. This paper introduces a novel linear time\ncompilation technique for automata based compilation of synchronous programs.\nGraph based rewrite rules for kernel programming constructs are introduced. A\nlinear time algorithm applies these rules to produce a FSM. The FSM is then\nencoded into a type-state program using template meta-programming in C++.\nExperimental results show that the compilation time and generated binary size\nis comparable, while the execution times are on average 31-60% faster than\ncurrent state-of-the-art compilers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u65f6\u95f4\u7f16\u8bd1\u6280\u672f\uff0c\u7528\u4e8e\u540c\u6b65\u7a0b\u5e8f\u7684\u81ea\u52a8\u673a\u7f16\u8bd1\uff0c\u751f\u6210\u66f4\u5c0f\u66f4\u5feb\u7684\u53ef\u6267\u884c\u6587\u4ef6\u3002", "motivation": "\u540c\u6b65\u7a0b\u5e8f\u5728\u5b89\u5168\u5173\u952e\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u591aFSM\u540c\u6b65\u7ec4\u5408\u4f1a\u5bfc\u81f4\u72b6\u6001\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\uff0c\u7f16\u8bd1\u6548\u7387\u548c\u6267\u884c\u6027\u80fd\u6210\u4e3a\u6311\u6218\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u6539\u5199\u89c4\u5219\u548c\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u751f\u6210FSM\uff0c\u5e76\u901a\u8fc7C++\u6a21\u677f\u5143\u7f16\u7a0b\u7f16\u7801\u4e3a\u7c7b\u578b\u72b6\u6001\u7a0b\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7f16\u8bd1\u65f6\u95f4\u548c\u4e8c\u8fdb\u5236\u5927\u5c0f\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u5f53\uff0c\u6267\u884c\u65f6\u95f4\u5e73\u5747\u5feb31-60%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u540c\u6b65\u7a0b\u5e8f\u7684\u7f16\u8bd1\u6548\u7387\u548c\u6267\u884c\u6027\u80fd\u3002"}}
{"id": "2508.02305", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.02305", "abs": "https://arxiv.org/abs/2508.02305", "authors": ["Rose Bohrer"], "title": "Proceedings 14th International Workshop on Trends in Functional Programming in Education", "comment": null, "summary": "The goal of TFPIE is to gather researchers, teachers and professionals that\nuse, or are interested in the use of, functional programming in education.\nTFPIE aims to be a venue where novel ideas, classroom-tested ideas and\nwork-in-progress on the use of functional programming in education are\ndiscussed. The one-day workshop will foster a spirit of open discussion by\nhaving a review process for publication after the workshop.", "AI": {"tldr": "TFPIE\u662f\u4e00\u4e2a\u805a\u96c6\u7814\u7a76\u4eba\u5458\u3001\u6559\u5e08\u548c\u4e13\u4e1a\u4eba\u58eb\u7684\u7814\u8ba8\u4f1a\uff0c\u4e13\u6ce8\u4e8e\u6559\u80b2\u4e2d\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u5e94\u7528\u3002", "motivation": "\u4fc3\u8fdb\u51fd\u6570\u5f0f\u7f16\u7a0b\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u4eab\u65b0\u9896\u548c\u7ecf\u8fc7\u8bfe\u5802\u9a8c\u8bc1\u7684\u60f3\u6cd5\u3002", "method": "\u901a\u8fc7\u4e3a\u671f\u4e00\u5929\u7684\u5f00\u653e\u8ba8\u8bba\u7814\u8ba8\u4f1a\uff0c\u91c7\u7528\u4f1a\u540e\u51fa\u7248\u7269\u7684\u8bc4\u5ba1\u6d41\u7a0b\u3002", "result": "\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e00\u4e2a\u4ea4\u6d41\u5e73\u53f0\uff0c\u63a8\u52a8\u51fd\u6570\u5f0f\u7f16\u7a0b\u5728\u6559\u80b2\u4e2d\u7684\u53d1\u5c55\u3002", "conclusion": "TFPIE\u65e8\u5728\u901a\u8fc7\u5f00\u653e\u8ba8\u8bba\u548c\u5206\u4eab\uff0c\u4fc3\u8fdb\u6559\u80b2\u4e2d\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u521b\u65b0\u4e0e\u5b9e\u8df5\u3002"}}
{"id": "2508.01180", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.01180", "abs": "https://arxiv.org/abs/2508.01180", "authors": ["Bowen Wang", "Marco Bertuletti", "Yichao Zhang", "Victor J. B. Jung", "Luca Benini"], "title": "A Dynamic Allocation Scheme for Adaptive Shared-Memory Mapping on Kilo-core RV Clusters for Attention-Based Model Deployment", "comment": "8 pages, 9 figures, 36th IEEE International Conference on\n  Application-specific Systems, Architectures and Processors", "summary": "Attention-based models demand flexible hardware to manage diverse kernels\nwith varying arithmetic intensities and memory access patterns. Large clusters\nwith shared L1 memory, a common architectural pattern, struggle to fully\nutilize their processing elements (PEs) when scaled up due to reduced\nthroughput in the hierarchical PE-to-L1 intra-cluster interconnect. This paper\npresents Dynamic Allocation Scheme (DAS), a runtime programmable address\nremapping hardware unit coupled with a unified memory allocator, designed to\nminimize data access contention of PEs onto the multi-banked L1. We evaluated\nDAS on an aggressively scaled-up 1024-PE RISC-V cluster with Non-Uniform Memory\nAccess (NUMA) PE-to-L1 interconnect to demonstrate its potential for improving\ndata locality in large parallel machine learning workloads. For a Vision\nTransformer (ViT)-L/16 model, each encoder layer executes in 5.67 ms, achieving\na 1.94x speedup over the fixed word-level interleaved baseline with 0.81 PE\nutilization. Implemented in 12nm FinFET technology, DAS incurs <0.1 % area\noverhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u5206\u914d\u65b9\u6848\uff08DAS\uff09\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u53ef\u7f16\u7a0b\u5730\u5740\u91cd\u6620\u5c04\u786c\u4ef6\u5355\u5143\u548c\u7edf\u4e00\u5185\u5b58\u5206\u914d\u5668\uff0c\u4f18\u5316\u5927\u89c4\u6a21\u5e76\u884c\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6570\u636e\u5c40\u90e8\u6027\uff0c\u663e\u8457\u63d0\u5347\u5904\u7406\u5355\u5143\uff08PE\uff09\u7684\u5229\u7528\u7387\u3002", "motivation": "\u6ce8\u610f\u529b\u6a21\u578b\u9700\u8981\u7075\u6d3b\u786c\u4ef6\u4ee5\u5e94\u5bf9\u4e0d\u540c\u7b97\u672f\u5f3a\u5ea6\u548c\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u800c\u4f20\u7edf\u5171\u4eabL1\u5185\u5b58\u7684\u5927\u578b\u96c6\u7fa4\u5728\u6269\u5c55\u65f6\u56e0PE\u95f4\u4e92\u8054\u541e\u5410\u4e0b\u964d\u5bfc\u81f4PE\u5229\u7528\u7387\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDAS\u65b9\u6848\uff0c\u7ed3\u5408\u5730\u5740\u91cd\u6620\u5c04\u786c\u4ef6\u548c\u7edf\u4e00\u5185\u5b58\u5206\u914d\u5668\uff0c\u51cf\u5c11PE\u5bf9\u591abank L1\u5185\u5b58\u7684\u8bbf\u95ee\u7ade\u4e89\u3002\u57281024-PE RISC-V\u96c6\u7fa4\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5728ViT-L/16\u6a21\u578b\u4e2d\uff0c\u6bcf\u5c42\u7f16\u7801\u5668\u6267\u884c\u65f6\u95f4\u4e3a5.67 ms\uff0c\u6bd4\u57fa\u7ebf\u63d0\u53471.94\u500d\u901f\u5ea6\uff0cPE\u5229\u7528\u7387\u4e3a0.81\u3002DAS\u9762\u79ef\u5f00\u9500<0.1%\u3002", "conclusion": "DAS\u80fd\u6709\u6548\u63d0\u5347\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u548cPE\u5229\u7528\u7387\uff0c\u786c\u4ef6\u5f00\u9500\u6781\u5c0f\u3002"}}
{"id": "2508.01373", "categories": ["cs.DC", "cs.DS", "F.2.2"], "pdf": "https://arxiv.org/pdf/2508.01373", "abs": "https://arxiv.org/abs/2508.01373", "authors": ["Dariusz R. Kowalski", "Jan Olkowski"], "title": "Deterministic Fault-Tolerant Local Load Balancing and its Applications against Adaptive Adversaries", "comment": null, "summary": "Load balancing is among the basic primitives in distributed computing. In\nthis paper, we consider this problem when executed locally on a network with\nnodes prone to failures. We show that there exist lightweight network\ntopologies that are immune to message delivery failures incurred by (at most) a\nconstant fraction of all nodes. More precisely, we design a novel deterministic\nfault-tolerant local load balancing (LLB) algorithm, which, similarly to their\nclassical counterparts working in fault-free networks, has a relatively simple\nstructure and guarantees exponentially fast convergence to the average value\ndespite crash and omission failures.\n  As the second part of our contribution, we show three applications of the\nnewly developed fault-tolerant local load balancing protocol. We give a\nrandomized consensus algorithm, working against $t < n / 3$ crash failures,\nthat improves over the best-known consensus solution by Hajiaghayi et al. with\nrespect to communication complexity, yet with an arguable simpler technique of\ncombining a randomly and locally selected virtual communication graph with a\ndeterministic fault-tolerant local load balancing on this graph.\n  We also give a new solution for consensus for networks with omission\nfailures. Our solution works against $t < \\frac{n}{C\\log{n} (\\log\\log n)^2}$\nomissions, for some constant $C$, is nearly optimal in terms of time\ncomplexity, but most notably -- it has communication complexity $O((t^2 +\nn)\\text{ polylog } {n})$, matching, within a polylogarithmic factor, the lower\nbound by Abraham et. al. with respect to both terms depending on $t$ and $n$.\nOurs is the first algorithm in the literature that is simultaneously nearly\noptimal, in terms of $n,t$, with respect to both complexity measures, against\nthe adaptive omission-causing adversary.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u786e\u5b9a\u6027\u5bb9\u9519\u672c\u5730\u8d1f\u8f7d\u5747\u8861\uff08LLB\uff09\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u8282\u70b9\u6613\u6545\u969c\u7684\u5206\u5e03\u5f0f\u7f51\u7edc\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5171\u8bc6\u7b97\u6cd5\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u5728\u8282\u70b9\u6613\u6545\u969c\u7684\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u672c\u5730\u8d1f\u8f7d\u5747\u8861\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u5171\u8bc6\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u5bb9\u9519\u672c\u5730\u8d1f\u8f7d\u5747\u8861\u7b97\u6cd5\uff0c\u7ed3\u5408\u968f\u673a\u9009\u62e9\u7684\u865a\u62df\u901a\u4fe1\u56fe\u548c\u8d1f\u8f7d\u5747\u8861\u6280\u672f\u3002", "result": "\u7b97\u6cd5\u5728\u6545\u969c\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5feb\u901f\u6536\u655b\u5230\u5e73\u5747\u503c\uff0c\u5e76\u5728\u5171\u8bc6\u95ee\u9898\u4e2d\u6539\u8fdb\u4e86\u901a\u4fe1\u590d\u6742\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u8d1f\u8f7d\u5747\u8861\u548c\u5171\u8bc6\u95ee\u9898\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u662f\u9996\u4e2a\u5728\u81ea\u9002\u5e94\u9057\u6f0f\u6545\u969c\u4e0b\u540c\u65f6\u63a5\u8fd1\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01786", "categories": ["cs.AR", "B.7; C.0; C.5"], "pdf": "https://arxiv.org/pdf/2508.01786", "abs": "https://arxiv.org/abs/2508.01786", "authors": ["Subhasish Mitra", "Subho Banerjee", "Martin Dixon", "Rama Govindaraju", "Peter Hochschild", "Eric X. Liu", "Bharath Parthasarathy", "Parthasarathy Ranganathan"], "title": "Silent Data Corruption by 10x Test Escapes Threatens Reliable Computing", "comment": null, "summary": "Too many defective compute chips are escaping existing manufacturing tests --\nat least an order of magnitude more than industrial targets across all compute\nchip types in data centers. Silent data corruptions (SDCs) caused by test\nescapes, when left unaddressed, pose a major threat to reliable computing. We\npresent a three-pronged approach to future directions in overcoming test\nescapes: (a) Quick diagnosis of defective chips directly from system-level\nincorrect behaviors. Such diagnosis is critical for gaining insights into why\nso many defective chips escape existing manufacturing testing. (b) In-field\ndetection of defective chips. (c) New test experiments to understand the\neffectiveness of new techniques for detecting defective chips. These\nexperiments must overcome the drawbacks and pitfalls of previous industrial\ntest experiments and case studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u7ba1\u9f50\u4e0b\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8ba1\u7b97\u82af\u7247\u5236\u9020\u6d4b\u8bd5\u4e2d\u7684\u7f3a\u9677\u9003\u9038\u95ee\u9898\uff0c\u5305\u62ec\u5feb\u901f\u8bca\u65ad\u3001\u73b0\u573a\u68c0\u6d4b\u548c\u65b0\u6d4b\u8bd5\u5b9e\u9a8c\u3002", "motivation": "\u73b0\u6709\u5236\u9020\u6d4b\u8bd5\u4e2d\u7f3a\u9677\u82af\u7247\u9003\u9038\u6570\u91cf\u8fdc\u8d85\u5de5\u4e1a\u76ee\u6807\uff0c\u5bfc\u81f4\u9759\u9ed8\u6570\u636e\u635f\u574f\uff08SDC\uff09\uff0c\u5a01\u80c1\u8ba1\u7b97\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u5feb\u901f\u8bca\u65ad\u3001\u73b0\u573a\u68c0\u6d4b\u548c\u65b0\u6d4b\u8bd5\u5b9e\u9a8c\u4e09\u79cd\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u7f3a\u9677\u82af\u7247\u68c0\u6d4b\u3002", "result": "\u672a\u660e\u786e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u901a\u8fc7\u591a\u89d2\u5ea6\u65b9\u6cd5\u6539\u8fdb\u6d4b\u8bd5\u6280\u672f\uff0c\u6709\u671b\u51cf\u5c11\u7f3a\u9677\u82af\u7247\u9003\u9038\uff0c\u63d0\u5347\u8ba1\u7b97\u53ef\u9760\u6027\u3002"}}
{"id": "2508.01494", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.01494", "abs": "https://arxiv.org/abs/2508.01494", "authors": ["Steven Santillan", "Cristina L. Abad"], "title": "An Analysis of HPC and Edge Architectures in the Cloud", "comment": "8 pages, 10 figures, accepted at 2nd Workshop on Accelerated HPC in\n  the Cloud-Edge Continuum 2025, held in conjunction with 13th IEEE\n  International Conference on Cloud Engineering (IC2E 2025)", "summary": "We analyze a recently published dataset of 396 real-world cloud architectures\ndeployed on AWS, from companies belonging to a wide range of industries. From\nthis dataset, we identify those architectures that contain HPC or edge\ncomponents and characterize their designs. Specifically, we investigate the\nprevalence and interplay of AWS services within these architectures, examine\nthe types of storage systems employed, assess architectural complexity and the\nuse of machine learning services, discuss the implications of our findings and\nhow representative these results are of HPC and edge architectures in the\ncloud. This characterization provides valuable insights into current industry\npractices and trends in building robust and scalable HPC and edge solutions in\nthe cloud continuum, and can be valuable for those seeking to better understand\nhow these architectures are being built and to guide new research.", "AI": {"tldr": "\u5206\u6790396\u4e2a\u771f\u5b9eAWS\u4e91\u67b6\u6784\uff0c\u805a\u7126HPC\u548c\u8fb9\u7f18\u7ec4\u4ef6\uff0c\u63a2\u8ba8\u5176\u8bbe\u8ba1\u3001\u670d\u52a1\u7ec4\u5408\u3001\u5b58\u50a8\u7cfb\u7edf\u3001\u590d\u6742\u6027\u548c\u673a\u5668\u5b66\u4e60\u670d\u52a1\u4f7f\u7528\u3002", "motivation": "\u4e86\u89e3\u5f53\u524d\u884c\u4e1a\u4e2dHPC\u548c\u8fb9\u7f18\u67b6\u6784\u7684\u8bbe\u8ba1\u8d8b\u52bf\uff0c\u4e3a\u5b9e\u8df5\u548c\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u57fa\u4e8eAWS\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u5305\u542bHPC\u6216\u8fb9\u7f18\u7ec4\u4ef6\u7684\u67b6\u6784\uff0c\u8bc4\u4f30\u670d\u52a1\u7ec4\u5408\u3001\u5b58\u50a8\u7cfb\u7edf\u3001\u590d\u6742\u6027\u548c\u673a\u5668\u5b66\u4e60\u670d\u52a1\u3002", "result": "\u63ed\u793a\u4e86HPC\u548c\u8fb9\u7f18\u67b6\u6784\u7684\u5e38\u89c1\u8bbe\u8ba1\u6a21\u5f0f\u3001\u670d\u52a1\u7ec4\u5408\u53ca\u884c\u4e1a\u5b9e\u8df5\uff0c\u63d0\u4f9b\u4e86\u884c\u4e1a\u8d8b\u52bf\u7684\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6784\u5efa\u7a33\u5065\u3001\u53ef\u6269\u5c55\u7684HPC\u548c\u8fb9\u7f18\u4e91\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u53c2\u8003\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.01800", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.01800", "abs": "https://arxiv.org/abs/2508.01800", "authors": ["Ajay Kumar M", "Cian O'Mahoney", "Pedro Kreutz Werle", "Shreejith Shanker", "Dimitrios S. Nikolopoulos", "Bo Ji", "Hans Vandierendonck", "Deepu John"], "title": "MARVEL: An End-to-End Framework for Generating Model-Class Aware Custom RISC-V Extensions for Lightweight AI", "comment": "To be published in IEEE Open Journal of Circuits and Systems", "summary": "Deploying deep neural networks (DNNs) on resource-constrained IoT devices\nremains a challenging problem, often requiring hardware modifications tailored\nto individual AI models. Existing accelerator-generation tools, such as AMD's\nFINN, do not adequately address extreme resource limitations faced by IoT\nendpoints operating in bare-metal environments without an operating system\n(OS). To overcome these constraints, we propose MARVEL-an automated, end-to-end\nframework that generates custom RISC-V ISA extensions tailored to specific DNN\nmodel classes, with a primary focus on convolutional neural networks (CNNs).\nThe proposed method profiles high-level DNN representations in Python and\ngenerates an ISA-extended RISC-V core with associated compiler tools for\nefficient deployment. The flow leverages (1) Apache TVM for translating\nhigh-level Python-based DNN models into optimized C code, (2) Synopsys ASIP\nDesigner for identifying compute-intensive kernels, modeling, and generating a\ncustom RISC-V and (3) Xilinx Vivado for FPGA implementation. Beyond a model\nclass specific RISC-V, our approach produces an optimized bare-metal C\nimplementation, eliminating the need for an OS or extensive software\ndependencies. Unlike conventional deployment pipelines relying on\nTensorFlow/PyTorch runtimes, our solution enables seamless execution in highly\nresource-constrained environments. We evaluated the flow on popular DNN models\nsuch as LeNet-5*, MobileNetV1, ResNet50, VGG16, MobileNetV2 and DenseNet121\nusing the Synopsys trv32p3 RISC-V core as a baseline. Results show a 2x speedup\nin inference and upto 2x reduction in energy per inference at a 28.23% area\noverhead when implemented on an AMD Zynq UltraScale+ ZCU104 FPGA platform.", "AI": {"tldr": "MARVEL\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4e3a\u7279\u5b9aDNN\u6a21\u578b\u7c7b\u751f\u6210\u5b9a\u5236\u7684RISC-V ISA\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\uff0c\u65e0\u9700\u64cd\u4f5c\u7cfb\u7edf\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5982AMD\u7684FINN\u65e0\u6cd5\u89e3\u51b3\u65e0\u64cd\u4f5c\u7cfb\u7edf\u7684IoT\u8bbe\u5907\u9762\u4e34\u7684\u6781\u7aef\u8d44\u6e90\u9650\u5236\u95ee\u9898\u3002", "method": "MARVEL\u901a\u8fc7\u5206\u6790Python\u4e2d\u7684DNN\u8868\u793a\uff0c\u751f\u6210\u5b9a\u5236\u7684RISC-V\u6838\u5fc3\u53ca\u7f16\u8bd1\u5668\u5de5\u5177\uff0c\u7ed3\u5408Apache TVM\u3001Synopsys ASIP Designer\u548cXilinx Vivado\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002", "result": "\u5728AMD Zynq UltraScale+\u5e73\u53f0\u4e0a\uff0cMARVEL\u5b9e\u73b0\u4e86\u63a8\u7406\u901f\u5ea6\u63d0\u53472\u500d\uff0c\u80fd\u8017\u964d\u4f4e2\u500d\uff0c\u9762\u79ef\u5f00\u9500\u4e3a28.23%\u3002", "conclusion": "MARVEL\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u64cd\u4f5c\u7cfb\u7edf\u7684\u9ad8\u6548DNN\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01762", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.01762", "abs": "https://arxiv.org/abs/2508.01762", "authors": ["Yann Bourreau", "Sebastian Brandt", "Alexandre Nolin"], "title": "Faster Distributed $\u0394$-Coloring via a Reduction to MIS", "comment": null, "summary": "Recent improvements on the deterministic complexities of fundamental graph\nproblems in the LOCAL model of distributed computing have yielded\nstate-of-the-art upper bounds of $\\tilde{O}(\\log^{5/3} n)$ rounds for maximal\nindependent set (MIS) and $(\\Delta + 1)$-coloring [Ghaffari, Grunau, FOCS'24]\nand $\\tilde{O}(\\log^{19/9} n)$ rounds for the more restrictive\n$\\Delta$-coloring problem [Ghaffari, Kuhn, FOCS'21; Ghaffari, Grunau, FOCS'24;\nBourreau, Brandt, Nolin, STOC'25]. In our work, we show that $\\Delta$-coloring\ncan be solved deterministically in $\\tilde{O}(\\log^{5/3} n)$ rounds as well,\nmatching the currently best bound for $(\\Delta + 1)$-coloring.\n  We achieve our result by developing a reduction from $\\Delta$-coloring to MIS\nthat guarantees that the (asymptotic) complexity of $\\Delta$-coloring is at\nmost the complexity of MIS, unless MIS can be solved in sublogarithmic time, in\nwhich case, due to the $\\Omega(\\log n)$-round $\\Delta$-coloring lower bound\nfrom [BFHKLRSU, STOC'16], our reduction implies a tight complexity of\n$\\Theta(\\log n)$ for $\\Delta$-coloring. In particular, any improvement on the\ncomplexity of the MIS problem will yield the same improvement for the\ncomplexity of $\\Delta$-coloring (up to the true complexity of\n$\\Delta$-coloring).\n  Our reduction yields improvements for $\\Delta$-coloring in the randomized\nLOCAL model and when complexities are parameterized by both $n$ and $\\Delta$.\nWe obtain a randomized complexity bound of $\\tilde{O}(\\log^{5/3} \\log n)$\nrounds (improving over the state of the art of $\\tilde{O}(\\log^{8/3} \\log n)$\nrounds) on general graphs and tight complexities of $\\Theta(\\log n)$ and\n$\\Theta(\\log \\log n)$ for the deterministic, resp.\\ randomized, complexity on\nbounded-degree graphs. In the special case of graphs of constant clique number\n(which for instance include bipartite graphs), we also give a reduction to the\n$(\\Delta+1)$-coloring problem.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.02007", "categories": ["cs.AR", "cs.OS", "B.3; D.4"], "pdf": "https://arxiv.org/pdf/2508.02007", "abs": "https://arxiv.org/abs/2508.02007", "authors": ["Konstantinos Kanellopoulos", "Konstantinos Sgouras", "Andreas Kosmas Kakolyris", "Vlad-Petru Nitu", "Berkin Kerim Konar", "Rahul Bera", "Onur Mutlu"], "title": "Revelator: Rapid Data Fetching via OS-Driven Hash-based Speculative Address Translation", "comment": null, "summary": "Address translation is a major performance bottleneck in modern computing\nsystems. Speculative address translation can hide this latency by predicting\nthe physical address (PA) of requested data early in the pipeline. However,\npredicting the PA from the virtual address (VA) is difficult due to the\nunpredictability of VA-to-PA mappings in conventional OSes. Prior works try to\novercome this but face two key issues: (i) reliance on large pages or VA-to-PA\ncontiguity, which is not guaranteed, and (ii) costly hardware changes to store\nspeculation metadata with limited effectiveness.\n  We introduce Revelator, a hardware-OS cooperative scheme enabling highly\naccurate speculative address translation with minimal modifications. Revelator\nemploys a tiered hash-based allocation strategy in the OS to create predictable\nVA-to-PA mappings, falling back to conventional allocation when needed. On a\nTLB miss, a lightweight speculation engine, guided by this policy, generates\ncandidate PAs for both program data and last-level page table entries (PTEs).\nThus, Revelator (i) speculatively fetches requested data before translation\nresolves, reducing access latency, and (ii) fetches the fourth-level PTE before\nthe third-level PTE is accessed, accelerating page table walks.\n  We prototype Revelator's OS support in Linux and evaluate it in simulation\nacross 11 diverse, data-intensive benchmarks in native and virtualized\nenvironments. Revelator achieves average speedups of 27% (20%) in native\n(virtualized) settings, surpasses a state-of-the-art speculative mechanism by\n5%, and reduces energy use by 9% compared to baseline. Our RTL prototype shows\nminimal area and power overheads on a modern CPU.", "AI": {"tldr": "Revelator\u662f\u4e00\u79cd\u786c\u4ef6-\u64cd\u4f5c\u7cfb\u7edf\u534f\u4f5c\u65b9\u6848\uff0c\u901a\u8fc7\u9884\u6d4b\u6027\u5730\u5740\u7ffb\u8bd1\u63d0\u5347\u6027\u80fd\uff0c\u51cf\u5c11\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u5730\u5740\u7ffb\u8bd1\u662f\u6027\u80fd\u74f6\u9888\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u9875\u6216\u8fde\u7eed\u6620\u5c04\uff0c\u6548\u679c\u6709\u9650\u4e14\u786c\u4ef6\u6539\u52a8\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u5206\u5c42\u54c8\u5e0c\u5206\u914d\u7b56\u7565\u521b\u5efa\u53ef\u9884\u6d4b\u7684\u865a\u62df\u5730\u5740\u5230\u7269\u7406\u5730\u5740\u6620\u5c04\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u63a8\u6d4b\u5f15\u64ce\u751f\u6210\u5019\u9009\u7269\u7406\u5730\u5740\u3002", "result": "\u5728\u539f\u751f\u548c\u865a\u62df\u5316\u73af\u5883\u4e2d\u5e73\u5747\u63d0\u901f27%\uff0820%\uff09\uff0c\u8d85\u8d8a\u73b0\u6709\u6280\u672f5%\uff0c\u80fd\u8017\u964d\u4f4e9%\u3002", "conclusion": "Revelator\u901a\u8fc7\u6700\u5c0f\u5316\u786c\u4ef6\u6539\u52a8\u548c\u64cd\u4f5c\u7cfb\u7edf\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u5730\u5740\u7ffb\u8bd1\u4f18\u5316\u3002"}}
{"id": "2508.01856", "categories": ["cs.DC", "cs.CR", "cs.DB", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.01856", "abs": "https://arxiv.org/abs/2508.01856", "authors": ["Xu Yuan", "Fang Luo", "Muhammad Zeeshan Haider", "Zhikui Chen", "Yucheng Li"], "title": "Efficient Byzantine Consensus MechanismBased on Reputation in IoT Blockchain", "comment": null, "summary": "Blockchain technology has advanced rapidly in recent years and is now widely\nused in a variety of fields. Blockchain appears to be one of the best solutions\nfor managing massive heterogeneous devices while achieving advanced data\nsecurity and data reputation, particularly in the field of large-scale IoT\n(Internet of Things) networks. Despite the numerous advantages, there are still\nchallenges while deploying IoT applications on blockchain systems due to the\nlimited storage, power, and computing capability of IoT devices, and some of\nthese problems are caused by the consensus algorithm, which plays a significant\nrole in blockchain systems by ensuring overall system reliability and\nrobustness. Nonetheless, most existing consensus algorithms are prone to poor\nnode reliability, low transaction per second (TPS) rates, and scalability\nissues. Aiming at some critical problems in the existing consensus algorithms,\nthis paper proposes the Efficient Byzantine Reputation-based Consensus (EBRC)\nmechanism to resolve the issues raised above. In comparison to traditional\nalgorithms, we reinvented ways to evaluate node reliability and robustness and\nmanage active nodes. Our experiments show that the EBRC algorithm has lower\nconsensus delay, higher throughput, improved security, and lower verification\ncosts. It offers new reference ideas for solving the Internet of\nThings+blockchain+Internet court construction problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u62dc\u5360\u5ead\u58f0\u8a89\u5171\u8bc6\u673a\u5236\uff08EBRC\uff09\uff0c\u4ee5\u89e3\u51b3\u533a\u5757\u94fe\u5728\u7269\u8054\u7f51\u4e2d\u90e8\u7f72\u65f6\u7684\u5b58\u50a8\u3001\u8ba1\u7b97\u548c\u5171\u8bc6\u7b97\u6cd5\u95ee\u9898\u3002", "motivation": "\u533a\u5757\u94fe\u5728\u7269\u8054\u7f51\u4e2d\u9762\u4e34\u5b58\u50a8\u3001\u8ba1\u7b97\u80fd\u529b\u548c\u5171\u8bc6\u7b97\u6cd5\u7684\u6311\u6218\uff0c\u73b0\u6709\u7b97\u6cd5\u5b58\u5728\u8282\u70b9\u53ef\u9760\u6027\u4f4e\u3001\u541e\u5410\u91cf\u5c0f\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faEBRC\u673a\u5236\uff0c\u91cd\u65b0\u8bbe\u8ba1\u8282\u70b9\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f18\u5316\u6d3b\u8dc3\u8282\u70b9\u7ba1\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEBRC\u5177\u6709\u66f4\u4f4e\u7684\u5171\u8bc6\u5ef6\u8fdf\u3001\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3001\u66f4\u5f3a\u7684\u5b89\u5168\u6027\u548c\u66f4\u4f4e\u7684\u9a8c\u8bc1\u6210\u672c\u3002", "conclusion": "EBRC\u4e3a\u89e3\u51b3\u7269\u8054\u7f51+\u533a\u5757\u94fe+\u4e92\u8054\u7f51\u6cd5\u9662\u5efa\u8bbe\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.02236", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.02236", "abs": "https://arxiv.org/abs/2508.02236", "authors": ["Lu Chen", "Dingyi Zhao", "Zihao Yu", "Ninghui Sun", "Yungang Bao"], "title": "GSIM: Accelerating RTL Simulation for Large-Scale Designs", "comment": null, "summary": "Register Transfer Level (RTL) simulation is widely used in design space\nexploration, verification, debugging, and preliminary performance evaluation\nfor hardware design. Among various RTL simulation approaches, software\nsimulation is the most commonly used due to its flexibility, low cost, and ease\nof debugging. However, the slow simulation of complex designs has become the\nbottleneck in design flow. In this work, we explore the sources of computation\noverhead of RTL simulation and conclude them into four factors. To optimize\nthese factors, we propose several techniques at the supernode level, node\nlevel, and bit level. Finally, we implement these techniques in a novel RTL\nsimulator GSIM. GSIM succeeds in simulating XiangShan, the state-of-the-art\nopen-source RISC-V processor. Besides, compared to Verilator, GSIM can achieve\nspeedup of 7.34x for booting Linux on XiangShan, and 19.94x for running\nCoreMark on Rocket.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86RTL\u4eff\u771f\u7684\u8ba1\u7b97\u5f00\u9500\u6765\u6e90\uff0c\u63d0\u51fa\u4e86\u591a\u5c42\u6b21\u7684\u4f18\u5316\u6280\u672f\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u578b\u4eff\u771f\u5668GSIM\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eff\u771f\u901f\u5ea6\u3002", "motivation": "RTL\u4eff\u771f\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u590d\u6742\u8bbe\u8ba1\u7684\u4eff\u771f\u901f\u5ea6\u6162\u6210\u4e3a\u74f6\u9888\u3002", "method": "\u5206\u6790\u4eff\u771f\u5f00\u9500\u7684\u56db\u4e2a\u56e0\u7d20\uff0c\u63d0\u51fa\u8d85\u8282\u70b9\u3001\u8282\u70b9\u548c\u6bd4\u7279\u7ea7\u522b\u7684\u4f18\u5316\u6280\u672f\u3002", "result": "GSIM\u4eff\u771f\u5668\u6210\u529f\u5e94\u7528\u4e8eXiangShan\u5904\u7406\u5668\uff0c\u901f\u5ea6\u63d0\u5347\u663e\u8457\uff08\u6700\u9ad819.94\u500d\uff09\u3002", "conclusion": "\u901a\u8fc7\u591a\u5c42\u6b21\u4f18\u5316\uff0cGSIM\u663e\u8457\u63d0\u5347\u4e86RTL\u4eff\u771f\u6548\u7387\u3002"}}
{"id": "2508.01911", "categories": ["cs.DC", "cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01911", "abs": "https://arxiv.org/abs/2508.01911", "authors": ["Muhammad Farhan Khan", "Muhammad Ahmed Mohsin", "Zeeshan Alam", "Muhammad Saad", "Muhammad Waqar"], "title": "Machine Learning-Driven Performance Analysis of Compressed Communication in Aerial-RIS Networks for Future 6G Networks", "comment": "Submitted to Mobile Networks and Applications", "summary": "In the future 6G and wireless networks, particularly in dense urban\nenvironments, bandwidth exhaustion and limited capacity pose significant\nchallenges to enhancing data rates. We introduce a novel system model designed\nto improve the data rate of users in next-generation multi-cell networks by\nintegrating Unmanned Aerial Vehicle (UAV)-Assisted Reconfigurable Intelligent\nSurfaces (RIS), Non-Orthogonal Multiple Access (NOMA), and Coordinated\nMultipoint Transmission (CoMP). Optimally deploying Aerial RIS for higher data\nrates, employing NOMA to improve spectral efficiency, and utilizing CoMP to\nmitigate inter-cell interference (ICI), we significantly enhance the overall\nsystem capacity and sum rate. Furthermore, we address the challenge of feedback\noverhead associated with Quantized Phase Shifts (QPS) from the receiver to RIS.\nThe feedback channel is band-limited and cannot support a large overhead of QPS\nfor uplink communication. To ensure seamless transmission, we propose a Machine\nLearning Autoencoder technique for a compressed communication of QPS from the\nreceiver to RIS, while maintaining high accuracy. Additionally, we investigate\nthe impact of the number of Aerial RIS elements and power allocation ratio for\nNOMA on the individual data rate of users. Our simulation results demonstrate\nsubstantial improvements in spectral efficiency, outage probability, and\nbandwidth utilization, highlighting the potential of the proposed architecture\nto enhance network performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65e0\u4eba\u673a\u8f85\u52a9RIS\u3001NOMA\u548cCoMP\u7684\u7cfb\u7edf\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad86G\u7f51\u7edc\u4e2d\u7684\u6570\u636e\u901f\u7387\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u538b\u7f29\u53cd\u9988\u4fe1\u606f\uff0c\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u5e26\u5bbd\u8017\u5c3d\u548c\u5bb9\u91cf\u9650\u5236\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e0b\u4e00\u4ee3\u591a\u5c0f\u533a\u7f51\u7edc\u7684\u6570\u636e\u901f\u7387\u3002", "method": "\u6574\u5408\u65e0\u4eba\u673a\u8f85\u52a9RIS\u3001NOMA\u548cCoMP\u6280\u672f\uff0c\u4f18\u5316\u90e8\u7f72\u548c\u8d44\u6e90\u5206\u914d\uff0c\u5e76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u538b\u7f29\u53cd\u9988\u4fe1\u606f\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u9891\u8c31\u6548\u7387\u3001\u964d\u4f4e\u4e86\u4e2d\u65ad\u6982\u7387\uff0c\u5e76\u4f18\u5316\u4e86\u5e26\u5bbd\u5229\u7528\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u67b6\u6784\u5728\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2508.02304", "categories": ["cs.AR", "cs.ET", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.02304", "abs": "https://arxiv.org/abs/2508.02304", "authors": ["Fangxin Liu", "Haomin Li", "Bowen Zhu", "Zongwu Wang", "Zhuoran Song", "Habing Guan", "Li Jiang"], "title": "ASDR: Exploiting Adaptive Sampling and Data Reuse for CIM-based Instant Neural Rendering", "comment": "Accepted by the 2025 International Conference on Architectural\n  Support for Programming Languages and Operating Systems (ASPLOS 2025). The\n  paper will be presented at ASPLOS 2026", "summary": "Neural Radiance Fields (NeRF) offer significant promise for generating\nphotorealistic images and videos. However, existing mainstream neural rendering\nmodels often fall short in meeting the demands for immediacy and power\nefficiency in practical applications. Specifically, these models frequently\nexhibit irregular access patterns and substantial computational overhead,\nleading to undesirable inference latency and high power consumption.\nComputing-in-memory (CIM), an emerging computational paradigm, has the\npotential to address these access bottlenecks and reduce the power consumption\nassociated with model execution.\n  To bridge the gap between model performance and real-world scene\nrequirements, we propose an algorithm-architecture co-design approach,\nabbreviated as ASDR, a CIM-based accelerator supporting efficient neural\nrendering. At the algorithmic level, we propose two rendering optimization\nschemes: (1) Dynamic sampling by online sensing of the rendering difficulty of\ndifferent pixels, thus reducing access memory and computational overhead. (2)\nReducing MLP overhead by decoupling and approximating the volume rendering of\ncolor and density. At the architecture level, we design an efficient\nReRAM-based CIM architecture with efficient data mapping and reuse\nmicroarchitecture. Experiments demonstrate that our design can achieve up to\n$9.55\\times$ and $69.75\\times$ speedup over state-of-the-art NeRF accelerators\nand Xavier NX GPU in graphics rendering tasks with only $0.1$ PSNR loss.", "AI": {"tldr": "ASDR\u662f\u4e00\u79cd\u57fa\u4e8eCIM\u7684\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u4f18\u5316\u795e\u7ecf\u6e32\u67d3\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6e32\u67d3\u6a21\u578b\u5728\u5b9e\u65f6\u6027\u548c\u80fd\u6548\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0cCIM\u6280\u672f\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u91c7\u6837\u548cMLP\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7684ReRAM CIM\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u663e\u793aASDR\u5728\u6e32\u67d3\u4efb\u52a1\u4e2d\u6bd4\u73b0\u6709\u52a0\u901f\u5668\u548cGPU\u5feb9.55\u500d\u548c69.75\u500d\uff0c\u4ec5\u635f\u59310.1 PSNR\u3002", "conclusion": "ASDR\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u795e\u7ecf\u6e32\u67d3\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.01989", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.01989", "abs": "https://arxiv.org/abs/2508.01989", "authors": ["Chao Wang", "Pengfei Zuo", "Zhangyu Chen", "Yunkai Liang", "Zhou Yu", "Ming-Chang Yang"], "title": "Prefill-Decode Aggregation or Disaggregation? Unifying Both for Goodput-Optimized LLM Serving", "comment": "17 pages, 19 figures", "summary": "An ongoing debate considers whether prefill-decode (PD) aggregation or\ndisaggregation is superior for serving large language models (LLMs). This has\ndriven optimizations for both approaches, each showing distinct advantages.\nThis paper compares PD aggregation and disaggregation, showing that each excels\nunder different service-level objectives (SLOs): aggregation is optimal for\ntight time-to-first-token (TTFT) and relaxed time-per-output-token (TPOT),\nwhile disaggregation excels for strict TPOT and relaxed TTFT. However, under\nbalanced TTFT and TPOT SLOs, neither approach delivers optimal goodput.\n  This paper proposes TaiChi, an LLM serving system that unifies PD\ndisaggregation and aggregation for optimal goodput under any combination of\nTTFT and TPOT SLOs. TaiChi uses a unified disaggregation-aggregation\narchitecture with differentiated-capability GPU instances: prefill-heavy (fast\nprefill, high-interference decode) and decode-heavy (low-interference decode,\nslow prefill). Three configurable sliders control the ratio between these\ninstances and their chunk sizes. TaiChi adapts to various SLO regimes by\nadjusting sliders. When TTFT constraints are tight, TaiChi resembles a PD\naggregation configuration; when TPOT dominates, it adapts toward PD\ndisaggregation. Crucially, under balanced SLOs, TaiChi enables a hybrid mode\nfor superior goodput. The key innovation behind this hybrid mode is latency\nshifting: selectively reallocating GPU resources from requests that meet SLOs\nto those at risk of violation, maximizing the number of SLO-satisfied requests.\nThis fine-grained latency shifting is orchestrated by two scheduling\nmechanisms: flowing decode scheduling to control TPOTs and length-aware prefill\nscheduling to manage TTFTs, which jointly optimize request assignment. Our\nexperiments show TaiChi improves goodput by up to 77% over state-of-the-art\nsystems under balanced TTFT and TPOT SLOs.", "AI": {"tldr": "TaiChi\u662f\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u670d\u52a1\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u9884\u586b\u5145-\u89e3\u7801\uff08PD\uff09\u7684\u805a\u5408\u4e0e\u89e3\u805a\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u673a\u5236\uff0c\u4f18\u5316\u4e0d\u540c\u670d\u52a1\u7ea7\u522b\u76ee\u6807\uff08SLOs\uff09\u4e0b\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u89e3\u51b3\u9884\u586b\u5145-\u89e3\u7801\uff08PD\uff09\u805a\u5408\u4e0e\u89e3\u805a\u5728LLM\u670d\u52a1\u4e2d\u5404\u81ea\u4f18\u52bf\u4f46\u65e0\u6cd5\u5728\u6240\u6709SLOs\u4e0b\u6700\u4f18\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faTaiChi\u7cfb\u7edf\uff0c\u91c7\u7528\u7edf\u4e00\u67b6\u6784\u548c\u53ef\u914d\u7f6e\u6ed1\u5757\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u5206\u914d\uff0c\u7ed3\u5408\u5ef6\u8fdf\u8f6c\u79fb\u548c\u8c03\u5ea6\u673a\u5236\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5728\u5e73\u8861\u7684TTFT\u548cTPOT SLOs\u4e0b\uff0cTaiChi\u6bd4\u73b0\u6709\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe77%\u3002", "conclusion": "TaiChi\u901a\u8fc7\u7075\u6d3b\u7684\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u673a\u5236\uff0c\u4e3aLLM\u670d\u52a1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.02536", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.02536", "abs": "https://arxiv.org/abs/2508.02536", "authors": ["Yuqi Xue", "Jian Huang"], "title": "ReGate: Enabling Power Gating in Neural Processing Units", "comment": "Accepted to MICRO'25", "summary": "The energy efficiency of neural processing units (NPU) is playing a critical\nrole in developing sustainable data centers. Our study with different\ngenerations of NPU chips reveals that 30%-72% of their energy consumption is\ncontributed by static power dissipation, due to the lack of power management\nsupport in modern NPU chips. In this paper, we present ReGate, which enables\nfine-grained power-gating of each hardware component in NPU chips with\nhardware/software co-design. Unlike conventional power-gating techniques for\ngeneric processors, enabling power-gating in NPUs faces unique challenges due\nto the fundamental difference in hardware architecture and program execution\nmodel. To address these challenges, we carefully investigate the power-gating\nopportunities in each component of NPU chips and decide the best-fit power\nmanagement scheme (i.e., hardware- vs. software-managed power gating).\nSpecifically, for systolic arrays (SAs) that have deterministic execution\npatterns, ReGate enables cycle-level power gating at the granularity of\nprocessing elements (PEs) following the inherent dataflow execution in SAs. For\ninter-chip interconnect (ICI) and HBM controllers that have long idle\nintervals, ReGate employs a lightweight hardware-based idle-detection\nmechanism. For vector units and SRAM whose idle periods vary significantly\ndepending on workload patterns, ReGate extends the NPU ISA and allows software\nlike compilers to manage the power gating. With implementation on a\nproduction-level NPU simulator, we show that ReGate can reduce the energy\nconsumption of NPU chips by up to 32.8% (15.5% on average), with negligible\nimpact on AI workload performance. The hardware implementation of power-gating\nlogic introduces less than 3.3% overhead in NPU chips.", "AI": {"tldr": "ReGate\u662f\u4e00\u79cd\u901a\u8fc7\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0NPU\u82af\u7247\u7ec6\u7c92\u5ea6\u7535\u6e90\u95e8\u63a7\u7684\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u73b0\u4ee3NPU\u82af\u7247\u7f3a\u4e4f\u7535\u6e90\u7ba1\u7406\u652f\u6301\uff0c\u5bfc\u81f430%-72%\u7684\u80fd\u8017\u6765\u81ea\u9759\u6001\u529f\u8017\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "ReGate\u9488\u5bf9NPU\u4e0d\u540c\u7ec4\u4ef6\uff08\u5982\u8109\u52a8\u9635\u5217\u3001\u4e92\u8fde\u63a7\u5236\u5668\u7b49\uff09\u8bbe\u8ba1\u5b9a\u5236\u5316\u7535\u6e90\u95e8\u63a7\u65b9\u6848\uff0c\u7ed3\u5408\u786c\u4ef6\u548c\u8f6f\u4ef6\u7ba1\u7406\u3002", "result": "ReGate\u5e73\u5747\u964d\u4f4e\u80fd\u801715.5%\uff08\u6700\u9ad832.8%\uff09\uff0c\u5bf9\u6027\u80fd\u5f71\u54cd\u53ef\u5ffd\u7565\uff0c\u786c\u4ef6\u5f00\u9500\u4f4e\u4e8e3.3%\u3002", "conclusion": "ReGate\u4e3aNPU\u82af\u7247\u63d0\u4f9b\u9ad8\u6548\u7535\u6e90\u7ba1\u7406\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u80fd\u6548\uff0c\u9002\u7528\u4e8e\u53ef\u6301\u7eed\u6570\u636e\u4e2d\u5fc3\u3002"}}
{"id": "2508.01996", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.01996", "abs": "https://arxiv.org/abs/2508.01996", "authors": ["Yizhou Shi", "Qianpiao Ma", "Yan Xu", "Junlong Zhou", "Ming Hu", "Yunming Liao", "Hongli Xu"], "title": "DySTop", "comment": null, "summary": "Federated Learning (FL) has emerged as a potential distributed learning\nparadigm that enables model training on edge devices (i.e., workers) while\npreserving data privacy. However, its reliance on a centralized server leads to\nlimited scalability. Decentralized federated learning (DFL) eliminates the\ndependency on a centralized server by enabling peer-to-peer model exchange.\nExisting DFL mechanisms mainly employ synchronous communication, which may\nresult in training inefficiencies under heterogeneous and dynamic edge\nenvironments. Although a few recent asynchronous DFL (ADFL) mechanisms have\nbeen proposed to address these issues, they typically yield stale model\naggregation and frequent model transmission, leading to degraded training\nperformance on non-IID data and high communication overhead. To overcome these\nissues, we present DySTop, an innovative mechanism that jointly optimizes\ndynamic staleness control and topology construction in ADFL. In each round,\nmultiple workers are activated, and a subset of their neighbors is selected to\ntransmit models for aggregation, followed by local training. We provide a\nrigorous convergence analysis for DySTop, theoretically revealing the\nquantitative relationships between the convergence bound and key factors such\nas maximum staleness, activating frequency, and data distribution among\nworkers. From the insights of the analysis, we propose a worker activation\nalgorithm (WAA) for staleness control and a phase-aware topology construction\nalgorithm (PTCA) to reduce communication overhead and handle data non-IID.\nExtensive evaluations through both large-scale simulations and real-world\ntestbed experiments demonstrate that our DySTop reduces completion time by\n51.8% and the communication resource consumption by 57.1% compared to\nstate-of-the-art solutions, while maintaining the same model accuracy.", "AI": {"tldr": "DySTop\u662f\u4e00\u79cd\u521b\u65b0\u7684\u5f02\u6b65\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u8fc7\u65f6\u63a7\u5236\u548c\u62d3\u6251\u7ed3\u6784\u4f18\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u901a\u4fe1\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u540c\u6b65\u901a\u4fe1\uff0c\u5728\u5f02\u6784\u548c\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e0b\u6548\u7387\u4f4e\u4e0b\uff0c\u4e14\u5f02\u6b65\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u8fc7\u65f6\u548c\u901a\u4fe1\u5f00\u9500\u5927\u7684\u95ee\u9898\u3002", "method": "DySTop\u7ed3\u5408\u52a8\u6001\u8fc7\u65f6\u63a7\u5236\u548c\u62d3\u6251\u7ed3\u6784\u4f18\u5316\uff0c\u6bcf\u8f6e\u6fc0\u6d3b\u591a\u4e2a\u5de5\u4eba\u5e76\u9009\u62e9\u90bb\u5c45\u8fdb\u884c\u6a21\u578b\u805a\u5408\u548c\u672c\u5730\u8bad\u7ec3\u3002", "result": "DySTop\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5c06\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1151.8%\uff0c\u901a\u4fe1\u8d44\u6e90\u6d88\u8017\u964d\u4f4e57.1%\u3002", "conclusion": "DySTop\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6b65\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6548\u7387\u548c\u901a\u4fe1\u95ee\u9898\u3002"}}
{"id": "2508.02202", "categories": ["cs.DC", "C.2.2; C.2.3; K.6.4"], "pdf": "https://arxiv.org/pdf/2508.02202", "abs": "https://arxiv.org/abs/2508.02202", "authors": ["Rui Eduardo Lopes", "Duarte Raposo", "Pedro V. Teixeira", "Susana Sargento"], "title": "Self-assessment approach for resource management protocols in heterogeneous computational systems", "comment": "13 pages, 12 figures, 6 tables", "summary": "With an ever growing number of heterogeneous applicational services running\non equally heterogeneous computational systems, the problem of resource\nmanagement becomes more essential. Although current solutions consider some\nnetwork and time requirements, they mostly handle a pre-defined list of\nresource types by design and, consequently, fail to provide an extensible\nsolution to assess any other set of requirements or to switch strategies on its\nresource estimation. This work proposes an heuristics-based estimation solution\nto support any computational system as a self-assessment, including\nconsiderations on dynamically weighting the requirements, how to compute each\nnode's capacity towards an admission request, and also offers the possibility\nto extend the list of resource types considered for assessment, which is an\nuncommon view in related works. This algorithm can be used by distributed and\ncentralized resource allocation protocols to decide the best node(s) for a\nservice intended for deployment. This approach was validated across its\ncomponents and the results show that its performance is straightforward in\nresource estimation while allowing scalability and extensibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u8d44\u6e90\u8bc4\u4f30\u65b9\u6cd5\uff0c\u652f\u6301\u52a8\u6001\u6743\u91cd\u548c\u8d44\u6e90\u7c7b\u578b\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u3002", "motivation": "\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\u65e5\u76ca\u91cd\u8981\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u52a8\u6001\u52a0\u6743\u9700\u6c42\uff0c\u8ba1\u7b97\u8282\u70b9\u5bb9\u91cf\uff0c\u5e76\u652f\u6301\u8d44\u6e90\u7c7b\u578b\u6269\u5c55\u3002", "result": "\u9a8c\u8bc1\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8d44\u6e90\u8bc4\u4f30\u4e2d\u8868\u73b0\u76f4\u63a5\uff0c\u652f\u6301\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u5206\u5e03\u5f0f\u548c\u96c6\u4e2d\u5f0f\u8d44\u6e90\u5206\u914d\u534f\u8bae\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8d44\u6e90\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.02230", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02230", "abs": "https://arxiv.org/abs/2508.02230", "authors": ["Yachao Yuan", "Zhen Yu", "Jin Wang", "Zhipeng Cheng", "Jianhua Hu"], "title": "FedAPTA: Federated Multi-task Learning in Computing Power Networks with Adaptive Layer-wise Pruning and Task-aware Aggregation", "comment": null, "summary": "Federated Learning (FL) has shown considerable promise in Computing Power\nNetworks (CPNs) for privacy protection, efficient data utilization, and dynamic\ncollaboration. Although it offers practical benefits, applying FL in CPNs\ncontinues to encounter a major obstacle, i.e., multi-task deployment. However,\nexisting work mainly focuses on mitigating FL's computation and communication\noverhead of a single task while overlooking the computing resource wastage\nissue of heterogeneous devices across multiple tasks in FL under CPNs. To\ntackle this, we design FedAPTA, a federated multi-task learning framework in\nCPNs. FedAPTA alleviates computing resource wastage through the developed\nlayer-wise model pruning technique, which reduces local model size while\nconsidering both data and device heterogeneity. To aggregate structurally\nheterogeneous local models of different tasks, we introduce a heterogeneous\nmodel recovery strategy and a task-aware model aggregation method that enables\nthe aggregation through infilling local model architecture with the shared\nglobal model and clustering local models according to their specific tasks. We\ndeploy FedAPTA on a realistic FL platform and benchmark it against nine SOTA FL\nmethods. The experimental outcomes demonstrate that the proposed FedAPTA\nconsiderably outperforms the state-of-the-art FL methods by up to 4.23%. Our\ncode is available at https://github.com/Zhenzovo/FedCPN.", "AI": {"tldr": "FedAPTA\u662f\u4e00\u4e2a\u9488\u5bf9\u8ba1\u7b97\u80fd\u529b\u7f51\u7edc\uff08CPNs\uff09\u4e2d\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u591a\u4efb\u52a1\u90e8\u7f72\u95ee\u9898\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u526a\u679d\u548c\u5f02\u6784\u6a21\u578b\u805a\u5408\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3FL\u5728CPNs\u4e2d\u591a\u4efb\u52a1\u90e8\u7f72\u65f6\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4efb\u52a1\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u5ffd\u7565\u4e86\u591a\u4efb\u52a1\u4e0b\u5f02\u6784\u8bbe\u5907\u7684\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u8bbe\u8ba1FedAPTA\u6846\u67b6\uff0c\u5305\u62ec\u5c42\u95f4\u6a21\u578b\u526a\u679d\u6280\u672f\u4ee5\u51cf\u5c11\u672c\u5730\u6a21\u578b\u5927\u5c0f\uff0c\u4ee5\u53ca\u5f02\u6784\u6a21\u578b\u6062\u590d\u7b56\u7565\u548c\u4efb\u52a1\u611f\u77e5\u7684\u6a21\u578b\u805a\u5408\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedAPTA\u5728\u6027\u80fd\u4e0a\u6bd4\u73b0\u6709FL\u65b9\u6cd5\u6700\u9ad8\u63d0\u53474.23%\u3002", "conclusion": "FedAPTA\u6709\u6548\u89e3\u51b3\u4e86FL\u5728CPNs\u4e2d\u591a\u4efb\u52a1\u90e8\u7f72\u7684\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.02309", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02309", "abs": "https://arxiv.org/abs/2508.02309", "authors": ["Yilong Zhao", "Mingyu Gao", "Huanchen Zhang", "Fangxin Liu", "Gongye Chen", "He Xian", "Haibing Guan", "Li Jiang"], "title": "PUSHtap: PIM-based In-Memory HTAP with Unified Data Storage Format", "comment": "Accepted by the 2025 International Conference on Architectural\n  Support for Programming Languages and Operating Systems (ASPLOS 2025) The\n  paper will be presented at ASPLOS 2026", "summary": "Hybrid transaction/analytical processing (HTAP) is an emerging database\nparadigm that supports both online transaction processing (OLTP) and online\nanalytical processing (OLAP) workloads. Computing-intensive OLTP operations,\ninvolving row-wise data manipulation, are suitable for row-store format. In\ncontrast, memory-intensive OLAP operations, which are column-centric, benefit\nfrom column-store format. This \\emph{data-format dilemma} prevents HTAP systems\nfrom concurrently achieving three design goals: performance isolation, data\nfreshness, and workload-specific optimization. Another background technology is\nProcessing-in-Memory (PIM), which integrates computing units (PIM units) inside\nDRAM memory devices to accelerate memory-intensive workloads, including OLAP.\n  Our key insight is to combine the interleaved CPU access and localized PIM\nunit access to provide two-dimensional access to address the data format\ncontradictions inherent in HTAP. First, we propose a unified data storage\nformat with novel data alignment and placement techniques to optimize the\neffective bandwidth of CPUs and PIM units and exploit the PIM's parallelism.\nSecond, we implement the multi-version concurrency control (MVCC) essential for\nsingle-instance HTAP. Third, we extend the commercial PIM architecture to\nsupport the OLAP operations and concurrent access from PIM and CPU. Experiments\nshow that PUSHtap can achieve 3.4\\texttimes{}/4.4\\texttimes{} OLAP/OLTP\nthroughput improvement compared to multi-instance PIM-based design.", "AI": {"tldr": "PUSHtap\u7ed3\u5408CPU\u548cPIM\u5355\u5143\u7684\u53cc\u7ef4\u8bbf\u95ee\uff0c\u89e3\u51b3\u4e86HTAP\u4e2d\u7684\u6570\u636e\u683c\u5f0f\u77db\u76fe\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u9694\u79bb\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\u3002", "motivation": "HTAP\u7cfb\u7edf\u4e2dOLTP\u548cOLAP\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6570\u636e\u683c\u5f0f\u77db\u76fe\u963b\u788d\u4e86\u6027\u80fd\u9694\u79bb\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\u7684\u540c\u65f6\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6570\u636e\u5b58\u50a8\u683c\u5f0f\uff0c\u4f18\u5316CPU\u548cPIM\u5355\u5143\u7684\u5e26\u5bbd\u5229\u7528\uff0c\u6269\u5c55PIM\u67b6\u6784\u652f\u6301OLAP\u64cd\u4f5c\u548c\u5e76\u53d1\u8bbf\u95ee\u3002", "result": "PUSHtap\u5728OLAP/OLTP\u541e\u5410\u91cf\u4e0a\u6bd4\u591a\u5b9e\u4f8bPIM\u8bbe\u8ba1\u63d0\u9ad8\u4e863.4\u500d/4.4\u500d\u3002", "conclusion": "PUSHtap\u901a\u8fc7\u7ed3\u5408CPU\u548cPIM\u7684\u53cc\u7ef4\u8bbf\u95ee\uff0c\u6709\u6548\u89e3\u51b3\u4e86HTAP\u4e2d\u7684\u6570\u636e\u683c\u5f0f\u77db\u76fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.02446", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02446", "abs": "https://arxiv.org/abs/2508.02446", "authors": ["Yichao Zhang", "Zexin Fu", "Tim Fischer", "Yinrong Li", "Marco Bertuletti", "Luca Benini"], "title": "TeraNoC: A Multi-Channel 32-bit Fine-Grained, Hybrid Mesh-Crossbar NoC for Efficient Scale-up of 1000+ Core Shared-L1-Memory Clusters", "comment": "8 pages, 9 figures. Proceeded by The 43rd IEEE International\n  Conference on Computer Design (ICCD 2025)", "summary": "A key challenge in on-chip interconnect design is to scale up bandwidth while\nmaintaining low latency and high area efficiency. 2D-meshes scale with low\nwiring area and congestion overhead; however, their end-to-end latency\nincreases with the number of hops, making them unsuitable for latency-sensitive\ncore-to-L1-memory access. On the other hand, crossbars offer low latency, but\ntheir routing complexity grows quadratically with the number of I/Os, requiring\nlarge physical routing resources and limiting area-efficient scalability. This\ntwo-sided interconnect bottleneck hinders the scale-up of many-core,\nlow-latency, tightly coupled shared-memory clusters, pushing designers toward\ninstantiating many smaller and loosely coupled clusters, at the cost of\nhardware and software overheads. We present TeraNoC, an open-source, hybrid\nmesh-crossbar on-chip interconnect that offers both scalability and low\nlatency, while maintaining very low routing overhead. The topology, built on\n32bit word-width multi-channel 2D-meshes and crossbars, enables the\narea-efficient scale-up of shared-memory clusters. A router remapper is\ndesigned to balance traffic load across interconnect channels. Using TeraNoC,\nwe build a cluster with 1024 single-stage, single-issue cores that share a\n4096-banked L1 memory, implemented in 12nm technology. The low interconnect\nstalls enable high compute utilization of up to 0.85 IPC in compute-intensive,\ndata-parallel key GenAI kernels. TeraNoC only consumes 7.6\\% of the total\ncluster power in kernels dominated by crossbar accesses, and 22.7\\% in kernels\nwith high 2D-mesh traffic. Compared to a hierarchical crossbar-only cluster,\nTeraNoC reduces die area by 37.8\\% and improves area efficiency (GFLOP/s/mm2)\nby up to 98.7\\%, while occupying only 10.9\\% of the logic area.", "AI": {"tldr": "TeraNoC\u662f\u4e00\u79cd\u6df7\u5408\u7f51\u72b6-\u4ea4\u53c9\u5f00\u5173\u7247\u4e0a\u4e92\u8fde\uff0c\u7ed3\u5408\u4e86\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u89e3\u51b3\u4e86\u591a\u6838\u5171\u4eab\u5185\u5b58\u96c6\u7fa4\u7684\u4e92\u8fde\u74f6\u9888\u3002", "motivation": "\u89e3\u51b3\u7247\u4e0a\u4e92\u8fde\u8bbe\u8ba1\u4e2d\u5e26\u5bbd\u6269\u5c55\u4e0e\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u9762\u79ef\u6548\u7387\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u907f\u514d\u56e0\u4e92\u8fde\u74f6\u9888\u5bfc\u81f4\u7684\u591a\u6838\u96c6\u7fa4\u89c4\u6a21\u53d7\u9650\u3002", "method": "\u91c7\u752832\u4f4d\u5b57\u5bbd\u591a\u901a\u90532D\u7f51\u72b6\u548c\u4ea4\u53c9\u5f00\u5173\u6df7\u5408\u62d3\u6251\uff0c\u8bbe\u8ba1\u8def\u7531\u5668\u91cd\u6620\u5c04\u5668\u4ee5\u5e73\u8861\u6d41\u91cf\u8d1f\u8f7d\u3002", "result": "\u572812nm\u5de5\u827a\u4e0b\u5b9e\u73b01024\u6838\u96c6\u7fa4\uff0cIPC\u8fbe0.85\uff0c\u529f\u8017\u5360\u6bd4\u4f4e\uff087.6%-22.7%\uff09\uff0c\u9762\u79ef\u6548\u7387\u63d0\u534798.7%\u3002", "conclusion": "TeraNoC\u5728\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u4f4e\u9762\u79ef\u5f00\u9500\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5171\u4eab\u5185\u5b58\u96c6\u7fa4\u8bbe\u8ba1\u3002"}}
{"id": "2508.02520", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02520", "abs": "https://arxiv.org/abs/2508.02520", "authors": ["Ao Xiao", "Bangzheng He", "Baoquan Zhang", "Baoxing Huai", "Bingji Wang", "Bo Wang", "Bo Xu", "Boyi Hou", "Chan Yang", "Changhong Liu", "Cheng Cui", "Chenyu Zhu", "Cong Feng", "Daohui Wang", "Dayun Lin", "Duo Zhao", "Fengshao Zou", "Fu Wang", "Gangqiang Zhang", "Gengyuan Dan", "Guanjie Chen", "Guodong Guan", "Guodong Yang", "Haifeng Li", "Haipei Zhu", "Hao Feng", "Hao Huang", "Hao Xu", "Hengrui Ma", "Hengtao Fan", "Hui Liu", "Jia Li", "Jiang Liu", "Jiang Xu", "Jie Meng", "Jinhan Xin", "Junhao Hu", "Juwei Chen", "Lan Yu", "Lanxin Miao", "Liang Liu", "Linan Jing", "Lu Zhou", "Meina Han", "Mingkun Deng", "Mingyu Deng", "Naitian Deng", "Nizhong Lin", "Peihan Zhao", "Peng Pan", "Pengfei Shen", "Ping Li", "Qi Zhang", "Qin Zhang", "Qingrong Xia", "Qingyi Zhang", "Qunchao Fu", "Ren Guo", "Ruimin Gao", "Shaochun Li", "Sheng Long", "Shentian Li", "Shining Wan", "Shuai Shen", "Shuangfu Zeng", "Shuming Jing", "Siqi Yang", "Song Zhang", "Tao Xu", "Tianlin Du", "Ting Chen", "Wanxu Wu", "Wei Jiang", "Weinan Tong", "Weiwei Chen", "Wen Peng", "Wenli Zhou", "Wenquan Yang", "Wenxin Liang", "Xiang Liu", "Xiaoli Zhou", "Xin Jin", "Xinyu Duan", "Xu Li", "Xu Zhang", "Xusheng Chen", "Yalong Shan", "Yang Gan", "Yao Lu", "Yi Deng", "Yi Zheng", "Yingfei Zheng", "Yiyun Zheng", "Yizhou Shan", "Yong Gao", "Yongqiang Yang", "Yuanjin Gong", "Yue Yu", "Yuetao Chen", "Yukun Zhu", "Yulong He", "Yusu Zhao", "Yuyan Wu", "Zenan Zhang", "Zhaojin Zhuo", "Zhaoyang Ji", "Zhefeng Wang", "Zheng Wang", "Zhenhua Yang", "Zhenli Sheng", "Zhibin Yu", "Zhigang Ji", "Zhihao Ren", "Zhipeng Bian", "Zhixia Liu", "Zhiyu Dong", "Zhonghua Li", "Zhou Yu", "Zhuoming Shen", "Zhuwei Peng", "Zi Ye", "Zihao Xiang", "Zimin Fu", "Zixuan Zhang"], "title": "xDeepServe: Model-as-a-Service on Huawei CloudMatrix384", "comment": null, "summary": "The rise of scaled-out LLMs and scaled-up SuperPods signals a new era in\nlarge-scale AI infrastructure. LLMs continue to scale out via MoE, as seen in\nrecent models like DeepSeek, Kimi, and Qwen. In parallel, AI hardware is\nscaling up, with Huawei's CloudMatrix384 SuperPod offering hundreds of GB/s\nhigh-speed interconnects. Running large MoE models on SuperPod-scale hardware\nbrings new challenges. It requires new execution models, scalable scheduling,\nefficient expert load balancing, and elimination of single points of failure.\nThis paper presents xDeepServe, Huawei Cloud's LLM serving system designed for\nSuperPod-scale infrastructure. At its core is Transformerless, a disaggregated\narchitecture that decomposes transformer models into modular units--attention,\nfeedforward, and MoE--executed independently on NPUs connected via high-speed\nfabric. We implement this design in two forms: disaggregated prefill-decode and\ndisaggregated MoE-attention. This fully disaggregated setup enables independent\nscaling of compute and memory without sacrificing performance. To support this\narchitecture, we propose XCCL, a communication library that leverages\nCloudMatrix384's global shared memory to implement efficient point-to-point and\nall-to-all primitives. We also extend our serving engine FlowServe with\nsystem-level techniques, enabling scalable inference across hundreds of NPUs.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86xDeepServe\uff0c\u534e\u4e3a\u4e91\u7684LLM\u670d\u52a1\u7cfb\u7edf\uff0c\u4e13\u4e3aSuperPod\u89c4\u6a21\u7684\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21MoE\u6a21\u578b\u8fd0\u884c\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740LLM\u901a\u8fc7MoE\u6269\u5c55\u548cAI\u786c\u4ef6\uff08\u5982SuperPod\uff09\u7684\u5347\u7ea7\uff0c\u8fd0\u884c\u5927\u89c4\u6a21MoE\u6a21\u578b\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u6267\u884c\u6a21\u578b\u548c\u9ad8\u6548\u8c03\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86Transformerless\u67b6\u6784\uff0c\u5c06Transformer\u6a21\u578b\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u5355\u5143\uff0c\u5e76\u8bbe\u8ba1\u4e86XCCL\u901a\u4fe1\u5e93\u548cFlowServe\u670d\u52a1\u5f15\u64ce\u3002", "result": "\u5b9e\u73b0\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u7684\u72ec\u7acb\u6269\u5c55\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u652f\u6301\u8de8\u6570\u767e\u4e2aNPU\u7684\u53ef\u6269\u5c55\u63a8\u7406\u3002", "conclusion": "xDeepServe\u4e3aSuperPod\u89c4\u6a21\u7684\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684LLM\u670d\u52a1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.02552", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02552", "abs": "https://arxiv.org/abs/2508.02552", "authors": ["Siamak Abdi", "Giuseppe Di Fatta", "Atta Badii", "Giancarlo Fortino"], "title": "Blockchain Epidemic Consensus for Large-Scale Networks", "comment": "2025 IEEE 7th International Conference on Blockchain Computing and\n  Applications (BCCA)", "summary": "Blockchain is a distributed ledger technology that has applications in many\ndomains such as cryptocurrency, smart contracts, supply chain management, and\nmany others. Distributed consensus is a fundamental component of blockchain\nsystems that enables secure, precise, and tamper-proof verification of data\nwithout relying on central authorities. Existing consensus protocols,\nnevertheless, suffer from drawbacks, some of which are related to scalability,\nresource consumption, and fault tolerance. We introduce Blockchain Epidemic\nConsensus Protocol (BECP), a novel fully decentralised consensus protocol for\nblockchain networks at a large scale. BECP follows epidemic communication\nprinciples, without fixed roles like validators or leaders, and achieves\nprobabilistic convergence, efficient message dissemination, and tolerance to\nmessage delays. We provide an extensive experimental comparison of BECP against\nclassic protocols like PAXOS, RAFT, and PBFT, and newer epidemic-based\nprotocols like Avalanche and Snowman. The findings indicate that BECP provides\ndesirable gains in throughput, consensus latency, and substantial\nmessage-passing efficiency compared to existing epidemic-based approaches,\nvalidating its usability as an effective and scalable approach for\nnext-generation blockchain systems.", "AI": {"tldr": "BECP\u662f\u4e00\u79cd\u65b0\u578b\u7684\u53bb\u4e2d\u5fc3\u5316\u533a\u5757\u94fe\u5171\u8bc6\u534f\u8bae\uff0c\u57fa\u4e8e\u6d41\u884c\u75c5\u4f20\u64ad\u539f\u7406\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u534f\u8bae\u5728\u53ef\u6269\u5c55\u6027\u3001\u8d44\u6e90\u6d88\u8017\u548c\u5bb9\u9519\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u5171\u8bc6\u534f\u8bae\u5728\u53ef\u6269\u5c55\u6027\u3001\u8d44\u6e90\u6d88\u8017\u548c\u5bb9\u9519\u6027\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "BECP\u91c7\u7528\u6d41\u884c\u75c5\u4f20\u64ad\u539f\u7406\uff0c\u65e0\u56fa\u5b9a\u89d2\u8272\uff08\u5982\u9a8c\u8bc1\u8005\u6216\u9886\u5bfc\u8005\uff09\uff0c\u5b9e\u73b0\u6982\u7387\u6536\u655b\u3001\u9ad8\u6548\u6d88\u606f\u4f20\u64ad\u548c\u5ef6\u8fdf\u5bb9\u5fcd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBECP\u5728\u541e\u5410\u91cf\u3001\u5171\u8bc6\u5ef6\u8fdf\u548c\u6d88\u606f\u4f20\u9012\u6548\u7387\u4e0a\u4f18\u4e8e\u7ecf\u5178\u534f\u8bae\uff08\u5982PAXOS\u3001RAFT\u3001PBFT\uff09\u548c\u5176\u4ed6\u6d41\u884c\u75c5\u534f\u8bae\uff08\u5982Avalanche\u3001Snowman\uff09\u3002", "conclusion": "BECP\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4e0b\u4e00\u4ee3\u533a\u5757\u94fe\u5171\u8bc6\u534f\u8bae\u3002"}}
{"id": "2508.02595", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.02595", "abs": "https://arxiv.org/abs/2508.02595", "authors": ["Siamak Abdi", "Giuseppe Di Fatta", "Atta Badii", "Giancarlo Fortino"], "title": "Fully Decentralised Consensus for Extreme-scale Blockchain", "comment": "IEEE Global Blockchain Conference (GBC) 2025", "summary": "Blockchain is a decentralised, immutable ledger technology that has been\nwidely adopted in many sectors for various applications such as\ncryptocurrencies, smart contracts and supply chain management. Distributed\nconsensus is a fundamental component of blockchain, which is required to ensure\ntrust, security, and integrity of the data stored and the transactions\nprocessed in the blockchain. Various consensus algorithms have been developed,\neach affected from certain issues such as node failures, high resource\nconsumption, collusion, etc. This work introduces a fully decentralised\nconsensus protocol, Blockchain Epidemic Consensus Protocol (BECP), suitable for\nvery large and extreme-scale blockchain systems. The proposed approach\nleverages the benefits of epidemic protocols, such as no reliance on a fixed\nset of validators or leaders, probabilistic guarantees of convergence,\nefficient use of network resources, and tolerance to node and network failures.\nA comparative experimental analysis has been carried out with traditional\nprotocols including PAXOS, RAFT, and Practical Byzantine Fault Tolerance\n(PBFT), as well as a relatively more recent protocol such as Avalanche, which\nis specifically designed for very large-scale systems. The results illustrate\nhow BECP outperforms them in terms of throughput, scalability and consensus\nlatency. BECP achieves an average of 1.196 times higher throughput in terms of\nconsensus on items and 4.775 times better average consensus latency.\nFurthermore, BECP significantly reduces the number of messages compared to\nAvalanche. These results demonstrate the effectiveness and efficiency of fully\ndecentralised consensus for blockchain technology based on epidemic protocols.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u884c\u75c5\u534f\u8bae\u7684\u5168\u53bb\u4e2d\u5fc3\u5316\u533a\u5757\u94fe\u5171\u8bc6\u534f\u8baeBECP\uff0c\u9002\u7528\u4e8e\u8d85\u5927\u89c4\u6a21\u7cfb\u7edf\uff0c\u5728\u541e\u5410\u91cf\u3001\u6269\u5c55\u6027\u548c\u5171\u8bc6\u5ef6\u8fdf\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u534f\u8bae\u3002", "motivation": "\u4f20\u7edf\u5171\u8bc6\u7b97\u6cd5\u5b58\u5728\u8282\u70b9\u6545\u969c\u3001\u9ad8\u8d44\u6e90\u6d88\u8017\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u6d41\u884c\u75c5\u534f\u8bae\u7684\u4f18\u52bf\uff0c\u63d0\u51faBECP\u534f\u8bae\uff0c\u4e0d\u4f9d\u8d56\u56fa\u5b9a\u9a8c\u8bc1\u8005\u96c6\uff0c\u5177\u6709\u6982\u7387\u6536\u655b\u6027\u548c\u7f51\u7edc\u8d44\u6e90\u9ad8\u6548\u5229\u7528\u3002", "result": "BECP\u5728\u541e\u5410\u91cf\u3001\u5171\u8bc6\u5ef6\u8fdf\u548c\u6d88\u606f\u6570\u91cf\u4e0a\u4f18\u4e8ePAXOS\u3001RAFT\u3001PBFT\u548cAvalanche\u534f\u8bae\u3002", "conclusion": "BECP\u8bc1\u660e\u4e86\u57fa\u4e8e\u6d41\u884c\u75c5\u534f\u8bae\u7684\u5168\u53bb\u4e2d\u5fc3\u5316\u5171\u8bc6\u5728\u533a\u5757\u94fe\u6280\u672f\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002"}}
