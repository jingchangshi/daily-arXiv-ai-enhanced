<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Remarks on Algebraic Reconstruction of Types and Effects](https://arxiv.org/abs/2601.15455)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 作者发现Jouvelot和Gifford 1991年开创性类型与效应重建算法中存在与高阶多态性相关的变量绑定bug，并重新审视了其类型系统和重建算法。


<details>
  <summary>Details</summary>
Motivation: 虽然Jouvelot和Gifford 1991年的论文《Algebraic Reconstruction of Types and Effects》被认为是类型与效应系统的里程碑工作，启发了大量后续研究，但原始算法处理高阶多态性时存在实现挑战。作者发现该算法中存在与变量绑定相关的微妙bug，需要重新审视和修正。

Method: 作者重新审视了Jouvelot和Gifford的类型系统和重建算法，识别并描述了与高阶多态性特征相关的变量绑定问题。通过分析原始算法在处理高阶多态性时的具体实现细节，发现了其中的bug。

Result: 发现了原始类型与效应重建算法中与变量绑定相关的微妙bug，特别是在处理高阶多态性特征时的问题。这些bug在后续研究中可能被忽略，因为后续工作通常不包含高阶多态性这一挑战性特征。

Conclusion: Jouvelot和Gifford的开创性工作虽然具有里程碑意义，但在处理高阶多态性时存在实现缺陷。作者的工作揭示了这些bug，为正确理解和实现类型与效应系统提供了重要修正。

Abstract: In their 1991 paper "Algebraic Reconstruction of Types and Effects," Pierre Jouvelot and David Gifford presented a type-and-effect reconstruction algorithm based on an algebraic structure of effects. Their work is considered a milestone in the development of type-and-effect systems, and has inspired numerous subsequent works in the area of static analysis. However, unlike the later research it spawned, the original algorithm considered a language with higher-rank polymorphism, a feature which is challenging to implement correctly. In this note, we identify subtle bugs related to variable binding in their approach to this feature. We revisit their type system and reconstruction algorithm, and describe the discovered issues.

</details>


### [2] [Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking](https://arxiv.org/abs/2601.16008)
*Federico Bruzzone,Walter Cazzola,Luca Favini*

Main category: cs.PL

TL;DR: 提出首个基于编译器的Rust配置优先级排序方法，通过图分析和中心性度量生成有限数量的相关配置，解决配置空间组合爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 现代编程语言（特别是Rust）通过特性聚合构建高度可配置软件系统，但配置的组合爆炸使得程序分析、优化和测试的穷举探索不可行，需要有效的配置优先级排序方法。

Method: 1. 从Rust编译器提取定制中间表示；2. 构建两个互补的图数据结构；3. 使用中心性度量对特性排序；4. 根据特性影响的代码范围细化排序。使用SAT求解器保证生成配置的有效性，实现原型RustyEx。

Result: RustyEx能在有限资源内高效生成用户指定的配置集，同时通过构造保证正确性。中心性引导的配置优先级排序实现了大型配置空间的有效实用探索。

Conclusion: 该方法为配置感知分析和优化开辟了新途径，证明了基于编译器的配置优先级排序在实践中的可行性和有效性。

Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform](https://arxiv.org/abs/2601.15528)
*Jiazhu Xie,Bowen Li,Heyu Fu,Chong Gao,Ziqi Xu,Fengling Han*

Main category: cs.DC

TL;DR: 本文介绍了一个开源多租户平台，帮助小企业通过无代码工作流部署定制化的LLM支持聊天机器人，解决了基础设施成本、工程复杂性和安全风险等部署挑战。


<details>
  <summary>Details</summary>
Motivation: LLM问答系统为小企业自动化客户支持和内部知识访问提供了巨大潜力，但实际部署面临基础设施成本高、工程复杂度大和安全风险（特别是在RAG场景下）等挑战，阻碍了小企业的实际应用。

Method: 开发了一个基于分布式轻量级k3s集群的开源多租户平台，跨异构低成本机器构建，通过加密覆盖网络连接，实现成本效益的资源池化，同时提供容器隔离和租户数据访问控制。平台还集成了针对RAG聊天机器人提示注入攻击的平台级防御机制。

Result: 通过真实电子商务部署评估，证明该平台能够在满足小企业现实成本、运营和安全约束的条件下，实现安全高效的LLM聊天机器人服务。

Conclusion: 该平台为小企业提供了可行的解决方案，使它们能够在现实约束下部署安全、高效的定制化LLM支持聊天机器人，将最新的提示注入研究成果转化为可部署的安全机制。

Abstract: Large Language Model (LLM)-based question-answering systems offer significant potential for automating customer support and internal knowledge access in small businesses, yet their practical deployment remains challenging due to infrastructure costs, engineering complexity, and security risks, particularly in retrieval-augmented generation (RAG)-based settings. This paper presents an industry case study of an open-source, multi-tenant platform that enables small businesses to deploy customised LLM-based support chatbots via a no-code workflow. The platform is built on distributed, lightweight k3s clusters spanning heterogeneous, low-cost machines and interconnected through an encrypted overlay network, enabling cost-efficient resource pooling while enforcing container-based isolation and per-tenant data access controls. In addition, the platform integrates practical, platform-level defences against prompt injection attacks in RAG-based chatbots, translating insights from recent prompt injection research into deployable security mechanisms without requiring model retraining or enterprise-scale infrastructure. We evaluate the proposed platform through a real-world e-commerce deployment, demonstrating that secure and efficient LLM-based chatbot services can be achieved under realistic cost, operational, and security constraints faced by small businesses.

</details>


### [4] [Advancing RT Core-Accelerated Fixed-Radius Nearest Neighbor Search](https://arxiv.org/abs/2601.15633)
*Enzo Meneses,Hugo Bec,Cristóbal A. Navarroa,Benoît Crespin,Felipe A. Quezada,Nancy Hitschfeld,Heinich Porro,Maxime Maria*

Main category: cs.DC

TL;DR: 本文提出三种改进RT Core粒子FRNN物理模拟的方法：BVH更新/重建比例优化器、无需邻居列表的RT Core新用法、支持周期性边界条件的RT Core技术，显著提升性能和能效。


<details>
  <summary>Details</summary>
Motivation: RT Core在粒子FRNN物理模拟中已有应用，但仍有优化空间。现有方法在BVH管理、邻居列表内存消耗、周期性边界条件支持等方面存在不足，需要进一步改进以提升性能和能效。

Method: 1) 实时BVH更新/重建比例优化器，根据模拟动态自适应调整；2) 两种无需邻居列表的RT Core变体；3) 支持周期性边界条件的RT Core技术。以Lennard-Jones FRNN相互作用模型为案例研究。

Result: BVH优化器使RT Core流水线比其他方法快约3.4倍；新变体在小半径时提升约1.3倍，对数正态半径分布时提升约2.0倍；支持周期性边界条件无显著性能损失；方法在不同GPU代际上均能扩展性能和能效。

Conclusion: 提出的三种方法显著提升了RT Core在FRNN物理模拟中的性能和能效，解决了邻居列表内存限制问题，支持周期性边界条件，同时明确了RT Core与传统GPU计算的适用场景边界。

Abstract: In this work we introduce three ideas that can further improve particle FRNN physics simulations running on RT Cores; i) a real-time update/rebuild ratio optimizer for the bounding volume hierarchy (BVH) structure, ii) a new RT core use, with two variants, that eliminates the need of a neighbor list and iii) a technique that enables RT cores for FRNN with periodic boundary conditions (BC). Experimental evaluation using the Lennard-Jones FRNN interaction model as a case study shows that the proposed update/rebuild ratio optimizer is capable of adapting to the different dynamics that emerge during a simulation, leading to a RT core pipeline up to $\sim 3.4\times$ faster than with other known approaches to manage the BVH. In terms of simulation step performance, the proposed variants can significantly improve the speedup and EE of the base RT core idea; from $\sim1.3\times$ at small radius to $\sim2.0\times$ for log normal radius distributions. Furthermore, the proposed variants manage to simulate cases that would otherwise not fit in memory because of the use of neighbor lists, such as clusters of particles with log normal radius distribution. The proposed RT Core technique to support periodic BC is indeed effective as it does not introduce any significant penalty in performance. In terms of scaling, the proposed methods scale both their performance and EE across GPU generations. Throughout the experimental evaluation, we also identify the simulation cases were regular GPU computation should still be preferred, contributing to the understanding of the strengths and limitations of RT cores.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [5] [FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design](https://arxiv.org/abs/2601.15710)
*Jiahao Zhang,Zifan He,Nicholas Fraser,Michaela Blott,Yizhou Sun,Jason Cong*

Main category: cs.AR

TL;DR: FlexLLM是一个可组合的HLS库，用于快速开发专用LLM加速器，支持阶段定制推理和量化部署，在FPGA上实现优于GPU的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理加速器开发复杂且耗时，需要简化专用加速器的开发流程，同时支持算法创新与高性能硬件实现的无缝集成。

Method: 提供可组合的HLS库，暴露架构自由度以支持阶段定制推理（prefill和decode采用不同数据流），包含全面的量化套件，并开发了Hierarchical Memory Transformer插件用于长上下文处理。

Result: 在AMD U280 FPGA上，相比NVIDIA A100 GPU，实现1.29倍端到端加速、1.64倍解码吞吐量和3.14倍能效提升；集成HMT插件后，在长上下文场景中减少23.23倍预填充延迟，扩展64倍上下文窗口。

Conclusion: FlexLLM能够以最小的人工工作量桥接LLM推理算法创新与高性能加速器开发，显著降低专用加速器的开发门槛和时间成本。

Abstract: We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\times$ end-to-end speedup, 1.64$\times$ higher decode throughput, and 3.14$\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\times$, 6.55$\times$, and 4.13$\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\times$ and extends the context window by 64$\times$, delivering 1.10$\times$/4.86$\times$ lower end-to-end latency and 5.21$\times$/6.27$\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.

</details>


### [6] [A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware](https://arxiv.org/abs/2601.16118)
*Marco Ronzani,Cristina Silvano*

Main category: cs.AR

TL;DR: 该论文提出将脉冲神经网络(SNN)从图模型提升到超图模型，以更好地映射到神经形态硬件上，通过利用超边的重叠和局部性特性来减少通信流量和硬件资源使用。


<details>
  <summary>Details</summary>
Motivation: 将SNN映射到神经形态硬件上面临两个NP-hard问题：图分区和分区放置。随着SNN和硬件规模扩展到数十亿神经元，现有基于图的方法难以有效处理，需要更高层次的抽象来捕捉核心内脉冲复制的特性。

Method: 将SNN从图模型提升到超图模型，利用超边共成员关系捕捉神经元之间的连接模式。基于超边的重叠和局部性特性设计新的分区和放置算法，包括新设计的算法和文献中改编的算法。

Result: 超图方法在不同执行时间范围内都能获得比现有技术更好的映射结果，能够显著减少通信流量和硬件资源使用，超越了仅压缩单个连接所能达到的效果。

Conclusion: 超图模型能够更准确地捕捉SNN在神经形态硬件上的执行特性，基于超边重叠和局部性的算法在不同规模下都能实现有效的映射，为大规模SNN映射提供了有前景的解决方案。

Abstract: Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.

</details>
