{"id": "2507.02124", "categories": ["cs.DC", "cs.NI", "C.5.5; B.8.2"], "pdf": "https://arxiv.org/pdf/2507.02124", "abs": "https://arxiv.org/abs/2507.02124", "authors": ["Fumikazu Konishi"], "title": "SAKURAONE: Empowering Transparent and Open AI Platforms through Private-Sector HPC Investment in Japan", "comment": "13 pages, 2 Figures, 10 tables", "summary": "SAKURAONE is a managed high performance computing (HPC) cluster developed and\noperated by the SAKURA Internet Research Center. It reinforces the ``KOKARYOKU\nPHY'' configuration of bare-metal GPU servers and is designed as a cluster\ncomputing resource optimized for advanced workloads, including large language\nmodel (LLM) training.\n  In the ISC 2025 edition of the TOP500 list, SAKURAONE was ranked\n\\textbf{49th} in the world based on its High Performance Linpack (HPL) score,\ndemonstrating its global competitiveness. In particular, it is the \\textbf{only\nsystem within the top 100} that employs a fully open networking stack based on\n\\textbf{800~GbE (Gigabit Ethernet)} and the \\textbf{SONiC (Software for Open\nNetworking in the Cloud)} operating system, highlighting the viability of open\nand vendor-neutral technologies in large-scale HPC infrastructure.\n  SAKURAONE achieved a sustained performance of 33.95~PFLOP/s on the HPL\nbenchmark (Rmax), and 396.295~TFLOP/s on the High Performance Conjugate\nGradient (HPCG) benchmark. For the HPL-MxP benchmark, which targets\nlow-precision workloads representative of AI applications, SAKURAONE delivered\nan impressive 339.86~PFLOP/s using FP8 precision.\n  The system comprises 100 compute nodes, each equipped with eight NVIDIA H100\nGPUs. It is supported by an all-flash Lustre storage subsystem with a total\nphysical capacity of 2~petabytes, providing high-throughput and low-latency\ndata access. Internode communication is enabled by a full-bisection bandwidth\ninterconnect based on a Rail-Optimized topology, where the Leaf and Spine\nlayers are interconnected via 800~GbE links. This topology, in combination with\nRoCEv2 (RDMA over Converged Ethernet version 2), enables high-speed, lossless\ndata transfers and mitigates communication bottlenecks in large-scale parallel\nworkloads.", "AI": {"tldr": "SAKURAONE\u662f\u4e00\u4e2a\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\uff0c\u91c7\u7528\u5f00\u653e\u7f51\u7edc\u6280\u672f\uff0c\u5728\u5168\u7403TOP500\u4e2d\u6392\u540d49\uff0c\u5c55\u793a\u4e86\u5176\u5728AI\u548c\u5927\u89c4\u6a21HPC\u4efb\u52a1\u4e2d\u7684\u7ade\u4e89\u529b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8e\u5f00\u653e\u548c\u4f9b\u5e94\u5546\u4e2d\u7acb\u6280\u672f\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\uff0c\u4ee5\u652f\u6301\u5148\u8fdb\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5982\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u91c7\u7528800 GbE\u548cSONiC\u64cd\u4f5c\u7cfb\u7edf\u6784\u5efa\u5f00\u653e\u7f51\u7edc\u5806\u6808\uff0c\u7ed3\u5408NVIDIA H100 GPU\u548c\u5168\u95ea\u5b58\u5b58\u50a8\u5b50\u7cfb\u7edf\u3002", "result": "\u5728HPL\u3001HPCG\u548cHPL-MxP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u522b\u8fbe\u523033.95 PFLOP/s\u3001396.295 TFLOP/s\u548c339.86 PFLOP/s\u3002", "conclusion": "SAKURAONE\u8bc1\u660e\u4e86\u5f00\u653e\u7f51\u7edc\u6280\u672f\u5728\u5927\u89c4\u6a21HPC\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u9ad8\u6027\u80fd\u8ba1\u7b97\u548cAI\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.02158", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.02158", "abs": "https://arxiv.org/abs/2507.02158", "authors": ["Jacob Roberts", "Blair Archibald", "Phil Trinder"], "title": "Signalling Health for Improved Kubernetes Microservice Availability", "comment": "10 pages, 7 figures", "summary": "Microservices are often deployed and managed by a container orchestrator that\ncan detect and fix failures to maintain the service availability critical in\nmany applications. In Poll-based Container Monitoring (PCM), the orchestrator\nperiodically checks container health. While a common approach, PCM requires\ncareful tuning, may degrade service availability, and can be slow to detect\ncontainer health changes. An alternative is Signal-based Container Monitoring\n(SCM), where the container signals the orchestrator when its status changes. We\npresent the design, implementation, and evaluation of an SCM approach for\nKubernetes and empirically show that it has benefits over PCM, as predicted by\na new mathematical model. We compare the service availability of SCM and PCM\nover six experiments using the SockShop benchmark. SCM does not require that\npolling intervals are tuned, and yet detects container failure 86\\% faster than\nPCM and container readiness in a comparable time with limited resource\noverheads. We find PCM can erroneously detect failures, and this reduces\nservice availability by 4\\%. We propose that orchestrators offer SCM features\nfor faster failure detection than PCM without erroneous detections or careful\ntuning.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u57fa\u4e8e\u8f6e\u8be2\uff08PCM\uff09\u548c\u57fa\u4e8e\u4fe1\u53f7\uff08SCM\uff09\u7684\u5bb9\u5668\u76d1\u63a7\u65b9\u6cd5\uff0c\u53d1\u73b0SCM\u5728Kubernetes\u4e2d\u68c0\u6d4b\u5bb9\u5668\u6545\u969c\u66f4\u5feb\u4e14\u65e0\u9700\u8c03\u4f18\uff0c\u63d0\u5347\u4e86\u670d\u52a1\u53ef\u7528\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3PCM\u65b9\u6cd5\u5728\u5bb9\u5668\u76d1\u63a7\u4e2d\u5b58\u5728\u7684\u8c03\u4f18\u56f0\u96be\u3001\u670d\u52a1\u53ef\u7528\u6027\u964d\u4f4e\u548c\u6545\u969c\u68c0\u6d4b\u6162\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u4fe1\u53f7\u7684\u5bb9\u5668\u76d1\u63a7\uff08SCM\uff09\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u548c\u5b9e\u9a8c\uff08\u4f7f\u7528SockShop\u57fa\u51c6\uff09\u4e0ePCM\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "SCM\u6bd4PCM\u68c0\u6d4b\u5bb9\u5668\u6545\u969c\u5feb86%\uff0c\u4e14\u65e0\u9700\u8c03\u4f18\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9519\u8bef\u68c0\u6d4b\uff0c\u63d0\u5347\u4e86\u670d\u52a1\u53ef\u7528\u60274%\u3002", "conclusion": "\u5efa\u8bae\u5bb9\u5668\u7f16\u6392\u5668\u652f\u6301SCM\u529f\u80fd\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u6545\u969c\u68c0\u6d4b\uff0c\u65e0\u9700\u590d\u6742\u8c03\u4f18\u3002"}}
{"id": "2507.02233", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.02233", "abs": "https://arxiv.org/abs/2507.02233", "authors": ["Bruce Fang", "Danyi Gao"], "title": "Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems", "comment": null, "summary": "This paper addresses the challenge of fault root cause identification in\ncloud computing environments. The difficulty arises from complex system\nstructures, dense service coupling, and limited fault information. To solve\nthis problem, an intelligent identification algorithm based on transfer\nlearning is proposed. The method introduces a shared feature extraction module\nand a domain adversarial mechanism to enable effective knowledge transfer from\nthe source domain to the target domain. This improves the model's\ndiscriminative ability and generalization performance in the target domain. The\nmodel incorporates a pseudo-label selection strategy. When labeled samples are\nlacking in the target domain, high-confidence predictions are used in training.\nThis enhances the model's ability to recognize minority classes. To evaluate\nthe stability and adaptability of the method in real-world scenarios,\nexperiments are designed under three conditions: label scarcity, class\nimbalance, and heterogeneous node environments. Experimental results show that\nthe proposed method outperforms existing mainstream approaches in several key\nmetrics, including accuracy, F1-Score, and AUC. The model demonstrates stronger\ndiscriminative power and robustness. Notably, under extreme class imbalance and\nsignificant structural differences in the target domain, the model still\nmaintains high performance. This validates the effectiveness and practical\nvalue of the proposed mechanisms in complex cloud computing systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u7684\u667a\u80fd\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e91\u8ba1\u7b97\u73af\u5883\u4e2d\u6545\u969c\u6839\u56e0\u8bc6\u522b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5171\u4eab\u7279\u5f81\u63d0\u53d6\u548c\u57df\u5bf9\u6297\u673a\u5236\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e91\u8ba1\u7b97\u73af\u5883\u4e2d\u6545\u969c\u6839\u56e0\u8bc6\u522b\u56e0\u7cfb\u7edf\u590d\u6742\u3001\u670d\u52a1\u8026\u5408\u5ea6\u9ad8\u548c\u6545\u969c\u4fe1\u606f\u6709\u9650\u800c\u56f0\u96be\u3002", "method": "\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5f15\u5165\u5171\u4eab\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u548c\u57df\u5bf9\u6297\u673a\u5236\uff0c\u7ed3\u5408\u4f2a\u6807\u7b7e\u9009\u62e9\u7b56\u7565\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001F1-Score\u548cAUC\u7b49\u5173\u952e\u6307\u6807\u4e0a\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u76ee\u6807\u57df\u7ed3\u6784\u5dee\u5f02\u5927\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u6240\u63d0\u673a\u5236\u5728\u590d\u6742\u4e91\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.02295", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.02295", "abs": "https://arxiv.org/abs/2507.02295", "authors": ["Roopkatha Banerjee", "Prince Modi", "Jinal Vyas", "Chunduru Sri Abhijit", "Tejus Chandrashekar", "Harsha Varun Marisetty", "Manik Gupta", "Yogesh Simmhan"], "title": "Flotilla: A scalable, modular and resilient federated learning framework for heterogeneous resources", "comment": null, "summary": "With the recent improvements in mobile and edge computing and rising concerns\nof data privacy, Federated Learning(FL) has rapidly gained popularity as a\nprivacy-preserving, distributed machine learning methodology. Several FL\nframeworks have been built for testing novel FL strategies. However, most focus\non validating the learning aspects of FL through pseudo-distributed simulation\nbut not for deploying on real edge hardware in a distributed manner to\nmeaningfully evaluate the federated aspects from a systems perspective. Current\nframeworks are also inherently not designed to support asynchronous\naggregation, which is gaining popularity, and have limited resilience to client\nand server failures. We introduce Flotilla, a scalable and lightweight FL\nframework. It adopts a ``user-first'' modular design to help rapidly compose\nvarious synchronous and asynchronous FL strategies while being agnostic to the\nDNN architecture. It uses stateless clients and a server design that separates\nout the session state, which are periodically or incrementally checkpointed. We\ndemonstrate the modularity of Flotilla by evaluating five different FL\nstrategies for training five DNN models. We also evaluate the client and\nserver-side fault tolerance on 200+ clients, and showcase its ability to\nrapidly failover within seconds. Finally, we show that Flotilla's resource\nusage on Raspberry Pis and Nvidia Jetson edge accelerators are comparable to or\nbetter than three state-of-the-art FL frameworks, Flower, OpenFL and FedML. It\nalso scales significantly better compared to Flower for 1000+ clients. This\npositions Flotilla as a competitive candidate to build novel FL strategies on,\ncompare them uniformly, rapidly deploy them, and perform systems research and\noptimizations.", "AI": {"tldr": "Flotilla\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u6269\u5c55\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u652f\u6301\u540c\u6b65\u548c\u5f02\u6b65\u7b56\u7565\uff0c\u5177\u5907\u5bb9\u9519\u80fd\u529b\uff0c\u5e76\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u53d1\u5c55\u53ca\u6570\u636e\u9690\u79c1\u95ee\u9898\u7684\u5173\u6ce8\uff0c\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4f5c\u4e3a\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53d7\u5230\u6b22\u8fce\u3002\u7136\u800c\uff0c\u73b0\u6709\u6846\u67b6\u591a\u7528\u4e8e\u4f2a\u5206\u5e03\u5f0f\u6a21\u62df\uff0c\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u8fb9\u7f18\u786c\u4ef6\u7684\u652f\u6301\uff0c\u4e14\u4e0d\u652f\u6301\u5f02\u6b65\u805a\u5408\u548c\u5bb9\u9519\u3002", "method": "Flotilla\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u652f\u6301\u591a\u79cd\u540c\u6b65\u548c\u5f02\u6b65FL\u7b56\u7565\uff0c\u72ec\u7acb\u4e8eDNN\u67b6\u6784\uff0c\u4f7f\u7528\u65e0\u72b6\u6001\u5ba2\u6237\u7aef\u548c\u5206\u79bb\u4f1a\u8bdd\u72b6\u6001\u7684\u670d\u52a1\u5668\u8bbe\u8ba1\uff0c\u5e76\u5177\u5907\u5bb9\u9519\u80fd\u529b\u3002", "result": "Flotilla\u5728200+\u5ba2\u6237\u7aef\u4e0a\u5c55\u793a\u4e86\u5bb9\u9519\u80fd\u529b\uff0c\u5e76\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8d44\u6e90\u4f7f\u7528\u4f18\u4e8e\u6216\u5ab2\u7f8e\u73b0\u6709\u6846\u67b6\uff08Flower\u3001OpenFL\u3001FedML\uff09\uff0c\u4e14\u80fd\u6269\u5c55\u52301000+\u5ba2\u6237\u7aef\u3002", "conclusion": "Flotilla\u662f\u4e00\u4e2a\u9ad8\u6548\u7684FL\u6846\u67b6\uff0c\u9002\u5408\u6784\u5efa\u65b0\u7b56\u7565\u3001\u5feb\u901f\u90e8\u7f72\u53ca\u7cfb\u7edf\u4f18\u5316\u7814\u7a76\u3002"}}
{"id": "2507.02067", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.02067", "abs": "https://arxiv.org/abs/2507.02067", "authors": ["Nikolaos Papanikolaou", "Doha Touhafi", "Jurgen Vandendriessche", "Danial Karimi", "Sohail Fatimi", "Gianluca Cornetta", "Abdellah Touhafi"], "title": "Advanced Printed Sensors for Environmental Applications: A Path Towards Sustainable Monitoring Solutions", "comment": null, "summary": "Printed sensors represent a transformative advancement in sensor technology,\nutilizing innovative printing techniques to create flexible, cost-effective,\nand highly customizable sensing devices. Their versatility allows integration\ninto numerous applications across diverse fields such as monitoring a wide\nrange of environmental factors e.g. air and water quality, soil conditions, and\natmospheric changes among others. These sensors demonstrate high sensitivity\nand accuracy in detecting pollutants, temperature variations, humidity levels,\nand other critical parameters essential for environmental assessment and\nprotection.", "AI": {"tldr": "\u5370\u5237\u4f20\u611f\u5668\u901a\u8fc7\u521b\u65b0\u5370\u5237\u6280\u672f\u5b9e\u73b0\u7075\u6d3b\u3001\u4f4e\u6210\u672c\u3001\u9ad8\u5ea6\u53ef\u5b9a\u5236\u7684\u4f20\u611f\u8bbe\u5907\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73af\u5883\u76d1\u6d4b\u7b49\u9886\u57df\u3002", "motivation": "\u63a8\u52a8\u4f20\u611f\u5668\u6280\u672f\u7684\u9769\u65b0\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u6ee1\u8db3\u591a\u6837\u5316\u7684\u73af\u5883\u76d1\u6d4b\u9700\u6c42\u3002", "method": "\u91c7\u7528\u521b\u65b0\u7684\u5370\u5237\u6280\u672f\u5236\u9020\u4f20\u611f\u5668\uff0c\u4f7f\u5176\u5177\u5907\u9ad8\u7075\u654f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "result": "\u4f20\u611f\u5668\u80fd\u591f\u9ad8\u6548\u68c0\u6d4b\u6c61\u67d3\u7269\u3001\u6e29\u6e7f\u5ea6\u53d8\u5316\u7b49\u5173\u952e\u73af\u5883\u53c2\u6570\u3002", "conclusion": "\u5370\u5237\u4f20\u611f\u5668\u5728\u73af\u5883\u76d1\u6d4b\u548c\u4fdd\u62a4\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u662f\u672a\u6765\u4f20\u611f\u5668\u6280\u672f\u7684\u91cd\u8981\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2507.02226", "categories": ["cs.PL", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02226", "abs": "https://arxiv.org/abs/2507.02226", "authors": ["Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "comment": "Accepted to the International Conference on Computer-Aided Design\n  (ICCAD 2025)", "summary": "As one of their many applications, large language models (LLMs) have recently\nshown promise in automating register transfer level (RTL) code generation.\nHowever, conventional LLM decoding strategies, originally designed for natural\nlanguage, often fail to meet the structural and semantic demands of RTL,\nleading to hallucinated, repetitive, or invalid code outputs. In this paper, we\nfirst investigate the root causes of these decoding failures through an\nempirical analysis of token-level entropy during RTL generation. Our findings\nreveal that LLMs exhibit low confidence in regions of structural ambiguity or\nsemantic complexity, showing that standard decoding strategies fail to\ndifferentiate between regions requiring determinism (syntax-critical regions)\nand those that benefit from creative exploratory variability (design-critical\nregions). Then, to overcome this, we introduce DecoRTL, a novel run-time\ndecoding strategy, that is both syntax-aware and contrastive for RTL code\ngeneration. DecoRTL integrates two complementary components: (i)\nself-consistency sampling, which generates multiple candidates and re-ranks\nthem based on token-level agreement to promote correctness while maintaining\ndiversity; and (ii) syntax-aware temperature adaptation, which classifies\ntokens by their syntactical and functional roles and adjusts the sampling\ntemperature accordingly, enforcing low temperature for syntax-critical tokens\nand higher temperature for exploratory ones. Our approach operates entirely at\ninference time without requiring any additional model fine-tuning. Through\nevaluations on multiple open-source LLMs using the VerilogEval benchmark, we\ndemonstrate significant improvements in syntactic validity, functional\ncorrectness, and output diversity, while the execution overhead (performance\noverhead) is imperceptible.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDecoRTL\u7684\u65b0\u89e3\u7801\u7b56\u7565\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728RTL\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u89e3\u7801\u7b56\u7565\u5728\u7ed3\u6784\u548c\u8bed\u4e49\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edfLLM\u89e3\u7801\u7b56\u7565\u5728RTL\u4ee3\u7801\u751f\u6210\u4e2d\u5e38\u5bfc\u81f4\u65e0\u6548\u6216\u91cd\u590d\u7684\u8f93\u51fa\uff0c\u65e0\u6cd5\u533a\u5206\u8bed\u6cd5\u5173\u952e\u533a\u57df\u548c\u8bbe\u8ba1\u5173\u952e\u533a\u57df\u7684\u9700\u6c42\u3002", "method": "DecoRTL\u7ed3\u5408\u4e86\u81ea\u4e00\u81f4\u6027\u91c7\u6837\u548c\u8bed\u6cd5\u611f\u77e5\u6e29\u5ea6\u8c03\u6574\uff0c\u524d\u8005\u901a\u8fc7\u591a\u5019\u9009\u751f\u6210\u548c\u91cd\u6392\u5e8f\u63d0\u5347\u6b63\u786e\u6027\uff0c\u540e\u8005\u6839\u636e\u8bed\u6cd5\u89d2\u8272\u8c03\u6574\u91c7\u6837\u6e29\u5ea6\u3002", "result": "\u5728VerilogEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDecoRTL\u663e\u8457\u63d0\u5347\u4e86\u8bed\u6cd5\u6709\u6548\u6027\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u8f93\u51fa\u591a\u6837\u6027\uff0c\u4e14\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "DecoRTL\u65e0\u9700\u989d\u5916\u5fae\u8c03\u5373\u53ef\u5728\u63a8\u7406\u65f6\u663e\u8457\u6539\u5584RTL\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2507.02404", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.02404", "abs": "https://arxiv.org/abs/2507.02404", "authors": ["Maxime Martinasso", "Mark Klein", "Thomas C. Schulthess"], "title": "Alps, a versatile research infrastructure", "comment": "10 pages, 6 figures, Cray User Group(CUG) 2025 Best Paper Award", "summary": "The Swiss National Supercomputing Centre (CSCS) has a long-standing tradition\nof delivering top-tier high-performance computing systems, exemplified by the\nPiz Daint supercomputer. However, the increasing diversity of scientific needs\nhas exposed limitations in traditional vertically integrated HPC architectures,\nwhich often lack flexibility and composability. To address these challenges,\nCSCS developed Alps, a next-generation HPC infrastructure designed with a\ntransformative principle: resources operate as independent endpoints within a\nhigh-speed network. This architecture enables the creation of independent\ntenant-specific and platform-specific services, tailored to diverse scientific\nrequirements.\n  Alps incorporates heterogeneous hardware, including CPUs and GPUs,\ninterconnected by a high-performance Slingshot network, and offers a modular\nstorage system. A key innovation is the versatile software-defined cluster\n(vCluster) technology, which bridges cloud and HPC paradigms. By abstracting\ninfrastructure, service management, and user environments into distinct layers,\nvClusters allow for customized platforms that support diverse workloads.\nCurrent platforms on Alps serve various scientific domains, including numerical\nweather prediction, and AI research.", "AI": {"tldr": "CSCS\u5f00\u53d1\u4e86Alps\uff0c\u4e00\u79cd\u65b0\u578b\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u72ec\u7acb\u7aef\u70b9\u8d44\u6e90\u548c\u9ad8\u901f\u7f51\u7edc\u8bbe\u8ba1\uff0c\u6ee1\u8db3\u591a\u6837\u5316\u7684\u79d1\u5b66\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u5782\u76f4\u96c6\u6210\u7684HPC\u67b6\u6784\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u7ec4\u5408\u6027\uff0c\u65e0\u6cd5\u9002\u5e94\u65e5\u76ca\u591a\u6837\u5316\u7684\u79d1\u5b66\u9700\u6c42\u3002", "method": "Alps\u91c7\u7528\u5f02\u6784\u786c\u4ef6\uff08CPU\u548cGPU\uff09\u548c\u9ad8\u6027\u80fdSlingshot\u7f51\u7edc\uff0c\u7ed3\u5408\u6a21\u5757\u5316\u5b58\u50a8\u7cfb\u7edf\u548c\u8f6f\u4ef6\u5b9a\u4e49\u7684vCluster\u6280\u672f\u3002", "result": "Alps\u652f\u6301\u591a\u79cd\u79d1\u5b66\u9886\u57df\uff0c\u5982\u6570\u503c\u5929\u6c14\u9884\u62a5\u548cAI\u7814\u7a76\uff0c\u63d0\u4f9b\u5b9a\u5236\u5316\u5e73\u53f0\u3002", "conclusion": "Alps\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u548c\u6280\u672f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfHPC\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.02164", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.02164", "abs": "https://arxiv.org/abs/2507.02164", "authors": ["Ruibai Tang", "Chengbin Quan"], "title": "Hardware-Accelerated Algorithm for Complex Function Roots Density Graph Plotting", "comment": null, "summary": "Solving and visualizing the potential roots of complex functions is essential\nin both theoretical and applied domains, yet often computationally intensive.\nWe present a hardware-accelerated algorithm for complex function roots density\ngraph plotting by approximating functions with polynomials and solving their\nroots using single-shift QR iteration. By leveraging the Hessenberg structure\nof companion matrices and optimizing QR decomposition with Givens rotations, we\ndesign a pipelined FPGA architecture capable of processing a large amount of\npolynomials with high throughput. Our implementation achieves up to 65x higher\nenergy efficiency than CPU-based approaches, and while it trails modern GPUs in\nperformance due to differences in fabrication technique.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u786c\u4ef6\u52a0\u901f\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u7ed8\u5236\u590d\u51fd\u6570\u6839\u7684\u5bc6\u5ea6\u56fe\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u903c\u8fd1\u548c\u5355\u4f4d\u79fbQR\u8fed\u4ee3\u6c42\u89e3\u6839\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u80fd\u6548\u3002", "motivation": "\u590d\u51fd\u6570\u6839\u7684\u6c42\u89e3\u548c\u53ef\u89c6\u5316\u5728\u7406\u8bba\u548c\u5e94\u7528\u9886\u57df\u90fd\u5f88\u91cd\u8981\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u4f34\u968f\u77e9\u9635\u7684Hessenberg\u7ed3\u6784\u548cGivens\u65cb\u8f6c\u4f18\u5316QR\u5206\u89e3\uff0c\u8bbe\u8ba1\u4e86\u6d41\u6c34\u7ebfFPGA\u67b6\u6784\uff0c\u5904\u7406\u5927\u91cf\u591a\u9879\u5f0f\u3002", "result": "\u76f8\u6bd4CPU\u65b9\u6cd5\uff0c\u80fd\u6548\u63d0\u5347\u9ad8\u8fbe65\u500d\uff0c\u4f46\u6027\u80fd\u4ecd\u843d\u540e\u4e8e\u73b0\u4ee3GPU\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u80fd\u6548\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u9700\u8981\u9ad8\u6548\u8ba1\u7b97\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.02620", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02620", "abs": "https://arxiv.org/abs/2507.02620", "authors": ["Xing Liu", "Lizhuo Luo", "Ming Tang", "Chao Huang"], "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference", "comment": "16 pages, and the last 3 are appendix", "summary": "Distributed inference serves as a promising approach to enabling the\ninference of large language models (LLMs) at the network edge. It distributes\nthe inference process to multiple devices to ensure that the LLMs can fit into\nthe device memory. Recent pipeline-based approaches have the potential to\nparallelize communication and computation, which helps reduce inference\nlatency. However, the benefit diminishes when the inference request at the\nnetwork edge is sparse, where pipeline is typically at low utilization. To\nenable efficient distributed LLM inference at the edge, we propose\n\\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding\nframework. FlowSpec incorporates three key mechanisms to improve decoding\nefficiency: 1) score-based step-wise verification prioritizes more important\ndraft tokens to bring earlier accpeted tokens; 2) efficient draft management to\nprune invalid tokens while maintaining correct causal relationship during\nverification; 3) dynamic draft expansion strategies to supply high-quality\nspeculative inputs. These techniques work in concert to enhance both pipeline\nutilization and speculative efficiency. We evaluate FlowSpec on a real-world\ntestbed with other baselines. Experimental results demonstrate that our\nproposed framework significantly improves inference speed across diverse models\nand configurations, achieving speedup ratios 1.36$\\times$-1.77$\\times$ compared\nto baselines. Our code is publicly available at\n\\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\\#}", "AI": {"tldr": "FlowSpec\u662f\u4e00\u4e2a\u57fa\u4e8e\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u6811\u72b6\u63a8\u6d4b\u89e3\u7801\u7684\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u8fb9\u7f18\u7f51\u7edc\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5206\u5e03\u5f0f\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6d41\u6c34\u7ebf\u65b9\u6cd5\u5728\u8fb9\u7f18\u7f51\u7edc\u8bf7\u6c42\u7a00\u758f\u65f6\u5229\u7528\u7387\u4f4e\uff0c\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u51cf\u5c11\u6548\u679c\u4e0d\u4f73\u3002", "method": "FlowSpec\u91c7\u7528\u4e09\u79cd\u673a\u5236\uff1a\u57fa\u4e8e\u5206\u6570\u7684\u9010\u6b65\u9a8c\u8bc1\u3001\u9ad8\u6548\u8349\u7a3f\u7ba1\u7406\u548c\u52a8\u6001\u8349\u7a3f\u6269\u5c55\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFlowSpec\u5728\u591a\u79cd\u6a21\u578b\u548c\u914d\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u901f\u5ea6\u6bd4\u57fa\u7ebf\u5feb1.36\u00d7-1.77\u00d7\u3002", "conclusion": "FlowSpec\u901a\u8fc7\u4f18\u5316\u6d41\u6c34\u7ebf\u5229\u7528\u7387\u548c\u63a8\u6d4b\u6548\u7387\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8fb9\u7f18\u7f51\u7edc\u4e2dLLM\u7684\u5206\u5e03\u5f0f\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2507.02456", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.02456", "abs": "https://arxiv.org/abs/2507.02456", "authors": ["Wenzhe Guo", "Joyjit Kundu", "Uras Tos", "Weijiang Kong", "Giuliano Sisto", "Timon Evenblij", "Manu Perumkunnil"], "title": "System-performance and cost modeling of Large Language Model training and inference", "comment": null, "summary": "Large language models (LLMs), based on transformer architectures, have\nrevolutionized numerous domains within artificial intelligence, science, and\nengineering due to their exceptional scalability and adaptability. However, the\nexponential growth in LLM size and complexity has outpaced advancements in\ncompute capacity, memory bandwidth, network performance, and cost efficiency,\nposing significant challenges to their scalability on distributed systems. To\naddress these limitations, alternative model architectures, optimization\nstrategies, communication-aware network topologies, and novel system design\napproaches have been proposed in literature. This paper introduces a\nperformance-cost modeling methodology for LLM training and inference that\nintegrates state-of-the-art compute techniques with memory optimizations, and\nlatest communication techniques. Building on an analytical performance model,\nour approach incorporates recent innovations such as the flash attention\ntechnique and mixture of experts models to address the memory bandwidth and\ncompute bottlenecks. It also considers the impact of different network\ntopologies and topology-specific communication algorithms with 5D parallellism.\nThe framework also integrates a chiplet cost model. The proposed modeling\nmethodology provides valuable insights to guide future compute system design\nand facilitates hardware-software co-development, in particular due to its\nability to analyze performance-cost trade-offs for various system architectural\nconfigurations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u6027\u80fd-\u6210\u672c\u5efa\u6a21\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5148\u8fdb\u7684\u8ba1\u7b97\u6280\u672f\u3001\u5185\u5b58\u4f18\u5316\u548c\u901a\u4fe1\u6280\u672f\uff0c\u4ee5\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "motivation": "\u968f\u7740LLM\u89c4\u6a21\u548c\u590d\u6742\u6027\u7684\u6307\u6570\u589e\u957f\uff0c\u8ba1\u7b97\u80fd\u529b\u3001\u5185\u5b58\u5e26\u5bbd\u3001\u7f51\u7edc\u6027\u80fd\u548c\u6210\u672c\u6548\u7387\u7684\u63d0\u5347\u672a\u80fd\u8ddf\u4e0a\uff0c\u5bfc\u81f4\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6027\u80fd-\u6210\u672c\u5efa\u6a21\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u95ea\u5b58\u6ce8\u610f\u529b\u6280\u672f\u548c\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u5e76\u8003\u8651\u4e86\u4e0d\u540c\u7f51\u7edc\u62d3\u6251\u548c\u901a\u4fe1\u7b97\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5206\u6790\u4e0d\u540c\u7cfb\u7edf\u67b6\u6784\u914d\u7f6e\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u4e3a\u672a\u6765\u8ba1\u7b97\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "\u8be5\u5efa\u6a21\u65b9\u6cd5\u4e3a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u6027\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u5206\u6790\u65b9\u9762\u3002"}}
{"id": "2507.02598", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02598", "abs": "https://arxiv.org/abs/2507.02598", "authors": ["Chenhao Xue", "Kezhi Li", "Jiaxing Zhang", "Yi Ren", "Zhengyuan Shi", "Chen Zhang", "Yibo Lin", "Lining Zhang", "Qiang Xu", "Guangyu Sun"], "title": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models", "comment": "8 pages, 12 figures", "summary": "Arithmetic circuits, such as adders and multipliers, are fundamental\ncomponents of digital systems, directly impacting the performance, power\nefficiency, and area footprint. However, optimizing these circuits remains\nchallenging due to the vast design space and complex physical constraints.\nWhile recent deep learning-based approaches have shown promise, they struggle\nto consistently explore high-potential design variants, limiting their\noptimization efficiency. To address this challenge, we propose AC-Refiner, a\nnovel arithmetic circuit optimization framework leveraging conditional\ndiffusion models. Our key insight is to reframe arithmetic circuit synthesis as\na conditional image generation task. By carefully conditioning the denoising\ndiffusion process on target quality-of-results (QoRs), AC-Refiner consistently\nproduces high-quality circuit designs. Furthermore, the explored designs are\nused to fine-tune the diffusion model, which focuses the exploration near the\nPareto frontier. Experimental results demonstrate that AC-Refiner generates\ndesigns with superior Pareto optimality, outperforming state-of-the-art\nbaselines. The performance gain is further validated by integrating AC-Refiner\ninto practical applications.", "AI": {"tldr": "AC-Refiner\u662f\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u7b97\u672f\u7535\u8def\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7535\u8def\u5408\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6761\u4ef6\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u8bbe\u8ba1\u8d28\u91cf\u3002", "motivation": "\u7b97\u672f\u7535\u8def\u4f18\u5316\u9762\u4e34\u8bbe\u8ba1\u7a7a\u95f4\u5927\u548c\u7269\u7406\u7ea6\u675f\u590d\u6742\u7684\u6311\u6218\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u63a2\u7d22\u9ad8\u6f5c\u529b\u8bbe\u8ba1\u53d8\u4f53\u3002", "method": "\u91c7\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u5c06\u7535\u8def\u5408\u6210\u89c6\u4e3a\u6761\u4ef6\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u7ed3\u5408\u76ee\u6807\u8d28\u91cf\u7ed3\u679c\uff08QoR\uff09\u8fdb\u884c\u4f18\u5316\u3002", "result": "AC-Refiner\u751f\u6210\u7684\u7535\u8def\u8bbe\u8ba1\u5728\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AC-Refiner\u901a\u8fc7\u6269\u6563\u6a21\u578b\u6709\u6548\u4f18\u5316\u7b97\u672f\u7535\u8def\u8bbe\u8ba1\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u7684\u9ad8\u6548\u63a2\u7d22\u80fd\u529b\u3002"}}
{"id": "2507.02654", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.02654", "abs": "https://arxiv.org/abs/2507.02654", "authors": ["Rui Xie", "Asad Ul Haq", "Yunhua Fang", "Linsen Ma", "Sanchari Sen", "Swagath Venkataramani", "Liu Liu", "Tong Zhang"], "title": "Breaking the HBM Bit Cost Barrier: Domain-Specific ECC for AI Inference Infrastructure", "comment": null, "summary": "High-Bandwidth Memory (HBM) delivers exceptional bandwidth and energy\nefficiency for AI workloads, but its high cost per bit, driven in part by\nstringent on-die reliability requirements, poses a growing barrier to scalable\ndeployment. This work explores a system-level approach to cost reduction by\neliminating on-die ECC and shifting all fault management to the memory\ncontroller. We introduce a domain-specific ECC framework combining\nlarge-codeword Reed--Solomon~(RS) correction with lightweight fine-grained CRC\ndetection, differential parity updates to mitigate write amplification, and\ntunable protection based on data importance. Our evaluation using LLM inference\nworkloads shows that, even under raw HBM bit error rates up to $10^{-3}$, the\nsystem retains over 78\\% of throughput and 97\\% of model accuracy compared with\nsystems equipped with ideal error-free HBM. By treating reliability as a\ntunable system parameter rather than a fixed hardware constraint, our design\nopens a new path toward low-cost, high-performance HBM deployment in AI\ninfrastructure.", "AI": {"tldr": "\u901a\u8fc7\u7cfb\u7edf\u7ea7\u65b9\u6cd5\u964d\u4f4eHBM\u6210\u672c\uff0c\u5c06\u6545\u969c\u7ba1\u7406\u79fb\u81f3\u5185\u5b58\u63a7\u5236\u5668\uff0c\u7ed3\u5408RS\u7ea0\u9519\u4e0eCRC\u68c0\u6d4b\uff0c\u4fdd\u6301\u9ad8\u541e\u5410\u548c\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "HBM\u7684\u9ad8\u6210\u672c\u9650\u5236\u4e86\u5176\u5728AI\u4e2d\u7684\u53ef\u6269\u5c55\u90e8\u7f72\uff0c\u9700\u63a2\u7d22\u964d\u4f4e\u6210\u672c\u7684\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57df\u7279\u5b9aECC\u6846\u67b6\uff0c\u7ed3\u5408RS\u7ea0\u9519\u3001CRC\u68c0\u6d4b\u3001\u5dee\u5206\u5947\u5076\u66f4\u65b0\u548c\u53ef\u8c03\u4fdd\u62a4\u3002", "result": "\u572810^-3\u8bef\u7801\u7387\u4e0b\uff0c\u7cfb\u7edf\u4fdd\u630178%\u541e\u5410\u548c97%\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "\u5c06\u53ef\u9760\u6027\u4f5c\u4e3a\u53ef\u8c03\u53c2\u6570\uff0c\u4e3a\u4f4e\u6210\u672c\u9ad8\u6027\u80fdHBM\u90e8\u7f72\u63d0\u4f9b\u65b0\u8def\u5f84\u3002"}}
