<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Numbers Reverse AD for Functional Array Languages](https://arxiv.org/abs/2507.12640)
*Tom Smeding,Mikołaj Konarski,Simon Peyton Jones,Andrew Fitzgibbon*

Main category: cs.PL

TL;DR: 本文提出了一种针对多维数组的对偶数反向模式自动微分方法，通过批量操作变换(BOT)、数组语言的对偶数算法提升和符号解释三个组件，在几乎无性能开销的情况下实现了对多维数组的一流支持


<details>
  <summary>Details</summary>
Motivation: 标准对偶数构造在前向模式自动微分中表现良好，但在反向模式自动微分中，特别是在数组程序上的实际性能表现不佳。现有方法在处理多维数组时存在显著的性能问题

Method: 提出三个松耦合组件的算法：1)语义保持的向量化代码变换(批量操作变换BOT)；2)基础对偶数反向AD算法向一阶数组语言的直接提升；3)符号解释实现端到端编译流水线。通过BOT消除输入程序的高阶特性，使得将对偶数提升为"对偶数组"的简单技巧能够有效工作

Result: 成功实现了对多维数组的一流支持，几乎没有性能开销。支持部分高阶数组组合子，包括'build'(逐元素数组构造)、'gather'和'scatter'操作

Conclusion: 虽然在过程中失去了对偶数AD的一些良好的可泛化特性(特别是对高阶代码的支持)，但通过精心选择的高阶数组组合子集合，BOT能够消除输入程序的基本高阶性，使AD本质上面对一阶程序，从而让简单的对偶数组方法能够有效工作

Abstract: The standard dual-numbers construction works well for forward-mode automatic
differentiation (AD) and is attractive due to its simplicity; recently, it also
has been adapted to reverse-mode AD, but practical performance, especially on
array programs, leaves a lot to be desired. In this paper we introduce
first-class support for multidimensional arrays in dual-numbers reverse-mode AD
with little to no performance overhead. The algorithm consists of three
loosely-coupled components: a semantics-preserving vectorisation code
transformation (the bulk-operation transform or BOT), a fairly straightforward
lifting of the basic dual-numbers reverse AD algorithm to a mostly first-order
array language, and symbolic interpretation to achieve an end-to-end
compilation pipeline. Unfortunately, we lose some of the nice generalisable
aspects of dual-numbers AD in the process, most importantly support for
higher-order code.
  We do support some higher-order array combinators, but only a
carefully-chosen set: 'build' (elementwise array construction), 'gather' and
'scatter'. In return, the BOT can eliminate the essential (for AD)
higher-orderness of the input program, meaning that AD gets essentially
presented with a first-order program. This allows the naive trick of lifting
dual numbers to "dual arrays" to work without much modification.

</details>


### [2] [Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications](https://arxiv.org/abs/2507.13091)
*Aurèle Barrière,Victor Deng,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 提出了首个机械化、简洁、实用、完整且经过验证的现代正则表达式语义，支持回溯语义，并通过与ECMAScript规范的等价性证明其忠实性。


<details>
  <summary>Details</summary>
Motivation: 为现代正则表达式提供一种可靠的语义模型，填补现有规范与形式化工作之间的空白。

Method: 通过机械化证明与ECMAScript规范的等价性，并展示两个实际应用：上下文等价性验证和PikeVM算法的形式化证明。

Result: 成功捕获完整的回溯树，记录所有可能的匹配及其优先级，所有定义和结果均在Rocq证明助手中实现。

Conclusion: 该语义模型不仅实用，还为正则表达式的形式化研究提供了新工具和方法。

Abstract: We present the first mechanized, succinct, practical, complete, and
proven-faithful semantics for a modern regular expression language with
backtracking semantics. We ensure its faithfulness by proving it equivalent to
a preexisting line-by-line embedding of the official ECMAScript specification
of JavaScript regular expressions. We demonstrate its practicality by
presenting two real-world applications. First, a new notion of contextual
equivalence for modern regular expressions, which we use to prove or disprove
rewrites drawn from previous work. Second, the first formal proof of the PikeVM
algorithm used in many real-world engines. In contrast with the specification
and other formalization work, our semantics captures not only the top-priority
match, but a full backtracking tree recording all possible matches and their
respective priority. All our definitions and results have been mechanized in
the Rocq proof assistant.

</details>


### [3] [Towards Formal Verification of LLM-Generated Code from Natural Language Prompts](https://arxiv.org/abs/2507.13290)
*Aaron Councilman,David Fu,Aryan Gupta,Chengxiao Wang,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.PL

TL;DR: 该论文提出了一种方法，通过结合形式化查询语言和验证技术，为LLM生成的代码提供正确性保证，从而提升AI代码助手的用户体验。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码常存在错误且用户难以检测，这限制了其作为编程辅助工具的潜力。

Method: 提出使用形式化查询语言表达用户意图，并通过符号解释器验证LLM生成的代码是否符合意图。

Result: 在21个代码生成任务中，验证器能正确验证83%的正确代码，并识别92%的错误代码。

Conclusion: 该方法为LLM生成的代码提供了形式化正确性保证，有望推动自然语言编程的普及。

Abstract: In the past few years LLMs have emerged as a tool that can aid programmers by
taking natural language descriptions and generating code based on it. However,
LLMs often generate incorrect code that users need to fix and the literature
suggests users often struggle to detect these errors. In this work we seek to
offer formal guarantees of correctness to LLM generated code; such guarantees
could improve the experience of using AI Code Assistants and potentially enable
natural language programming for users with little or no programming knowledge.
To address this challenge we propose to incorporate a formal query language
that can represent a user's intent in a formally defined but natural
language-like manner that a user can confirm matches their intent. Then, using
such a query we propose to verify LLM generated code to ensure it matches the
user's intent. We implement these ideas in our system, Astrogator, for the
Ansible programming language which includes such a formal query language, a
calculus for representing the behavior of Ansible programs, and a symbolic
interpreter which is used for the verification. On a benchmark suite of 21
code-generation tasks, our verifier is able to verify correct code in 83% of
cases and identify incorrect code in 92%.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Building State Machine Replication Using Practical Network Synchrony](https://arxiv.org/abs/2507.12792)
*Yiliang Wan,Nitin Shivaraman,Akshaye Shenoi,Xiang Liu,Tao Luo,Jialin Li*

Main category: cs.DC

TL;DR: 论文提出了一种利用数据中心强同步性设计的高效复制协议Chora，通过内核旁路网络和多线程架构实现2微秒内的严格轮次同步，显著提升了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统通常基于部分同步或异步网络模型，但现代数据中心可以设计为提供强同步性，从而优化协议性能。

Method: 结合内核旁路网络、多线程架构和宽松轮次长度，设计出Chora协议，利用网络同步性实现高效并行复制。

Result: Chora在实验中比现有单领导者和多领导者协议分别提升了255%和109%的吞吐量。

Conclusion: 现代数据中心可通过强同步性优化分布式协议设计，Chora协议展示了其高效性和实用性。

Abstract: Distributed systems, such as state machine replication, are critical
infrastructures for modern applications. Practical distributed protocols make
minimum assumptions about the underlying network: They typically assume a
partially synchronous or fully asynchronous network model. In this work, we
argue that modern data center systems can be designed to provide strong
synchrony properties in the common case, where servers move in synchronous
lock-step rounds. We prove this hypothesis by engineering a practical design
that uses a combination of kernel-bypass network, multithreaded architecture,
and loosened round length, achieving a tight round bound under 2us. Leveraging
our engineered networks with strong synchrony, we co-design a new replication
protocol, Chora. Chora exploits the network synchrony property to efficiently
pipeline multiple replication instances, while allowing all replicas to propose
in parallel without extra coordination. Through experiments, we show that Chora
achieves 255% and 109% improvement in throughput over state-of-the-art
single-leader and multi-leader protocols, respectively.

</details>


### [5] [Autonomous Resource Management in Microservice Systems via Reinforcement Learning](https://arxiv.org/abs/2507.12879)
*Yujun Zou,Nia Qi,Yingnan Deng,Zhihao Xue,Ming Gong,Wuyang Zhang*

Main category: cs.DC

TL;DR: 提出了一种基于强化学习的微服务资源调度与优化方法，显著提升系统性能与资源利用率。


<details>
  <summary>Details</summary>
Motivation: 解决传统微服务架构中资源分配不均、高延迟和吞吐量不足的问题。

Method: 采用基于强化学习的智能调度算法，通过代理与环境的交互优化资源分配策略。

Result: 实验表明，该方法在低负载和高并发条件下显著提升响应速度和吞吐量，同时优化资源利用率和能耗。

Conclusion: 相比传统静态方法，强化学习模型更具适应性和优化能力，能实时调整策略以适应动态环境。

Abstract: This paper proposes a reinforcement learning-based method for microservice
resource scheduling and optimization, aiming to address issues such as uneven
resource allocation, high latency, and insufficient throughput in traditional
microservice architectures. In microservice systems, as the number of services
and the load increase, efficiently scheduling and allocating resources such as
computing power, memory, and storage becomes a critical research challenge. To
address this, the paper employs an intelligent scheduling algorithm based on
reinforcement learning. Through the interaction between the agent and the
environment, the resource allocation strategy is continuously optimized. In the
experiments, the paper considers different resource conditions and load
scenarios, evaluating the proposed method across multiple dimensions, including
response time, throughput, resource utilization, and cost efficiency. The
experimental results show that the reinforcement learning-based scheduling
method significantly improves system response speed and throughput under low
load and high concurrency conditions, while also optimizing resource
utilization and reducing energy consumption. Under multi-dimensional resource
conditions, the proposed method can consider multiple objectives and achieve
optimized resource scheduling. Compared to traditional static resource
allocation methods, the reinforcement learning model demonstrates stronger
adaptability and optimization capability. It can adjust resource allocation
strategies in real time, thereby maintaining good system performance in
dynamically changing load and resource environments.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [6] [Modular SAIL: dream or reality?](https://arxiv.org/abs/2507.12471)
*Petr Kourzanov,Anmol*

Main category: cs.AR

TL;DR: 论文探讨了如何通过模块化SAIL在SAIL-RISCV黄金模型中实现组合性，以支持RISC-V开发流程中的仿真和验证。


<details>
  <summary>Details</summary>
Motivation: 解决RISC-V ISA模块化中的组合性问题，扩展至仿真和验证等开发流程。

Method: 引入模块化SAIL，调整SAIL-RISCV流程以支持模拟器级别的模块化。

Result: 实验表明，模块化模拟器在静态和动态绑定下性能与原始单块模拟器一致。

Conclusion: 模块化SAIL可行，且不影响功能行为，为RISC-V开发流程提供了灵活性。

Abstract: In order to truly benefit from RISC-V ISA modularity, the community has to
address the issue of compositionality, going beyond modules at the
specification level covering larger subsets of the RISC-V development flow
including emulation, simulation and verification. In this paper we introduce
modular SAIL, an experiment to inject compositionality into the SAIL-RISCV
golden model. We show that it is, in principle, not difficult to adapt the
SAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at
the emulator level. We back our findings by a comparative study of the
resulting pluggable emulator's performance using both static and dynamic
binding, which both exhibit same functional behavior as the original monolithic
emulator (aka RISC-V ISS).

</details>


### [7] [An ultra-low-power CGRA for accelerating Transformers at the edge](https://arxiv.org/abs/2507.12904)
*Rohit Prasad*

Main category: cs.AR

TL;DR: 提出了一种专为边缘设备设计的超低功耗CGRA架构，用于加速Transformer模型中的GEMM操作，通过并行计算和优化的内存操作降低功耗和延迟。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在边缘设备上的部署面临高计算需求挑战，需要低功耗解决方案。

Method: 采用4x4 PE阵列和4x2 MOB块，结合无交换环形互连网络，优化并行计算和内存操作。

Result: 该架构显著降低了内存带宽需求，提升了数据重用效率，适合边缘设备部署。

Conclusion: 通过异构设计和高效数据流，为边缘设备上的Transformer模型提供了可扩展的解决方案。

Abstract: Transformers have revolutionized deep learning with applications in natural
language processing, computer vision, and beyond. However, their computational
demands make it challenging to deploy them on low-power edge devices. This
paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA)
architecture specifically designed to accelerate General Matrix Multiplication
(GEMM) operations in transformer models tailored for the energy and resource
constraints of edge applications. The proposed architecture integrates a 4 x 4
array of Processing Elements (PEs) for efficient parallel computation and
dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE
operations, reducing memory bandwidth demands and enhancing data reuse. A
switchless mesh torus interconnect network further minimizes power and latency
by enabling direct communication between PEs and MOBs, eliminating the need for
centralized switching. Through its heterogeneous array design and efficient
dataflow, this CGRA architecture addresses the unique computational needs of
transformers, offering a scalable pathway to deploy sophisticated machine
learning models on edge devices.

</details>


### [8] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
*Haniye Mehraban,Saad Azmeen-ur-Rahman,John Hu*

Main category: cs.AR

TL;DR: 论文通过假冒TL074运算放大器的案例，将其转化为教学机会，帮助学生深入理解模拟电路和供应链安全。


<details>
  <summary>Details</summary>
Motivation: 假冒集成电路在本科电子实验室中日益普遍，威胁实验完整性，作者希望通过实际案例提升学生的实践能力。

Method: 学生通过测量电流、分析波形和故障排除等实际操作，学习如何识别和处理假冒芯片。

Result: 学生通过实践加深了对模拟电路、供应链安全和实际工程的理解。

Conclusion: 将假冒组件问题转化为教学机会，有效提升了学生的实践能力和工程意识。

Abstract: This work-in-progress paper presents a case study in which counterfeit TL074
operational amplifiers, discovered in a junior level electronics course, became
the basis for a hands on learning experience. Counterfeit integrated circuits
(IC) are increasingly common, posing a significant threat to the integrity of
undergraduate electronics laboratories. Instead of simply replacing the
counterfeit components, we turned the issue into a teaching moment. Students
engaged in hands-on diagnostics measuring current, analyzing waveforms, and
troubleshooting. By working with fake chip components, they gained deeper
insight into analog circuits, supply chain security, and practical engineering.

</details>
