<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Numbers Reverse AD for Functional Array Languages](https://arxiv.org/abs/2507.12640)
*Tom Smeding,Mikołaj Konarski,Simon Peyton Jones,Andrew Fitzgibbon*

Main category: cs.PL

TL;DR: 本文提出了一种支持多维数组的双数反向模式自动微分方法，通过向量化代码转换和符号解释实现高性能，但牺牲了高阶代码支持。


<details>
  <summary>Details</summary>
Motivation: 标准双数构造在反向模式自动微分中性能不足，尤其是对数组程序。本文旨在解决这一问题。

Method: 结合向量化代码转换（BOT）、双数反向AD算法的数组语言扩展，以及符号解释，实现端到端编译。

Result: 实现了高性能的多维数组支持，但失去了对高阶代码的通用支持。

Conclusion: 通过牺牲部分通用性，实现了对数组程序的高效反向模式自动微分。

Abstract: The standard dual-numbers construction works well for forward-mode automatic
differentiation (AD) and is attractive due to its simplicity; recently, it also
has been adapted to reverse-mode AD, but practical performance, especially on
array programs, leaves a lot to be desired. In this paper we introduce
first-class support for multidimensional arrays in dual-numbers reverse-mode AD
with little to no performance overhead. The algorithm consists of three
loosely-coupled components: a semantics-preserving vectorisation code
transformation (the bulk-operation transform or BOT), a fairly straightforward
lifting of the basic dual-numbers reverse AD algorithm to a mostly first-order
array language, and symbolic interpretation to achieve an end-to-end
compilation pipeline. Unfortunately, we lose some of the nice generalisable
aspects of dual-numbers AD in the process, most importantly support for
higher-order code.
  We do support some higher-order array combinators, but only a
carefully-chosen set: 'build' (elementwise array construction), 'gather' and
'scatter'. In return, the BOT can eliminate the essential (for AD)
higher-orderness of the input program, meaning that AD gets essentially
presented with a first-order program. This allows the naive trick of lifting
dual numbers to "dual arrays" to work without much modification.

</details>


### [2] [Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications](https://arxiv.org/abs/2507.13091)
*Aurèle Barrière,Victor Deng,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 提出了首个机械化、简洁、实用、完整且忠实证明的现代正则表达式语义，支持回溯语义。


<details>
  <summary>Details</summary>
Motivation: 为现代正则表达式语言提供可靠的语义定义，并验证其与ECMAScript规范的等价性。

Method: 通过证明与ECMAScript规范的等价性确保语义的忠实性，并展示两个实际应用：上下文等价性证明和PikeVM算法的形式化验证。

Result: 定义了完整的回溯树语义，捕获所有可能的匹配及其优先级，所有定义和结果已在Rocq证明助手中机械化实现。

Conclusion: 该研究为现代正则表达式提供了可靠的语义基础，并展示了其在实际应用中的价值。

Abstract: We present the first mechanized, succinct, practical, complete, and
proven-faithful semantics for a modern regular expression language with
backtracking semantics. We ensure its faithfulness by proving it equivalent to
a preexisting line-by-line embedding of the official ECMAScript specification
of JavaScript regular expressions. We demonstrate its practicality by
presenting two real-world applications. First, a new notion of contextual
equivalence for modern regular expressions, which we use to prove or disprove
rewrites drawn from previous work. Second, the first formal proof of the PikeVM
algorithm used in many real-world engines. In contrast with the specification
and other formalization work, our semantics captures not only the top-priority
match, but a full backtracking tree recording all possible matches and their
respective priority. All our definitions and results have been mechanized in
the Rocq proof assistant.

</details>


### [3] [Towards Formal Verification of LLM-Generated Code from Natural Language Prompts](https://arxiv.org/abs/2507.13290)
*Aaron Councilman,David Fu,Aryan Gupta,Chengxiao Wang,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.PL

TL;DR: 论文提出了一种方法，通过结合形式化查询语言和验证技术，为LLM生成的代码提供正确性保证。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码常存在错误且用户难以检测，希望通过形式化方法提升AI代码助手的可靠性和用户体验。

Method: 提出结合形式化查询语言表示用户意图，并通过符号解释器验证LLM生成的代码是否符合意图。

Result: 在21个代码生成任务中，验证器能正确验证83%的正确代码，并识别92%的错误代码。

Conclusion: 该方法有效提升了LLM生成代码的可靠性，为自然语言编程提供了潜在支持。

Abstract: In the past few years LLMs have emerged as a tool that can aid programmers by
taking natural language descriptions and generating code based on it. However,
LLMs often generate incorrect code that users need to fix and the literature
suggests users often struggle to detect these errors. In this work we seek to
offer formal guarantees of correctness to LLM generated code; such guarantees
could improve the experience of using AI Code Assistants and potentially enable
natural language programming for users with little or no programming knowledge.
To address this challenge we propose to incorporate a formal query language
that can represent a user's intent in a formally defined but natural
language-like manner that a user can confirm matches their intent. Then, using
such a query we propose to verify LLM generated code to ensure it matches the
user's intent. We implement these ideas in our system, Astrogator, for the
Ansible programming language which includes such a formal query language, a
calculus for representing the behavior of Ansible programs, and a symbolic
interpreter which is used for the verification. On a benchmark suite of 21
code-generation tasks, our verifier is able to verify correct code in 83% of
cases and identify incorrect code in 92%.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Building State Machine Replication Using Practical Network Synchrony](https://arxiv.org/abs/2507.12792)
*Yiliang Wan,Nitin Shivaraman,Akshaye Shenoi,Xiang Liu,Tao Luo,Jialin Li*

Main category: cs.DC

TL;DR: 本文通过工程化设计实现了强同步性数据中心网络，并基于此提出了新的复制协议Chora，该协议能够高效流水线化多个复制实例并允许所有副本并行提议，相比现有协议显著提升了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统分布式系统通常假设部分同步或完全异步的网络模型，但现代数据中心系统可以设计为在常见情况下提供强同步特性，服务器能够以同步锁步轮次运行，这为设计更高效的分布式协议提供了机会。

Method: 采用内核旁路网络、多线程架构和宽松轮次长度的组合设计，实现了在2微秒内的紧密轮次边界，构建了具有强同步性的工程化网络。基于此网络特性，协同设计了新的复制协议Chora，该协议利用网络同步性高效流水线化多个复制实例，同时允许所有副本无需额外协调即可并行提议。

Result: 实验结果显示，Chora协议相比最先进的单主导者协议提升了255%的吞吐量，相比多主导者协议提升了109%的吞吐量，证明了强同步网络设计和协同优化协议的有效性。

Conclusion: 现代数据中心系统可以通过工程化设计实现强同步网络特性，基于这种网络设计的分布式复制协议能够显著提升性能。Chora协议成功利用了网络同步性，在保证正确性的同时大幅提升了分布式系统的吞吐量性能。

Abstract: Distributed systems, such as state machine replication, are critical
infrastructures for modern applications. Practical distributed protocols make
minimum assumptions about the underlying network: They typically assume a
partially synchronous or fully asynchronous network model. In this work, we
argue that modern data center systems can be designed to provide strong
synchrony properties in the common case, where servers move in synchronous
lock-step rounds. We prove this hypothesis by engineering a practical design
that uses a combination of kernel-bypass network, multithreaded architecture,
and loosened round length, achieving a tight round bound under 2us. Leveraging
our engineered networks with strong synchrony, we co-design a new replication
protocol, Chora. Chora exploits the network synchrony property to efficiently
pipeline multiple replication instances, while allowing all replicas to propose
in parallel without extra coordination. Through experiments, we show that Chora
achieves 255% and 109% improvement in throughput over state-of-the-art
single-leader and multi-leader protocols, respectively.

</details>


### [5] [Autonomous Resource Management in Microservice Systems via Reinforcement Learning](https://arxiv.org/abs/2507.12879)
*Yujun Zou,Nia Qi,Yingnan Deng,Zhihao Xue,Ming Gong,Wuyang Zhang*

Main category: cs.DC

TL;DR: 本文提出了一种基于强化学习的微服务资源调度与优化方法，旨在解决传统微服务架构中资源分配不均、高延迟和吞吐量不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着微服务系统中服务数量和负载的增加，高效调度和分配计算、内存和存储等资源成为关键研究挑战。

Method: 采用基于强化学习的智能调度算法，通过代理与环境的交互不断优化资源分配策略。

Result: 实验表明，该方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，同时优化了资源利用率和能耗。

Conclusion: 与传统静态资源分配方法相比，强化学习模型展现出更强的适应性和优化能力，能够实时调整策略以应对动态变化的负载和资源环境。

Abstract: This paper proposes a reinforcement learning-based method for microservice
resource scheduling and optimization, aiming to address issues such as uneven
resource allocation, high latency, and insufficient throughput in traditional
microservice architectures. In microservice systems, as the number of services
and the load increase, efficiently scheduling and allocating resources such as
computing power, memory, and storage becomes a critical research challenge. To
address this, the paper employs an intelligent scheduling algorithm based on
reinforcement learning. Through the interaction between the agent and the
environment, the resource allocation strategy is continuously optimized. In the
experiments, the paper considers different resource conditions and load
scenarios, evaluating the proposed method across multiple dimensions, including
response time, throughput, resource utilization, and cost efficiency. The
experimental results show that the reinforcement learning-based scheduling
method significantly improves system response speed and throughput under low
load and high concurrency conditions, while also optimizing resource
utilization and reducing energy consumption. Under multi-dimensional resource
conditions, the proposed method can consider multiple objectives and achieve
optimized resource scheduling. Compared to traditional static resource
allocation methods, the reinforcement learning model demonstrates stronger
adaptability and optimization capability. It can adjust resource allocation
strategies in real time, thereby maintaining good system performance in
dynamically changing load and resource environments.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [6] [Modular SAIL: dream or reality?](https://arxiv.org/abs/2507.12471)
*Petr Kourzanov,Anmol*

Main category: cs.AR

TL;DR: 论文探讨了如何在RISC-V开发流程中实现模块化组合性，提出了模块化SAIL方法，并验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决RISC-V ISA模块化在实际开发流程（如仿真、模拟和验证）中的组合性问题。

Method: 引入模块化SAIL，改造SAIL-RISCV黄金模型以支持模块化，比较静态和动态绑定的性能。

Result: 模块化SAIL的功能行为与原始单块模拟器一致，性能表现良好。

Conclusion: 模块化SAIL可行，为RISC-V开发流程的组合性提供了有效解决方案。

Abstract: In order to truly benefit from RISC-V ISA modularity, the community has to
address the issue of compositionality, going beyond modules at the
specification level covering larger subsets of the RISC-V development flow
including emulation, simulation and verification. In this paper we introduce
modular SAIL, an experiment to inject compositionality into the SAIL-RISCV
golden model. We show that it is, in principle, not difficult to adapt the
SAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at
the emulator level. We back our findings by a comparative study of the
resulting pluggable emulator's performance using both static and dynamic
binding, which both exhibit same functional behavior as the original monolithic
emulator (aka RISC-V ISS).

</details>


### [7] [An ultra-low-power CGRA for accelerating Transformers at the edge](https://arxiv.org/abs/2507.12904)
*Rohit Prasad*

Main category: cs.AR

TL;DR: 提出了一种针对边缘设备的低功耗CGRA架构，用于加速Transformer模型中的GEMM操作。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在边缘设备上的部署面临高计算需求挑战，需要低功耗解决方案。

Method: 设计了一种4x4 PE阵列和4x2 MOB的CGRA架构，采用无交换环面互连网络优化数据流。

Result: 该架构减少了内存带宽需求，提高了数据重用，降低了功耗和延迟。

Conclusion: 为边缘设备部署复杂机器学习模型提供了可扩展的解决方案。

Abstract: Transformers have revolutionized deep learning with applications in natural
language processing, computer vision, and beyond. However, their computational
demands make it challenging to deploy them on low-power edge devices. This
paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA)
architecture specifically designed to accelerate General Matrix Multiplication
(GEMM) operations in transformer models tailored for the energy and resource
constraints of edge applications. The proposed architecture integrates a 4 x 4
array of Processing Elements (PEs) for efficient parallel computation and
dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE
operations, reducing memory bandwidth demands and enhancing data reuse. A
switchless mesh torus interconnect network further minimizes power and latency
by enabling direct communication between PEs and MOBs, eliminating the need for
centralized switching. Through its heterogeneous array design and efficient
dataflow, this CGRA architecture addresses the unique computational needs of
transformers, offering a scalable pathway to deploy sophisticated machine
learning models on edge devices.

</details>


### [8] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
*Haniye Mehraban,Saad Azmeen-ur-Rahman,John Hu*

Main category: cs.AR

TL;DR: 利用课程中发现的假冒TL074运算放大器，将其转化为实践学习机会，提升学生对模拟电路和供应链安全的理解。


<details>
  <summary>Details</summary>
Motivation: 假冒集成电路在本科电子实验室中日益普遍，威胁实验完整性，但可以转化为教学资源。

Method: 通过学生动手诊断，测量电流、分析波形和故障排除，利用假冒芯片进行实践学习。

Result: 学生通过实践加深了对模拟电路、供应链安全和实际工程的理解。

Conclusion: 假冒组件可以成为有效的教学工具，提升学生的实践能力和工程意识。

Abstract: This work-in-progress paper presents a case study in which counterfeit TL074
operational amplifiers, discovered in a junior level electronics course, became
the basis for a hands on learning experience. Counterfeit integrated circuits
(IC) are increasingly common, posing a significant threat to the integrity of
undergraduate electronics laboratories. Instead of simply replacing the
counterfeit components, we turned the issue into a teaching moment. Students
engaged in hands-on diagnostics measuring current, analyzing waveforms, and
troubleshooting. By working with fake chip components, they gained deeper
insight into analog circuits, supply chain security, and practical engineering.

</details>
