{"id": "2510.03415", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03415", "abs": "https://arxiv.org/abs/2510.03415", "authors": ["Aditya Thimmaiah", "Jiyang Zhang", "Jayanth Srinivasa", "Junyi Jessy Li", "Milos Gligoric"], "title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters", "comment": null, "summary": "As large language models (LLMs) excel at code reasoning, a natural question\narises: can an LLM execute programs (i.e., act as an interpreter) purely based\non a programming language's formal semantics? If so, it will enable rapid\nprototyping of new programming languages and language features. We study this\nquestion using the imperative language IMP (a subset of C), formalized via\nsmall-step operational semantics (SOS) and rewriting-based operational\nsemantics (K-semantics). We introduce three evaluation sets-Human-Written,\nLLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by\ncode-complexity metrics spanning the size, control-flow, and data-flow axes.\nGiven a program and its semantics formalized with SOS/K-semantics, models are\nevaluated on three tasks ranging from coarse to fine: (1) final-state\nprediction, (2) semantic rule prediction, and (3) execution trace prediction.\nTo distinguish pretraining memorization from semantic competence, we define two\nnonstandard semantics obtained through systematic mutations of the standard\nrules. Across strong code/reasoning LLMs, performance drops under nonstandard\nsemantics despite high performance under the standard one. We further find that\n(i) there are patterns to different model failures, (ii) most reasoning models\nperform exceptionally well on coarse grained tasks involving reasoning about\nhighly complex programs often containing nested loop depths beyond five, and\nsurprisingly, (iii) providing formal semantics helps on simple programs but\noften hurts on more complex ones. Overall, the results show a promise that LLMs\ncould serve as programming language interpreters, but points to the lack of\ntheir robust semantics understanding. We release the benchmark and the\nsupporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u57fa\u4e8e\u5f62\u5f0f\u8bed\u4e49\u4f5c\u4e3a\u7f16\u7a0b\u8bed\u8a00\u89e3\u91ca\u5668\uff0c\u4f7f\u7528IMP\u8bed\u8a00\u548c\u4e0d\u540c\u8bed\u4e49\u5f62\u5f0f\u5316\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u6807\u51c6\u8bed\u4e49\u4e0b\u8868\u73b0\u826f\u597d\u4f46\u5728\u975e\u6807\u51c6\u8bed\u4e49\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u8868\u660e\u5176\u8bed\u4e49\u7406\u89e3\u4e0d\u591f\u9c81\u68d2\u3002", "motivation": "\u63a2\u7d22LLM\u80fd\u5426\u4ec5\u57fa\u4e8e\u7f16\u7a0b\u8bed\u8a00\u7684\u5f62\u5f0f\u8bed\u4e49\u6765\u6267\u884c\u7a0b\u5e8f\uff0c\u8fd9\u5c06\u6709\u52a9\u4e8e\u5feb\u901f\u539f\u578b\u5316\u65b0\u7f16\u7a0b\u8bed\u8a00\u548c\u8bed\u8a00\u7279\u6027\u3002", "method": "\u4f7f\u7528IMP\u8bed\u8a00\uff08C\u7684\u5b50\u96c6\uff09\uff0c\u901a\u8fc7\u5c0f\u6b65\u64cd\u4f5c\u8bed\u4e49\u548c\u57fa\u4e8e\u91cd\u5199\u7684\u64cd\u4f5c\u8bed\u4e49\u8fdb\u884c\u5f62\u5f0f\u5316\u3002\u521b\u5efa\u4e09\u4e2a\u8bc4\u4f30\u96c6\uff08\u4eba\u5de5\u7f16\u5199\u3001LLM\u7ffb\u8bd1\u3001\u6a21\u7cca\u751f\u6210\uff09\uff0c\u63a7\u5236\u4ee3\u7801\u590d\u6742\u5ea6\u3002\u8bc4\u4f30\u4e09\u4e2a\u4efb\u52a1\uff1a\u6700\u7ec8\u72b6\u6001\u9884\u6d4b\u3001\u8bed\u4e49\u89c4\u5219\u9884\u6d4b\u3001\u6267\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u5b9a\u4e49\u975e\u6807\u51c6\u8bed\u4e49\u6765\u533a\u5206\u9884\u8bad\u7ec3\u8bb0\u5fc6\u548c\u8bed\u4e49\u80fd\u529b\u3002", "result": "\u5f3a\u4ee3\u7801/\u63a8\u7406LLM\u5728\u6807\u51c6\u8bed\u4e49\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u975e\u6807\u51c6\u8bed\u4e49\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u6a21\u578b\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7a0b\u5e8f\u4e0a\u8868\u73b0\u6a21\u5f0f\u5316\uff1a\u5728\u7b80\u5355\u7a0b\u5e8f\u4e0a\u5f62\u5f0f\u8bed\u4e49\u6709\u5e2e\u52a9\uff0c\u4f46\u5728\u590d\u6742\u7a0b\u5e8f\u4e0a\u53cd\u800c\u6709\u5bb3\u3002\u63a8\u7406\u6a21\u578b\u5728\u7c97\u7c92\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u5904\u7406\u5d4c\u5957\u5faa\u73af\u6df1\u5ea6\u8d85\u8fc75\u7684\u590d\u6742\u7a0b\u5e8f\u3002", "conclusion": "LLM\u6709\u6f5c\u529b\u4f5c\u4e3a\u7f16\u7a0b\u8bed\u8a00\u89e3\u91ca\u5668\uff0c\u4f46\u5176\u8bed\u4e49\u7406\u89e3\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002\u53d1\u5e03\u4e86\u57fa\u51c6\u6d4b\u8bd5\u548c\u652f\u6301\u4ee3\u7801\u3002"}}
{"id": "2510.04049", "categories": ["cs.PL", "03B70, 68T27, 68T30"], "pdf": "https://arxiv.org/pdf/2510.04049", "abs": "https://arxiv.org/abs/2510.04049", "authors": ["Xiangyu Guo", "Ajay Bansal"], "title": "Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren", "comment": "12 pages, 2 figures, ICFP '25 The miniKanren and Relational\n  Programming Workshop", "summary": "This paper presents examples of using integrity constraints in stableKanren\nto encode numeric computations for problem solving. Then, we use one of the\nexamples to introduce multiple ways to infuse heuristic knowledge and reduce\nsolving time. stableKanren is an extension of miniKanren that supports normal\nlogic programs under stable model semantics. stableKanren further supports\nnumeric computation by constructing a constraint store for integrity\nconstraints. There are three ways to extend a relational programming language\nwith numeric computations: relational number representation, grounding numbers\nto symbols, and constraint store construction. We demonstrate that the numeric\ncomputations in stableKanren have a straightforward numerical representation\ncompared to relational number representations. More importantly, stableKanren\nbalances symbolic and numeric computation in relational programming by avoiding\nthe grounding of all numbers to symbols. Lastly, it also has simpler syntax\ncompared to other constraint store construction approaches. stableKanren\nsupports combinatorial search problem solving under a declarative generate and\ntest paradigm. Such a paradigm generates all possible combinations of solutions\nto the problem, then applies a set of constraints to prune out the unwanted\nsolutions. We demonstrate that different approaches to writing programs or\nqueries affect the solver's performance in the SEND+MORE=MONEY puzzle. The\nperformance gradually improves as more heuristic knowledge is infused through\nthe programs or queries. Additionally, we show how to use an external function\nto achieve a hybrid solution.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5728stableKanren\u4e2d\u4f7f\u7528\u5b8c\u6574\u6027\u7ea6\u675f\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u4ee5\u89e3\u51b3\u95ee\u9898\u7684\u793a\u4f8b\uff0c\u5e76\u4ecb\u7ecd\u4e86\u591a\u79cd\u6ce8\u5165\u542f\u53d1\u5f0f\u77e5\u8bc6\u4ee5\u51cf\u5c11\u6c42\u89e3\u65f6\u95f4\u7684\u65b9\u6cd5\u3002", "motivation": "\u6269\u5c55\u5173\u7cfb\u578b\u7f16\u7a0b\u8bed\u8a00\u4ee5\u652f\u6301\u6570\u503c\u8ba1\u7b97\uff0c\u5e76\u5e73\u8861\u7b26\u53f7\u4e0e\u6570\u503c\u8ba1\u7b97\uff0c\u907f\u514d\u5c06\u6240\u6709\u6570\u5b57\u8f6c\u6362\u4e3a\u7b26\u53f7\uff0c\u540c\u65f6\u7b80\u5316\u8bed\u6cd5\u3002", "method": "\u4f7f\u7528stableKanren\uff08miniKanren\u7684\u6269\u5c55\uff09\u6784\u5efa\u7ea6\u675f\u5b58\u50a8\u6765\u5b9e\u73b0\u5b8c\u6574\u6027\u7ea6\u675f\uff0c\u652f\u6301\u7ec4\u5408\u641c\u7d22\u95ee\u9898\u7684\u58f0\u660e\u5f0f\u751f\u6210\u548c\u6d4b\u8bd5\u8303\u5f0f\u3002", "result": "\u5c55\u793a\u4e86\u5728SEND+MORE=MONEY\u8c1c\u9898\u4e2d\uff0c\u4e0d\u540c\u7f16\u7a0b\u6216\u67e5\u8be2\u65b9\u6cd5\u5bf9\u6c42\u89e3\u5668\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u968f\u7740\u66f4\u591a\u542f\u53d1\u5f0f\u77e5\u8bc6\u7684\u6ce8\u5165\uff0c\u6027\u80fd\u9010\u6e10\u63d0\u5347\u3002", "conclusion": "stableKanren\u901a\u8fc7\u7ea6\u675f\u5b58\u50a8\u6784\u9020\u63d0\u4f9b\u4e86\u76f4\u63a5\u7684\u6570\u503c\u8868\u793a\uff0c\u5e73\u8861\u4e86\u7b26\u53f7\u548c\u6570\u503c\u8ba1\u7b97\uff0c\u5e76\u652f\u6301\u901a\u8fc7\u5916\u90e8\u51fd\u6570\u5b9e\u73b0\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04890", "categories": ["cs.PL", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.04890", "abs": "https://arxiv.org/abs/2510.04890", "authors": ["Shihan Fang", "Wenxin Zheng"], "title": "Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization", "comment": null, "summary": "Modern processors increasingly rely on SIMD instruction sets, such as AVX and\nRVV, to significantly enhance parallelism and computational performance.\nHowever, production-ready compilers like LLVM and GCC often fail to fully\nexploit available vectorization opportunities due to disjoint vectorization\npasses and limited extensibility. Although recent attempts in heuristics and\nintermediate representation (IR) designs have attempted to address these\nproblems, efficiently simplifying control flow analysis and accurately\nidentifying vectorization opportunities remain challenging tasks.\n  To address these issues, we introduce a novel vectorization pipeline\nfeaturing two specialized IR extensions: SIR, which encodes high-level\nstructural information, and VIR, which explicitly represents instruction\ndependencies through data dependency analysis. Leveraging the detailed\ndependency information provided by VIR, we develop a flexible and extensible\nvectorization framework. This approach substantially improves interoperability\nacross vectorization passes and expands the search space for identifying\nisomorphic instructions, ultimately enhancing both the scope and efficiency of\nautomatic vectorization. Experimental evaluations demonstrate that our proposed\nvectorization pipeline achieves significant performance improvements,\ndelivering speedups of up to 53% and 58% compared to LLVM and GCC,\nrespectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7SIR\u548cVIR\u4e24\u79cd\u4e13\u7528IR\u6269\u5c55\u6765\u6539\u8fdb\u63a7\u5236\u6d41\u5206\u6790\u548c\u6307\u4ee4\u4f9d\u8d56\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5411\u91cf\u5316\u7684\u8303\u56f4\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u4ee3\u5904\u7406\u5668\u4f9d\u8d56SIMD\u6307\u4ee4\u96c6\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u73b0\u6709\u7f16\u8bd1\u5668\u5982LLVM\u548cGCC\u7531\u4e8e\u5411\u91cf\u5316\u8fc7\u7a0b\u5206\u6563\u4e14\u6269\u5c55\u6027\u6709\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5411\u91cf\u5316\u673a\u4f1a\u3002\u63a7\u5236\u6d41\u5206\u6790\u548c\u5411\u91cf\u5316\u673a\u4f1a\u8bc6\u522b\u4ecd\u662f\u6311\u6218\u3002", "method": "\u5f15\u5165\u5305\u542bSIR\u548cVIR\u4e24\u79cdIR\u6269\u5c55\u7684\u65b0\u578b\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\u3002SIR\u7f16\u7801\u9ad8\u5c42\u6b21\u7ed3\u6784\u4fe1\u606f\uff0cVIR\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u5206\u6790\u663e\u5f0f\u8868\u793a\u6307\u4ee4\u4f9d\u8d56\u5173\u7cfb\u3002\u57fa\u4e8eVIR\u63d0\u4f9b\u7684\u8be6\u7ec6\u4f9d\u8d56\u4fe1\u606f\uff0c\u6784\u5efa\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u5411\u91cf\u5316\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u4e0eLLVM\u548cGCC\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\u5206\u522b\u5b9e\u73b0\u4e86\u9ad8\u8fbe53%\u548c58%\u7684\u6027\u80fd\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u4e13\u95e8\u7684IR\u6269\u5c55\u548c\u4f9d\u8d56\u5206\u6790\uff0c\u63d0\u51fa\u7684\u5411\u91cf\u5316\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u5411\u91cf\u5316\u8fc7\u7a0b\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u6269\u5c55\u4e86\u540c\u6784\u6307\u4ee4\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5411\u91cf\u5316\u7684\u8303\u56f4\u548c\u6548\u7387\u3002"}}
{"id": "2510.04994", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.04994", "abs": "https://arxiv.org/abs/2510.04994", "authors": ["Sjoerd Dost"], "title": "concurrentKanren: miniKanren for parallel execution", "comment": "13 pages, 1 figure, for associated repo see\n  https://github.com/deosjr/concurrentKanren", "summary": "Concurrent logic programming predates miniKanren, but concurrent\nimplementations of miniKanren have remained largely unexplored. In this work we\npresent a parallel implementation of miniKanren in Go, demonstrating its\nfeasibility and potential for performance improvements. Our approach leverages\nimplicit parallelism allowing legacy programs to benefit from parallel\nexecution. We discuss implementation strategies and evaluate the impact of\nparallelism, laying groundwork for future language-agnostic models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528Go\u8bed\u8a00\u5b9e\u73b0\u7684\u5e76\u884cminiKanren\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u53ca\u6027\u80fd\u63d0\u5347\u6f5c\u529b", "motivation": "\u867d\u7136\u5e76\u53d1\u903b\u8f91\u7f16\u7a0b\u65e9\u4e8eminiKanren\uff0c\u4f46miniKanren\u7684\u5e76\u53d1\u5b9e\u73b0\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22", "method": "\u5229\u7528\u9690\u5f0f\u5e76\u884c\u6027\uff0c\u5141\u8bb8\u9057\u7559\u7a0b\u5e8f\u4ece\u5e76\u884c\u6267\u884c\u4e2d\u53d7\u76ca\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b9e\u73b0\u7b56\u7565", "result": "\u8bc4\u4f30\u4e86\u5e76\u884c\u6027\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u4e86\u5e76\u884c\u5b9e\u73b0\u7684\u53ef\u884c\u6027", "conclusion": "\u4e3a\u672a\u6765\u8bed\u8a00\u65e0\u5173\u7684\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2510.04158", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.04158", "abs": "https://arxiv.org/abs/2510.04158", "authors": ["Emad Jacob Maroun"], "title": "A Dense and Efficient Instruction Set Architecture Encoding", "comment": null, "summary": "Instruction density and encoding efficiency are some of the few things\ndirectly affected by an instruction set architecture's design. In contrast, a\nprocessor's implementation often significantly influences performance, power\nefficiency, and area usage. Therefore, a major goal of instruction set design\nshould be maximizing instruction density and encoding efficiency. This paper\nintroduces the design elements of the Scry instruction set architecture that\nmost significantly affect instruction density and encoding efficiency. Scry is\na novel and experimental instruction set that revisits first principles to\ndesign an instruction set fit for modern processor implementations. Scry uses\nforward-temporal referencing as a means of data flow, where instructions refer\nto which future instructions consume their outputs. It also uses internal\ntagging, where the processors track data types internally, to reduce the number\nof instructions needed and increase flexibility. Combining these two methods,\nScry achieves instruction-feature parity with RISC-V's RV64IMC using only\n2-byte instructions compared to RISC-V's 4 bytes. Scry's instructions occupy\nonly 28% of the 2-byte encoding space, where RV64IMC instructions occupy 68% of\nthe 4-byte encoding space. We show that hand-compiled Scry's static instruction\ndensity is comparable to RV64IMC for small functions and improves as functions\ngrow in size.", "AI": {"tldr": "Scry\u6307\u4ee4\u96c6\u67b6\u6784\u901a\u8fc7\u524d\u5411\u65f6\u95f4\u5f15\u7528\u548c\u5185\u90e8\u6807\u8bb0\u6280\u672f\uff0c\u57282\u5b57\u8282\u6307\u4ee4\u7a7a\u95f4\u5185\u5b9e\u73b0\u4e86\u4e0eRISC-V RV64IMC 4\u5b57\u8282\u6307\u4ee4\u76f8\u5f53\u7684\u529f\u80fd\uff0c\u6307\u4ee4\u5bc6\u5ea6\u663e\u8457\u63d0\u9ad8\u3002", "motivation": "\u6307\u4ee4\u96c6\u8bbe\u8ba1\u5e94\u6700\u5927\u5316\u6307\u4ee4\u5bc6\u5ea6\u548c\u7f16\u7801\u6548\u7387\uff0c\u56e0\u4e3a\u8fd9\u4e24\u8005\u76f4\u63a5\u5f71\u54cd\u5904\u7406\u5668\u6027\u80fd\uff0c\u800c\u5b9e\u73b0\u7ec6\u8282\u901a\u5e38\u5f71\u54cd\u6027\u80fd\u3001\u529f\u8017\u548c\u9762\u79ef\u3002", "method": "\u91c7\u7528\u524d\u5411\u65f6\u95f4\u5f15\u7528\u4f5c\u4e3a\u6570\u636e\u6d41\u673a\u5236\uff0c\u6307\u4ee4\u5f15\u7528\u672a\u6765\u6d88\u8017\u5176\u8f93\u51fa\u7684\u6307\u4ee4\uff1b\u4f7f\u7528\u5185\u90e8\u6807\u8bb0\u6280\u672f\uff0c\u5904\u7406\u5668\u5185\u90e8\u8ddf\u8e2a\u6570\u636e\u7c7b\u578b\u4ee5\u51cf\u5c11\u6307\u4ee4\u6570\u91cf\u5e76\u63d0\u9ad8\u7075\u6d3b\u6027\u3002", "result": "Scry\u4ec5\u75282\u5b57\u8282\u6307\u4ee4\u5c31\u5b9e\u73b0\u4e86RISC-V RV64IMC\u7684\u529f\u80fd\uff0c\u5360\u752828%\u76842\u5b57\u8282\u7f16\u7801\u7a7a\u95f4\uff0c\u800cRISC-V\u5360\u752868%\u76844\u5b57\u8282\u7f16\u7801\u7a7a\u95f4\u3002\u624b\u7f16\u8bd1\u7684Scry\u9759\u6001\u6307\u4ee4\u5bc6\u5ea6\u5728\u5c0f\u51fd\u6570\u4e2d\u4e0eRV64IMC\u76f8\u5f53\uff0c\u968f\u51fd\u6570\u89c4\u6a21\u589e\u5927\u800c\u63d0\u9ad8\u3002", "conclusion": "Scry\u6307\u4ee4\u96c6\u901a\u8fc7\u521b\u65b0\u7684\u8bbe\u8ba1\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6307\u4ee4\u5bc6\u5ea6\u548c\u7f16\u7801\u6548\u7387\uff0c\u4e3a\u73b0\u4ee3\u5904\u7406\u5668\u5b9e\u73b0\u63d0\u4f9b\u4e86\u66f4\u4f18\u5316\u7684\u6307\u4ee4\u96c6\u67b6\u6784\u3002"}}
{"id": "2510.03557", "categories": ["cs.DC", "astro-ph.CO", "astro-ph.IM", "cs.PF", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.03557", "abs": "https://arxiv.org/abs/2510.03557", "authors": ["Nicholas Frontiere", "J. D. Emberson", "Michael Buehlmann", "Esteban M. Rangel", "Salman Habib", "Katrin Heitmann", "Patricia Larsen", "Vitali Morozov", "Adrian Pope", "Claude-Andr\u00e9 Faucher-Gigu\u00e8re", "Antigoni Georgiadou", "Damien Lebrun-Grandi\u00e9", "Andrey Prokopenko"], "title": "Cosmological Hydrodynamics at Exascale: A Trillion-Particle Leap in Capability", "comment": null, "summary": "Resolving the most fundamental questions in cosmology requires simulations\nthat match the scale, fidelity, and physical complexity demanded by\nnext-generation sky surveys. To achieve the realism needed for this critical\nscientific partnership, detailed gas dynamics, along with a host of\nastrophysical effects, must be treated self-consistently with gravity for\nend-to-end modeling of structure formation. As an important step on this\nroadmap, exascale computing enables simulations that span survey-scale volumes\nwhile incorporating key subgrid processes that shape complex cosmic structures.\nWe present results from CRK-HACC, a cosmological hydrodynamics code built for\nthe extreme scalability requirements set by modern cosmological surveys. Using\nseparation-of-scale techniques, GPU-resident tree solvers, in situ analysis\npipelines, and multi-tiered I/O, CRK-HACC executed Frontier-E: a four trillion\nparticle full-sky simulation, over an order of magnitude larger than previous\nefforts. The run achieved 513.1 PFLOPs peak performance, processing 46.6\nbillion particles per second and writing more than 100 PB of data in just over\none week of runtime.", "AI": {"tldr": "CRK-HACC\u662f\u4e00\u4e2a\u5b87\u5b99\u5b66\u6d41\u4f53\u52a8\u529b\u5b66\u4ee3\u7801\uff0c\u6267\u884c\u4e86Frontier-E\u6a21\u62df\uff1a\u4e00\u4e2a\u5305\u542b4\u4e07\u4ebf\u7c92\u5b50\u7684\u5168\u5929\u7a7a\u6a21\u62df\uff0c\u6bd4\u4ee5\u5f80\u52aa\u529b\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u5cf0\u503c\u6027\u80fd\u8fbe513.1 PFLOPs\uff0c\u5728\u4e00\u5468\u591a\u65f6\u95f4\u5185\u5904\u7406\u4e86466\u4ebf\u7c92\u5b50/\u79d2\u5e76\u5199\u5165\u8d85\u8fc7100PB\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u5b87\u5b99\u5b66\u4e2d\u6700\u57fa\u672c\u7684\u95ee\u9898\u9700\u8981\u4e0e\u4e0b\u4e00\u4ee3\u5929\u7a7a\u5de1\u5929\u76f8\u5339\u914d\u7684\u6a21\u62df\uff0c\u8981\u6c42\u5904\u7406\u8be6\u7ec6\u6c14\u4f53\u52a8\u529b\u5b66\u548c\u5929\u4f53\u7269\u7406\u6548\u5e94\uff0c\u4e0e\u5f15\u529b\u81ea\u6d3d\u5730\u5efa\u6a21\u7ed3\u6784\u5f62\u6210\u3002", "method": "\u4f7f\u7528\u5c3a\u5ea6\u5206\u79bb\u6280\u672f\u3001GPU\u9a7b\u7559\u6811\u6c42\u89e3\u5668\u3001\u539f\u4f4d\u5206\u6790\u7ba1\u9053\u548c\u591a\u5c42I/O\uff0c\u6784\u5efa\u4e86CRK-HACC\u5b87\u5b99\u5b66\u6d41\u4f53\u52a8\u529b\u5b66\u4ee3\u7801\u3002", "result": "\u6267\u884c\u4e86Frontier-E\u6a21\u62df\uff1a4\u4e07\u4ebf\u7c92\u5b50\u5168\u5929\u7a7a\u6a21\u62df\uff0c\u5cf0\u503c\u6027\u80fd513.1 PFLOPs\uff0c\u5904\u7406\u901f\u5ea646.6\u4ebf\u7c92\u5b50/\u79d2\uff0c\u5199\u5165\u6570\u636e\u8d85\u8fc7100PB\u3002", "conclusion": "\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u4f7f\u5f97\u80fd\u591f\u5728\u5de1\u5929\u5c3a\u5ea6\u4f53\u79ef\u4e2d\u8fd0\u884c\u6a21\u62df\uff0c\u540c\u65f6\u7eb3\u5165\u5851\u9020\u590d\u6742\u5b87\u5b99\u7ed3\u6784\u7684\u5173\u952e\u5b50\u7f51\u683c\u8fc7\u7a0b\uff0c\u8fd9\u662f\u5b9e\u73b0\u6240\u9700\u771f\u5b9e\u611f\u7684\u91cd\u8981\u6b65\u9aa4\u3002"}}
{"id": "2510.03872", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.03872", "abs": "https://arxiv.org/abs/2510.03872", "authors": ["Sreedhar Narayanaswamy", "Pratikkumar Dilipkumar Patel", "Ian Karlin", "Apoorv Gupta", "Sudhir Saripalli", "Janey Guo"], "title": "Datacenter Energy Optimized Power Profiles", "comment": null, "summary": "This paper presents datacenter power profiles, a new NVIDIA software feature\nreleased with Blackwell B200, aimed at improving energy efficiency and/or\nperformance. The initial feature provides coarse-grain user control for HPC and\nAI workloads leveraging hardware and software innovations for intelligent power\nmanagement and domain knowledge of HPC and AI workloads. The resulting\nworkload-aware optimization recipes maximize computational throughput while\noperating within strict facility power constraints. The phase-1 Blackwell\nimplementation achieves up to 15% energy savings while maintaining performance\nlevels above 97% for critical applications, enabling an overall throughput\nincrease of up to 13% in a power-constrained facility.\n  KEYWORDS GPU power management, energy efficiency, power profile, HPC\noptimization, Max-Q, Blackwell architecture", "AI": {"tldr": "NVIDIA\u63a8\u51faBlackwell B200\u7684\u6570\u636e\u4e2d\u5fc3\u7535\u6e90\u914d\u7f6e\u6587\u4ef6\u529f\u80fd\uff0c\u901a\u8fc7\u667a\u80fd\u7535\u6e90\u7ba1\u7406\u548cHPC/AI\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\uff0c\u5728\u529f\u7387\u53d7\u9650\u8bbe\u65bd\u4e2d\u5b9e\u73b0\u9ad8\u8fbe15%\u7684\u8282\u80fd\u548c13%\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u4e2d\u5fc3\u5728\u4e25\u683c\u529f\u7387\u9650\u5236\u4e0b\u5982\u4f55\u5e73\u8861\u80fd\u6e90\u6548\u7387\u548c\u6027\u80fd\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728HPC\u548cAI\u5de5\u4f5c\u8d1f\u8f7d\u573a\u666f\u4e2d\u3002", "method": "\u5229\u7528Blackwell\u67b6\u6784\u7684\u786c\u4ef6\u548c\u8f6f\u4ef6\u521b\u65b0\uff0c\u63d0\u4f9b\u7c97\u7c92\u5ea6\u7684\u7528\u6237\u63a7\u5236\uff0c\u7ed3\u5408HPC\u548cAI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9886\u57df\u77e5\u8bc6\u8fdb\u884c\u667a\u80fd\u7535\u6e90\u7ba1\u7406\u3002", "result": "Blackwell\u7b2c\u4e00\u9636\u6bb5\u5b9e\u73b0\u9ad8\u8fbe15%\u7684\u8282\u80fd\uff0c\u5173\u952e\u5e94\u7528\u6027\u80fd\u4fdd\u6301\u572897%\u4ee5\u4e0a\uff0c\u5728\u529f\u7387\u53d7\u9650\u8bbe\u65bd\u4e2d\u603b\u4f53\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe13%\u3002", "conclusion": "\u6570\u636e\u4e2d\u5fc3\u7535\u6e90\u914d\u7f6e\u6587\u4ef6\u529f\u80fd\u4e3a\u529f\u7387\u53d7\u9650\u73af\u5883\u4e2d\u7684HPC\u548cAI\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u80fd\u6e90\u6548\u7387\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2510.03891", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.03891", "abs": "https://arxiv.org/abs/2510.03891", "authors": ["Shawn Shuoshuo Chen", "Daiyaan Arfeen", "Minlan Yu", "Peter Steenkiste", "Srinivasan Seshan"], "title": "Toward Co-adapting Machine Learning Job Shape and Cluster Topology", "comment": null, "summary": "Allocating resources to distributed machine learning jobs in multi-tenant\ntorus-topology clusters must meet each job's specific placement and\ncommunication requirements, which are typically described using shapes. There\nis an inherent tension between minimizing network contention and maximizing\ncluster utilization when placing various-shaped jobs. While existing schedulers\ntypically optimize for one objective at the expense of the other, we\ndemonstrate that both can be achieved simultaneously.\n  Our proposed approach, RFold, adapts both job shapes and the underlying\ncluster topology at runtime. This is accomplished by combining two techniques:\n(1) identifying homomorphic job shapes that support the jobs communication\nneeds, and (2) reconfiguring the optical circuit switch-enabled topology to\nsupport more diverse job shapes. Preliminary evaluation performed on a\n4096-node torus cluster simulator indicates that RFold can improve absolute\ncluster utilization by 57% and reduce job completion time by up to 11x relative\nto existing methods", "AI": {"tldr": "RFold\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u540c\u65f6\u8c03\u6574\u4f5c\u4e1a\u5f62\u72b6\u548c\u96c6\u7fa4\u62d3\u6251\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u4f5c\u4e1a\u8c03\u5ea6\u4e2d\u7f51\u7edc\u4e89\u7528\u6700\u5c0f\u5316\u548c\u96c6\u7fa4\u5229\u7528\u7387\u6700\u5927\u5316\u4e4b\u95f4\u7684\u56fa\u6709\u77db\u76fe\u3002", "motivation": "\u5728\u591a\u79df\u6237\u73af\u9762\u62d3\u6251\u96c6\u7fa4\u4e2d\u5206\u914d\u8d44\u6e90\u65f6\uff0c\u73b0\u6709\u8c03\u5ea6\u5668\u901a\u5e38\u53ea\u80fd\u4f18\u5316\u4e00\u4e2a\u76ee\u6807\uff08\u6700\u5c0f\u5316\u7f51\u7edc\u4e89\u7528\u6216\u6700\u5927\u5316\u96c6\u7fa4\u5229\u7528\u7387\uff09\uff0c\u800c\u727a\u7272\u53e6\u4e00\u4e2a\u76ee\u6807\u3002", "method": "RFold\u7ed3\u5408\u4e24\u79cd\u6280\u672f\uff1a(1)\u8bc6\u522b\u652f\u6301\u4f5c\u4e1a\u901a\u4fe1\u9700\u6c42\u7684\u540c\u6784\u4f5c\u4e1a\u5f62\u72b6\uff1b(2)\u91cd\u65b0\u914d\u7f6e\u652f\u6301\u5149\u5b66\u7535\u8def\u4ea4\u6362\u7684\u62d3\u6251\u4ee5\u652f\u6301\u66f4\u591a\u6837\u5316\u7684\u4f5c\u4e1a\u5f62\u72b6\u3002", "result": "\u57284096\u8282\u70b9\u73af\u9762\u96c6\u7fa4\u6a21\u62df\u5668\u4e0a\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0cRFold\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53ef\u5c06\u7edd\u5bf9\u96c6\u7fa4\u5229\u7528\u7387\u63d0\u9ad857%\uff0c\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u6700\u591a\u51cf\u5c1111\u500d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7f51\u7edc\u4e89\u7528\u6700\u5c0f\u5316\u548c\u96c6\u7fa4\u5229\u7528\u7387\u6700\u5927\u5316\u8fd9\u4e24\u4e2a\u76ee\u6807\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4f5c\u4e1a\u5f62\u72b6\u548c\u96c6\u7fa4\u62d3\u6251\u6765\u8fbe\u6210\u8fd9\u4e00\u76ee\u6807\u3002"}}
{"id": "2510.03970", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03970", "abs": "https://arxiv.org/abs/2510.03970", "authors": ["Zainab Saad", "Jialin Yang", "Henry Leung", "Steve Drew"], "title": "Towards Carbon-Aware Container Orchestration: Predicting Workload Energy Consumption with Federated Learning", "comment": "Accepted to 2025 IEEE Smart World Congress (SWC 2025)", "summary": "The growing reliance on large-scale data centers to run resource-intensive\nworkloads has significantly increased the global carbon footprint, underscoring\nthe need for sustainable computing solutions. While container orchestration\nplatforms like Kubernetes help optimize workload scheduling to reduce carbon\nemissions, existing methods often depend on centralized machine learning models\nthat raise privacy concerns and struggle to generalize across diverse\nenvironments. In this paper, we propose a federated learning approach for\nenergy consumption prediction that preserves data privacy by keeping sensitive\noperational data within individual enterprises. By extending the Kubernetes\nEfficient Power Level Exporter (Kepler), our framework trains XGBoost models\ncollaboratively across distributed clients using Flower's FedXgbBagging\naggregation using a bagging strategy, eliminating the need for centralized data\nsharing. Experimental results on the SPECPower benchmark dataset show that our\nFL-based approach achieves 11.7 percent lower Mean Absolute Error compared to a\ncentralized baseline. This work addresses the unresolved trade-off between data\nprivacy and energy prediction efficiency in prior systems such as Kepler and\nCASPER and offers enterprises a viable pathway toward sustainable cloud\ncomputing without compromising operational privacy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u80fd\u8017\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u6bd4\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\uff08MAE\u964d\u4f4e11.7%\uff09\uff0c\u89e3\u51b3\u4e86Kepler\u548cCASPER\u7b49\u7cfb\u7edf\u4e2d\u9690\u79c1\u4e0e\u80fd\u6548\u9884\u6d4b\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u589e\u52a0\u5bfc\u81f4\u78b3\u8db3\u8ff9\u589e\u957f\uff0c\u73b0\u6709Kubernetes\u8c03\u5ea6\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u4e14\u96be\u4ee5\u8de8\u73af\u5883\u6cdb\u5316\u3002", "method": "\u6269\u5c55Kubernetes Efficient Power Level Exporter (Kepler)\uff0c\u4f7f\u7528Flower\u7684FedXgbBagging\u805a\u5408\u7b56\u7565\uff0c\u5728\u5206\u5e03\u5f0f\u5ba2\u6237\u7aef\u4e0a\u534f\u4f5c\u8bad\u7ec3XGBoost\u6a21\u578b\uff0c\u65e0\u9700\u96c6\u4e2d\u5171\u4eab\u6570\u636e\u3002", "result": "\u5728SPECPower\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u6bd4\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u964d\u4f4e\u4e8611.7%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4f01\u4e1a\u5728\u4e0d\u727a\u7272\u8fd0\u8425\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u53ef\u6301\u7eed\u4e91\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u7cfb\u7edf\u4e2d\u6570\u636e\u9690\u79c1\u4e0e\u80fd\u8017\u9884\u6d4b\u6548\u7387\u4e4b\u95f4\u7684\u672a\u89e3\u6743\u8861\u3002"}}
{"id": "2510.04186", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04186", "abs": "https://arxiv.org/abs/2510.04186", "authors": ["Xuan Jiang", "Xuanyu Zhou", "Yibo Zhao", "Shangqing Cao", "Jinhua Zhao", "Mark Hansen", "Raja Sengupta"], "title": "From Patchwork to Network: A Comprehensive Framework for Demand Analysis and Fleet Optimization of Urban Air Mobility", "comment": null, "summary": "Urban Air Mobility (UAM) presents a transformative vision for metropolitan\ntransportation, but its practical implementation is hindered by substantial\ninfrastructure costs and operational complexities. We address these challenges\nby modeling a UAM network that leverages existing regional airports and\noperates with an optimized, heterogeneous fleet of aircraft. We introduce\nLPSim, a Large-Scale Parallel Simulation framework that utilizes multi-GPU\ncomputing to co-optimize UAM demand, fleet operations, and ground\ntransportation interactions simultaneously. Our equilibrium search algorithm is\nextended to accurately forecast demand and determine the most efficient fleet\ncomposition. Applied to a case study of the San Francisco Bay Area, our results\ndemonstrate that this UAM model can yield over 20 minutes' travel time savings\nfor 230,000 selected trips. However, the analysis also reveals that system-wide\nsuccess is critically dependent on seamless integration with ground access and\ndynamic scheduling.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5229\u7528\u73b0\u6709\u533a\u57df\u673a\u573a\u548c\u4f18\u5316\u5f02\u6784\u673a\u961f\u7684UAM\u7f51\u7edc\u6a21\u578b\uff0c\u901a\u8fc7LPSim\u5e76\u884c\u4eff\u771f\u6846\u67b6\u540c\u65f6\u4f18\u5316\u9700\u6c42\u3001\u8fd0\u8425\u548c\u5730\u9762\u4ea4\u901a\u4ea4\u4e92\uff0c\u5728\u65e7\u91d1\u5c71\u6e7e\u533a\u6848\u4f8b\u4e2d\u53ef\u4e3a23\u4e07\u6b21\u51fa\u884c\u8282\u770120\u5206\u949f\u4ee5\u4e0a\u65f6\u95f4\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u9ad8\u548c\u8fd0\u8425\u590d\u6742\u6027\u7684\u6311\u6218\uff0c\u5b9e\u73b0UAM\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f00\u53d1LPSim\u5927\u89c4\u6a21\u5e76\u884c\u4eff\u771f\u6846\u67b6\uff0c\u4f7f\u7528\u591aGPU\u8ba1\u7b97\u540c\u65f6\u4f18\u5316UAM\u9700\u6c42\u3001\u673a\u961f\u8fd0\u8425\u548c\u5730\u9762\u4ea4\u901a\u4ea4\u4e92\uff0c\u6269\u5c55\u5747\u8861\u641c\u7d22\u7b97\u6cd5\u9884\u6d4b\u9700\u6c42\u548c\u786e\u5b9a\u6700\u4f18\u673a\u961f\u7ec4\u6210\u3002", "result": "\u5728\u65e7\u91d1\u5c71\u6e7e\u533a\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5UAM\u6a21\u578b\u53ef\u4e3a23\u4e07\u6b21\u9009\u5b9a\u51fa\u884c\u8282\u7701\u8d85\u8fc720\u5206\u949f\u65c5\u884c\u65f6\u95f4\u3002", "conclusion": "UAM\u7cfb\u7edf\u7684\u6210\u529f\u5173\u952e\u4f9d\u8d56\u4e8e\u4e0e\u5730\u9762\u4ea4\u901a\u7684\u65e0\u7f1d\u96c6\u6210\u548c\u52a8\u6001\u8c03\u5ea6\u3002"}}
{"id": "2510.04310", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04310", "abs": "https://arxiv.org/abs/2510.04310", "authors": ["Hagit Attiya", "Itay Flam", "Jennifer L. Welch"], "title": "Beyond Canonical Rounds: Communication Abstractions for Optimal Byzantine Resilience", "comment": "31 pages, 4 figures, 1 table, 5 algorithms", "summary": "We study communication abstractions for asynchronous Byzantine fault\ntolerance with optimal failure resilience, where $n > 3f$. Two classic patterns\n-- canonical asynchronous rounds and communication-closed layers -- have long\nbeen considered as general frameworks for designing distributed algorithms,\nmaking asynchronous executions appear synchronous and enabling modular\nreasoning.\n  We show that these patterns are inherently limited in the critical resilience\nregime $3f < n \\le 5f$. Several key tasks -- such as approximate and crusader\nagreement, reliable broadcast and gather -- cannot be solved by bounded-round\ncanonical-round algorithms, and are unsolvable if communication closure is\nimposed. These results explain the historical difficulty of achieving\noptimal-resilience algorithms within round-based frameworks.\n  On the positive side, we show that the gather abstraction admits\nconstant-time solutions with optimal resilience ($n > 3f$), and supports\nmodular reductions. Specifically, we present the first optimally-resilient\nalgorithm for connected consensus by reducing it to gather.\n  Our results demonstrate that while round-based abstractions are analytically\nconvenient, they obscure the true complexity of Byzantine fault-tolerant\nalgorithms. Richer communication patterns such as gather provide a better\nfoundation for modular, optimal-resilience design.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u7cfb\u7edf\u4e2d\u901a\u4fe1\u62bd\u8c61\u6a21\u5f0f\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u5728\u5173\u952e\u5f39\u6027\u8303\u56f43f < n \u2264 5f\u5185\uff0c\u7ecf\u5178\u7684\u5f02\u6b65\u8f6e\u6b21\u548c\u901a\u4fe1\u95ed\u5305\u6a21\u5f0f\u5b58\u5728\u56fa\u6709\u5c40\u9650\uff0c\u800cgather\u62bd\u8c61\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u57fa\u7840\u3002", "motivation": "\u63a2\u7d22\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u7cfb\u7edf\u4e2d\u901a\u4fe1\u62bd\u8c61\u6a21\u5f0f\u7684\u9002\u7528\u6027\uff0c\u89e3\u91ca\u4e3a\u4f55\u5728\u6700\u4f18\u5f39\u6027(n > 3f)\u4e0b\uff0c\u4f20\u7edf\u7684\u8f6e\u6b21\u6846\u67b6\u96be\u4ee5\u5b9e\u73b0\u67d0\u4e9b\u5173\u952e\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u7ecf\u5178\u5f02\u6b65\u8f6e\u6b21\u548c\u901a\u4fe1\u95ed\u5305\u6a21\u5f0f\u57283f < n \u2264 5f\u8303\u56f4\u5185\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fagather\u62bd\u8c61\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fde\u63a5\u5171\u8bc6\u95ee\u9898\u5f52\u7ea6\u5230gather\u3002", "result": "\u53d1\u73b0\u8fd1\u4f3c\u5171\u8bc6\u3001\u5341\u5b57\u519b\u5171\u8bc6\u3001\u53ef\u9760\u5e7f\u64ad\u548cgather\u7b49\u5173\u952e\u4efb\u52a1\u65e0\u6cd5\u901a\u8fc7\u6709\u9650\u8f6e\u6b21\u7684\u89c4\u8303\u8f6e\u7b97\u6cd5\u89e3\u51b3\uff0c\u5728\u901a\u4fe1\u95ed\u5305\u6761\u4ef6\u4e0b\u4e0d\u53ef\u89e3\u3002\u540c\u65f6\u5c55\u793a\u4e86gather\u62bd\u8c61\u5728\u6700\u4f18\u5f39\u6027\u4e0b\u53ef\u5b9e\u73b0\u5e38\u6570\u65f6\u95f4\u89e3\u3002", "conclusion": "\u8f6e\u6b21\u62bd\u8c61\u867d\u7136\u5206\u6790\u65b9\u4fbf\uff0c\u4f46\u63a9\u76d6\u4e86\u62dc\u5360\u5ead\u5bb9\u9519\u7b97\u6cd5\u7684\u771f\u5b9e\u590d\u6742\u6027\uff0c\u800c\u66f4\u4e30\u5bcc\u7684\u901a\u4fe1\u6a21\u5f0f\u5982gather\u4e3a\u6a21\u5757\u5316\u6700\u4f18\u5f39\u6027\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u7840\u3002"}}
{"id": "2510.04404", "categories": ["cs.DC", "cs.PF", "68M14, 68T05, 90C59", "C.2.4; D.4.4; D.4.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.04404", "abs": "https://arxiv.org/abs/2510.04404", "authors": ["Jahidul Arafat", "Fariha Tasmin", "Sanjaya Poudel", "Ahsan Habib Tareq"], "title": "Next-Generation Event-Driven Architectures: Performance, Scalability, and Intelligent Orchestration Across Messaging Frameworks", "comment": "45 pages, 8 tables, 1 figure. Comprehensive evaluation of 12\n  messaging frameworks with AI-enhanced orchestration system", "summary": "Modern distributed systems demand low-latency, fault-tolerant event\nprocessing that exceeds traditional messaging architecture limits. While\nframeworks including Apache Kafka, RabbitMQ, Apache Pulsar, NATS JetStream, and\nserverless event buses have matured significantly, no unified comparative study\nevaluates them holistically under standardized conditions. This paper presents\nthe first comprehensive benchmarking framework evaluating 12 messaging systems\nacross three representative workloads: e-commerce transactions, IoT telemetry\ningestion, and AI inference pipelines. We introduce AIEO (AI-Enhanced Event\nOrchestration), employing machine learning-driven predictive scaling,\nreinforcement learning for dynamic resource allocation, and multi-objective\noptimization. Our evaluation reveals fundamental trade-offs: Apache Kafka\nachieves peak throughput (1.2M messages/sec, 18ms p95 latency) but requires\nsubstantial operational expertise; Apache Pulsar provides balanced performance\n(950K messages/sec, 22ms p95) with superior multi-tenancy; serverless solutions\noffer elastic scaling for variable workloads despite higher baseline latency\n(80-120ms p95). AIEO demonstrates 34\\% average latency reduction, 28\\% resource\nutilization improvement, and 42% cost optimization across all platforms. We\ncontribute standardized benchmarking methodologies, open-source intelligent\norchestration, and evidence-based decision guidelines. The evaluation\nencompasses 2,400+ experimental configurations with rigorous statistical\nanalysis, providing comprehensive performance characterization and establishing\nfoundations for next-generation distributed system design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u9762\u7684\u6d88\u606f\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc4\u4f3012\u4e2a\u7cfb\u7edf\u5728\u4e09\u79cd\u5178\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u5f15\u5165AIEO\u667a\u80fd\u7f16\u6392\u7cfb\u7edf\uff0c\u663e\u8457\u4f18\u5316\u5ef6\u8fdf\u3001\u8d44\u6e90\u5229\u7528\u7387\u548c\u6210\u672c\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u9700\u8981\u4f4e\u5ef6\u8fdf\u3001\u5bb9\u9519\u7684\u4e8b\u4ef6\u5904\u7406\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e3b\u6d41\u6d88\u606f\u7cfb\u7edf\u7684\u7edf\u4e00\u6807\u51c6\u5316\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u8bc4\u4f3012\u4e2a\u6d88\u606f\u7cfb\u7edf\uff0c\u5f15\u5165AIEO\u7cfb\u7edf\uff08\u91c7\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7f29\u653e\u3001\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u591a\u76ee\u6807\u4f18\u5316\uff09\u3002", "result": "\u53d1\u73b0\u5404\u7cfb\u7edf\u6027\u80fd\u6743\u8861\uff1aKafka\u541e\u5410\u91cf\u6700\u9ad8\u4f46\u8fd0\u7ef4\u590d\u6742\uff0cPulsar\u6027\u80fd\u5747\u8861\u652f\u6301\u591a\u79df\u6237\uff0c\u65e0\u670d\u52a1\u5668\u65b9\u6848\u5f39\u6027\u597d\u4f46\u5ef6\u8fdf\u8f83\u9ad8\u3002AIEO\u5b9e\u73b034%\u5ef6\u8fdf\u964d\u4f4e\u300128%\u8d44\u6e90\u5229\u7528\u7387\u63d0\u5347\u548c42%\u6210\u672c\u4f18\u5316\u3002", "conclusion": "\u8d21\u732e\u4e86\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3001\u5f00\u6e90\u667a\u80fd\u7f16\u6392\u7cfb\u7edf\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u51b3\u7b56\u6307\u5357\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.04644", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04644", "abs": "https://arxiv.org/abs/2510.04644", "authors": ["Hirotsugu Kakugawa", "Sayaka Kamei", "Masahiro Shibata", "Fukuhito Ooshita"], "title": "The R(1)W(1) Communication Model for Self-Stabilizing Distributed Algorithms", "comment": null, "summary": "Self-stabilization is a versatile methodology in the design of fault-tolerant\ndistributed algorithms for transient faults. A self-stabilizing system\nautomatically recovers from any kind and any finite number of transient faults.\nThis property is specifically useful in modern distributed systems with a large\nnumber of components. In this paper, we propose a new communication and\nexecution model named the R(1)W(1) model in which each process can read and\nwrite its own and neighbors' local variables in a single step. We propose\nself-stabilizing distributed algorithms in the R(1)W(1) model for the problems\nof maximal matching, minimal k-dominating set and maximal k-dependent set.\nFinally, we propose an example transformer, based on randomized distance-two\nlocal mutual exclusion, to simulate algorithms designed for the R(1)W(1) model\nin the synchronous message passing model with synchronized clocks.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684R(1)W(1)\u901a\u4fe1\u6267\u884c\u6a21\u578b\uff0c\u8bbe\u8ba1\u81ea\u7a33\u5b9a\u5206\u5e03\u5f0f\u7b97\u6cd5\u89e3\u51b3\u6700\u5927\u5339\u914d\u3001\u6700\u5c0fk\u652f\u914d\u96c6\u548c\u6700\u5927k\u4f9d\u8d56\u96c6\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u968f\u673a\u8ddd\u79bb\u4e8c\u5c40\u90e8\u4e92\u65a5\u7684\u8f6c\u6362\u5668\u6765\u5728\u540c\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\u4e2d\u6a21\u62dfR(1)W(1)\u6a21\u578b\u7b97\u6cd5\u3002", "motivation": "\u81ea\u7a33\u5b9a\u662f\u8bbe\u8ba1\u5bb9\u9519\u5206\u5e03\u5f0f\u7b97\u6cd5\u7684\u91cd\u8981\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u4efb\u4f55\u7c7b\u578b\u548c\u6709\u9650\u6570\u91cf\u7684\u77ac\u65f6\u6545\u969c\u4e2d\u81ea\u52a8\u6062\u590d\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002", "method": "\u63d0\u51faR(1)W(1)\u6a21\u578b\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u5728\u5355\u6b65\u4e2d\u8bfb\u5199\u81ea\u8eab\u548c\u90bb\u5c45\u7684\u5c40\u90e8\u53d8\u91cf\uff1b\u8bbe\u8ba1\u81ea\u7a33\u5b9a\u5206\u5e03\u5f0f\u7b97\u6cd5\uff1b\u5f00\u53d1\u57fa\u4e8e\u968f\u673a\u8ddd\u79bb\u4e8c\u5c40\u90e8\u4e92\u65a5\u7684\u8f6c\u6362\u5668\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u4e86\u5728R(1)W(1)\u6a21\u578b\u4e0b\u7684\u81ea\u7a33\u5b9a\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u6700\u5927\u5339\u914d\u3001\u6700\u5c0fk\u652f\u914d\u96c6\u548c\u6700\u5927k\u4f9d\u8d56\u96c6\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u5411\u540c\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\u7684\u8f6c\u6362\u3002", "conclusion": "R(1)W(1)\u6a21\u578b\u4e3a\u81ea\u7a33\u5b9a\u5206\u5e03\u5f0f\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u8f6c\u6362\u5668\u6269\u5c55\u4e86\u81ea\u7a33\u5b9a\u7406\u8bba\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
