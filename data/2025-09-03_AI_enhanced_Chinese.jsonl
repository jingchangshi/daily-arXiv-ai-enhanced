{"id": "2509.00360", "categories": ["cs.PL", "D.3.0"], "pdf": "https://arxiv.org/pdf/2509.00360", "abs": "https://arxiv.org/abs/2509.00360", "authors": ["Shaan Nagy", "Timothy Zhou", "Nadia Polikarpova", "Loris D'Antoni"], "title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "comment": null, "summary": "Language models (LMs) can generate code, but cannot guarantee its\ncorrectness--producing outputs that often violate type safety, program\ninvariants, or semantic equivalence. Constrained decoding offers a solution by\nrestricting generation to programs that satisfy desired properties. Yet,\nexisting methods are limited to shallow syntactic constraints or rely on\nbrittle, ad hoc encodings of semantics over token sequences.\n  We present ChopChop, the first programmable framework for semantic\nconstrained decoding, enabling LMs to generate code that provably satisfies\nrich semantic properties. ChopChop connects token-level generation with\nreasoning over abstract program structures using a coinduction-based formalism\nand reduces constraint enforcement to a realizability problem over regular\ncodata. We demonstrate ChopChop's generality through generation constrained by\ntype safety and program equivalence, showing how formal methods can be\nseamlessly integrated into LM-driven code generation. ChopChop transforms\nsemantic constrained decoding from a niche technique into a systematic,\nprincipled extension of LMs--improving success rates across models and tasks\nwhile maintaining practical decoding latency.", "AI": {"tldr": "ChopChop\u662f\u4e00\u4e2a\u53ef\u7f16\u7a0b\u7684\u8bed\u4e49\u7ea6\u675f\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u8fde\u63a5token\u7ea7\u751f\u6210\u548c\u62bd\u8c61\u7a0b\u5e8f\u7ed3\u6784\u63a8\u7406\uff0c\u786e\u4fdd\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u6ee1\u8db3\u4e30\u5bcc\u7684\u8bed\u4e49\u5c5e\u6027\uff0c\u5982\u7c7b\u578b\u5b89\u5168\u548c\u7a0b\u5e8f\u7b49\u4ef7\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u65e0\u6cd5\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u7ecf\u5e38\u8fdd\u53cd\u7c7b\u578b\u5b89\u5168\u3001\u7a0b\u5e8f\u4e0d\u53d8\u91cf\u6216\u8bed\u4e49\u7b49\u4ef7\u6027\u3002\u73b0\u6709\u7684\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u4ec5\u9650\u4e8e\u6d45\u5c42\u8bed\u6cd5\u7ea6\u675f\u6216\u4f9d\u8d56\u8106\u5f31\u7684\u8bed\u4e49\u7f16\u7801\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5171\u5f52\u7eb3\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5c06token\u7ea7\u751f\u6210\u4e0e\u62bd\u8c61\u7a0b\u5e8f\u7ed3\u6784\u63a8\u7406\u8fde\u63a5\u8d77\u6765\uff0c\u5c06\u7ea6\u675f\u6267\u884c\u7b80\u5316\u4e3a\u6b63\u5219\u5171\u6570\u636e\u4e0a\u7684\u53ef\u5b9e\u73b0\u6027\u95ee\u9898\u3002", "result": "ChopChop\u5c06\u8bed\u4e49\u7ea6\u675f\u89e3\u7801\u4ece\u5c0f\u4f17\u6280\u672f\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u5316\u3001\u539f\u5219\u6027\u7684\u8bed\u8a00\u6a21\u578b\u6269\u5c55\uff0c\u63d0\u9ad8\u4e86\u8de8\u6a21\u578b\u548c\u4efb\u52a1\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u7684\u89e3\u7801\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230LM\u9a71\u52a8\u7684\u4ee3\u7801\u751f\u6210\u4e2d\uff0c\u4e3a\u751f\u6210\u53ef\u8bc1\u660e\u6ee1\u8db3\u4e30\u5bcc\u8bed\u4e49\u5c5e\u6027\u7684\u4ee3\u7801\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00587", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.00587", "abs": "https://arxiv.org/abs/2509.00587", "authors": ["Vaibhav Mehta", "Justin Hsu"], "title": "A Hoare Logic for Symmetry Properties", "comment": "Accepted to OOPSLA '25", "summary": "Many natural program correctness properties can be stated in terms of\n  symmetries, but existing formal methods have little support for reasoning\n  about such properties. We consider how to formally verify a broad class of\n  symmetry properties expressed in terms of group actions. To specify these\n  properties, we design a syntax for group actions, supporting standard\n  constructions and a natural notion of entailment. Then, we develop a\n  Hoare-style logic for verifying symmetry properties of imperative programs,\n  where group actions take the place of the typical pre- and post-condition\n  assertions. Finally, we develop a prototype tool $\\mathsf{SymVerif}$, and use\n  it to verify symmetry properties on a series of handcrafted benchmarks. Our\n  tool uncovered an error in a model of a dynamical system described by\n\\citet{McLachlan_Quispel_2002}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9a8c\u8bc1\u7a0b\u5e8f\u5bf9\u79f0\u6027\u5c5e\u6027\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u5de5\u5177\uff0c\u901a\u8fc7\u7fa4\u52a8\u4f5c\u8bed\u6cd5\u548cHoare\u98ce\u683c\u903b\u8f91\u6765\u9a8c\u8bc1\u5bf9\u79f0\u6027\u5c5e\u6027", "motivation": "\u73b0\u6709\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u5bf9\u5bf9\u79f0\u6027\u5c5e\u6027\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u800c\u8bb8\u591a\u7a0b\u5e8f\u6b63\u786e\u6027\u5c5e\u6027\u90fd\u53ef\u4ee5\u7528\u5bf9\u79f0\u6027\u6765\u8868\u8fbe", "method": "\u8bbe\u8ba1\u4e86\u7fa4\u52a8\u4f5c\u8bed\u6cd5\u6765\u6307\u5b9a\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u5f00\u53d1\u4e86Hoare\u98ce\u683c\u7684\u903b\u8f91\u6765\u9a8c\u8bc1\u547d\u4ee4\u5f0f\u7a0b\u5e8f\u7684\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u539f\u578b\u5de5\u5177SymVerif", "result": "\u5728\u624b\u5de5\u5236\u4f5c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u9a8c\u8bc1\u4e86\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u5e76\u53d1\u73b0\u4e86McLachlan\u548cQuispel(2002)\u63cf\u8ff0\u7684\u52a8\u6001\u7cfb\u7edf\u6a21\u578b\u4e2d\u7684\u4e00\u4e2a\u9519\u8bef", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9a8c\u8bc1\u5e7f\u6cdb\u7684\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u4e3a\u7a0b\u5e8f\u6b63\u786e\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u5f62\u5f0f\u5316\u5de5\u5177"}}
{"id": "2509.00699", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.00699", "abs": "https://arxiv.org/abs/2509.00699", "authors": ["Yumeng He", "Chandrakana Nandi", "Sreepathi Pai"], "title": "Formalizing Linear Motion G-code for Invariant Checking and Differential Testing of Fabrication Tools", "comment": null, "summary": "The computational fabrication pipeline for 3D printing is much like a\ncompiler - users design models in Computer Aided Design (CAD) tools that are\nlowered to polygon meshes to be ultimately compiled to machine code by 3D\nslicers. For traditional compilers and programming languages, techniques for\nchecking program invariants are well-established. Similarly, methods like\ndifferential testing are often used to uncover bugs in compilers themselves,\nwhich makes them more reliable. The fabrication pipeline would benefit from\nsimilar techniques but traditional approaches do not directly apply to the\nrepresentations used in this domain. Unlike traditional programs, 3D models\nexist both as geometric objects as well as machine code that ultimately runs on\nthe hardware. The machine code, like in traditional compiling, is affected by\nmany factors like the model, the slicer being used, and numerous\nuser-configurable parameters that control the slicing process. In this work, we\npropose a new algorithm for lifting G-code (a common language used in\nfabrication pipelines) by denoting a G-code program to a set of cuboids, and\nthen defining an approximate point cloud representation for efficiently\noperating on these cuboids. Our algorithm opens up new opportunities: we show\nthree use cases that demonstrate how it enables error localization in CAD\nmodels through invariant checking, quantitative comparisons between slicers,\nand evaluating the efficacy of mesh repair tools. We present a prototype\nimplementation of our algorithm in a tool, GlitchFinder, and evaluate it on 58\nreal-world CAD models. Our results show that GlitchFinder is particularly\neffective in identifying slicing issues due to small features, can highlight\ndifferences in how popular slicers (Cura and PrusaSlicer) slice the same model,\nand can identify cases where mesh repair tools (MeshLab and Meshmixer)\nintroduce new errors during repair.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684G\u4ee3\u7801\u5206\u6790\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06G\u4ee3\u7801\u8f6c\u6362\u4e3a\u7acb\u65b9\u4f53\u96c6\u5408\u548c\u8fd1\u4f3c\u70b9\u4e91\u8868\u793a\uff0c\u652f\u6301CAD\u6a21\u578b\u9519\u8bef\u5b9a\u4f4d\u3001\u5207\u7247\u5668\u6bd4\u8f83\u548c\u7f51\u683c\u4fee\u590d\u5de5\u5177\u6548\u679c\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u7f16\u8bd1\u5668\u6709\u5f88\u591a\u7a0b\u5e8f\u4e0d\u53d8\u91cf\u68c0\u67e5\u6280\u672f\uff0c\u4f463D\u6253\u5370\u5236\u9020\u6d41\u6c34\u7ebf\u7f3a\u4e4f\u7c7b\u4f3c\u65b9\u6cd5\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u51e0\u4f55\u5bf9\u8c61\u548c\u673a\u5668\u4ee3\u7801\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u5207\u7247\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u548c\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684G\u4ee3\u7801\u63d0\u53d6\u7b97\u6cd5\uff0c\u5c06G\u4ee3\u7801\u7a0b\u5e8f\u8f6c\u6362\u4e3a\u7acb\u65b9\u4f53\u96c6\u5408\uff0c\u7136\u540e\u5b9a\u4e49\u8fd1\u4f3c\u70b9\u4e91\u8868\u793a\u4ee5\u9ad8\u6548\u64cd\u4f5c\u8fd9\u4e9b\u7acb\u65b9\u4f53\u3002\u5b9e\u73b0\u4e86\u539f\u578b\u5de5\u5177GlitchFinder\u3002", "result": "\u572858\u4e2a\u5b9e\u9645CAD\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aGlitchFinder\u80fd\u6709\u6548\u8bc6\u522b\u5c0f\u7279\u5f81\u5bfc\u81f4\u7684\u5207\u7247\u95ee\u9898\uff0c\u663e\u793a\u4e0d\u540c\u5207\u7247\u5668\uff08Cura\u548cPrusaSlicer\uff09\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u8bc6\u522b\u7f51\u683c\u4fee\u590d\u5de5\u5177\uff08MeshLab\u548cMeshmixer\uff09\u5728\u4fee\u590d\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u65b0\u9519\u8bef\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a3D\u6253\u5370\u5236\u9020\u6d41\u6c34\u7ebf\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u4f20\u7edf\u7f16\u8bd1\u5668\u7684\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u5f00\u542f\u4e86CAD\u6a21\u578b\u8d28\u91cf\u63a7\u5236\u3001\u5207\u7247\u5668\u6bd4\u8f83\u548c\u7f51\u683c\u4fee\u590d\u6548\u679c\u8bc4\u4f30\u7b49\u65b0\u7684\u5e94\u7528\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.00948", "categories": ["cs.PL", "cs.FL"], "pdf": "https://arxiv.org/pdf/2509.00948", "abs": "https://arxiv.org/abs/2509.00948", "authors": ["Denghang Hu", "Taolue Chen", "Philipp R\u00fcmmer", "Fu Song", "Zhilin Wu"], "title": "Decision Procedure for A Theory of String Sequences", "comment": "21 pages, 2 tables, APLAS 2025", "summary": "The theory of sequences, supported by many SMT solvers, can model program\ndata types including bounded arrays and lists. Sequences are parameterized by\nthe element data type and provide operations such as accessing elements,\nconcatenation, forming sub-sequences and updating elements. Strings and\nsequences are intimately related; many operations, e.g., matching a string\naccording to a regular expression, splitting strings, or joining strings in a\nsequence, are frequently used in string-manipulating programs. Nevertheless,\nthese operations are typically not directly supported by existing SMT solvers,\nwhich instead only consider the generic theory of sequences. In this paper, we\npropose a theory of string sequences and study its satisfiability. We show\nthat, while it is undecidable in general, the decidability can be recovered by\nrestricting to the straight-line fragment. This is shown by encoding each\nstring sequence as a string, and each string sequence operation as a\ncorresponding string operation. We provide pre-image computation for the\nresulting string operations with respect to automata, effectively casting it\ninto the generic OSTRICH string constraint solving framework. We implement the\nnew decision procedure as a tool $\\ostrichseq$, and carry out experiments on\nbenchmark constraints generated from real-world JavaScript programs,\nhand-crafted templates and unit tests. The experiments confirm the efficacy of\nour approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\uff0c\u901a\u8fc7\u5c06\u5b57\u7b26\u4e32\u5e8f\u5217\u7f16\u7801\u4e3a\u5b57\u7b26\u4e32\u5e76\u5229\u7528OSTRICH\u6846\u67b6\u5b9e\u73b0\u7ea6\u675f\u6c42\u89e3\uff0c\u89e3\u51b3\u4e86SMT\u6c42\u89e3\u5668\u5bf9\u5b57\u7b26\u4e32\u64cd\u4f5c\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684SMT\u6c42\u89e3\u5668\u4ec5\u652f\u6301\u901a\u7528\u5e8f\u5217\u7406\u8bba\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5b57\u7b26\u4e32\u64cd\u4f5c\uff08\u5982\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u3001\u5b57\u7b26\u4e32\u5206\u5272\u548c\u8fde\u63a5\uff09\u7684\u76f4\u63a5\u652f\u6301\uff0c\u800c\u8fd9\u4e9b\u64cd\u4f5c\u5728\u5b57\u7b26\u4e32\u5904\u7406\u7a0b\u5e8f\u4e2d\u7ecf\u5e38\u4f7f\u7528\u3002", "method": "\u63d0\u51fa\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\uff0c\u5c06\u6bcf\u4e2a\u5b57\u7b26\u4e32\u5e8f\u5217\u7f16\u7801\u4e3a\u5b57\u7b26\u4e32\uff0c\u5e76\u5c06\u5b57\u7b26\u4e32\u5e8f\u5217\u64cd\u4f5c\u6620\u5c04\u4e3a\u5bf9\u5e94\u7684\u5b57\u7b26\u4e32\u64cd\u4f5c\u3002\u901a\u8fc7\u9884\u50cf\u8ba1\u7b97\u548cOSTRICH\u6846\u67b6\u5b9e\u73b0\u7ea6\u675f\u6c42\u89e3\uff0c\u9650\u5236\u5728\u76f4\u7ebf\u7247\u6bb5\u5185\u4fdd\u8bc1\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u5de5\u5177ostrichseq\uff0c\u5728\u771f\u5b9eJavaScript\u7a0b\u5e8f\u751f\u6210\u7684\u57fa\u51c6\u7ea6\u675f\u3001\u624b\u5de5\u5236\u4f5c\u7684\u6a21\u677f\u548c\u5355\u5143\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\u867d\u7136\u4e00\u822c\u60c5\u51b5\u4e0b\u4e0d\u53ef\u5224\u5b9a\uff0c\u4f46\u901a\u8fc7\u9650\u5236\u5728\u76f4\u7ebf\u7247\u6bb5\u53ef\u4ee5\u6062\u590d\u53ef\u5224\u5b9a\u6027\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5b57\u7b26\u4e32\u5e8f\u5217\u64cd\u4f5c\uff0c\u4e3aSMT\u6c42\u89e3\u5668\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5b57\u7b26\u4e32\u64cd\u4f5c\u652f\u6301\u3002"}}
{"id": "2509.00433", "categories": ["cs.AR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.00433", "abs": "https://arxiv.org/abs/2509.00433", "authors": ["Houshu He", "Naifeng Jing", "Li Jiang", "Xiaoyao Liang", "Zhuoran Song"], "title": "AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame Covisibility Detection", "comment": "15 pages", "summary": "Simultaneous Localization and Mapping (SLAM) is a critical task that enables\nautonomous vehicles to construct maps and localize themselves in unknown\nenvironments. Recent breakthroughs combine SLAM with 3D Gaussian Splatting\n(3DGS) to achieve exceptional reconstruction fidelity. However, existing\n3DGS-SLAM systems provide insufficient throughput due to the need for multiple\ntraining iterations per frame and the vast number of Gaussians.\n  In this paper, we propose AGS, an algorithm-hardware co-design framework to\nboost the efficiency of 3DGS-SLAM based on the intuition that SLAM systems\nprocess frames in a streaming manner, where adjacent frames exhibit high\nsimilarity that can be utilized for acceleration. On the software level: 1) We\npropose a coarse-then-fine-grained pose tracking method with respect to the\nrobot's movement. 2) We avoid redundant computations of Gaussians by sharing\ntheir contribution information across frames. On the hardware level, we propose\na frame covisibility detection engine to extract intermediate data from the\nvideo CODEC. We also implement a pose tracking engine and a mapping engine with\nworkload schedulers to efficiently deploy the AGS algorithm. Our evaluation\nshows that AGS achieves up to $17.12\\times$, $6.71\\times$, and $5.41\\times$\nspeedups against the mobile and high-end GPUs, and a state-of-the-art 3DGS\naccelerator, GSCore.", "AI": {"tldr": "AGS\u662f\u4e00\u4e2a\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528SLAM\u7cfb\u7edf\u4e2d\u76f8\u90bb\u5e27\u7684\u9ad8\u76f8\u4f3c\u6027\u6765\u52a0\u901f3D\u9ad8\u65af\u6e85\u5c04SLAM\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u76843DGS-SLAM\u7cfb\u7edf\u7531\u4e8e\u6bcf\u5e27\u9700\u8981\u591a\u6b21\u8bad\u7ec3\u8fed\u4ee3\u548c\u5927\u91cf\u9ad8\u65af\u5143\u7d20\uff0c\u5bfc\u81f4\u541e\u5410\u91cf\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8f6f\u4ef6\u5c42\u9762\uff1a\u63d0\u51fa\u7c97\u5230\u7ec6\u7684\u4f4d\u59ff\u8ddf\u8e2a\u65b9\u6cd5\u548c\u8de8\u5e27\u5171\u4eab\u9ad8\u65af\u8d21\u732e\u4fe1\u606f\uff1b\u786c\u4ef6\u5c42\u9762\uff1a\u8bbe\u8ba1\u5e27\u5171\u89c6\u68c0\u6d4b\u5f15\u64ce\u3001\u4f4d\u59ff\u8ddf\u8e2a\u5f15\u64ce\u548c\u5efa\u56fe\u5f15\u64ce\uff0c\u5e76\u914d\u5907\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u5668\u3002", "result": "AGS\u76f8\u6bd4\u79fb\u52a8\u548c\u9ad8\u6027\u80fdGPU\u4ee5\u53ca\u6700\u5148\u8fdb\u76843DGS\u52a0\u901f\u5668GSCore\uff0c\u5206\u522b\u5b9e\u73b0\u4e8617.12\u500d\u30016.71\u500d\u548c5.41\u500d\u7684\u52a0\u901f\u6bd4\u3002", "conclusion": "AGS\u6846\u67b6\u901a\u8fc7\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u5229\u7528\u4e86SLAM\u7cfb\u7edf\u4e2d\u5e27\u95f4\u76f8\u4f3c\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e863DGS-SLAM\u7cfb\u7edf\u7684\u6548\u7387\u3002"}}
{"id": "2509.00579", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00579", "abs": "https://arxiv.org/abs/2509.00579", "authors": ["Bo Jiang", "Taolue Yang", "Youyuan Liu", "Chengming Zhang", "Xubin He", "Sian Jin"], "title": "KVComp: A High-Performance, LLM-Aware, Lossy Compression Framework for KV Cache", "comment": null, "summary": "Transformer-based large language models (LLMs) demonstrate impressive\npotential in various practical applications. However, long context inference\nposes a significant challenge due to the enormous memory requirements of the\nkey-value (KV) cache, which can scale to multiple gigabytes as sequence length\nand batch size increase. In this paper, we present KVComp, a generic and\nefficient KV cache management framework optimized for long-text generation that\nsynergistically works with both latency-critical and throughput-critical\ninference systems. KVComp employs novel lossy compression techniques\nspecifically designed for KV cache data characteristics, featuring careful\nco-design of compression algorithms and system architecture. Our approach\nmaintains compatibility with the growing nature of KV cache while preserving\nhigh computational efficiency. Experimental results show that KVComp achieves\non average 47\\% and up to 83\\% higher memory reduction rate compared to\nexisting methods with little/no model accuracy degradation. Furthermore, KVComp\nachieves extremely high execution throughput, effectively reducing\ndecompression overhead and, in some cases, even accelerating the matrix-vector\nmultiplication operation and outperform cuBLAS-based attention kernels with\nless data movement.", "AI": {"tldr": "KVComp\u662f\u4e00\u4e2a\u9488\u5bf9\u957f\u6587\u672c\u751f\u6210\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6709\u635f\u538b\u7f29\u6280\u672f\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u548c\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u548c\u6279\u91cf\u5927\u5c0f\u7684\u589e\u52a0\uff0cTransformer\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42\u53ef\u8fbe\u6570GB\uff0c\u6210\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u4e3b\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e13\u95e8\u4e3aKV\u7f13\u5b58\u6570\u636e\u7279\u6027\u8bbe\u8ba1\u7684\u6709\u635f\u538b\u7f29\u6280\u672f\uff0c\u7ed3\u5408\u538b\u7f29\u7b97\u6cd5\u548c\u7cfb\u7edf\u67b6\u6784\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u4fdd\u6301\u4e0eKV\u7f13\u5b58\u589e\u957f\u7279\u6027\u7684\u517c\u5bb9\u6027\u3002", "result": "\u5e73\u5747\u5b9e\u73b047%\u7684\u5185\u5b58\u51cf\u5c11\u7387\uff0c\u6700\u9ad8\u53ef\u8fbe83%\uff0c\u4e14\u51e0\u4e4e\u6ca1\u6709\u6a21\u578b\u7cbe\u5ea6\u635f\u5931\u3002\u6267\u884c\u541e\u5410\u91cf\u6781\u9ad8\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u52a0\u901f\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u64cd\u4f5c\u3002", "conclusion": "KVComp\u662f\u4e00\u4e2a\u901a\u7528\u9ad8\u6548\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u5728\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5185\u5b58\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01511", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.01511", "abs": "https://arxiv.org/abs/2509.01511", "authors": ["Zhe Zhou", "Benjamin Delaware", "Suresh Jagannathan"], "title": "Type-Based Incorrectness Reasoning", "comment": null, "summary": "A coverage type generalizes refinement types found in many functional\nlanguages with support for must-style underapproximate reasoning.\nProperty-based testing frameworks are one particularly useful domain where such\ncapabilities are useful as they allow us to verify the completeness, as well as\nsafety, of test generators. There is a surprising connection between the kind\nof underapproximate reasoning coverage types offer and the style of reasoning\nenabled by recently proposed Incorrectness Logic frameworks. In our\npresentation, we propose to explore this connection more deeply, identifying\nmechanisms that more systematically integrate incorrectness reasoning within an\nexpressive refinement type system and the opportunities that such integration\noffers to functional programmers, program verifiers, and program analyzers and\nrelated tools.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8986\u76d6\u7c7b\u578b\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u63d0\u51fa\u5c06\u4e0d\u6b63\u786e\u6027\u63a8\u7406\u7cfb\u7edf\u5316\u96c6\u6210\u5230\u7cbe\u5316\u7c7b\u578b\u7cfb\u7edf\u4e2d\u7684\u673a\u5236\uff0c\u4e3a\u51fd\u6570\u5f0f\u7a0b\u5e8f\u5458\u548c\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u65b0\u673a\u4f1a", "motivation": "\u8986\u76d6\u7c7b\u578b\u80fd\u591f\u652f\u6301must-style\u7684\u6b20\u8fd1\u4f3c\u63a8\u7406\uff0c\u8fd9\u5728\u57fa\u4e8e\u5c5e\u6027\u7684\u6d4b\u8bd5\u6846\u67b6\u4e2d\u7279\u522b\u6709\u7528\uff0c\u53ef\u4ee5\u9a8c\u8bc1\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\u3002\u7814\u7a76\u53d1\u73b0\u8986\u76d6\u7c7b\u578b\u63d0\u4f9b\u7684\u63a8\u7406\u65b9\u5f0f\u4e0e\u6700\u8fd1\u63d0\u51fa\u7684\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u6846\u67b6\u5b58\u5728\u60ca\u4eba\u8054\u7cfb", "method": "\u901a\u8fc7\u6df1\u5165\u63a2\u7d22\u8986\u76d6\u7c7b\u578b\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u8bc6\u522b\u51fa\u5c06\u4e0d\u6b63\u786e\u6027\u63a8\u7406\u66f4\u7cfb\u7edf\u5316\u5730\u96c6\u6210\u5230\u8868\u8fbe\u6027\u7cbe\u5316\u7c7b\u578b\u7cfb\u7edf\u4e2d\u7684\u673a\u5236", "result": "\u5efa\u7acb\u4e86\u8986\u76d6\u7c7b\u578b\u63a8\u7406\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u96c6\u6210\u65b9\u6cd5", "conclusion": "\u8fd9\u79cd\u96c6\u6210\u4e3a\u51fd\u6570\u5f0f\u7a0b\u5e8f\u5458\u3001\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u3001\u7a0b\u5e8f\u5206\u6790\u5668\u53ca\u76f8\u5173\u5de5\u5177\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u548c\u53ef\u80fd\u6027\uff0c\u63a8\u52a8\u4e86\u6b20\u8fd1\u4f3c\u63a8\u7406\u5728\u7a0b\u5e8f\u5206\u6790\u4e2d\u7684\u5e94\u7528"}}
{"id": "2509.00500", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.00500", "abs": "https://arxiv.org/abs/2509.00500", "authors": ["Yizhi Chen", "Jingwei Li", "Wenyao Zhu", "Zhonghai Lu"], "title": "Bit Transition Reduction by Data Transmission Ordering in NoC-based DNN Accelerator", "comment": "Accepted to IEEE SoCC 2025 (38th IEEE International System-on-Chip\n  Conference)", "summary": "As Deep Neural Networks (DNN) are becoming essential, Network-on-Chip\n(NoC)-based DNN accelerators gained increasing popularity. To save link power\nin NoC, many researchers focus on reducing the Bit Transition (BT). We propose\n'1'-bit count-based ordering method to reduce BT for DNN workloads. We provide\na mathematical proof of the efficacy of proposed ordering. We evaluate our\nmethod through experiments without NoC and with NoC. Without NoC, our proposed\nordering method achieves up to 20.38% BT reduction for floating-point-32 data\nand 55.71% for fixed-point-8 data, respectively. We propose two data ordering\nmethods, affiliated-ordering and separated-ordering to process weight and input\njointly or individually and apply them to run full DNNs in NoC-based DNN\naccelerator. We evaluate our approaches under various configurations, including\ndifferent DNN models such as LeNet and DarkNet, various NoC sizes with\ndifferent numbers of memory controllers, random weights and trained weights,\nand different data precision. Our approach efficiently reduces the link power\nby achieving up to 32.01% BT reduction for floating-point-32 data and 40.85% BT\nreduction for fixed-point-8 data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e'1'\u6bd4\u7279\u8ba1\u6570\u7684\u6392\u5e8f\u65b9\u6cd5\u6765\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u4e2d\u7247\u4e0a\u7f51\u7edc\u7684\u6bd4\u7279\u7ffb\u8f6c\uff0c\u4ece\u800c\u964d\u4f4e\u94fe\u8def\u529f\u8017\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u6d6e\u70b932\u548c\u5b9a\u70b98\u6570\u636e\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad832.01%\u548c40.85%\u7684\u6bd4\u7279\u7ffb\u8f6c\u51cf\u5c11\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc(DNN)\u7684\u666e\u53ca\uff0c\u57fa\u4e8e\u7247\u4e0a\u7f51\u7edc(NoC)\u7684DNN\u52a0\u901f\u5668\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\u3002\u4e3a\u4e86\u8282\u7701NoC\u4e2d\u7684\u94fe\u8def\u529f\u8017\uff0c\u8bb8\u591a\u7814\u7a76\u8005\u4e13\u6ce8\u4e8e\u51cf\u5c11\u6bd4\u7279\u7ffb\u8f6c(BT)\u3002", "method": "\u63d0\u51fa'1'\u6bd4\u7279\u8ba1\u6570\u6392\u5e8f\u65b9\u6cd5\uff0c\u5305\u62ec\u5173\u8054\u6392\u5e8f\u548c\u5206\u79bb\u6392\u5e8f\u4e24\u79cd\u65b9\u5f0f\u6765\u5904\u7406\u6743\u91cd\u548c\u8f93\u5165\u6570\u636e\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u6709\u65e0NoC\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u65e0NoC\u65f6\uff1a\u6d6e\u70b932\u6570\u636e\u6700\u9ad8\u51cf\u5c1120.38% BT\uff0c\u5b9a\u70b98\u6570\u636e\u6700\u9ad8\u51cf\u5c1155.71% BT\u3002\u6709NoC\u65f6\uff1a\u6d6e\u70b932\u6570\u636e\u6700\u9ad8\u51cf\u5c1132.01% BT\uff0c\u5b9a\u70b98\u6570\u636e\u6700\u9ad8\u51cf\u5c1140.85% BT\u3002\u5728\u4e0d\u540cDNN\u6a21\u578b\u3001NoC\u914d\u7f6e\u3001\u6743\u91cd\u7c7b\u578b\u548c\u6570\u636e\u7cbe\u5ea6\u4e0b\u5747\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e'1'\u6bd4\u7279\u8ba1\u6570\u7684\u6392\u5e8f\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11DNN\u52a0\u901f\u5668\u4e2dNoC\u7684\u6bd4\u7279\u7ffb\u8f6c\uff0c\u663e\u8457\u964d\u4f4e\u94fe\u8def\u529f\u8017\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u914d\u7f6e\u548c\u6570\u636e\u7c7b\u578b\u3002"}}
{"id": "2509.00642", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.00642", "abs": "https://arxiv.org/abs/2509.00642", "authors": ["Qizheng Yang", "Tung-I Chen", "Siyu Zhao", "Ramesh K. Sitaraman", "Hui Guan"], "title": "HADIS: Hybrid Adaptive Diffusion Model Serving for Efficient Text-to-Image Generation", "comment": "13 pages, 10 figures", "summary": "Text-to-image diffusion models have achieved remarkable visual quality but\nincur high computational costs, making real-time, scalable deployment\nchallenging. Existing query-aware serving systems mitigate the cost by\ncascading lightweight and heavyweight models, but most rely on a fixed cascade\nconfiguration and route all prompts through an initial lightweight stage,\nwasting resources on complex queries. We present HADIS, a hybrid adaptive\ndiffusion model serving system that jointly optimizes cascade model selection,\nquery routing, and resource allocation. HADIS employs a rule-based prompt\nrouter to send clearly hard queries directly to heavyweight models, bypassing\nthe overhead of the lightweight stage. To reduce the complexity of resource\nmanagement, HADIS uses an offline profiling phase to produce a Pareto-optimal\ncascade configuration table. At runtime, HADIS selects the best cascade\nconfiguration and GPU allocation given latency and workload constraints.\nEmpirical evaluations on real-world traces demonstrate that HADIS improves\nresponse quality by up to 35% while reducing latency violation rates by\n2.7-45$\\times$ compared to state-of-the-art model serving systems.", "AI": {"tldr": "HADIS\u662f\u4e00\u4e2a\u6df7\u5408\u81ea\u9002\u5e94\u6269\u6563\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u667a\u80fd\u67e5\u8be2\u8def\u7531\u548c\u8d44\u6e90\u914d\u7f6e\u4f18\u5316\uff0c\u5728\u4fdd\u8bc1\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u8fdd\u89c4\u7387", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u867d\u7136\u89c6\u89c9\u8d28\u91cf\u51fa\u8272\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u73b0\u6709\u670d\u52a1\u7cfb\u7edf\u91c7\u7528\u56fa\u5b9a\u7ea7\u8054\u914d\u7f6e\u4e14\u6240\u6709\u67e5\u8be2\u90fd\u7ecf\u8fc7\u8f7b\u91cf\u7ea7\u9636\u6bb5\uff0c\u5bf9\u590d\u6742\u67e5\u8be2\u9020\u6210\u8d44\u6e90\u6d6a\u8d39", "method": "\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u8def\u7531\u5668\u5c06\u660e\u663e\u56f0\u96be\u7684\u67e5\u8be2\u76f4\u63a5\u8def\u7531\u5230\u91cd\u91cf\u7ea7\u6a21\u578b\uff1b\u901a\u8fc7\u79bb\u7ebf\u5206\u6790\u751f\u6210\u5e15\u7d2f\u6258\u6700\u4f18\u7ea7\u8054\u914d\u7f6e\u8868\uff1b\u8fd0\u884c\u65f6\u6839\u636e\u5ef6\u8fdf\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7ea6\u675f\u9009\u62e9\u6700\u4f73\u7ea7\u8054\u914d\u7f6e\u548cGPU\u5206\u914d", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u8ddf\u8e2a\u8bc4\u4f30\u4e2d\uff0cHADIS\u5c06\u54cd\u5e94\u8d28\u91cf\u63d0\u5347\u9ad8\u8fbe35%\uff0c\u540c\u65f6\u5c06\u5ef6\u8fdf\u8fdd\u89c4\u7387\u964d\u4f4e2.7-45\u500d", "conclusion": "HADIS\u7cfb\u7edf\u901a\u8fc7\u81ea\u9002\u5e94\u67e5\u8be2\u8def\u7531\u548c\u8d44\u6e90\u914d\u7f6e\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u670d\u52a1\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u670d\u52a1\u6548\u7387\u548c\u8d28\u91cf"}}
{"id": "2509.02428", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.02428", "abs": "https://arxiv.org/abs/2509.02428", "authors": ["Yongwei Yuan", "Zhe Zhou", "Julia Belyakova", "Benjamin Delaware", "Suresh Jagannathan"], "title": "From Traces to Program Incorrectness: A Type-Theoretic Approach", "comment": null, "summary": "We present a type-theoretic framework for reasoning about incorrectness in\nfunctional programs that interact with effectful, opaque library APIs. Our\napproach centers on traces -- temporally-ordered sequences of library API\ninvocations -- which naturally characterize both the preconditions of\nindividual APIs and their composite behavior. We represent these traces using\nsymbolic regular expressions (SREs), enabling formal specification of incorrect\nabstract data type (ADT) behaviors across function boundaries. The core\ncontribution is a novel type inference algorithm that operates modulo specified\nincorrectness properties and leverages the symbolic finite automata (SFAs)\nrepresentations of regexes for compositional reasoning of traces. When the\nalgorithm succeeds, the inferred types witness that an ADT implementation can\nexhibit some subset of the specified incorrect behaviors. This represents the\nfirst systematic approach to underapproximate reasoning against trace-based\nincorrectness specifications, enabling a new form of trace-guided compositional\nanalysis.", "AI": {"tldr": "\u57fa\u4e8e\u7b26\u53f7\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u7c7b\u578b\u63a8\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u51fd\u6570\u7a0b\u5e8f\u4e2d\u4e0e\u6548\u679c\u5e93API\u4ea4\u4e92\u65f6\u7684\u9519\u8bef\u884c\u4e3a", "motivation": "\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u8fdb\u884c\u4e0d\u6b63\u786e\u6027\u63a8\u7406\uff0c\u7279\u522b\u662f\u5728\u51fd\u6570\u7a0b\u5e8f\u4e0e\u4e0d\u900f\u660e\u5e93API\u4ea4\u4e92\u65f6\u8bc6\u522b\u53ef\u80fd\u7684\u9519\u8bef\u884c\u4e3a", "method": "\u4f7f\u7528\u7b26\u53f7\u6b63\u5219\u8868\u8fbe\u5f0f(SREs)\u8868\u793a\u8ddf\u8e2a\u5e8f\u5217\uff0c\u901a\u8fc7\u7b26\u53f7\u6709\u9650\u81ea\u52a8\u673a(SFAs)\u8fdb\u884c\u7ec4\u5408\u63a8\u7406\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u7c7b\u578b\u63a8\u65ad\u7b97\u6cd5", "result": "\u7b97\u6cd5\u6210\u529f\u65f6\uff0c\u63a8\u65ad\u51fa\u7684\u7c7b\u578b\u80fd\u591f\u8bc1\u660eADT\u5b9e\u73b0\u53ef\u80fd\u5c55\u73b0\u6307\u5b9a\u7684\u4e0d\u6b63\u786e\u884c\u4e3a\u5b50\u96c6", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u7684\u4e0d\u6b63\u786e\u6027\u8f68\u8ff9\u89c4\u8303\u5206\u6790\u65b9\u6cd5\uff0c\u5f00\u542f\u4e86\u8f68\u8ff9\u5bfc\u5411\u7684\u7ec4\u5408\u5206\u6790\u65b0\u65b9\u5411"}}
{"id": "2509.00589", "categories": ["cs.AR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.00589", "abs": "https://arxiv.org/abs/2509.00589", "authors": ["Shafayet M. Anik", "D. G. Perera"], "title": "Real-Time Piano Note Frequency Detection Using FPGA and FFT Core", "comment": "20 pages, 11 Figures", "summary": "Real-time frequency analysis of musical instruments, such as the piano, is an\nessential feature in areas like electronic tuners, music visualizers, and live\nsound monitoring. Traditional methods often rely on software-based digital\nsignal processing (DSP), which may introduce latency and require significant\ncomputational power. In contrast, hardware platforms such as FPGAs (Field\nProgrammable Gate Arrays) offer the ability to perform such analyses with\ngreater speed and determinism due to their parallel processing capabilities.\nThe primary objective of this project was to analyze analog audio signals from\na digital piano using an FPGA-based real-time Fast Fourier Transform (FFT)\nsystem.", "AI": {"tldr": "\u4f7f\u7528FPGA\u5b9e\u73b0\u94a2\u7434\u97f3\u9891\u4fe1\u53f7\u7684\u5b9e\u65f6FFT\u9891\u7387\u5206\u6790\uff0c\u76f8\u6bd4\u4f20\u7edf\u8f6f\u4ef6DSP\u65b9\u6cd5\u5177\u6709\u66f4\u4f4e\u5ef6\u8fdf\u548c\u66f4\u9ad8\u8ba1\u7b97\u6548\u7387", "motivation": "\u4f20\u7edf\u8f6f\u4ef6DSP\u65b9\u6cd5\u5728\u5b9e\u65f6\u97f3\u4e50\u9891\u7387\u5206\u6790\u4e2d\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u800cFPGA\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u53ef\u4ee5\u63d0\u4f9b\u66f4\u5feb\u901f\u548c\u786e\u5b9a\u6027\u7684\u5206\u6790\u6027\u80fd", "method": "\u91c7\u7528\u57fa\u4e8eFPGA\u7684\u5b9e\u65f6\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362(FFT)\u7cfb\u7edf\u6765\u5206\u6790\u6570\u5b57\u94a2\u7434\u7684\u6a21\u62df\u97f3\u9891\u4fe1\u53f7", "result": "FPGA\u5e73\u53f0\u80fd\u591f\u5b9e\u73b0\u6bd4\u8f6f\u4ef6DSP\u65b9\u6cd5\u66f4\u5feb\u901f\u3001\u66f4\u786e\u5b9a\u7684\u5b9e\u65f6\u9891\u7387\u5206\u6790", "conclusion": "FPGA\u786c\u4ef6\u5e73\u53f0\u5728\u5b9e\u65f6\u97f3\u4e50\u4fe1\u53f7\u5904\u7406\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u9002\u5408\u94a2\u7434\u7b49\u4e50\u5668\u7684\u9ad8\u6027\u80fd\u9891\u7387\u5206\u6790\u5e94\u7528"}}
{"id": "2509.00883", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00883", "abs": "https://arxiv.org/abs/2509.00883", "authors": ["Denis Los", "Igor Petushkov"], "title": "Accelerating Latency-Critical Applications with AI-Powered Semi-Automatic Fine-Grained Parallelization on SMT Processors", "comment": null, "summary": "Latency-critical applications tend to show low utilization of functional\nunits due to frequent cache misses and mispredictions during speculative\nexecution in high-performance superscalar processors. However, due to\nsignificant impact on single-thread performance, Simultaneous Multithreading\n(SMT) technology is rarely used with heavy threads of latency-critical\napplications. In this paper, we explore utilization of SMT technology to\nsupport fine-grained parallelization of latency-critical applications.\nFollowing the advancements in the development of Large Language Models (LLMs),\nwe introduce Aira, an AI-powered Parallelization Adviser. To implement Aira, we\nextend AI Coding Agent in Cursor IDE with additional tools connected through\nModel Context Protocol, enabling end-to-end AI Agent for parallelization.\nAdditional connected tools enable LLM-guided hotspot detection, collection of\ndynamic dependencies with Dynamic Binary Instrumentation, SMT-aware performance\nsimulation to estimate performance gains. We apply Aira with Relic parallel\nframework for fine-grained task parallelism on SMT cores to parallelize\nlatency-critical benchmarks representing real-world applications used in\nindustry. We show 17% geomean performance gain from parallelization of\nlatency-critical benchmarks using Aira with Relic framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAira AI\u5e76\u884c\u5316\u987e\u95ee\u7cfb\u7edf\uff0c\u5229\u7528SMT\u6280\u672f\u5b9e\u73b0\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u7684\u7ec6\u7c92\u5ea6\u5e76\u884c\u5316\uff0c\u5728\u5de5\u4e1a\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u4e8617%\u7684\u51e0\u4f55\u5e73\u5747\u6027\u80fd\u63d0\u5347", "motivation": "\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u5728\u8d85\u6807\u91cf\u5904\u7406\u5668\u4e2d\u7531\u4e8e\u7f13\u5b58\u7f3a\u5931\u548c\u9884\u6d4b\u9519\u8bef\u5bfc\u81f4\u529f\u80fd\u5355\u5143\u5229\u7528\u7387\u4f4e\uff0c\u4f46\u4f20\u7edfSMT\u6280\u672f\u5f88\u5c11\u7528\u4e8e\u6b64\u7c7b\u91cd\u7ebf\u7a0b\u5e94\u7528", "method": "\u6269\u5c55Cursor IDE\u4e2d\u7684AI\u7f16\u7801\u4ee3\u7406\uff0c\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u8fde\u63a5\u989d\u5916\u5de5\u5177\uff0c\u5b9e\u73b0LLM\u5f15\u5bfc\u7684\u70ed\u70b9\u68c0\u6d4b\u3001\u52a8\u6001\u4f9d\u8d56\u6536\u96c6\u548cSMT\u611f\u77e5\u6027\u80fd\u6a21\u62df\uff0c\u7ed3\u5408Relic\u5e76\u884c\u6846\u67b6", "result": "\u4f7f\u7528Aira\u548cRelic\u6846\u67b6\u5bf9\u5ef6\u8fdf\u5173\u952e\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u5e76\u884c\u5316\uff0c\u83b7\u5f97\u4e8617%\u7684\u51e0\u4f55\u5e73\u5747\u6027\u80fd\u589e\u76ca", "conclusion": "Aira\u7cfb\u7edf\u6210\u529f\u8bc1\u660e\u4e86AI\u9a71\u52a8\u7684\u5e76\u884c\u5316\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u7684\u6027\u80fd\uff0c\u4e3aSMT\u6280\u672f\u5728\u91cd\u7ebf\u7a0b\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2509.02457", "categories": ["cs.DC", "cs.DS", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.02457", "abs": "https://arxiv.org/abs/2509.02457", "authors": ["Ajay Singh"], "title": "Safe Memory Reclamation Techniques", "comment": "Ph.D. Thesis", "summary": "Safe memory reclamation is crucial to memory safety for optimistic and\nlock-free concurrent data structures in non garbage collected programming\nlanguages. However, several challenges arise in designing an ideal safe memory\nreclamation algorithm, including achieving high speed and scalability, easy of\nuse for programmers, applicability to wide class of data structures, managing\nthe large memory footprint caused by delayed freeing of memory for safety and\nperformance, and avoiding asymmetric overhead on data structure operations.\nSeveral approaches to designing safe memory reclamation algorithms are studied\nby blending ideas and tools from across the hardware-software stack. These\nsolutions cross traditional boundaries and exploit features exposed at\ndifferent layers.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u975e\u5783\u573e\u56de\u6536\u7f16\u7a0b\u8bed\u8a00\u4e2d\u4e50\u89c2\u548c\u65e0\u9501\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u7684\u5b89\u5168\u5185\u5b58\u56de\u6536\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u8de8\u8f6f\u4ef6\u786c\u4ef6\u5c42\u6b21\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u9ad8\u6027\u80fd\u3001\u6613\u7528\u6027\u3001\u5e94\u7528\u8303\u56f4\u548c\u5185\u5b58\u5360\u7528\u7b49\u6311\u6218\u3002", "motivation": "\u5728\u975e\u5783\u573e\u56de\u6536\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u5b89\u5168\u5185\u5b58\u56de\u6536\u5bf9\u4e8e\u4e50\u89c2\u548c\u65e0\u9501\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u7684\u5185\u5b58\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u4f46\u8bbe\u8ba1\u7406\u60f3\u7684\u5b89\u5168\u5185\u5b58\u56de\u6536\u7b97\u6cd5\u9762\u4e34\u7740\u591a\u91cd\u6311\u6218\uff0c\u5305\u62ec\u5b9e\u73b0\u9ad8\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3001\u7f16\u7a0b\u4eba\u5458\u6613\u7528\u6027\u3001\u5e94\u7528\u4e8e\u5e7f\u6cdb\u6570\u636e\u7ed3\u6784\u7c7b\u578b\u3001\u7ba1\u7406\u56e0\u5ef6\u8fdf\u91ca\u653e\u5185\u5b58\u800c\u5bfc\u81f4\u7684\u5927\u5185\u5b58\u5360\u7528\u4ee5\u53ca\u907f\u514d\u6570\u636e\u7ed3\u6784\u64cd\u4f5c\u7684\u4e0d\u5bf9\u79f0\u5f00\u9500\u3002", "method": "\u7814\u7a76\u4e86\u591a\u79cd\u8bbe\u8ba1\u5b89\u5168\u5185\u5b58\u56de\u6536\u7b97\u6cd5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u6765\u81ea\u786c\u4ef6-\u8f6f\u4ef6\u6808\u4e0d\u540c\u5c42\u6b21\u7684\u601d\u60f3\u548c\u5de5\u5177\u3002\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u8de8\u8d8a\u4e86\u4f20\u7edf\u754c\u9650\uff0c\u5229\u7528\u4e86\u4e0d\u540c\u5c42\u6b21\u66b4\u9732\u7684\u7279\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u5c42\u6b21\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5b89\u5168\u5185\u5b58\u56de\u6536\u7684\u591a\u91cd\u6311\u6218\uff0c\u5305\u62ec\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u3001\u6613\u7528\u6027\u548c\u5185\u5b58\u7ba1\u7406\u7b49\u65b9\u9762\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u786c\u4ef6-\u8f6f\u4ef6\u6808\u4e0d\u540c\u5c42\u6b21\u7684\u6280\u672f\u7279\u6027\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u66f4\u6709\u6548\u7684\u5b89\u5168\u5185\u5b58\u56de\u6536\u7b97\u6cd5\uff0c\u4ee5\u6ee1\u8db3\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u5728\u975e\u5783\u573e\u56de\u6536\u8bed\u8a00\u4e2d\u7684\u5185\u5b58\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2509.00599", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.00599", "abs": "https://arxiv.org/abs/2509.00599", "authors": ["Shubham Negi", "Manik Singhal", "Aayush Ankit", "Sudeep Bhoja", "Kaushik Roy"], "title": "COMET: A Framework for Modeling Compound Operation Dataflows with Explicit Collectives", "comment": null, "summary": "Modern machine learning accelerators are designed to efficiently execute deep\nneural networks (DNNs) by optimizing data movement, memory hierarchy, and\ncompute throughput. However, emerging DNN models such as large language models,\nstate space models increasingly rely on compound operations-structured\ncompositions of multiple basic operations-which introduce new challenges for\ndataflow optimization and minimizing off-chip memory traffic. Moreover, as\nmodel size continues to grow, deployment across spatially distributed compute\nclusters becomes essential, requiring frequent and complex collective\ncommunication. Existing dataflow optimization frameworks and performance models\neither focus on single operations or lack explicit modeling of collective\ncommunication cost, limiting their applicability to modern workloads.\n  To address these limitations, we propose, a framework for modeling and\noptimizing dataflow for compound operations on machine learning accelerators.\nCOMET introduces a novel representation that explicitly models collective\ncommunication across spatial clusters, along with latency and energy cost\nmodels that account for both GEMM and non-GEMM operation level dependencies\nwithin compound operations. We demonstrate COMET's capabilities to analyze and\noptimize dataflows for compound operations such as GEMM--Softmax,\nGEMM--LayerNorm, and self-attention, across both edge and cloud accelerator\nconfigurations. Our collective-aware modeling enables exploration of a broader\nmapping space, leading to improved performance and energy efficiency.\nSpecifically, our optimized dataflows achieve up to 1.42$\\times$ speedup for\nGEMM-Softmax, 3.46$\\times$ for GEMM-LayerNorm and 1.82$\\times$ for\nself-attention compared to unfused baselines.", "AI": {"tldr": "COMET\u662f\u4e00\u4e2a\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u7684\u6570\u636e\u6d41\u5efa\u6a21\u548c\u4f18\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u5904\u7406\u590d\u5408\u64cd\u4f5c\u548c\u96c6\u4f53\u901a\u4fe1\uff0c\u76f8\u6bd4\u672a\u878d\u5408\u57fa\u51c6\u5b9e\u73b0\u4e861.42-3.46\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u9762\u4e34\u65b0\u5174DNN\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\u3001\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff09\u4e2d\u590d\u5408\u64cd\u4f5c\u5e26\u6765\u7684\u6570\u636e\u6d41\u4f18\u5316\u6311\u6218\uff0c\u4ee5\u53ca\u5206\u5e03\u5f0f\u8ba1\u7b97\u96c6\u7fa4\u4e2d\u96c6\u4f53\u901a\u4fe1\u6210\u672c\u7f3a\u4e4f\u660e\u786e\u5efa\u6a21\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faCOMET\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u9896\u8868\u793a\u6cd5\u663e\u5f0f\u5efa\u6a21\u7a7a\u95f4\u96c6\u7fa4\u95f4\u7684\u96c6\u4f53\u901a\u4fe1\uff0c\u5305\u542b\u8003\u8651GEMM\u548c\u975eGEMM\u64cd\u4f5c\u7ea7\u4f9d\u8d56\u5173\u7cfb\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u6210\u672c\u6a21\u578b\u3002", "result": "\u4f18\u5316\u7684\u6570\u636e\u6d41\u5728GEMM-Softmax\u4e0a\u5b9e\u73b01.42\u500d\u52a0\u901f\uff0cGEMM-LayerNorm\u4e0a3.46\u500d\u52a0\u901f\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e0a1.82\u500d\u52a0\u901f\u3002", "conclusion": "COMET\u901a\u8fc7\u96c6\u4f53\u901a\u4fe1\u611f\u77e5\u5efa\u6a21\u6269\u5c55\u4e86\u6620\u5c04\u7a7a\u95f4\u63a2\u7d22\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u4ee3\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2509.00937", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.00937", "abs": "https://arxiv.org/abs/2509.00937", "authors": ["Paul Ruiz Alliata", "Diana Rubaga", "Daniel Kumlin", "Alberto Puliga"], "title": "Parallelizing Drug Discovery: HPC Pipelines for Alzheimer's Molecular Docking and Simulation", "comment": "7 pages, 5 figures", "summary": "High-performance computing (HPC) is reshaping computational drug discovery by\nenabling large-scale, time-efficient molecular simulations. In this work, we\nexplore HPC-driven pipelines for Alzheimer's disease drug discovery, focusing\non virtual screening, molecular docking, and molecular dynamics simulations. We\nimplemented a parallelised workflow using GROMACS with hybrid MPI-OpenMP\nstrategies, benchmarking scaling performance across energy minimisation,\nequilibration, and production stages. Additionally, we developed a docking\nprototype that demonstrates significant runtime gains when moving from\nsequential execution to process-based parallelism using Python's\nmultiprocessing library. Case studies on prolinamide derivatives and baicalein\nhighlight the biological relevance of these workflows in targeting amyloid-beta\nand tau proteins. While limitations remain in data management, computational\ncosts, and scaling efficiency, our results underline the potential of HPC to\naccelerate neurodegenerative drug discovery.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86HPC\u9a71\u52a8\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5e76\u884c\u5316\u5de5\u4f5c\u6d41\u7a0b\u548c\u5206\u5b50\u5bf9\u63a5\u539f\u578b\uff0c\u5728\u865a\u62df\u7b5b\u9009\u3001\u5206\u5b50\u5bf9\u63a5\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5229\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97\u91cd\u5851\u8ba1\u7b97\u836f\u7269\u53d1\u73b0\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u3001\u65f6\u95f4\u9ad8\u6548\u7684\u5206\u5b50\u6a21\u62df\u6765\u52a0\u901f\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u836f\u7269\u7814\u53d1\uff0c\u7279\u522b\u662f\u9488\u5bf9\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u6cbb\u7597\u836f\u7269\u53d1\u73b0\u3002", "method": "\u91c7\u7528GROMACS\u5de5\u5177\u914d\u5408\u6df7\u5408MPI-OpenMP\u7b56\u7565\u5b9e\u73b0\u5e76\u884c\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u80fd\u91cf\u6700\u5c0f\u5316\u3001\u5e73\u8861\u548c\u751f\u4ea7\u9636\u6bb5\uff1b\u4f7f\u7528Python\u7684multiprocessing\u5e93\u5f00\u53d1\u4e86\u57fa\u4e8e\u8fdb\u7a0b\u5e76\u884c\u7684\u5206\u5b50\u5bf9\u63a5\u539f\u578b\u3002", "result": "\u5728\u80fd\u91cf\u6700\u5c0f\u5316\u3001\u5e73\u8861\u548c\u751f\u4ea7\u9636\u6bb5\u5c55\u793a\u4e86\u826f\u597d\u7684\u6269\u5c55\u6027\u80fd\uff1b\u5206\u5b50\u5bf9\u63a5\u4ece\u987a\u5e8f\u6267\u884c\u8f6c\u5411\u8fdb\u7a0b\u5e76\u884c\u540e\u83b7\u5f97\u4e86\u663e\u8457\u7684\u8fd0\u884c\u65f6\u589e\u76ca\uff1b\u901a\u8fc7\u812f\u6c28\u9170\u80fa\u884d\u751f\u7269\u548c\u9ec4\u82a9\u7d20\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5de5\u4f5c\u6d41\u7a0b\u7684\u751f\u7269\u76f8\u5173\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u5728\u6570\u636e\u7ba1\u7406\u3001\u8ba1\u7b97\u6210\u672c\u548c\u6269\u5c55\u6548\u7387\u65b9\u9762\u4ecd\u5b58\u5728\u9650\u5236\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86HPC\u5728\u52a0\u901f\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u836f\u7269\u53d1\u73b0\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.00633", "categories": ["cs.AR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2509.00633", "abs": "https://arxiv.org/abs/2509.00633", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed A. Badawy", "Ahmad Patooghy"], "title": "On the Thermal Vulnerability of 3D-Stacked High-Bandwidth Memory Architectures", "comment": null, "summary": "3D-stacked High Bandwidth Memory (HBM) architectures provide high-performance\nmemory interactions to address the well-known performance challenge, namely the\nmemory wall. However, these architectures are susceptible to thermal\nvulnerabilities due to the inherent vertical adjacency that occurs during the\nmanufacturing process of HBM architectures. We anticipate that adversaries may\nexploit the intense vertical and lateral adjacency to design and develop\nthermal performance degradation attacks on the memory banks that host\ndata/instructions from victim applications. In such attacks, the adversary\nmanages to inject short and intense heat pulses from vertically and/or\nlaterally adjacent memory banks, creating a convergent thermal wave that\nmaximizes impact and delays the victim application from accessing its\ndata/instructions. As the attacking application does not access any\nout-of-range memory locations, it can bypass both design-time security tests\nand the operating system's memory management policies. In other words, since\nthe attack mimics legitimate workloads, it will be challenging to detect.", "AI": {"tldr": "HBM\u67b6\u6784\u5b58\u5728\u70ed\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u76f8\u90bb\u5185\u5b58\u5e93\u6ce8\u5165\u70ed\u8109\u51b2\uff0c\u5236\u9020\u6c47\u805a\u70ed\u6d6a\u6765\u5ef6\u8fdf\u53d7\u5bb3\u8005\u5e94\u7528\u8bbf\u95ee\u6570\u636e\uff0c\u8fd9\u79cd\u653b\u51fb\u6a21\u4eff\u5408\u6cd5\u5de5\u4f5c\u8d1f\u8f7d\u96be\u4ee5\u68c0\u6d4b", "motivation": "3D\u5806\u53e0\u9ad8\u5e26\u5bbd\u5185\u5b58(HBM)\u67b6\u6784\u867d\u7136\u89e3\u51b3\u4e86\u5185\u5b58\u5899\u6027\u80fd\u95ee\u9898\uff0c\u4f46\u7531\u4e8e\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u5782\u76f4\u90bb\u63a5\u7279\u6027\uff0c\u5bb9\u6613\u53d7\u5230\u70ed\u6f0f\u6d1e\u653b\u51fb\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u8fd9\u79cd\u90bb\u63a5\u6027\u8bbe\u8ba1\u70ed\u6027\u80fd\u964d\u7ea7\u653b\u51fb", "method": "\u653b\u51fb\u8005\u901a\u8fc7\u5782\u76f4\u548c/\u6216\u6c34\u5e73\u76f8\u90bb\u7684\u5185\u5b58\u5e93\u6ce8\u5165\u77ed\u6682\u800c\u5f3a\u70c8\u7684\u70ed\u8109\u51b2\uff0c\u5236\u9020\u6c47\u805a\u70ed\u6ce2\u6765\u6700\u5927\u5316\u5f71\u54cd\uff0c\u5ef6\u8fdf\u53d7\u5bb3\u8005\u5e94\u7528\u8bbf\u95ee\u5176\u6570\u636e/\u6307\u4ee4\u3002\u653b\u51fb\u5e94\u7528\u4e0d\u8bbf\u95ee\u8d8a\u754c\u5185\u5b58\u4f4d\u7f6e\uff0c\u53ef\u7ed5\u8fc7\u8bbe\u8ba1\u65f6\u5b89\u5168\u6d4b\u8bd5\u548c\u64cd\u4f5c\u7cfb\u7edf\u5185\u5b58\u7ba1\u7406\u7b56\u7565", "result": "\u8fd9\u79cd\u653b\u51fb\u80fd\u591f\u6709\u6548\u5ef6\u8fdf\u53d7\u5bb3\u8005\u5e94\u7528\u7684\u5185\u5b58\u8bbf\u95ee\uff0c\u7531\u4e8e\u653b\u51fb\u884c\u4e3a\u6a21\u4eff\u5408\u6cd5\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u68c0\u6d4b\u5177\u6709\u6311\u6218\u6027", "conclusion": "HBM\u67b6\u6784\u7684\u70ed\u90bb\u63a5\u7279\u6027\u4f7f\u5176\u9762\u4e34\u65b0\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u68c0\u6d4b\u548c\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u79cd\u6a21\u4eff\u5408\u6cd5\u5de5\u4f5c\u8d1f\u8f7d\u7684\u70ed\u653b\u51fb"}}
{"id": "2509.01083", "categories": ["cs.DC", "cs.AI", "cs.IT", "math.IT", "I.2.7; C.2.4"], "pdf": "https://arxiv.org/pdf/2509.01083", "abs": "https://arxiv.org/abs/2509.01083", "authors": ["Mingyu Yang", "Jae-Young Choi", "Kihyo Moon", "Minsung Jang", "Eunjoo Joen"], "title": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving", "comment": "10 pages, 9 figures. Preprint submitted to IEEE BigData 2025", "summary": "Speculative decoding accelerates large language model inference, but its\nreliance on a fixed speculation length is suboptimal in large-batch serving\nenvironments with diverse requests. This paper explores a new direction for\ndynamic adaptation by investigating a novel class of post-hoc, diagnostic\nsignals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free\nframework built on two primary components: (1) a predictive signal based on the\nvariance of the Kullback-Leibler (KLD) divergence, which diagnoses the\ngeneration's regional stability, and (2) an adaptive speculation length cap to\nmitigate the straggler problem in per-sequence decoding. Experiments\ndemonstrate the potential of using KLD-based stability signals for dynamic\nadaptation. An algorithm guided by these signals achieves end-to-end latency\ncompetitive with leading baselines and exhibits superior robustness across\ndiverse workloads. This robustness is particularly valuable in challenging\nlow-acceptance-rate regimes, where the proposed signal maintains its diagnostic\nutility. Collectively, these findings validate post-hoc signals as a valuable\ncomponent for building more robust and intelligent LLM inference systems, and\nhighlight a promising direction for future research on dynamic speculation\nlength adaptation.", "AI": {"tldr": "\u63d0\u51faDSDE\u6846\u67b6\uff0c\u901a\u8fc7KLD\u65b9\u5dee\u9884\u6d4b\u4fe1\u53f7\u548c\u81ea\u9002\u5e94\u63a8\u6d4b\u957f\u5ea6\u4e0a\u9650\uff0c\u5b9e\u73b0\u52a8\u6001\u63a8\u6d4b\u89e3\u7801\uff0c\u5728\u6279\u91cf\u670d\u52a1\u73af\u5883\u4e2d\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387", "motivation": "\u4f20\u7edf\u63a8\u6d4b\u89e3\u7801\u4f9d\u8d56\u56fa\u5b9a\u63a8\u6d4b\u957f\u5ea6\uff0c\u5728\u6279\u91cf\u670d\u52a1\u73af\u5883\u4e2d\u9762\u5bf9\u591a\u6837\u5316\u8bf7\u6c42\u65f6\u6548\u7387\u4e0d\u4f73\uff0c\u9700\u8981\u52a8\u6001\u9002\u5e94\u673a\u5236", "method": "DSDE\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u57fa\u4e8eKLD\u65b9\u5dee\u7684\u5206\u6790\u751f\u6210\u533a\u57df\u7a33\u5b9a\u6027\u7684\u9884\u6d4b\u4fe1\u53f7\uff0c\u4ee5\u53ca\u89e3\u51b3\u5355\u5e8f\u5217\u89e3\u7801\u4e2d\u6ede\u540e\u95ee\u9898\u7684\u81ea\u9002\u5e94\u63a8\u6d4b\u957f\u5ea6\u4e0a\u9650\u673a\u5236", "result": "\u5b9e\u9a8c\u663e\u793a\u57fa\u4e8eKLD\u7684\u7a33\u5b9a\u6027\u4fe1\u53f7\u5728\u52a8\u6001\u9002\u5e94\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7b97\u6cd5\u5728\u7aef\u5230\u7aef\u5ef6\u8fdf\u65b9\u9762\u4e0e\u9886\u5148\u57fa\u7ebf\u7ade\u4e89\uff0c\u5e76\u5728\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9c81\u68d2\u6027", "conclusion": "\u540e\u9a8c\u4fe1\u53f7\u662f\u6784\u5efa\u66f4\u9c81\u68d2\u667a\u80fdLLM\u63a8\u7406\u7cfb\u7edf\u7684\u91cd\u8981\u7ec4\u4ef6\uff0c\u4e3a\u52a8\u6001\u63a8\u6d4b\u957f\u5ea6\u9002\u5e94\u7684\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2509.00764", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00764", "abs": "https://arxiv.org/abs/2509.00764", "authors": ["Pragun Jaswal", "L. Hemanth Krishna", "B. Srinivasu"], "title": "Low Power Approximate Multiplier Architecture for Deep Neural Networks", "comment": null, "summary": "This paper proposes an low power approximate multiplier architecture for deep\nneural network (DNN) applications. A 4:2 compressor, introducing only a single\ncombination error, is designed and integrated into an 8x8 unsigned multiplier.\nThis integration significantly reduces the usage of exact compressors while\npreserving low error rates. The proposed multiplier is employed within a custom\nconvolution layer and evaluated on neural network tasks, including image\nrecognition and denoising. Hardware evaluation demonstrates that the proposed\ndesign achieves up to 30.24% energy savings compared to the best among existing\nmultipliers. In image denoising, the custom approximate convolution layer\nachieves improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity\nIndex Measure (SSIM) compared to other approximate designs. Additionally, when\napplied to handwritten digit recognition, the model maintains high\nclassification accuracy. These results demonstrate that the proposed\narchitecture offers a favorable balance between energy efficiency and\ncomputational precision, making it suitable for low-power AI hardware\nimplementations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u4f4e\u529f\u8017\u8fd1\u4f3c\u4e58\u6cd5\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4ec5\u4ea7\u751f\u5355\u4e00\u7ec4\u5408\u9519\u8bef\u76844:2\u538b\u7f29\u5668\uff0c\u5728\u4fdd\u6301\u4f4e\u9519\u8bef\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u7cbe\u786e\u538b\u7f29\u5668\u7684\u4f7f\u7528\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u5f00\u53d1\u4f4e\u529f\u8017\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u7684\u80fd\u8017\u8282\u7701\u3002", "method": "\u8bbe\u8ba1\u4ec5\u5f15\u5165\u5355\u4e00\u7ec4\u5408\u9519\u8bef\u76844:2\u538b\u7f29\u5668\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u52308x8\u65e0\u7b26\u53f7\u4e58\u6cd5\u5668\u4e2d\uff0c\u51cf\u5c11\u7cbe\u786e\u538b\u7f29\u5668\u7684\u4f7f\u7528\uff0c\u5e76\u5728\u81ea\u5b9a\u4e49\u5377\u79ef\u5c42\u4e2d\u5e94\u7528\u8be5\u4e58\u6cd5\u5668\u3002", "result": "\u786c\u4ef6\u8bc4\u4f30\u663e\u793a\u80fd\u8017\u8282\u7701\u8fbe30.24%\uff0c\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2dPSNR\u548cSSIM\u6307\u6807\u4f18\u4e8e\u5176\u4ed6\u8fd1\u4f3c\u8bbe\u8ba1\uff0c\u624b\u5199\u6570\u5b57\u8bc6\u522b\u4fdd\u6301\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u67b6\u6784\u5728\u80fd\u6548\u548c\u8ba1\u7b97\u7cbe\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u4f4e\u529f\u8017AI\u786c\u4ef6\u5b9e\u73b0\u3002"}}
{"id": "2509.01118", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.01118", "abs": "https://arxiv.org/abs/2509.01118", "authors": ["Jinyuan Chen"], "title": "Ocior: Ultra-Fast Asynchronous Leaderless Consensus with Two-Round Finality, Linear Overhead, and Adaptive Security", "comment": "52 pages", "summary": "In this work, we propose Ocior, a practical asynchronous Byzantine\nfault-tolerant (BFT) consensus protocol that achieves the optimal performance\nin resilience, communication, computation, and round complexity. Unlike\ntraditional BFT consensus protocols, Ocior processes incoming transactions\nindividually and concurrently using parallel instances of consensus. While\nleader-based consensus protocols rely on a designated leader to propose\ntransactions, Ocior is a leaderless consensus protocol that guarantees stable\nliveness. Ocior achieves: 1) Optimal resilience: Ocior tolerates up to $t$\nfaulty nodes controlled by an adaptive adversary, for $n\\geq 3t+1$. 2) Optimal\ncommunication complexity: The total expected communication per transaction is\n$O(n)$. 3) Optimal (or near-optimal) computation complexity: The total\ncomputation per transaction is $O(n)$ in the best case, or $O(n \\log^2 n)$ in\nthe worst case. 4) Optimal round complexity: A legitimate two-party transaction\ncan be finalized with a good-case latency of two asynchronous rounds, for any\n$n\\geq 3t+1$. The good case in terms of latency refers to the scenario where\nthe transaction is proposed by any (not necessarily designated) honest node. A\ntwo-party transaction involves the transfer of digital assets from one user (or\ngroup of users) to one or more recipients. To support efficient consensus, we\nintroduce a novel non-interactive threshold signature (TS) scheme called\nOciorBLSts. It offers fast signature aggregation, and is adaptively secure.\nOciorBLSts achieves a signature aggregation computation cost of only $O(n)$ for\nthe best case. Moreover, OciorBLSts supports the property of Instantaneous TS\nAggregation. This enables real-time aggregation of partial signatures as they\narrive, reducing waiting time and improving responsiveness.", "AI": {"tldr": "Ocior\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u5171\u8bc6\u534f\u8bae\uff0c\u5728\u5f39\u6027\u3001\u901a\u4fe1\u3001\u8ba1\u7b97\u548c\u8f6e\u6b21\u590d\u6742\u5ea6\u65b9\u9762\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002\u5b83\u662f\u4e00\u4e2a\u65e0\u9886\u5bfc\u8005\u7684\u534f\u8bae\uff0c\u901a\u8fc7\u5e76\u884c\u5171\u8bc6\u5b9e\u4f8b\u5904\u7406\u4ea4\u6613\uff0c\u652f\u6301\u77ac\u65f6\u9608\u503c\u7b7e\u540d\u805a\u5408\u3002", "motivation": "\u4f20\u7edfBFT\u5171\u8bc6\u534f\u8bae\u4f9d\u8d56\u6307\u5b9a\u9886\u5bfc\u8005\u6765\u63d0\u8bae\u4ea4\u6613\uff0c\u5b58\u5728\u6027\u80fd\u74f6\u9888\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u65e0\u9886\u5bfc\u8005\u7684\u5171\u8bc6\u534f\u8bae\uff0c\u5728\u5f02\u6b65\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u8bc1\u7a33\u5b9a\u7684\u6d3b\u8dc3\u6027\u3002", "method": "\u63d0\u51faOcior\u534f\u8bae\uff0c\u4f7f\u7528\u5e76\u884c\u5171\u8bc6\u5b9e\u4f8b\u5904\u7406\u4ea4\u6613\uff0c\u5f15\u5165\u65b0\u578b\u975e\u4ea4\u4e92\u5f0f\u9608\u503c\u7b7e\u540d\u65b9\u6848OciorBLSts\uff0c\u652f\u6301\u77ac\u65f6\u7b7e\u540d\u805a\u5408\u548c\u81ea\u9002\u5e94\u5b89\u5168\u6027\u3002", "result": "\u8fbe\u5230\u6700\u4f18\u5f39\u6027\uff08n\u22653t+1\uff09\u3001\u6700\u4f18\u901a\u4fe1\u590d\u6742\u5ea6\uff08O(n)\uff09\u3001\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u8ba1\u7b97\u590d\u6742\u5ea6\uff08O(n)\u6216O(n log\u00b2 n)\uff09\u3001\u6700\u4f18\u8f6e\u6b21\u590d\u6742\u5ea6\uff082\u8f6e\u5f02\u6b65\u5ef6\u8fdf\uff09\u3002", "conclusion": "Ocior\u534f\u8bae\u5728\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u5171\u8bc6\u4e2d\u5b9e\u73b0\u4e86\u5168\u9762\u7684\u6027\u80fd\u4f18\u5316\uff0c\u901a\u8fc7\u65e0\u9886\u5bfc\u8005\u8bbe\u8ba1\u548c\u521b\u65b0\u7684\u9608\u503c\u7b7e\u540d\u6280\u672f\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5171\u8bc6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00778", "categories": ["cs.AR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.00778", "abs": "https://arxiv.org/abs/2509.00778", "authors": ["Pragun Jaswal", "L. Hemanth Krishna", "B. Srinivasu"], "title": "Energy Efficient Exact and Approximate Systolic Array Architecture for Matrix Multiplication", "comment": "Submitted to 39th International Conference on VLSI Design, 2026", "summary": "Deep Neural Networks (DNNs) require highly efficient matrix multiplication\nengines for complex computations. This paper presents a systolic array\narchitecture incorporating novel exact and approximate processing elements\n(PEs), designed using energy-efficient positive partial product and negative\npartial product cells, termed as PPC and NPPC, respectively. The proposed 8-bit\nexact and approximate PE designs are employed in a 8x8 systolic array, which\nachieves a energy savings of 22% and 32%, respectively, compared to the\nexisting design. To demonstrate their effectiveness, the proposed PEs are\nintegrated into a systolic array (SA) for Discrete Cosine Transform (DCT)\ncomputation, achieving high output quality with a PSNR of 38.21,dB.\nFurthermore, in an edge detection application using convolution, the\napproximate PE achieves a PSNR of 30.45,dB. These results highlight the\npotential of the proposed design to deliver significant energy efficiency while\nmaintaining competitive output quality, making it well-suited for\nerror-resilient image and vision processing applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5305\u542b\u7cbe\u786e\u548c\u8fd1\u4f3c\u5904\u7406\u5355\u5143\u7684\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u5728DCT\u8ba1\u7b97\u548c\u8fb9\u7f18\u68c0\u6d4b\u5e94\u7528\u4e2d\u5b9e\u73b0\u663e\u8457\u8282\u80fd\u540c\u65f6\u4fdd\u6301\u826f\u597d\u8f93\u51fa\u8d28\u91cf", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u9ad8\u6548\u7684\u77e9\u9635\u4e58\u6cd5\u5f15\u64ce\uff0c\u4f20\u7edf\u8bbe\u8ba1\u80fd\u8017\u8f83\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u8282\u80fd\u7684\u67b6\u6784\u6765\u6ee1\u8db3\u590d\u6742\u8ba1\u7b97\u9700\u6c42", "method": "\u4f7f\u7528\u80fd\u91cf\u9ad8\u6548\u7684PPC\u548cNPPC\u5355\u5143\u8bbe\u8ba18\u4f4d\u7cbe\u786e\u548c\u8fd1\u4f3c\u5904\u7406\u5355\u5143\uff0c\u5e76\u96c6\u6210\u52308x8\u8109\u52a8\u9635\u5217\u4e2d", "result": "\u76f8\u6bd4\u73b0\u6709\u8bbe\u8ba1\u8282\u80fd22%\u548c32%\uff0cDCT\u8ba1\u7b97PSNR\u8fbe38.21dB\uff0c\u8fb9\u7f18\u68c0\u6d4bPSNR\u8fbe30.45dB", "conclusion": "\u6240\u63d0\u8bbe\u8ba1\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u8f93\u51fa\u8d28\u91cf\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u80fd\u6548\u63d0\u5347\uff0c\u975e\u5e38\u9002\u5408\u5bb9\u9519\u56fe\u50cf\u548c\u89c6\u89c9\u5904\u7406\u5e94\u7528"}}
{"id": "2509.01168", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01168", "abs": "https://arxiv.org/abs/2509.01168", "authors": ["Dmitry Yaremus", "Jianghai Li", "Alisa Kalacheva", "Igor Vodolazov", "Yury Yanovich"], "title": "Detecting Rug Pulls in Decentralized Exchanges: Machine Learning Evidence from the TON Blockchain", "comment": null, "summary": "This paper presents a machine learning framework for the early detection of\nrug pull scams on decentralized exchanges (DEXs) within The Open Network (TON)\nblockchain. TON's unique architecture, characterized by asynchronous execution\nand a massive web2 user base from Telegram, presents a novel and critical\nenvironment for fraud analysis. We conduct a comprehensive study on the two\nlargest TON DEXs, Ston.Fi and DeDust, fusing data from both platforms to train\nour models. A key contribution is the implementation and comparative analysis\nof two distinct rug pull definitions--TVL-based (a catastrophic liquidity\nwithdrawal) and idle-based (a sudden cessation of all trading activity)--within\na single, unified study. We demonstrate that Gradient Boosting models can\neffectively identify rug pulls within the first five minutes of trading, with\nthe TVL-based method achieving superior AUC (up to 0.891) while the idle-based\nmethod excels at recall. Our analysis reveals that while feature sets are\nconsistent across exchanges, their underlying distributions differ\nsignificantly, challenging straightforward data fusion and highlighting the\nneed for robust, platform-aware models. This work provides a crucial\nearly-warning mechanism for investors and enhances the security infrastructure\nof the rapidly growing TON DeFi ecosystem.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728TON\u533a\u5757\u94fe\u4e0a\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\u4e2d\u65e9\u671f\u68c0\u6d4brug pull\u9a97\u5c40\uff0c\u901a\u8fc7\u4e24\u79cd\u4e0d\u540c\u7684rug pull\u5b9a\u4e49\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u80fd\u591f\u5728\u4ea4\u6613\u524d5\u5206\u949f\u5185\u6709\u6548\u8bc6\u522b\u6b3a\u8bc8\u884c\u4e3a\u3002", "motivation": "TON\u533a\u5757\u94fe\u7684\u72ec\u7279\u67b6\u6784\uff08\u5f02\u6b65\u6267\u884c\u548cTelegram\u5e26\u6765\u7684\u6d77\u91cfweb2\u7528\u6237\uff09\u4e3a\u6b3a\u8bc8\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u9896\u4e14\u5173\u952e\u7684\u73af\u5883\uff0c\u9700\u8981\u4fdd\u62a4\u6295\u8d44\u8005\u5e76\u589e\u5f3aTON DeFi\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u5728TON\u6700\u5927\u7684\u4e24\u4e2aDEX\u5e73\u53f0Ston.Fi\u548cDeDust\u4e0a\u6536\u96c6\u6570\u636e\uff0c\u878d\u5408\u4e24\u4e2a\u5e73\u53f0\u7684\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002\u91c7\u7528\u4e24\u79cdrug pull\u5b9a\u4e49\u65b9\u6cd5\uff1aTVL-based\uff08\u707e\u96be\u6027\u6d41\u52a8\u6027\u63d0\u53d6\uff09\u548cidle-based\uff08\u4ea4\u6613\u6d3b\u52a8\u7a81\u7136\u505c\u6b62\uff09\uff0c\u4f7f\u7528\u68af\u5ea6\u63d0\u5347\u6a21\u578b\u8fdb\u884c\u65e9\u671f\u68c0\u6d4b\u3002", "result": "\u68af\u5ea6\u63d0\u5347\u6a21\u578b\u80fd\u5728\u4ea4\u6613\u524d5\u5206\u949f\u5185\u6709\u6548\u8bc6\u522brug pull\uff0cTVL-based\u65b9\u6cd5\u8fbe\u5230\u6700\u4f73AUC\uff080.891\uff09\uff0cidle-based\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u7814\u7a76\u53d1\u73b0\u867d\u7136\u7279\u5f81\u96c6\u5728\u4ea4\u6613\u6240\u95f4\u4e00\u81f4\uff0c\u4f46\u5e95\u5c42\u5206\u5e03\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6295\u8d44\u8005\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u65e9\u671f\u9884\u8b66\u673a\u5236\uff0c\u589e\u5f3a\u4e86\u5feb\u901f\u589e\u957f\u7684TON DeFi\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5065\u58ee\u7684\u3001\u5e73\u53f0\u611f\u77e5\u7684\u6a21\u578b\u6765\u5e94\u5bf9\u4e0d\u540c\u4ea4\u6613\u6240\u7684\u6570\u636e\u5206\u5e03\u5dee\u5f02\u3002"}}
{"id": "2509.00911", "categories": ["cs.AR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.00911", "abs": "https://arxiv.org/abs/2509.00911", "authors": ["Joongho Jo", "Jongsun Park"], "title": "GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency", "comment": "DAC 2025", "summary": "3D Gaussian Splatting (3D-GS) has emerged as a promising alternative to\nneural radiance fields (NeRF) as it offers high speed as well as high image\nquality in novel view synthesis. Despite these advancements, 3D-GS still\nstruggles to meet the frames per second (FPS) demands of real-time\napplications. In this paper, we introduce GS-TG, a tile-grouping-based\naccelerator that enhances 3D-GS rendering speed by reducing redundant sorting\noperations and preserving rasterization efficiency. GS-TG addresses a critical\ntrade-off issue in 3D-GS rendering: increasing the tile size effectively\nreduces redundant sorting operations, but it concurrently increases unnecessary\nrasterization computations. So, during sorting of the proposed approach, GS-TG\ngroups small tiles (for making large tiles) to share sorting operations across\ntiles within each group, significantly reducing redundant computations. During\nrasterization, a bitmask assigned to each Gaussian identifies relevant small\ntiles, to enable efficient sharing of sorting results. Consequently, GS-TG\nenables sorting to be performed as if a large tile size is used by grouping\ntiles during the sorting stage, while allowing rasterization to proceed with\nthe original small tiles by using bitmasks in the rasterization stage. GS-TG is\na lossless method requiring no retraining or fine-tuning and it can be\nseamlessly integrated with previous 3D-GS optimization techniques. Experimental\nresults show that GS-TG achieves an average speed-up of 1.54 times over\nstate-of-the-art 3D-GS accelerators.", "AI": {"tldr": "GS-TG\u662f\u4e00\u79cd\u57fa\u4e8e\u74e6\u7247\u5206\u7ec4\u76843D\u9ad8\u65af\u6cfc\u6e85\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u51cf\u5c11\u5197\u4f59\u6392\u5e8f\u64cd\u4f5c\u5e76\u4fdd\u6301\u5149\u6805\u5316\u6548\u7387\uff0c\u5b9e\u73b01.54\u500d\u7684\u5e73\u5747\u52a0\u901f\u6548\u679c", "motivation": "3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u867d\u7136\u6bd4NeRF\u66f4\u5feb\uff0c\u4f46\u4ecd\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u5e94\u7528\u7684\u9ad8\u5e27\u7387\u9700\u6c42\uff0c\u9700\u8981\u5728\u51cf\u5c11\u6392\u5e8f\u5197\u4f59\u548c\u4fdd\u6301\u5149\u6805\u5316\u6548\u7387\u4e4b\u95f4\u627e\u5230\u5e73\u8861", "method": "\u63d0\u51fa\u74e6\u7247\u5206\u7ec4\u65b9\u6cd5\uff1a\u5728\u6392\u5e8f\u9636\u6bb5\u5c06\u5c0f\u74e6\u7247\u5206\u7ec4\u5f62\u6210\u5927\u74e6\u7247\u6765\u5171\u4eab\u6392\u5e8f\u64cd\u4f5c\uff0c\u5728\u5149\u6805\u5316\u9636\u6bb5\u4f7f\u7528\u4f4d\u63a9\u7801\u6807\u8bc6\u76f8\u5173\u5c0f\u74e6\u7247\uff0c\u5b9e\u73b0\u6392\u5e8f\u7528\u5927\u74e6\u7247\u3001\u5149\u6805\u5316\u7528\u5c0f\u74e6\u7247\u7684\u7b56\u7565", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eGS-TG\u76f8\u6bd4\u6700\u5148\u8fdb\u76843D-GS\u52a0\u901f\u5668\u5e73\u5747\u52a0\u901f1.54\u500d\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03", "conclusion": "GS-TG\u6210\u529f\u89e3\u51b3\u4e863D-GS\u6e32\u67d3\u4e2d\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\uff0c\u662f\u4e00\u79cd\u65e0\u635f\u7684\u52a0\u901f\u65b9\u6cd5\uff0c\u53ef\u4e0e\u73b0\u6709\u4f18\u5316\u6280\u672f\u65e0\u7f1d\u96c6\u6210"}}
{"id": "2509.01193", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.01193", "abs": "https://arxiv.org/abs/2509.01193", "authors": ["Sheng Lin", "Fangcheng Fu", "Haoyang Li", "Hao Ge", "Xuanyu Wang", "Jiawen Niu", "Yaofeng Tu", "Bin Cui"], "title": "LobRA: Multi-tenant Fine-tuning over Heterogeneous Data", "comment": "VLDB 2025, version with appendix", "summary": "With the breakthrough of Transformer-based pre-trained models, the demand for\nfine-tuning (FT) to adapt the base pre-trained models to downstream\napplications continues to grow, so it is essential for service providers to\nreduce the cost of processing FT requests. Low-rank adaption (LoRA) is a widely\nused FT technique that only trains small-scale adapters and keeps the base\nmodel unaltered, conveying the possibility of processing multiple FT tasks by\njointly training different LoRA adapters with a shared base model.\n  Nevertheless, through in-depth analysis, we reveal the efficiency of joint FT\nis dampened by two heterogeneity issues in the training data -- the sequence\nlength variation and skewness. To tackle these issues, we develop LobRA, a\nbrand new framework that supports processing multiple FT tasks by jointly\ntraining LoRA adapters. Two innovative designs are introduced. Firstly, LobRA\ndeploys the FT replicas (i.e., model replicas for FT) with heterogeneous\nresource usages and parallel configurations, matching the diverse workloads\ncaused by the sequence length variation. Secondly, for each training step,\nLobRA takes account of the sequence length skewness and dispatches the training\ndata among the heterogeneous FT replicas to achieve workload balance. We\nconduct experiments to assess the performance of LobRA, validating that it\nsignificantly reduces the GPU seconds required for joint FT by 45.03%-60.67%.", "AI": {"tldr": "LobRA\u6846\u67b6\u901a\u8fc7\u5f02\u6784\u8d44\u6e90\u914d\u7f6e\u548c\u8d1f\u8f7d\u5747\u8861\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u591a\u4efb\u52a1LoRA\u8054\u5408\u5fae\u8c03\u4e2d\u7684\u5e8f\u5217\u957f\u5ea6\u53d8\u5316\u548c\u504f\u659c\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387", "motivation": "\u968f\u7740Transformer\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u666e\u53ca\uff0c\u5fae\u8c03\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u964d\u4f4e\u5904\u7406\u6210\u672c\u3002LoRA\u6280\u672f\u5141\u8bb8\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\uff0c\u4f46\u5b58\u5728\u5e8f\u5217\u957f\u5ea6\u53d8\u5316\u548c\u504f\u659c\u5bfc\u81f4\u7684\u6548\u7387\u95ee\u9898", "method": "1) \u90e8\u7f72\u5f02\u6784\u8d44\u6e90\u914d\u7f6e\u7684FT\u526f\u672c\u5339\u914d\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\uff1b2) \u57fa\u4e8e\u5e8f\u5217\u957f\u5ea6\u504f\u659c\u8fdb\u884c\u8bad\u7ec3\u6570\u636e\u8c03\u5ea6\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861", "result": "\u5b9e\u9a8c\u9a8c\u8bc1LobRA\u663e\u8457\u51cf\u5c11\u8054\u5408\u5fae\u8c03\u6240\u9700\u7684GPU\u65f6\u95f4\uff0c\u964d\u4f4e45.03%-60.67%", "conclusion": "LobRA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4efb\u52a1LoRA\u8054\u5408\u8bad\u7ec3\u4e2d\u7684\u5f02\u6784\u6027\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387"}}
{"id": "2509.01020", "categories": ["cs.AR", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.01020", "abs": "https://arxiv.org/abs/2509.01020", "authors": ["Elena Espinosa", "Rub\u00e9n Rodr\u00edguez \u00c1lvarez", "Jos\u00e9 Miranda", "Rafael Larrosa", "Miguel Pe\u00f3n-Quir\u00f3s", "Oscar Plata", "David Atienza"], "title": "GeneTEK: Low-power, high-performance and scalable genome sequence matching in FPGAs", "comment": null, "summary": "The advent of next-generation sequencing (NGS) has revolutionized genomic\nresearch by enabling high-throughput data generation through parallel\nsequencing of a diverse range of organisms at significantly reduced costs. This\nbreakthrough has unleashed a \"Cambrian explosion\" in genomic data volume and\ndiversity. This volume of workloads places genomics among the top four big data\nchallenges anticipated for this decade. In this context, pairwise sequence\nalignment represents a very time- and energy-consuming step in common\nbioinformatics pipelines. Speeding up this step requires the implementation of\nheuristic approaches, optimized algorithms, and/or hardware acceleration.\n  Whereas state-of-the-art CPU and GPU implementations have demonstrated\nsignificant performance gains, recent field programmable gate array (FPGA)\nimplementations have shown improved energy efficiency. However, the latter\noften suffer from limited scalability due to constraints on hardware resources\nwhen aligning longer sequences. In this work, we present a scalable and\nflexible FPGA-based accelerator template that implements Myers's algorithm\nusing high-level synthesis and a worker-based architecture. GeneTEK, an\ninstance of this accelerator template in a Xilinx Zynq UltraScale+ FPGA,\noutperforms state-of-the-art CPU and GPU implementations in both speed and\nenergy efficiency, while overcoming scalability limitations of current FPGA\napproaches. Specifically, GeneTEK achieves at least a 19.4% increase in\nexecution speed and up to 62x reduction in energy consumption compared to\nleading CPU and GPU solutions, while fitting comparison matrices up to 72%\nlarger compared to previous FPGA solutions. These results reaffirm the\npotential of FPGAs as an energy-efficient platform for scalable genomic\nworkloads.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684FPGA\u52a0\u901f\u5668\u6a21\u677fGeneTEK\uff0c\u901a\u8fc7\u9ad8\u7ea7\u7efc\u5408\u548c\u5de5\u4f5c\u8005\u67b6\u6784\u5b9e\u73b0Myers\u7b97\u6cd5\uff0c\u5728\u57fa\u56e0\u7ec4\u5e8f\u5217\u6bd4\u5bf9\u6b63\u5bf9\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u901f\u5ea6\u548c\u80fd\u6d88\u8017\u6548\u7387\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u5e8f\u5217\u6280\u672f\u4ea7\u751f\u7684\u5de8\u91cf\u57fa\u56e0\u7ec4\u6570\u636e\u5bfc\u81f4\u5e8f\u5217\u6bd4\u5bf9\u6210\u4e3a\u8010\u65f6\u548c\u80fd\u8017\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u9700\u8981\u5feb\u901f\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684FPGA\u52a0\u901f\u5668\u6a21\u677f\uff0c\u4f7f\u7528\u9ad8\u7ea7\u7efc\u5408\u6280\u672f\u5b9e\u73b0Myers\u7b97\u6cd5\uff0c\u91c7\u7528\u5de5\u4f5c\u8005\u57fa\u7840\u67b6\u6784\u6765\u63d0\u9ad8\u6269\u5c55\u6027\u3002", "result": "GeneTEK\u5728Xilinx Zynq UltraScale+ FPGA\u4e0a\u5b9e\u73b0\uff0c\u4e0e\u9886\u5148\u7684CPU\u548cGPU\u5b9e\u73b0\u76f8\u6bd4\uff0c\u901f\u5ea6\u63d0\u9ad8\u81f3\u5c1119.4%\uff0c\u80fd\u8017\u964d\u4f4e\u8fbe62\u500d\uff0c\u5e76\u80fd\u5904\u7406\u6bd4\u4e4b\u524dFPGA\u65b9\u6848\u592772%\u7684\u6bd4\u5bf9\u77e9\u9635\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u786e\u8ba4\u4e86FPGA\u4f5c\u4e3a\u80fd\u6548\u9ad8\u7684\u5e73\u53f0\uff0c\u5728\u53ef\u6269\u5c55\u7684\u57fa\u56e0\u7ec4\u5de5\u4f5c\u8d1f\u8377\u5904\u7406\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.01229", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01229", "abs": "https://arxiv.org/abs/2509.01229", "authors": ["Huanqi Hu", "Bowen Xiao", "Shixuan Sun", "Jianian Yin", "Zhexi Zhang", "Xiang Luo", "Chengquan Jiang", "Weiqi Xu", "Xiaoying Jia", "Xin Liu", "Minyi Guo"], "title": "LiquidGEMM: Hardware-Efficient W4A8 GEMM Kernel for High-Performance LLM Serving", "comment": "12 pages, 13 figures", "summary": "Quantization is a critical technique for accelerating LLM inference by\nreducing memory footprint and improving computational efficiency. Among various\nschemes, 4-bit weight and 8-bit activation quantization (W4A8) offers a strong\nbalance between accuracy and performance. However, existing W4A8 GEMM kernels\nfall short in practice due to inefficient dequantization on CUDA Cores, which\ncannot keep pace with the high throughput of Tensor Cores. In this paper, we\npresent LiquidGEMM, a hardware-efficient W4A8 GEMM kernel for efficient LLM\nserving. LiquidGEMM designs two key techniques: LiquidQuant, a\nhardware-efficient quantization method that enables fast, overflow-safe\ndequantization using just two arithmetic instructions per four elements; and an\nimplicit fine-grained pipeline that fully overlaps weight loading,\ndequantization, and MMA across warp groups without software synchronization or\nredundant memory traffic. Experimental results show that LiquidGEMM achieves up\nto 2.90x speedup over state-of-the-art W4A8 kernels and up to 4.94x end-to-end\nsystem-level speedup. Compared to various quantized GEMM kernels in NVIDIA\nTensorRT-LLM, LiquidGEMM delivers 1.12-1.63x performance gains, and achieves up\nto 1.63x system-level speedup.", "AI": {"tldr": "LiquidGEMM\u662f\u4e00\u4e2a\u786c\u4ef6\u9ad8\u6548\u7684W4A8 GEMM\u5185\u6838\uff0c\u901a\u8fc7LiquidQuant\u91cf\u5316\u65b9\u6cd5\u548c\u9690\u5f0f\u7ec6\u7c92\u5ea6\u6d41\u6c34\u7ebf\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6848\u6700\u9ad82.9\u500d\u7684\u52a0\u901f\u548c4.94\u500d\u7684\u7cfb\u7edf\u7ea7\u7aef\u5230\u7aef\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684W4A8 GEMM\u5185\u6838\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3aCUDA\u6838\u5fc3\u4e0a\u7684\u4f4e\u6548\u53cd\u91cf\u5316\u65e0\u6cd5\u8ddf\u4e0aTensor Core\u7684\u9ad8\u541e\u5410\u91cf\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u91cf\u5316\u65b9\u6848\u6765\u52a0\u901fLLM\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86LiquidGEMM\u5185\u6838\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a1) LiquidQuant\u786c\u4ef6\u9ad8\u6548\u91cf\u5316\u65b9\u6cd5\uff0c\u6bcf4\u4e2a\u5143\u7d20\u4ec5\u9700\u4e24\u6761\u7b97\u672f\u6307\u4ee4\u5b9e\u73b0\u5feb\u901f\u3001\u9632\u6ea2\u51fa\u7684\u53cd\u91cf\u5316\uff1b2) \u9690\u5f0f\u7ec6\u7c92\u5ea6\u6d41\u6c34\u7ebf\uff0c\u5728warp\u7ec4\u95f4\u5b8c\u5168\u91cd\u53e0\u6743\u91cd\u52a0\u8f7d\u3001\u53cd\u91cf\u5316\u548c\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97\uff0c\u65e0\u9700\u8f6f\u4ef6\u540c\u6b65\u6216\u5197\u4f59\u5185\u5b58\u8bbf\u95ee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u76f8\u6bd4\u6700\u5148\u8fdb\u7684W4A8\u5185\u6838\u8fbe\u52302.90\u500d\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u7cfb\u7edf\u7ea7\u52a0\u901f\u8fbe4.94\u500d\uff1b\u76f8\u6bd4NVIDIA TensorRT-LLM\u4e2d\u7684\u5404\u79cd\u91cf\u5316GEMM\u5185\u6838\uff0c\u6027\u80fd\u63d0\u53471.12-1.63\u500d\uff0c\u7cfb\u7edf\u7ea7\u52a0\u901f\u6700\u9ad81.63\u500d\u3002", "conclusion": "LiquidGEMM\u901a\u8fc7\u786c\u4ef6\u4f18\u5316\u7684\u91cf\u5316\u65b9\u6cd5\u548c\u9ad8\u6548\u7684\u6d41\u6c34\u7ebf\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86W4A8\u91cf\u5316\u5728LLM\u63a8\u7406\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548LLM\u670d\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01339", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.01339", "abs": "https://arxiv.org/abs/2509.01339", "authors": ["Bochen Ye", "Gustavo Naspolini", "Kimmo Salo", "Manil Dev Gomony"], "title": "LinkBo: An Adaptive Single-Wire, Low-Latency, and Fault-Tolerant Communications Interface for Variable-Distance Chip-to-Chip Systems", "comment": "This paper is full version of SOCC'2025 conference", "summary": "Cost-effective embedded systems necessitate utilizing the single-wire\ncommunication protocol for inter-chip communication, thanks to its reduced pin\ncount in comparison to the multi-wire I2C or SPI protocols. However, current\nsingle-wire protocols suffer from increased latency, restricted throughput, and\nlack of robustness. This paper presents LinkBo, an innovative single-wire\nprotocol that offers reduced latency, enhanced throughput, and greater\nrobustness with hardware-interrupt for variable-distance inter-chip\ncommunication. The LinkBo protocol-level guarantees that high-priority messages\nare delivered with an error detection feature in just 50.4 $\\mu$s, surpassing\ncurrent commercial options, 1-wire and UNI/O by at least 20X and 6.3X,\nrespectively. In addition, we present the hardware architecture for this new\nprotocol and its performance evaluation on a hardware platform consisting of\ntwo FPGAs. Our findings demonstrate that the protocol reliably supports wire\nlengths up to 15 meters with a data rate of 300 kbps, while reaching a maximum\ndata rate of 7.5 Mbps over an 11 cm wire, providing reliable performance for\nvarying inter-chip communication distances.", "AI": {"tldr": "LinkBo\u662f\u4e00\u79cd\u521b\u65b0\u7684\u5355\u7ebf\u901a\u4fe1\u534f\u8bae\uff0c\u76f8\u6bd4\u73b0\u6709\u76841-wire\u548cUNI/O\u534f\u8bae\uff0c\u5728\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u652f\u6301\u6700\u957f15\u7c73\u7ebf\u7f06\u548c\u6700\u9ad87.5 Mbps\u7684\u6570\u636e\u901f\u7387\u3002", "motivation": "\u73b0\u6709\u5355\u7ebf\u901a\u4fe1\u534f\u8bae\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u541e\u5410\u91cf\u53d7\u9650\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5355\u7ebf\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\u6765\u51cf\u5c11\u5f15\u811a\u6570\u91cf\u3002", "method": "\u63d0\u51fa\u4e86LinkBo\u534f\u8bae\u53ca\u5176\u786c\u4ef6\u67b6\u6784\uff0c\u91c7\u7528\u786c\u4ef6\u4e2d\u65ad\u673a\u5236\u548c\u9519\u8bef\u68c0\u6d4b\u529f\u80fd\uff0c\u5728FPGA\u5e73\u53f0\u4e0a\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "LinkBo\u534f\u8bae\u9ad8\u4f18\u5148\u7ea7\u6d88\u606f\u4f20\u8f93\u5ef6\u8fdf\u4ec550.4\u03bcs\uff0c\u6bd4\u73b0\u6709\u5546\u4e1a\u65b9\u6848\u5feb20\u500d\u548c6.3\u500d\uff0c\u652f\u6301300 kbps@15\u7c73\u548c7.5 Mbps@11\u5398\u7c73\u7684\u901a\u4fe1\u6027\u80fd\u3002", "conclusion": "LinkBo\u534f\u8bae\u4e3a\u53ef\u53d8\u8ddd\u79bb\u82af\u7247\u95f4\u901a\u4fe1\u63d0\u4f9b\u4e86\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u548c\u9ad8\u9c81\u68d2\u6027\u7684\u5355\u7ebf\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2509.01425", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.01425", "abs": "https://arxiv.org/abs/2509.01425", "authors": ["Sergio Miguel Martin", "Luca Terracciano", "Kiril Dichev", "Noah Baumann", "Jiashu Lin", "Albert-Jan Yzelman"], "title": "HiCR, an Abstract Model for Distributed Heterogeneous Programming", "comment": null, "summary": "We present HiCR, a model to represent the semantics of distributed\nheterogeneous applications and runtime systems. The model describes a minimal\nset of abstract operations to enable hardware topology discovery, kernel\nexecution, memory management, communication, and instance management, without\nprescribing any implementation decisions. The goal of the model is to enable\nexecution in current and future systems without the need for significant\nrefactoring, while also being able to serve any governing parallel programming\nparadigm. In terms of software abstraction, HiCR is naturally located between\ndistributed heterogeneous systems and runtime systems. We coin the phrase\n\\emph{Runtime Support Layer} for this level of abstraction. We explain how the\nmodel's components and operations are realized by a plugin-based approach that\ntakes care of device-specific implementation details, and present examples of\nHiCR-based applications that operate equally on a diversity of platforms.", "AI": {"tldr": "HiCR\u662f\u4e00\u4e2a\u7528\u4e8e\u8868\u793a\u5206\u5e03\u5f0f\u5f02\u6784\u5e94\u7528\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u8bed\u4e49\u7684\u6a21\u578b\uff0c\u63d0\u4f9b\u786c\u4ef6\u62d3\u6251\u53d1\u73b0\u3001\u5185\u6838\u6267\u884c\u3001\u5185\u5b58\u7ba1\u7406\u3001\u901a\u4fe1\u548c\u5b9e\u4f8b\u7ba1\u7406\u7b49\u62bd\u8c61\u64cd\u4f5c\uff0c\u4f4d\u4e8e\u5206\u5e03\u5f0f\u5f02\u6784\u7cfb\u7edf\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u4e4b\u95f4\u7684\u62bd\u8c61\u5c42\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5206\u5e03\u5f0f\u5f02\u6784\u7cfb\u7edf\u5728\u786c\u4ef6\u591a\u6837\u6027\u548c\u7f16\u7a0b\u8303\u5f0f\u53d8\u5316\u65f6\u9700\u8981\u8fdb\u884c\u91cd\u5927\u91cd\u6784\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u80fd\u591f\u9002\u5e94\u5f53\u524d\u548c\u672a\u6765\u7cfb\u7edf\u3001\u652f\u6301\u5404\u79cd\u5e76\u884c\u7f16\u7a0b\u8303\u5f0f\u7684\u7edf\u4e00\u62bd\u8c61\u6a21\u578b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63d2\u4ef6\u7684\u65b9\u6cd5\u5b9e\u73b0\u6a21\u578b\u7ec4\u4ef6\u548c\u64cd\u4f5c\uff0c\u5904\u7406\u8bbe\u5907\u7279\u5b9a\u7684\u5b9e\u73b0\u7ec6\u8282\uff0c\u5b9a\u4e49\u6700\u5c0f\u5316\u7684\u62bd\u8c61\u64cd\u4f5c\u96c6\u800c\u4e0d\u89c4\u5b9a\u5177\u4f53\u5b9e\u73b0\u51b3\u7b56\u3002", "result": "\u5f00\u53d1\u4e86HiCR\u6a21\u578b\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8be5\u6a21\u578b\u7684\u5e94\u7528\uff0c\u8fd9\u4e9b\u5e94\u7528\u80fd\u591f\u5728\u591a\u79cd\u5e73\u53f0\u4e0a\u540c\u7b49\u8fd0\u884c\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u3002", "conclusion": "HiCR\u4f5c\u4e3a\u8fd0\u884c\u65f6\u652f\u6301\u5c42\u62bd\u8c61\uff0c\u6210\u529f\u63d0\u4f9b\u4e86\u786c\u4ef6\u65e0\u5173\u7684\u7f16\u7a0b\u63a5\u53e3\uff0c\u4f7f\u5206\u5e03\u5f0f\u5f02\u6784\u5e94\u7528\u80fd\u591f\u5728\u4e0d\u8fdb\u884c\u91cd\u5927\u91cd\u6784\u7684\u60c5\u51b5\u4e0b\u9002\u5e94\u4e0d\u540c\u7684\u786c\u4ef6\u5e73\u53f0\u548c\u7f16\u7a0b\u8303\u5f0f\u3002"}}
{"id": "2509.02369", "categories": ["cs.AR", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.02369", "abs": "https://arxiv.org/abs/2509.02369", "authors": ["Zacharia A. Rudge", "Dario Izzo", "Moritz Fieback", "Anteneh Gebregiorgis", "Said Hamdioui", "Dominik Dold"], "title": "Guidance and Control Neural Network Acceleration using Memristors", "comment": "4 pages, SPAICE 2024 conference", "summary": "In recent years, the space community has been exploring the possibilities of\nArtificial Intelligence (AI), specifically Artificial Neural Networks (ANNs),\nfor a variety of on board applications. However, this development is limited by\nthe restricted energy budget of smallsats and cubesats as well as radiation\nconcerns plaguing modern chips. This necessitates research into neural network\naccelerators capable of meeting these requirements whilst satisfying the\ncompute and performance needs of the application. This paper explores the use\nof Phase-Change Memory (PCM) and Resistive Random-Access Memory (RRAM)\nmemristors for on-board in-memory computing AI acceleration in space\napplications. A guidance and control neural network (G\\&CNET) accelerated using\nmemristors is simulated in a variety of scenarios and with both device types to\nevaluate the performance of memristor-based accelerators, considering device\nnon-idealities such as noise and conductance drift. We show that the memristive\naccelerator is able to learn the expert actions, though challenges remain with\nthe impact of noise on accuracy. We also show that re-training after\ndegradation is able to restore performance to nominal levels. This study\nprovides a foundation for future research into memristor-based AI accelerators\nfor space, highlighting their potential and the need for further investigation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4f7f\u7528\u76f8\u53d8\u5b58\u50a8\u5668(PCM)\u548c\u7535\u963b\u5f0f\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668(RRAM)\u5fc6\u963b\u5668\u5728\u592a\u7a7a\u5e94\u7528\u4e2d\u5b9e\u73b0\u661f\u8f7d\u5185\u5b58\u8ba1\u7b97AI\u52a0\u901f\uff0c\u7279\u522b\u9488\u5bf9\u5236\u5bfc\u63a7\u5236\u795e\u7ecf\u7f51\u7edc(G&CNET)\u7684\u52a0\u901f\u6027\u80fd\u8fdb\u884c\u4eff\u771f\u8bc4\u4f30\u3002", "motivation": "\u5c0f\u578b\u536b\u661f\u548c\u7acb\u65b9\u4f53\u536b\u661f\u7684\u6709\u9650\u80fd\u6e90\u9884\u7b97\u4ee5\u53ca\u73b0\u4ee3\u82af\u7247\u7684\u8f90\u5c04\u95ee\u9898\u9650\u5236\u4e86AI\u5728\u661f\u8f7d\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\uff0c\u9700\u8981\u7814\u7a76\u80fd\u591f\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u540c\u65f6\u6ee1\u8db3\u5e94\u7528\u8ba1\u7b97\u548c\u6027\u80fd\u9700\u6c42\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u3002", "method": "\u4f7f\u7528PCM\u548cRRAM\u5fc6\u963b\u5668\u5bf9\u5236\u5bfc\u63a7\u5236\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u52a0\u901f\u4eff\u771f\uff0c\u8003\u8651\u5668\u4ef6\u7684\u975e\u7406\u60f3\u7279\u6027\u5982\u566a\u58f0\u548c\u7535\u5bfc\u6f02\u79fb\uff0c\u5e76\u5728\u5404\u79cd\u573a\u666f\u4e0b\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5fc6\u963b\u5668\u52a0\u901f\u5668\u80fd\u591f\u5b66\u4e60\u4e13\u5bb6\u52a8\u4f5c\uff0c\u4f46\u566a\u58f0\u5bf9\u51c6\u786e\u6027\u7684\u5f71\u54cd\u4ecd\u5b58\u5728\u6311\u6218\uff1b\u5728\u6027\u80fd\u9000\u5316\u540e\u91cd\u65b0\u8bad\u7ec3\u80fd\u591f\u5c06\u6027\u80fd\u6062\u590d\u5230\u6807\u79f0\u6c34\u5e73\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u672a\u6765\u592a\u7a7a\u5e94\u7528\u4e2d\u57fa\u4e8e\u5fc6\u963b\u5668\u7684AI\u52a0\u901f\u5668\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7a81\u51fa\u4e86\u5176\u6f5c\u529b\u4ee5\u53ca\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.01626", "categories": ["cs.DC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.01626", "abs": "https://arxiv.org/abs/2509.01626", "authors": ["Daoce Wang", "Pascal Grosset", "Jesus Pulido", "Jiannan Tian", "Tushar M. Athawale", "Jinda Jia", "Baixi Sun", "Boyuan Zhang", "Sian Jin", "Kai Zhao", "James Ahrens", "Fengguang Song"], "title": "STZ: A High Quality and High Speed Streaming Lossy Compression Framework for Scientific Data", "comment": "accepted by SC '25", "summary": "Error-bounded lossy compression is one of the most efficient solutions to\nreduce the volume of scientific data. For lossy compression, progressive\ndecompression and random-access decompression are critical features that enable\non-demand data access and flexible analysis workflows. However, these features\ncan severely degrade compression quality and speed. To address these\nlimitations, we propose a novel streaming compression framework that supports\nboth progressive decompression and random-access decompression while\nmaintaining high compression quality and speed. Our contributions are\nthree-fold: (1) we design the first compression framework that simultaneously\nenables both progressive decompression and random-access decompression; (2) we\nintroduce a hierarchical partitioning strategy to enable both streaming\nfeatures, along with a hierarchical prediction mechanism that mitigates the\nimpact of partitioning and achieves high compression quality -- even comparable\nto state-of-the-art (SOTA) non-streaming compressor SZ3; and (3) our framework\ndelivers high compression and decompression speed, up to 6.7$\\times$ faster\nthan SZ3.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u540c\u65f6\u652f\u6301\u6e10\u8fdb\u89e3\u538b\u7f29\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u9ad8\u538b\u7f29\u8d28\u91cf\u548c\u901f\u5ea6\u7684\u524d\u63d0\u4e0b\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9650\u5236\u3002", "motivation": "\u6e10\u8fdb\u89e3\u538b\u7f29\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\u5bf9\u79d1\u5b66\u6570\u636e\u7684\u6309\u9700\u8bbf\u95ee\u548c\u7075\u6d3b\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f1a\u4e25\u91cd\u964d\u4f4e\u538b\u7f29\u8d28\u91cf\u548c\u901f\u5ea6\u3002", "method": "\u8bbe\u8ba1\u4e86\u7b2c\u4e00\u4e2a\u540c\u65f6\u652f\u6301\u4e24\u79cd\u6d41\u5f0f\u7279\u6027\u7684\u538b\u7f29\u6846\u67b6\uff0c\u91c7\u7528\u5c42\u6b21\u5206\u533a\u7b56\u7565\u548c\u5c42\u6b21\u9884\u6d4b\u673a\u5236\u6765\u51cf\u5c11\u5206\u533a\u5e26\u6765\u7684\u5f71\u54cd\uff0c\u4fdd\u6301\u9ad8\u538b\u7f29\u8d28\u91cf\u3002", "result": "\u538b\u7f29\u8d28\u91cf\u53ef\u4e0e\u6700\u5148\u8fdb\u975e\u6d41\u5f0f\u538b\u7f29\u5668SZ3\u76f8\u6bd4\uff0c\u538b\u7f29\u548c\u89e3\u538b\u7f29\u901f\u5ea6\u6700\u9ad8\u53ef\u8fbeSZ3\u76846.7\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6e10\u8fdb\u89e3\u538b\u7f29\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\u7684\u6027\u80fd\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u538b\u7f29\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2509.01811", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.01811", "abs": "https://arxiv.org/abs/2509.01811", "authors": ["Chengzhang Li", "Peizhong Ju", "Atilla Eryilmaz", "Ness Shroff"], "title": "Optimal Parallel Scheduling under Concave Speedup Functions", "comment": null, "summary": "Efficient scheduling of parallel computation resources across multiple jobs\nis a fundamental problem in modern cloud/edge computing systems for many\nAI-based applications. Allocating more resources to a job accelerates its\ncompletion, but with diminishing returns. Prior work (heSRPT) solved this\nproblem only for some specific speedup functions with an exponential form,\nproviding a closed-form solution. However, the general case with arbitrary\nconcave speedup functions -- which more accurately capture real-world workloads\n-- has remained open.\n  In this paper, we solve this open problem by developing optimal scheduling\nalgorithms for parallel jobs under general concave speedup functions. We first\ndiscover a fundamental and broadly-applicable rule for optimal parallel\nscheduling, namely the Consistent Derivative Ratio (CDR) Rule, which states\nthat the ratio of the derivatives of the speedup functions across active jobs\nremains constant over time. To efficiently compute the optimal allocations that\nsatisfy the CDR Rule, we propose the General Water-Filling (GWF) method, a more\ngeneral version of classical water-filling in wireless communications.\nCombining these insights, we design the SmartFill Algorithm to solve the\ngeneral scheduling problem. Unlike heSRPT, which always allocates resources to\nall active jobs, SmartFill selectively determines which jobs should receive\nresources and how much they should be allocated. For a broad class of so-called\n\\emph{regular} speedup functions, SmartFill yields closed-form optimal\nsolutions, while for non-regular functions it efficiently computes the optimum\nwith low complexity. Numerical evaluations show that SmartFill can\nsubstantially outperform heSRPT across a wide range of concave speedup\nfunctions.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5e76\u884c\u4f5c\u4e1a\u8c03\u5ea6\u4e2d\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e00\u822c\u51f9\u52a0\u901f\u51fd\u6570\u7684\u4f18\u5316\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5305\u62ecCDR\u89c4\u5219\u3001GWF\u65b9\u6cd5\u548cSmartFill\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u4e91\u8ba1\u7b97\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u9ad8\u6548\u8c03\u5ea6\u5e76\u884c\u8ba1\u7b97\u8d44\u6e90\u662f\u4e00\u4e2a\u57fa\u7840\u6027\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5heSRPT\u53ea\u80fd\u5904\u7406\u7279\u5b9a\u6307\u6570\u5f62\u5f0f\u7684\u52a0\u901f\u51fd\u6570\uff0c\u800c\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u66f4\u7b26\u5408\u4e00\u822c\u51f9\u52a0\u901f\u51fd\u6570\uff0c\u8fd9\u4e2a\u95ee\u9898\u4e00\u76f4\u672a\u5f97\u5230\u89e3\u51b3\u3002", "method": "\u9996\u5148\u53d1\u73b0\u4e86\u6700\u4f18\u5e76\u884c\u8c03\u5ea6\u7684\u57fa\u672c\u89c4\u5219\u2014\u2014\u6052\u5b9a\u5bfc\u6570\u6bd4(CDR)\u89c4\u5219\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u5e7f\u4e49\u6ce8\u6c34(GWF)\u65b9\u6cd5\u6765\u8ba1\u7b97\u6ee1\u8db3CDR\u89c4\u5219\u7684\u6700\u4f18\u5206\u914d\uff0c\u6700\u540e\u8bbe\u8ba1\u4e86SmartFill\u7b97\u6cd5\u6765\u9009\u62e9\u6027\u786e\u5b9a\u54ea\u4e9b\u4f5c\u4e1a\u5e94\u8be5\u83b7\u5f97\u8d44\u6e90\u4ee5\u53ca\u5206\u914d\u591a\u5c11\u3002", "result": "\u5bf9\u4e8e\u4e00\u7c7b\u6b63\u5219\u52a0\u901f\u51fd\u6570\uff0cSmartFill\u80fd\u591f\u7ed9\u51fa\u95ed\u5f0f\u6700\u4f18\u89e3\uff1b\u5bf9\u4e8e\u975e\u6b63\u5219\u51fd\u6570\uff0c\u4e5f\u80fd\u4ee5\u4f4e\u590d\u6742\u5ea6\u9ad8\u6548\u8ba1\u7b97\u6700\u4f18\u89e3\u3002\u6570\u503c\u8bc4\u4f30\u663e\u793a\uff0cSmartFill\u5728\u5404\u79cd\u51f9\u52a0\u901f\u51fd\u6570\u4e0b\u90fd\u663e\u8457\u4f18\u4e8eheSRPT\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u5e76\u884c\u4f5c\u4e1a\u8c03\u5ea6\u4e2d\u7684\u4e00\u822c\u51f9\u52a0\u901f\u51fd\u6570\u95ee\u9898\uff0c\u63d0\u51fa\u7684CDR\u89c4\u5219\u3001GWF\u65b9\u6cd5\u548cSmartFill\u7b97\u6cd5\u4e3a\u5b9e\u9645\u4e91\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01928", "categories": ["cs.DC", "math-ph", "math.MP", "math.OC", "quant-ph", "90C26, 90C59, 82B20, 68W40, 65K10, 82C32"], "pdf": "https://arxiv.org/pdf/2509.01928", "abs": "https://arxiv.org/abs/2509.01928", "authors": ["Debraj Banerjee", "Santanu Mahapatra", "Kunal Narayan Chaudhury"], "title": "A Continuous Energy Ising Machine Leveraging Difference-of-Convex Programming", "comment": "41 pages, 24 figures, journal paper", "summary": "Many combinatorial optimization problems can be reformulated as the task of\nfinding the ground state of a physical system, such as the Ising model. Most\nexisting Ising solvers are inspired by simulated annealing. Although annealing\ntechniques offer scalability, they lack convergence guarantees and are\nsensitive to the cooling schedule. We propose to solve the Ising problem by\nrelaxing the binary spins to continuous variables and introducing a potential\nfunction (attractor) that steers the solution toward binary spin\nconfigurations. The resulting Hamiltonian can be expressed as a difference of\nconvex functions, enabling the design of efficient iterative algorithms that\nrequire a single matrix-vector multiplication per iteration and are backed by\nconvergence guarantees. We implement our Ising solver across a range of GPU\nplatforms: from edge devices to high-performance computing clusters and\ndemonstrate that it consistently outperforms existing solvers across problem\nsizes ranging from small ($10^3$ spins) to ultra-large ($10^8$ spins).", "AI": {"tldr": "\u901a\u8fc7\u5c06\u4e8c\u8fdb\u5236\u65cb\u94c3\u653e\u677e\u4e3a\u8fde\u7eed\u53d8\u91cf\u5e76\u5f15\u5165\u5438\u5f15\u5b50\u51fd\u6570\uff0c\u8bbe\u8ba1\u4e86\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u9ad8\u6548Ising\u6c42\u89e3\u5668\uff0c\u5728\u5404\u79cdGPU\u5e73\u53f0\u4e0a\u90fd\u8d85\u8fc7\u73b0\u6709\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u4fdd\u6e29\u6c42\u89e3\u5668\u867d\u7136\u53ef\u6269\u5c55\uff0c\u4f46\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\u4e14\u5bf9\u51b7\u5374\u8c03\u5ea6\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u89e3\u51b3Ising\u95ee\u9898\u3002", "method": "\u5c06\u4e8c\u8fdb\u5236\u65cb\u94c3\u653e\u677e\u4e3a\u8fde\u7eed\u53d8\u91cf\uff0c\u5f15\u5165\u5438\u5f15\u5b50\u51fd\u6570\u5c06\u89e3\u5f15\u5bfc\u5411\u4e8c\u8fdb\u5236\u914d\u7f6e\uff0c\u5f62\u6210\u53ef\u8868\u793a\u4e3a\u51f8\u51fd\u6570\u5dee\u7684\u54c8\u5bc6\u987f\u91cf\uff0c\u8bbe\u8ba1\u6bcf\u8fed\u4ee3\u4ec5\u9700\u4e00\u6b21\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5728\u4ece\u8fb9\u7f18\u8bbe\u5907\u5230\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\u7684\u5404\u79cdGPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\uff0c\u5728\u4ece\u5c0f\u89c4\u6a21(10^3\u65cb\u94c3)\u5230\u8d85\u5927\u89c4\u6a21(10^8\u65cb\u94c3)\u7684\u95ee\u9898\u4e0a\u5747\u4e00\u81f4\u8d85\u8fc7\u73b0\u6709\u6c42\u89e3\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684Ising\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u5145\u5206\u5229\u7528\u4e86GPU\u5e73\u53f0\u7684\u8ba1\u7b97\u80fd\u529b\u3002"}}
{"id": "2509.02186", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.02186", "abs": "https://arxiv.org/abs/2509.02186", "authors": ["Phani Sahasra Akkinepally", "Manaswini Piduguralla", "Sushant Joshi", "Sathya Peri", "Sandeep Kulkarni"], "title": "Fault-Tolerant Decentralized Distributed Asynchronous Federated Learning with Adaptive Termination Detection", "comment": null, "summary": "Federated Learning (FL) facilitates collaborative model training across\ndistributed clients while ensuring data privacy. Traditionally, FL relies on a\ncentralized server to coordinate learning, which creates bottlenecks and a\nsingle point of failure. Decentralized FL architectures eliminate the need for\na central server and can operate in either synchronous or asynchronous modes.\nSynchronous FL requires all clients to compute updates and wait for one another\nbefore aggregation, guaranteeing consistency but often suffering from delays\ndue to slower participants. Asynchronous FL addresses this by allowing clients\nto update independently, offering better scalability and responsiveness in\nheterogeneous environments.\n  Our research develops an asynchronous decentralized FL approach in two\nprogressive phases. (a) In Phase 1, we develop an asynchronous FL framework\nthat enables clients to learn and update independently, removing the need for\nstrict synchronization. (b) In Phase 2, we extend this framework with fault\ntolerance mechanisms to handle client failures and message drops, ensuring\nrobust performance even under unpredictable conditions. As a central\ncontribution, we propose Client-Confident Convergence and Client-Responsive\nTermination novel techniques that provide each client with the ability to\nautonomously determine appropriate termination points. These methods ensure\nthat all active clients conclude meaningfully and efficiently, maintaining\nreliable convergence despite the challenges of asynchronous communication and\nfaults.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6b65\u5206\u5e03\u5f0f\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u81ea\u4e3b\u7ec8\u6b62\u6280\u672f\u89e3\u51b3\u4e86\u540c\u6b65\u65b9\u5f0f\u7684\u6027\u80fd\u74f6\u9888\u548c\u6545\u969c\u5bb9\u9510\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u4f9d\u8d56\u4e2d\u592e\u670d\u52a1\u5668\uff0c\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u6027\u80fd\u74f6\u9888\uff0c\u540c\u6b65\u65b9\u5f0f\u53c8\u5bb9\u6613\u53d7\u6162\u901f\u5ba2\u6237\u7aef\u5f71\u54cd\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u4e14\u6545\u969c\u5bb9\u9510\u7684\u5f02\u6b65\u5206\u5e03\u5f0f\u65b9\u6848\u3002", "method": "\u5206\u4e24\u4e2a\u9636\u6bb5\u5f00\u53d1\uff1a\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u5f02\u6b65FL\u6846\u67b6\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u72ec\u7acb\u5b66\u4e60\u548c\u66f4\u65b0\uff1b\u7b2c\u4e8c\u9636\u6bb5\u589e\u52a0\u6545\u969c\u5bb9\u9510\u673a\u5236\uff0c\u5904\u7406\u5ba2\u6237\u7aef\u6545\u969c\u548c\u6d88\u606f\u4e22\u5931\u3002\u6838\u5fc3\u521b\u65b0\u662fClient-Confident Convergence\u548cClient-Responsive Termination\u6280\u672f\uff0c\u8ba9\u5ba2\u6237\u7aef\u81ea\u4e3b\u51b3\u5b9a\u7ec8\u6b62\u65f6\u673a\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5f02\u8d28\u6027\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u54cd\u5e94\u80fd\u529b\uff0c\u80fd\u591f\u5728\u4e0d\u53ef\u9884\u6d4b\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002\u5ba2\u6237\u7aef\u81ea\u4e3b\u7ec8\u6b62\u6280\u672f\u786e\u4fdd\u4e86\u6240\u6709\u6d3b\u8dc3\u5ba2\u6237\u7aef\u90fd\u80fd\u6709\u6548\u5b8c\u6210\u8bad\u7ec3\u3002", "conclusion": "\u8fd9\u79cd\u5f02\u6b65\u5206\u5e03\u5f0fFL\u65b9\u6848\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6848\u7684\u6027\u80fd\u548c\u6545\u969c\u5bb9\u9510\u95ee\u9898\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u81ea\u4e3b\u7ec8\u6b62\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u9760\u7684\u6536\u655b\uff0c\u9002\u7528\u4e8e\u5f02\u8d28\u6027\u7f51\u7edc\u73af\u5883\u3002"}}
{"id": "2509.02421", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.02421", "abs": "https://arxiv.org/abs/2509.02421", "authors": ["Ramesh Adhikari", "Costas Busch", "Dariusz R. Kowalski"], "title": "Near-Optimal Stability for Distributed Transaction Processing in Blockchain Sharding", "comment": "13 pages, 1 figure, accepted for publication in Proceedings of the\n  27th International Symposium on Stabilization, Safety, and Security of\n  Distributed Systems (SSS 2025)", "summary": "In blockchain sharding, $n$ processing nodes are divided into $s$ shards, and\neach shard processes transactions in parallel. A key challenge in such a system\nis to ensure system stability for any ``tractable'' pattern of generated\ntransactions; this is modeled by an adversary generating transactions with a\ncertain rate of at most $\\rho$ and burstiness $b$. This model captures\nworst-case scenarios and even some attacks on transactions' processing, e.g.,\nDoS. A stable system ensures bounded transaction queue sizes and bounded\ntransaction latency. It is known that the absolute upper bound on the maximum\ninjection rate for which any scheduler could guarantee bounded queues and\nlatency of transactions is $\\max\\left\\{ \\frac{2}{k+1}, \\frac{2}{\n\\left\\lfloor\\sqrt{2s}\\right\\rfloor}\\right\\}$, where $k$ is the maximum number\nof shards that each transaction accesses. Here, we first provide a single\nleader scheduler that guarantees stability under injection rate $\\rho \\leq\n\\max\\left\\{ \\frac{1}{16k}, \\frac{1}{16\\lceil \\sqrt{s} \\rceil}\\right\\}$.\nMoreover, we also give a distributed scheduler with multiple leaders that\nguarantees stability under injection rate $\\rho \\leq \\frac{1}{16c_1 \\log D \\log\ns}\\max\\left\\{ \\frac{1}{k}, \\frac{1}{\\lceil \\sqrt{s} \\rceil} \\right\\}$, where\n$c_1$ is some positive constant and $D$ is the diameter of shard graph $G_s$.\nThis bound is within a poly-log factor from the optimal injection rate, and\nsignificantly improves the best previous known result for the distributed\nsetting by Adhikari et al., SPAA 2024.", "AI": {"tldr": "\u533a\u5757\u94fe\u5206\u7247\u7cfb\u7edf\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u8c03\u5ea6\u5668\uff08\u5355\u9886\u5bfc\u8005\u548c\u5206\u5e03\u5f0f\u591a\u9886\u5bfc\u8005\uff09\u6765\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u52a1\u5904\u7406\u901f\u7387\u7684\u4e0a\u754c\uff0c\u63a5\u8fd1\u6700\u4f18\u89e3\u3002", "motivation": "\u89e3\u51b3\u533a\u5757\u94fe\u5206\u7247\u4e2d\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u5173\u952e\u6311\u6218\uff0c\u5373\u5728\u6700\u574f\u60c5\u51b5\u4e8b\u52a1\u6a21\u5f0f\uff08\u5305\u62ecDoS\u653b\u51fb\uff09\u4e0b\u786e\u4fdd\u4e8b\u52a1\u961f\u5217\u5927\u5c0f\u548c\u5ef6\u8fdf\u6709\u754c\u3002\u73b0\u6709\u8c03\u5ea6\u5668\u7684\u5904\u7406\u901f\u7387\u4e0a\u754c\u8f83\u4f4e\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u8c03\u5ea6\u5668\uff1a1\uff09\u5355\u9886\u5bfc\u8005\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u63a7\u5236\u4fdd\u8bc1\u7a33\u5b9a\u6027\uff1b2\uff09\u5206\u5e03\u5f0f\u591a\u9886\u5bfc\u8005\u8c03\u5ea6\u5668\uff0c\u5229\u7528\u5206\u7247\u56fe\u76f4\u5f84\u548c\u65e5\u5fd7\u56e0\u5b50\u5b9e\u73b0\u5206\u5e03\u5f0f\u534f\u8c03\u3002", "result": "\u5355\u9886\u5bfc\u8005\u8c03\u5ea6\u5668\u652f\u6301\u6ce8\u5165\u901f\u7387\u03c1 \u2264 max{1/(16k), 1/(16\u2308\u221as\u2309)}\uff1b\u5206\u5e03\u5f0f\u8c03\u5ea6\u5668\u652f\u6301\u03c1 \u2264 1/(16c\u2081logDlogs) \u00b7 max{1/k, 1/\u2308\u221as\u2309}\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u7ed3\u679c\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u8c03\u5ea6\u5668\u5728\u4e8b\u52a1\u5904\u7406\u901f\u7387\u4e0a\u754c\u65b9\u9762\u63a5\u8fd1\u6700\u4f18\uff0c\u5206\u5e03\u5f0f\u65b9\u6848\u5c24\u5176\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u533a\u5757\u94fe\u5206\u7247\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7a33\u5b9a\u6027\u4fdd\u969c\u65b9\u6848\u3002"}}
{"id": "2509.02440", "categories": ["cs.DC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.02440", "abs": "https://arxiv.org/abs/2509.02440", "authors": ["Marie Reinbigler", "Rishi Sharma", "Rafael Pires", "Elisabeth Brunet", "Anne-Marie Kermarrec", "Catalin Fetita"], "title": "Efficient Pyramidal Analysis of Gigapixel Images on a Decentralized Modest Computer Cluster", "comment": "Accepted at the 31st International European Conference on Parallel\n  and Distributed Computing (Euro-Par'25)", "summary": "Analyzing gigapixel images is recognized as computationally demanding. In\nthis paper, we introduce PyramidAI, a technique for analyzing gigapixel images\nwith reduced computational cost. The proposed approach adopts a gradual\nanalysis of the image, beginning with lower resolutions and progressively\nconcentrating on regions of interest for detailed examination at higher\nresolutions. We investigated two strategies for tuning the accuracy-computation\nperformance trade-off when implementing the adaptive resolution selection,\nvalidated against the Camelyon16 dataset of biomedical images. Our results\ndemonstrate that PyramidAI substantially decreases the amount of processed data\nrequired for analysis by up to 2.65x, while preserving the accuracy in\nidentifying relevant sections on a single computer. To ensure democratization\nof gigapixel image analysis, we evaluated the potential to use mainstream\ncomputers to perform the computation by exploiting the parallelism potential of\nthe approach. Using a simulator, we estimated the best data distribution and\nload balancing algorithm according to the number of workers. The selected\nalgorithms were implemented and highlighted the same conclusions in a\nreal-world setting. Analysis time is reduced from more than an hour to a few\nminutes using 12 modest workers, offering a practical solution for efficient\nlarge-scale image analysis.", "AI": {"tldr": "PyramidAI\u662f\u4e00\u79cd\u5206\u6790\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u7684\u6280\u672f\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5206\u8fa8\u7387\u5206\u6790\u548c\u81ea\u9002\u5e94\u533a\u57df\u9009\u62e9\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5c06\u8ba1\u7b97\u91cf\u51cf\u5c112.65\u500d\uff0c\u4f7f\u752812\u4e2a\u666e\u901a\u8ba1\u7b97\u8282\u70b9\u53ef\u5c06\u5206\u6790\u65f6\u95f4\u4ece1\u5c0f\u65f6\u7f29\u77ed\u5230\u51e0\u5206\u949f\u3002", "motivation": "\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u5206\u6790\u8ba1\u7b97\u9700\u6c42\u5de8\u5927\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u6280\u672f\uff0c\u4f7f\u666e\u901a\u8ba1\u7b97\u673a\u4e5f\u80fd\u8fdb\u884c\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u56fe\u50cf\u5206\u6790\u3002", "method": "\u91c7\u7528\u6e10\u8fdb\u5f0f\u5206\u6790\u65b9\u6cd5\uff0c\u4ece\u4f4e\u5206\u8fa8\u7387\u5f00\u59cb\u9010\u6b65\u805a\u7126\u611f\u5174\u8da3\u533a\u57df\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u8be6\u7ec6\u68c0\u67e5\uff0c\u7814\u7a76\u4e24\u79cd\u81ea\u9002\u5e94\u5206\u8fa8\u7387\u9009\u62e9\u7b56\u7565\uff0c\u5e76\u5728Camelyon16\u751f\u7269\u533b\u5b66\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002\u8fd8\u8bc4\u4f30\u4e86\u5e76\u884c\u5316\u6f5c\u529b\uff0c\u901a\u8fc7\u6a21\u62df\u5668\u9009\u62e9\u6700\u4f73\u6570\u636e\u5206\u5e03\u548c\u8d1f\u8f7d\u5747\u8861\u7b97\u6cd5\u3002", "result": "PyramidAI\u5c06\u5904\u7406\u6570\u636e\u91cf\u51cf\u5c11\u9ad8\u8fbe2.65\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u8bc6\u522b\u76f8\u5173\u533a\u57df\u7684\u51c6\u786e\u6027\u3002\u4f7f\u752812\u4e2a\u666e\u901a\u8ba1\u7b97\u8282\u70b9\u65f6\uff0c\u5206\u6790\u65f6\u95f4\u4ece\u8d85\u8fc71\u5c0f\u65f6\u7f29\u77ed\u5230\u51e0\u5206\u949f\u3002", "conclusion": "PyramidAI\u4e3a\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8ba1\u7b97\u4f18\u5316\u548c\u5e76\u884c\u5316\u5b9e\u73b0\u4e86\u5728\u666e\u901a\u8ba1\u7b97\u673a\u4e0a\u7684\u53ef\u884c\u90e8\u7f72\uff0c\u4fc3\u8fdb\u4e86\u8be5\u6280\u672f\u7684\u6c11\u4e3b\u5316\u5e94\u7528\u3002"}}
{"id": "2509.02447", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.02447", "abs": "https://arxiv.org/abs/2509.02447", "authors": ["Xinrui Zhong", "Xinze Feng", "Jingwei Zuo", "Fanjiang Ye", "Yi Mu", "Junfeng Guo", "Heng Huang", "Myungjin Lee", "Yuke Wang"], "title": "An Efficient and Adaptive Watermark Detection System with Tile-based Error Correction", "comment": null, "summary": "Efficient and reliable detection of generated images is critical for the\nresponsible deployment of generative models. Existing approaches primarily\nfocus on improving detection accuracy and robustness under various image\ntransformations and adversarial manipulations, yet they largely overlook the\nefficiency challenges of watermark detection across large-scale image\ncollections. To address this gap, we propose QRMark, an efficient and adaptive\nend-to-end method for detecting embedded image watermarks. The core idea of\nQRMark is to combine QR Code inspired error correction with tailored tiling\ntechniques to improve detection efficiency while preserving accuracy and\nrobustness. At the algorithmic level, QRMark employs a Reed-Solomon error\ncorrection mechanism to mitigate the accuracy degradation introduced by tiling.\nAt the system level, QRMark implements a resource-aware stream allocation\npolicy that adaptively assigns more streams to GPU-intensive stages of the\ndetection pipeline. It further employs a tile-based workload interleaving\nstrategy to overlap data-loading overhead with computation and schedules\nkernels across stages to maximize efficiency. End-to-end evaluations show that\nQRMark achieves an average 2.43x inference speedup over the sequential\nbaseline.", "AI": {"tldr": "QRMark\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u7aef\u5230\u7aef\u56fe\u50cf\u6c34\u5370\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408QR\u7801\u7ea0\u9519\u673a\u5236\u548c\u5206\u5757\u6280\u672f\uff0c\u5728\u4fdd\u6301\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u7387", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u5728\u5927\u89c4\u6a21\u56fe\u50cf\u96c6\u5408\u4e2d\u6c34\u5370\u68c0\u6d4b\u7684\u6548\u7387\u6311\u6218", "method": "\u7ed3\u5408QR\u7801\u542f\u53d1\u7684\u7ea0\u9519\u673a\u5236\u548c\u5b9a\u5236\u5316\u5206\u5757\u6280\u672f\uff0c\u91c7\u7528Reed-Solomon\u7ea0\u9519\u673a\u5236\u51cf\u8f7b\u5206\u5757\u5e26\u6765\u7684\u7cbe\u5ea6\u4e0b\u964d\uff0c\u5b9e\u73b0\u8d44\u6e90\u611f\u77e5\u7684\u6d41\u5206\u914d\u7b56\u7565\u548c\u57fa\u4e8e\u5206\u5757\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4ea4\u9519\u7b56\u7565", "result": "\u7aef\u5230\u7aef\u8bc4\u4f30\u663e\u793aQRMark\u76f8\u6bd4\u987a\u5e8f\u57fa\u7ebf\u5e73\u5747\u5b9e\u73b02.43\u500d\u7684\u63a8\u7406\u52a0\u901f", "conclusion": "QRMark\u901a\u8fc7\u7b97\u6cd5\u548c\u7cfb\u7edf\u5c42\u9762\u7684\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u56fe\u50cf\u6c34\u5370\u68c0\u6d4b\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6"}}
{"id": "2509.02449", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.02449", "abs": "https://arxiv.org/abs/2509.02449", "authors": ["Mohsen Seyedkazemi Ardebili", "Andrea Bartolini"], "title": "KubeIntellect: A Modular LLM-Orchestrated Agent Framework for End-to-End Kubernetes Management", "comment": null, "summary": "Kubernetes has become the foundation of modern cloud-native infrastructure,\nyet its management remains complex and fragmented. Administrators must navigate\na vast API surface, manage heterogeneous workloads, and coordinate tasks across\ndisconnected tools - often requiring precise commands, YAML configuration, and\ncontextual expertise.\n  This paper presents KubeIntellect, a Large Language Model (LLM)-powered\nsystem for intelligent, end-to-end Kubernetes control. Unlike existing tools\nthat focus on observability or static automation, KubeIntellect supports\nnatural language interaction across the full spectrum of Kubernetes API\noperations, including read, write, delete, exec, access control, lifecycle, and\nadvanced verbs. The system uses modular agents aligned with functional domains\n(e.g., logs, metrics, RBAC), orchestrated by a supervisor that interprets user\nqueries, maintains workflow memory, invokes reusable tools, or synthesizes new\nones via a secure Code Generator Agent.\n  KubeIntellect integrates memory checkpoints, human-in-the-loop clarification,\nand dynamic task sequencing into a structured orchestration framework.\nEvaluation results show a 93% tool synthesis success rate and 100% reliability\nacross 200 natural language queries, demonstrating the system's ability to\noperate efficiently under diverse workloads. An automated demo environment is\nprovided on Azure, with additional support for local testing via kind. This\nwork introduces a new class of interpretable, extensible, and LLM-driven\nsystems for managing complex infrastructure.", "AI": {"tldr": "KubeIntellect\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdKubernetes\u63a7\u5236\u7cfb\u7edf\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u80fd\u591f\u5904\u7406\u5b8c\u6574\u7684Kubernetes API\u64cd\u4f5c\uff0c\u5305\u62ec\u8bfb\u5199\u3001\u5220\u9664\u3001\u6267\u884c\u7b49\u9ad8\u7ea7\u529f\u80fd\u3002", "motivation": "Kubernetes\u7ba1\u7406\u590d\u6742\u4e14\u788e\u7247\u5316\uff0c\u7ba1\u7406\u5458\u9700\u8981\u5904\u7406\u5927\u91cfAPI\u3001\u7ba1\u7406\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u4f7f\u7528\u7cbe\u786e\u547d\u4ee4\u548cYAML\u914d\u7f6e\uff0c\u8fd9\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u6a21\u5757\u5316\u4ee3\u7406\u67b6\u6784\uff0c\u6309\u529f\u80fd\u57df\u5212\u5206\uff08\u5982\u65e5\u5fd7\u3001\u6307\u6807\u3001RBAC\uff09\uff0c\u7531\u76d1\u7763\u5668\u534f\u8c03\u7528\u6237\u67e5\u8be2\u3001\u7ef4\u62a4\u5de5\u4f5c\u6d41\u5185\u5b58\u3001\u8c03\u7528\u53ef\u91cd\u7528\u5de5\u5177\u6216\u901a\u8fc7\u5b89\u5168\u7684\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u5408\u6210\u65b0\u5de5\u5177\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a93%\u7684\u5de5\u5177\u5408\u6210\u6210\u529f\u7387\u548c100%\u7684\u53ef\u9760\u6027\uff08\u57fa\u4e8e200\u4e2a\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff09\uff0c\u7cfb\u7edf\u80fd\u591f\u5728\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f15\u5165\u4e86\u65b0\u4e00\u4ee3\u53ef\u89e3\u91ca\u3001\u53ef\u6269\u5c55\u7684LLM\u9a71\u52a8\u7cfb\u7edf\uff0c\u7528\u4e8e\u7ba1\u7406\u590d\u6742\u57fa\u7840\u8bbe\u65bd\uff0c\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684\u6f14\u793a\u73af\u5883\u548c\u672c\u5730\u6d4b\u8bd5\u652f\u6301\u3002"}}
{"id": "2509.02480", "categories": ["cs.DC", "cs.AI", "cs.LG", "H.2.0; E.2; I.2.11"], "pdf": "https://arxiv.org/pdf/2509.02480", "abs": "https://arxiv.org/abs/2509.02480", "authors": ["Avinash Maurya", "M. Mustafa Rafique", "Franck Cappello", "Bogdan Nicolae"], "title": "MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall", "comment": "SC'25: The International Conference for High Performance Computing,\n  Networking, Storage and Analysis", "summary": "Training LLMs larger than the aggregated memory of multiple GPUs is\nincreasingly necessary due to the faster growth of LLM sizes compared to GPU\nmemory. To this end, multi-tier host memory or disk offloading techniques are\nproposed by state of art. Despite advanced asynchronous multi-tier read/write\nstrategies, such offloading strategies result in significant I/O overheads in\nthe critical path of training, resulting in slower iterations. To this end, we\npropose MLP-Offload, a novel multi-level, multi-path offloading engine\nspecifically designed for optimizing LLM training on resource-constrained\nsetups by mitigating I/O bottlenecks. We make several key observations that\ndrive the design of MLP-Offload, such as I/O overheads during the update\ndominate the iteration time; I/O bandwidth of the third-level remote storage\ntier remains unutilized; and, contention due to concurrent offloading amplifies\nI/O bottlenecks. Driven by these insights, we design and implement MLP-Offload\nto offload the optimizer states across multiple tiers in a cache-efficient and\nconcurrency-controlled fashion to mitigate I/O bottlenecks during the backward\nand update phases. Evaluations on models up to 280B parameters shows that\nMLP-Offload achieves 2.5$\\times$ faster iterations compared to the\nstate-of-the-art LLM training runtimes.", "AI": {"tldr": "MLP-Offload\u662f\u4e00\u79cd\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0bLLM\u8bad\u7ec3\u4f18\u5316\u7684\u591a\u7ea7\u591a\u8def\u5f84\u5378\u8f7d\u5f15\u64ce\uff0c\u901a\u8fc7\u7f13\u89e3I/O\u74f6\u9888\uff0c\u5728280B\u53c2\u6570\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6280\u672f\u5feb2.5\u500d\u7684\u8fed\u4ee3\u901f\u5ea6\u3002", "motivation": "\u7531\u4e8eLLM\u6a21\u578b\u89c4\u6a21\u7684\u589e\u957f\u901f\u5ea6\u8fdc\u8d85GPU\u5185\u5b58\u5bb9\u91cf\uff0c\u9700\u8981\u5c06\u6a21\u578b\u53c2\u6570\u5378\u8f7d\u5230\u4e3b\u673a\u5185\u5b58\u6216\u78c1\u76d8\u3002\u73b0\u6709\u5378\u8f7d\u6280\u672f\u867d\u7136\u91c7\u7528\u4e86\u5148\u8fdb\u7684\u5f02\u6b65\u591a\u7ea7\u8bfb\u5199\u7b56\u7565\uff0c\u4f46\u5728\u8bad\u7ec3\u5173\u952e\u8def\u5f84\u4e2d\u4ecd\u4ea7\u751f\u663e\u8457\u7684I/O\u5f00\u9500\uff0c\u5bfc\u81f4\u8fed\u4ee3\u901f\u5ea6\u53d8\u6162\u3002", "method": "\u63d0\u51fa\u4e86MLP-Offload\u591a\u7ea7\u591a\u8def\u5f84\u5378\u8f7d\u5f15\u64ce\uff0c\u901a\u8fc7\u5173\u952e\u89c2\u5bdf\u53d1\u73b0\uff1a\u66f4\u65b0\u9636\u6bb5\u7684I/O\u5f00\u9500\u4e3b\u5bfc\u8fed\u4ee3\u65f6\u95f4\uff1b\u7b2c\u4e09\u7ea7\u8fdc\u7a0b\u5b58\u50a8\u5e26\u5bbd\u672a\u88ab\u5145\u5206\u5229\u7528\uff1b\u5e76\u53d1\u5378\u8f7d\u5bfc\u81f4\u7684\u4e89\u7528\u653e\u5927\u4e86I/O\u74f6\u9888\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u4ee5\u7f13\u5b58\u9ad8\u6548\u548c\u5e76\u53d1\u63a7\u5236\u7684\u65b9\u5f0f\u8de8\u591a\u7ea7\u5378\u8f7d\u4f18\u5316\u5668\u72b6\u6001\u3002", "result": "\u5728\u9ad8\u8fbe280B\u53c2\u6570\u7684\u6a21\u578b\u8bc4\u4f30\u4e2d\uff0cMLP-Offload\u76f8\u6bd4\u6700\u5148\u8fdb\u7684LLM\u8bad\u7ec3\u8fd0\u884c\u65f6\u5b9e\u73b0\u4e862.5\u500d\u7684\u8fed\u4ee3\u52a0\u901f\u3002", "conclusion": "MLP-Offload\u901a\u8fc7\u6709\u6548\u7f13\u89e3I/O\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21LLM\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u89e3\u51b3GPU\u5185\u5b58\u9650\u5236\u4e0e\u6a21\u578b\u89c4\u6a21\u589e\u957f\u4e4b\u95f4\u7684\u77db\u76fe\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02549", "categories": ["cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.02549", "abs": "https://arxiv.org/abs/2509.02549", "authors": ["Keiwan Soltani", "Vishesh Kumar Tanwar", "Ashish Gupta", "Sajal K. Das"], "title": "Energy-Efficient Split Learning for Resource-Constrained Environments: A Smart Farming Solution", "comment": "Accepted at the 22nd IEEE International Conference on Mobile Ad-Hoc\n  and Smart Systems (MASS), 2025", "summary": "Smart farming systems encounter significant challenges, including limited\nresources, the need for data privacy, and poor connectivity in rural areas. To\naddress these issues, we present eEnergy-Split, an energy-efficient framework\nthat utilizes split learning (SL) to enable collaborative model training\nwithout direct data sharing or heavy computation on edge devices. By\ndistributing the model between edge devices and a central server, eEnergy-Split\nreduces on-device energy usage by up to 86 percent compared to federated\nlearning (FL) while safeguarding data privacy. Moreover, SL improves\nclassification accuracy by up to 6.2 percent over FL on ResNet-18 and by more\nmodest amounts on GoogleNet and MobileNetV2. We propose an optimal edge\ndeployment algorithm and a UAV trajectory planning strategy that solves the\nTraveling Salesman Problem (TSP) exactly to minimize flight cost and extend and\nmaximize communication rounds. Comprehensive evaluations on agricultural pest\ndatasets reveal that eEnergy-Split lowers UAV energy consumption compared to\nbaseline methods and boosts overall accuracy by up to 17 percent. Notably, the\nenergy efficiency of SL is shown to be model-dependent-yielding substantial\nsavings in lightweight models like MobileNet, while communication and memory\noverheads may reduce efficiency gains in deeper networks. These results\nhighlight the potential of combining SL with energy-aware design to deliver a\nscalable, privacy-preserving solution for resource-constrained smart farming\nenvironments.", "AI": {"tldr": "eEnergy-Split\u662f\u4e00\u4e2a\u57fa\u4e8e\u5206\u5272\u5b66\u4e60\u7684\u9ad8\u6548\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u5206\u5e03\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u4e2d\u592e\u670d\u52a1\u5668\u4e4b\u95f4\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u8054\u90a6\u5b66\u4e60\u51cf\u5c11\u9ad8\u8fbe86%\u7684\u8bbe\u5907\u80fd\u8017\uff0c\u5e76\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u519c\u4e1a\u7cfb\u7edf\u9762\u4e34\u7684\u8d44\u6e90\u6709\u9650\u3001\u6570\u636e\u9690\u79c1\u9700\u6c42\u548c\u519c\u6751\u5730\u533a\u8fde\u63a5\u6027\u5dee\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u9ad8\u6548\u5229\u7528\u80fd\u6e90\u7684\u534f\u4f5c\u5b66\u4e60\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5206\u5272\u5b66\u4e60(SL)\u6846\u67b6\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u4e2d\u592e\u670d\u52a1\u5668\u4e4b\u95f4\u5206\u914d\u6a21\u578b\u8bad\u7ec3\uff1b\u63d0\u51fa\u6700\u4f18\u8fb9\u7f18\u90e8\u7f72\u7b97\u6cd5\u548c\u57fa\u4e8eTSP\u7cbe\u786e\u89e3\u7684\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u7b56\u7565\uff0c\u4ee5\u6700\u5c0f\u5316\u98de\u884c\u6210\u672c\u5e76\u6700\u5927\u5316\u901a\u4fe1\u8f6e\u6b21\u3002", "result": "\u5728\u519c\u4e1a\u5bb3\u866b\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u8054\u90a6\u5b66\u4e60\uff0c\u80fd\u8017\u964d\u4f4e86%\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53476.2%(ResNet-18)\uff1b\u6574\u4f53\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe17%\uff0c\u65e0\u4eba\u673a\u80fd\u8017\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u5206\u5272\u5b66\u4e60\u4e0e\u80fd\u6e90\u611f\u77e5\u8bbe\u8ba1\u76f8\u7ed3\u5408\uff0c\u53ef\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u667a\u80fd\u519c\u4e1a\u73af\u5883\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u80fd\u6548\u4f18\u52bf\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\u3002"}}
