{"id": "2507.21317", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.21317", "abs": "https://arxiv.org/abs/2507.21317", "authors": ["Paulette Koronkevich", "William J. Bowman"], "title": "One Weird Trick to Untie Landin's Knot", "comment": null, "summary": "In this work, we explore Landin's Knot, which is understood as a pattern for\nencoding general recursion, including non-termination, that is possible after\nadding higher-order references to an otherwise terminating language. We observe\nthat this isn't always true -- higher-order references, by themselves, don't\nlead to non-termination. The key insight is that Landin's Knot relies not\nprimarily on references storing functions, but on unrestricted quantification\nover a function's environment. We show this through a closure converted\nlanguage, in which the function's environment is made explicit and hides the\ntype of the environment through impredicative quantification. Once references\nare added, this impredicative quantification can be exploited to encode\nrecursion. We conjecture that by restricting the quantification over the\nenvironment, higher-order references can be safely added to terminating\nlanguages, without resorting to more complex type systems such as linearity,\nand without restricting references from storing functions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86Landin's Knot\u5728\u7f16\u7801\u9012\u5f52\u4e2d\u7684\u4f5c\u7528\uff0c\u6307\u51fa\u9ad8\u9636\u5f15\u7528\u672c\u8eab\u4e0d\u5bfc\u81f4\u975e\u7ec8\u6b62\u6027\uff0c\u5173\u952e\u5728\u4e8e\u5bf9\u51fd\u6570\u73af\u5883\u7684\u65e0\u9650\u5236\u91cf\u5316\u3002\u901a\u8fc7\u95ed\u5305\u8f6c\u6362\u8bed\u8a00\u5c55\u793a\u4e86\u8fd9\u4e00\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u9650\u5236\u73af\u5883\u91cf\u5316\u53ef\u4ee5\u5b89\u5168\u6dfb\u52a0\u9ad8\u9636\u5f15\u7528\u3002", "motivation": "\u7814\u7a76Landin's Knot\u5728\u7f16\u7801\u9012\u5f52\u4e2d\u7684\u4f5c\u7528\uff0c\u6f84\u6e05\u9ad8\u9636\u5f15\u7528\u4e0e\u975e\u7ec8\u6b62\u6027\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u5982\u4f55\u5728\u7ec8\u6b62\u8bed\u8a00\u4e2d\u5b89\u5168\u6dfb\u52a0\u9ad8\u9636\u5f15\u7528\u3002", "method": "\u4f7f\u7528\u95ed\u5305\u8f6c\u6362\u8bed\u8a00\uff0c\u660e\u786e\u51fd\u6570\u73af\u5883\u5e76\u901a\u8fc7\u975e\u9884\u6d4b\u6027\u91cf\u5316\u9690\u85cf\u73af\u5883\u7c7b\u578b\uff0c\u5c55\u793a\u5982\u4f55\u5229\u7528\u9ad8\u9636\u5f15\u7528\u7f16\u7801\u9012\u5f52\u3002", "result": "\u53d1\u73b0\u9ad8\u9636\u5f15\u7528\u672c\u8eab\u4e0d\u5bfc\u81f4\u975e\u7ec8\u6b62\u6027\uff0c\u5173\u952e\u5728\u4e8e\u5bf9\u51fd\u6570\u73af\u5883\u7684\u65e0\u9650\u5236\u91cf\u5316\u3002", "conclusion": "\u901a\u8fc7\u9650\u5236\u73af\u5883\u91cf\u5316\uff0c\u53ef\u4ee5\u5b89\u5168\u5730\u5728\u7ec8\u6b62\u8bed\u8a00\u4e2d\u6dfb\u52a0\u9ad8\u9636\u5f15\u7528\uff0c\u65e0\u9700\u590d\u6742\u7c7b\u578b\u7cfb\u7edf\u6216\u9650\u5236\u51fd\u6570\u5b58\u50a8\u3002"}}
{"id": "2507.21439", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.21439", "abs": "https://arxiv.org/abs/2507.21439", "authors": ["Yong Qi Foo", "Brian Sze-Kai Cheong", "Michael D. Adams"], "title": "Fixed-Point-Oriented Programming: A Concise and Elegant Paradigm", "comment": null, "summary": "Fixed-Point-Oriented Programming (FPOP) is an emerging paradigm designed to\nstreamline the implementation of problems involving self-referential\ncomputations. These include graph algorithms, static analysis, parsing, and\ndistributed computing-domains that traditionally require complex and\ntricky-to-implement work-queue algorithms. Existing programming paradigms lack\ndirect support for these inherently fixed-point computations, leading to\ninefficient and error-prone implementations.\n  This white paper explores the potential of the FPOP paradigm, which offers a\nhigh-level abstraction that enables concise and expressive problem\nformulations. By leveraging structured inference rules and user-directed\noptimizations, FPOP allows developers to write declarative specifications while\nthe compiler ensures efficient execution. It not only reduces implementation\ncomplexity for programmers but also enhances adaptability, making it easier for\nprogrammers to explore alternative solutions and optimizations without\nmodifying the core logic of their program.\n  We demonstrate how FPOP simplifies algorithm implementation, improves\nmaintainability, and enables rapid prototyping by allowing problems to be\nclearly and concisely expressed. For example, the graph distance problem can be\nexpressed in only two executable lines of code with FPOP, while it takes an\norder of magnitude more code in other paradigms. By bridging the gap between\ntheoretical fixed-point formulations and practical implementations, we aim to\nfoster further research and adoption of this paradigm.", "AI": {"tldr": "FPOP\u662f\u4e00\u79cd\u65b0\u5174\u7f16\u7a0b\u8303\u5f0f\uff0c\u65e8\u5728\u7b80\u5316\u81ea\u5f15\u7528\u8ba1\u7b97\u95ee\u9898\u7684\u5b9e\u73b0\uff0c\u5982\u56fe\u7b97\u6cd5\u3001\u9759\u6001\u5206\u6790\u548c\u5206\u5e03\u5f0f\u8ba1\u7b97\u3002\u5b83\u901a\u8fc7\u9ad8\u7ea7\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u63a8\u7406\u89c4\u5219\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u7f16\u5199\u7b80\u6d01\u7684\u58f0\u660e\u5f0f\u89c4\u8303\uff0c\u540c\u65f6\u7f16\u8bd1\u5668\u786e\u4fdd\u9ad8\u6548\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u7f16\u7a0b\u8303\u5f0f\u7f3a\u4e4f\u5bf9\u56fa\u5b9a\u70b9\u8ba1\u7b97\u7684\u76f4\u63a5\u652f\u6301\uff0c\u5bfc\u81f4\u5b9e\u73b0\u590d\u6742\u4e14\u6613\u51fa\u9519\u3002FPOP\u901a\u8fc7\u63d0\u4f9b\u9ad8\u5c42\u6b21\u7684\u62bd\u8c61\uff0c\u7b80\u5316\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "FPOP\u5229\u7528\u7ed3\u6784\u5316\u63a8\u7406\u89c4\u5219\u548c\u7528\u6237\u5bfc\u5411\u7684\u4f18\u5316\uff0c\u652f\u6301\u58f0\u660e\u5f0f\u89c4\u8303\u7f16\u5199\uff0c\u5e76\u7531\u7f16\u8bd1\u5668\u5904\u7406\u9ad8\u6548\u6267\u884c\u3002", "result": "FPOP\u663e\u8457\u7b80\u5316\u4e86\u7b97\u6cd5\u5b9e\u73b0\uff0c\u63d0\u9ad8\u4e86\u53ef\u7ef4\u62a4\u6027\uff0c\u5e76\u652f\u6301\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002\u4f8b\u5982\uff0c\u56fe\u8ddd\u79bb\u95ee\u9898\u4ec5\u9700\u4e24\u884c\u4ee3\u7801\u5373\u53ef\u5b9e\u73b0\u3002", "conclusion": "FPOP\u586b\u8865\u4e86\u7406\u8bba\u56fa\u5b9a\u70b9\u516c\u5f0f\u4e0e\u5b9e\u9645\u5b9e\u73b0\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u8303\u5f0f\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2507.22048", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.22048", "abs": "https://arxiv.org/abs/2507.22048", "authors": ["Di Wang"], "title": "Composable Effect Handling for Programming LLM-integrated Scripts", "comment": null, "summary": "Implementing LLM-integrated scripts introduces challenges in modularity and\nperformance, as scripts are often coupled to specific LLM implementations and\nfail to exploit parallelization opportunities. This paper proposes using\ncomposable effect handling to separate workflow logic from effectful\noperations, such as LLM calls, I/O, and concurrency, enabling modularity\nwithout sacrificing the opportunity for performance optimization. By treating\nthese operations as abstract interfaces and discharging them via effect\nhandlers, this paper shows that scripts can achieve significant speedups (e.g.,\n10$\\times$ in a Tree-of-Thoughts case study) without compromising modularity.\nThis paper aims to promote composable effect handling as a programming style\nfor LLM scripting.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u53ef\u7ec4\u5408\u6548\u5e94\u5904\u7406\u6765\u5206\u79bb\u5de5\u4f5c\u6d41\u903b\u8f91\u4e0e\u6548\u5e94\u64cd\u4f5c\uff08\u5982LLM\u8c03\u7528\u3001I/O\u548c\u5e76\u53d1\uff09\uff0c\u4ee5\u63d0\u5347\u6a21\u5757\u5316\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLM\u96c6\u6210\u811a\u672c\u4e2d\u6a21\u5757\u5316\u4e0e\u6027\u80fd\u7684\u6311\u6218\uff0c\u907f\u514d\u811a\u672c\u4e0e\u7279\u5b9aLLM\u5b9e\u73b0\u8026\u5408\u5e76\u5229\u7528\u5e76\u884c\u5316\u673a\u4f1a\u3002", "method": "\u901a\u8fc7\u5c06\u6548\u5e94\u64cd\u4f5c\u89c6\u4e3a\u62bd\u8c61\u63a5\u53e3\uff0c\u5e76\u901a\u8fc7\u6548\u5e94\u5904\u7406\u5668\u5b9e\u73b0\uff0c\u5206\u79bb\u903b\u8f91\u4e0e\u6548\u5e94\u64cd\u4f5c\u3002", "result": "\u5728Tree-of-Thoughts\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4e8610\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u5757\u5316\u3002", "conclusion": "\u63d0\u5021\u53ef\u7ec4\u5408\u6548\u5e94\u5904\u7406\u4f5c\u4e3aLLM\u811a\u672c\u7f16\u7a0b\u98ce\u683c\uff0c\u4ee5\u517c\u987e\u6a21\u5757\u5316\u548c\u6027\u80fd\u4f18\u5316\u3002"}}
{"id": "2507.21253", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.21253", "abs": "https://arxiv.org/abs/2507.21253", "authors": ["Abdullah Al Raqibul Islam", "Helen Xu", "Dong Dai", "Ayd\u0131n Bulu\u00e7"], "title": "Improving SpGEMM Performance Through Matrix Reordering and Cluster-wise Computation", "comment": "Accepted to appear in the International Conference for High\n  Performance Computing, Networking, Storage, and Analysis (SC) 2025", "summary": "Sparse matrix-sparse matrix multiplication (SpGEMM) is a key kernel in many\nscientific applications and graph workloads. Unfortunately, SpGEMM is\nbottlenecked by data movement due to its irregular memory access patterns.\nSignificant work has been devoted to developing row reordering schemes towards\nimproving locality in sparse operations, but prior studies mostly focus on the\ncase of sparse-matrix vector multiplication (SpMV).\n  In this paper, we address these issues with hierarchical clustering for\nSpGEMM that leverages both row reordering and cluster-wise computation to\nimprove reuse in the second input (B) matrix with a novel row-clustered matrix\nformat and access pattern in the first input (A) matrix. We find that\nhierarchical clustering can speed up SpGEMM by 1.39x on average with low\npreprocessing cost (less than 20x the cost of a single SpGEMM on about 90% of\ninputs). Furthermore, we decouple the reordering algorithm from the clustered\nmatrix format so they can be applied as independent optimizations.\n  Additionally, this paper sheds light on the role of both row reordering and\nclustering independently and together for SpGEMM with a comprehensive empirical\nstudy of the effect of 10 different reordering algorithms and 3 clustering\nschemes on SpGEMM performance on a suite of 110 matrices. We find that\nreordering based on graph partitioning provides better SpGEMM performance than\nexisting alternatives at the cost of high preprocessing time. The evaluation\ndemonstrates that the proposed hierarchical clustering method achieves greater\naverage speedup compared to other reordering schemes with similar preprocessing\ntimes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\uff08SpGEMM\uff09\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u884c\u91cd\u6392\u5e8f\u548c\u805a\u7c7b\u8ba1\u7b97\u63d0\u9ad8\u6027\u80fd\uff0c\u5e73\u5747\u52a0\u901f1.39\u500d\uff0c\u4e14\u9884\u5904\u7406\u6210\u672c\u4f4e\u3002", "motivation": "\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\uff08SpGEMM\uff09\u56e0\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7a00\u758f\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff08SpMV\uff09\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3SpGEMM\u7684\u6027\u80fd\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408\u884c\u91cd\u6392\u5e8f\u548c\u805a\u7c7b\u8ba1\u7b97\uff0c\u63d0\u51fa\u65b0\u7684\u884c\u805a\u7c7b\u77e9\u9635\u683c\u5f0f\u548c\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4ee5\u63d0\u9ad8\u8f93\u5165\u77e9\u9635B\u7684\u590d\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u52a0\u901f1.39\u500d\uff0c\u9884\u5904\u7406\u6210\u672c\u4f4e\uff08\u7ea690%\u7684\u8f93\u5165\u4e0a\u4f4e\u4e8e\u5355\u6b21SpGEMM\u6210\u672c\u768420\u500d\uff09\u3002", "conclusion": "\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u5728SpGEMM\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u91cd\u6392\u5e8f\u65b9\u6848\uff0c\u4e14\u9884\u5904\u7406\u65f6\u95f4\u76f8\u8fd1\uff0c\u4e3a\u7a00\u758f\u77e9\u9635\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u4f18\u5316\u624b\u6bb5\u3002"}}
{"id": "2507.21464", "categories": ["cs.DC", "H.3.4; D.2.6"], "pdf": "https://arxiv.org/pdf/2507.21464", "abs": "https://arxiv.org/abs/2507.21464", "authors": ["Marco Mambelli", "Bruno Moreira Coimbra", "Namratha Urs", "Ilya Baburashvili"], "title": "Using Containers to Speed Up Development, to Run Integration Tests and to Teach About Distributed Systems", "comment": "8 pages, 3 figures, for associated code, see [this https\n  URL](https://github.com/glideinWMS/containers), to be published in\n  proceedings of 27th International Conference on Computing in High Energy and\n  Nuclear Physics (CHEP 2024). 21-25 October 2024. Krakow,; Poland.\n  (C24-10-21.8)", "summary": "GlideinWMS is a workload manager provisioning resources for many experiments,\nincluding CMS and DUNE. The software is distributed both as native packages and\nspecialized production containers. Following an approach used in other\ncommunities like web development, we built our workspaces, system-like\ncontainers to ease development and testing. Developers can change the source\ntree or check out a different branch and quickly reconfigure the services to\nsee the effect of their changes. In this paper, we will talk about what\ndifferentiates workspaces from other containers. We will describe our base\nsystem, composed of three containers: a one-node cluster including a compute\nelement and a batch system, a GlideinWMS Factory controlling pilot jobs, and a\nscheduler and Frontend to submit jobs and provision resources. Additional\ncontainers can be used for optional components. This system can easily run on a\nlaptop, and we will share our evaluation of different container runtimes, with\nan eye for ease of use and performance. Finally, we will talk about our\nexperience as developers and with students. The GlideinWMS workspaces are\neasily integrated with IDEs like VS Code, simplifying debugging and allowing\ndevelopment and testing of the system even when offline. They simplified the\ntraining and onboarding of new team members and summer interns. And they were\nuseful in workshops where students could have first-hand experience with the\nmechanisms and components that, in production, run millions of jobs.", "AI": {"tldr": "GlideinWMS\u901a\u8fc7\u5de5\u4f5c\u7a7a\u95f4\u5bb9\u5668\u7b80\u5316\u5f00\u53d1\u548c\u6d4b\u8bd5\uff0c\u652f\u6301\u5feb\u901f\u914d\u7f6e\u548c\u79bb\u7ebf\u5f00\u53d1\uff0c\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u548c\u5b66\u751f\u57f9\u8bad\u6548\u7387\u3002", "motivation": "\u4e3a\u5b9e\u9a8c\uff08\u5982CMS\u548cDUNE\uff09\u63d0\u4f9b\u8d44\u6e90\u7ba1\u7406\uff0c\u540c\u65f6\u7b80\u5316\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u57f9\u8bad\u6d41\u7a0b\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u5bb9\u5668\u7684\u5de5\u4f5c\u7a7a\u95f4\uff0c\u5305\u62ec\u6838\u5fc3\u7ec4\u4ef6\uff08\u8ba1\u7b97\u8282\u70b9\u3001\u8c03\u5ea6\u5668\u7b49\uff09\u548c\u53ef\u9009\u7ec4\u4ef6\uff0c\u652f\u6301\u591a\u79cd\u5bb9\u5668\u8fd0\u884c\u65f6\u3002", "result": "\u5de5\u4f5c\u7a7a\u95f4\u6613\u4e8e\u5728\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u8fd0\u884c\uff0c\u96c6\u6210IDE\uff08\u5982VS Code\uff09\uff0c\u63d0\u5347\u5f00\u53d1\u548c\u8c03\u8bd5\u6548\u7387\uff0c\u5e76\u6210\u529f\u7528\u4e8e\u5b66\u751f\u57f9\u8bad\u3002", "conclusion": "GlideinWMS\u5de5\u4f5c\u7a7a\u95f4\u663e\u8457\u7b80\u5316\u4e86\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u57f9\u8bad\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\uff0c\u5305\u62ec\u79bb\u7ebf\u5f00\u53d1\u548c\u6559\u5b66\u3002"}}
{"id": "2507.21472", "categories": ["cs.DC", "H.3.4; K.6.2"], "pdf": "https://arxiv.org/pdf/2507.21472", "abs": "https://arxiv.org/abs/2507.21472", "authors": ["Marco Mambelli", "Shrijan Swaminathan"], "title": "GlideinBenchmark: collecting resource information to optimize provisioning", "comment": "6 pages, 3 figures, for associated code, see [this https\n  URL](https://github.com/glideinWMS/glideinbenchmark), to be published in\n  proceedings of 27th International Conference on Computing in High Energy and\n  Nuclear Physics (CHEP 2024). 21-25 October 2024. Krakow,; Poland.\n  (C24-10-21.8)", "summary": "Choosing the right resource can speed up job completion, better utilize the\navailable hardware, and visibly reduce costs, especially when renting computers\nin the cloud. This was demonstrated in earlier studies on HEPCloud. However,\nthe benchmarking of the resources proved to be a laborious and time-consuming\nprocess. This paper presents GlideinBenchmark, a new Web application leveraging\nthe pilot infrastructure of GlideinWMS to benchmark resources, and it shows how\nto use the data collected and published by GlideinBenchmark to automate the\noptimal selection of resources. An experiment can select the benchmark or the\nset of benchmarks that most closely evaluate the performance of its workflows.\nGlideinBenchmark, with the help of the GlideinWMS Factory, controls the\nbenchmark execution. Finally, a scheduler like HEPCloud's Decision Engine can\nuse the results to optimize resource provisioning.", "AI": {"tldr": "GlideinBenchmark\u662f\u4e00\u4e2a\u65b0\u7684Web\u5e94\u7528\uff0c\u5229\u7528GlideinWMS\u7684\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u8d44\u6e90\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e2e\u52a9\u81ea\u52a8\u5316\u9009\u62e9\u6700\u4f18\u8d44\u6e90\u3002", "motivation": "\u9009\u62e9\u5408\u9002\u7684\u8d44\u6e90\u53ef\u4ee5\u52a0\u901f\u4efb\u52a1\u5b8c\u6210\u3001\u63d0\u9ad8\u786c\u4ef6\u5229\u7528\u7387\u5e76\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u57fa\u51c6\u6d4b\u8bd5\u8fc7\u7a0b\u7e41\u7410\u8017\u65f6\u3002", "method": "\u5229\u7528GlideinWMS\u7684pilot\u57fa\u7840\u8bbe\u65bd\u5f00\u53d1GlideinBenchmark\uff0c\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u6267\u884c\uff0c\u5e76\u5c06\u6570\u636e\u7528\u4e8e\u8d44\u6e90\u4f18\u5316\u9009\u62e9\u3002", "result": "GlideinBenchmark\u80fd\u591f\u9ad8\u6548\u6267\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5c06\u7ed3\u679c\u7528\u4e8e\u8c03\u5ea6\u5668\uff08\u5982HEPCloud\u7684Decision Engine\uff09\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "conclusion": "GlideinBenchmark\u7b80\u5316\u4e86\u8d44\u6e90\u57fa\u51c6\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u4e3a\u81ea\u52a8\u5316\u8d44\u6e90\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.21492", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.21492", "abs": "https://arxiv.org/abs/2507.21492", "authors": ["Yicong Luo", "Senhe Hao", "Brian Wheatman", "Prashant Pandey", "Helen Xu"], "title": "Bridging Cache-Friendliness and Concurrency: A Locality-Optimized In-Memory B-Skiplist", "comment": "Accepted into ICPP 2025", "summary": "Skiplists are widely used for in-memory indexing in many key-value stores,\nsuch as RocksDB and LevelDB, due to their ease of implementation and simple\nconcurrency control mechanisms. However, traditional skiplists suffer from poor\ncache locality, as they store only a single element per node, leaving\nperformance on the table. Minimizing last-level cache misses is key to\nmaximizing in-memory index performance, making high cache locality essential.\nIn this paper, we present a practical concurrent B-skiplist that enhances cache\nlocality and performance while preserving the simplicity of traditional\nskiplist structures and concurrency control schemes. Our key contributions\ninclude a top-down, single-pass insertion algorithm for B-skiplists and a\ncorresponding simple and efficient top-down concurrency control scheme. On 128\nthreads, the proposed concurrent B-skiplist achieves between 2x-9x higher\nthroughput compared to state-of-the-art concurrent skiplist implementations,\nincluding Facebook's concurrent skiplist from Folly and the Java\nConcurrentSkipListMap. Furthermore, we find that the B-skiplist achieves\ncompetitive (0.9x-1.7x) throughput on point workloads compared to\nstate-of-the-art cache-optimized tree-based indices (e.g., Masstree). For a\nmore complete picture of the performance, we also measure the latency of\nskiplist and tree-based indices and find that the B-skiplist achieves between\n3.5x-103x lower 99% latency compared to other concurrent skiplists and between\n0.85x-64x lower 99% latency compared to tree-based indices on point workloads\nwith inserts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u53d1B-skiplist\uff0c\u901a\u8fc7\u63d0\u5347\u7f13\u5b58\u5c40\u90e8\u6027\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f20\u7edfskiplist\u7684\u7b80\u5355\u6027\u548c\u5e76\u53d1\u63a7\u5236\u673a\u5236\u3002", "motivation": "\u4f20\u7edfskiplist\u56e0\u6bcf\u4e2a\u8282\u70b9\u4ec5\u5b58\u50a8\u5355\u4e00\u5143\u7d20\u5bfc\u81f4\u7f13\u5b58\u5c40\u90e8\u6027\u5dee\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002\u63d0\u5347\u7f13\u5b58\u5c40\u90e8\u6027\u662f\u4f18\u5316\u5185\u5b58\u7d22\u5f15\u6027\u80fd\u7684\u5173\u952e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e0a\u800c\u4e0b\u3001\u5355\u904d\u63d2\u5165\u7b97\u6cd5\u548c\u5bf9\u5e94\u7684\u5e76\u53d1\u63a7\u5236\u65b9\u6848\uff0c\u7528\u4e8e\u5b9e\u73b0\u5e76\u53d1B-skiplist\u3002", "result": "\u5728128\u7ebf\u7a0b\u4e0b\uff0cB-skiplist\u7684\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u5e76\u53d1skiplist\u9ad82x-9x\uff0c\u4e0e\u7f13\u5b58\u4f18\u5316\u7684\u6811\u7ed3\u6784\u7d22\u5f15\u76f8\u6bd4\u541e\u5410\u91cf\u76f8\u5f53\uff080.9x-1.7x\uff09\uff0c\u4e1499%\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "B-skiplist\u5728\u4fdd\u6301\u7b80\u5355\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u7f13\u5b58\u5c40\u90e8\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u6027\u80fd\u5185\u5b58\u7d22\u5f15\u573a\u666f\u3002"}}
{"id": "2507.21685", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.21685", "abs": "https://arxiv.org/abs/2507.21685", "authors": ["Marlon Etheredge", "Thomas Fahringer", "Felix Erlacher", "Elias Kohler", "Stefan Pedratscher", "Juan Aznar-Poveda", "Nishant Saurabh", "Adrien Lebre"], "title": "Collaborative State Machines: A Better Programming Model for the Cloud-Edge-IoT Continuum", "comment": null, "summary": "The development of Cloud-Edge-IoT applications requires robust programming\nmodels. Existing models often struggle to manage the dynamic and stateful\nnature of these applications effectively. This paper introduces the\nCollaborative State Machines (CSM) programming model to address these\ncomplexities. CSM facilitates the development of reactive, event-driven, and\nstateful applications targeting the Cloud-Edge-IoT continuum. Applications\nbuilt with CSM are composed of state machines that collaborate autonomously and\ncan be distributed across different layers of the continuum. Key features of\nCSM include (i) a sophisticated collaboration mechanism among state machines\nutilizing events and persistent data; (ii) encapsulation of state through the\ninherent state of state machines and persistent data; (iii) integration of\nactions and service invocations within states and state transitions, thereby\ndecoupling complex application logic from compute and data processing services;\nand (iv) an advanced data model that supports the processing of local, static,\nand persistent data with defined scope and lifetime. In addition to introducing\nthe CSM programming model, we present a runtime system and a comprehensive\nevaluation of our approach. This evaluation is based on three use cases: a\nstress test on a large-scale infrastructure, a surveillance system application,\nand a complex smart factory scenario, all deployed on the Grid'5000 testbed.\nOur results demonstrate a 12x increase in throughput through novel language\nfeatures in the stress test. Compared to Serverless Workflow, a\nstate-of-the-art baseline system, we show a 2.3x improvement in processing time\nper processed image in a surveillance system use case, a 55x reduction in total\nprocessing time for a smart factory use case, and an overall improvement in\nproductivity across these use cases.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u534f\u4f5c\u72b6\u6001\u673a\uff08CSM\uff09\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3Cloud-Edge-IoT\u5e94\u7528\u4e2d\u52a8\u6001\u548c\u72b6\u6001\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7f16\u7a0b\u6a21\u578b\u96be\u4ee5\u6709\u6548\u7ba1\u7406Cloud-Edge-IoT\u5e94\u7528\u7684\u52a8\u6001\u548c\u72b6\u6001\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u6765\u652f\u6301\u53cd\u5e94\u5f0f\u3001\u4e8b\u4ef6\u9a71\u52a8\u548c\u72b6\u6001\u5316\u7684\u5e94\u7528\u5f00\u53d1\u3002", "method": "CSM\u6a21\u578b\u901a\u8fc7\u534f\u4f5c\u72b6\u6001\u673a\u3001\u4e8b\u4ef6\u9a71\u52a8\u673a\u5236\u3001\u6570\u636e\u5c01\u88c5\u548c\u52a8\u4f5c\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u5e94\u7528\u903b\u8f91\u4e0e\u8ba1\u7b97\u670d\u52a1\u7684\u89e3\u8026\uff0c\u5e76\u652f\u6301\u672c\u5730\u548c\u6301\u4e45\u5316\u6570\u636e\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCSM\u5728\u541e\u5410\u91cf\u3001\u5904\u7406\u65f6\u95f4\u548c\u751f\u4ea7\u529b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u5982\u541e\u5410\u91cf\u63d0\u534712\u500d\uff0c\u56fe\u50cf\u5904\u7406\u65f6\u95f4\u51cf\u5c112.3\u500d\uff0c\u667a\u80fd\u5de5\u5382\u603b\u5904\u7406\u65f6\u95f4\u51cf\u5c1155\u500d\u3002", "conclusion": "CSM\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u9002\u7528\u4e8eCloud-Edge-IoT\u8fde\u7eed\u4f53\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5e94\u7528\u6027\u80fd\u548c\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2507.21791", "categories": ["cs.DC", "cs.NA", "math.NA", "65F10, 65F25, 65G50, 65Y20"], "pdf": "https://arxiv.org/pdf/2507.21791", "abs": "https://arxiv.org/abs/2507.21791", "authors": ["Erin Carson", "Yuxin Ma"], "title": "The Performance of Low-Synchronization Variants of Reorthogonalized Block Classical Gram--Schmidt", "comment": "7 pages, 2 figures", "summary": "Numerous applications, such as Krylov subspace solvers, make extensive use of\nthe block classical Gram-Schmidt (BCGS) algorithm and its reorthogonalized\nvariants for orthogonalizing a set of vectors. For large-scale problems in\ndistributed memory settings, the communication cost, particularly the global\nsynchronization cost, is a major performance bottleneck. In recent years, many\nlow-synchronization BCGS variants have been proposed in an effort to reduce the\nnumber of synchronization points. The work [E. Carson, Y. Ma, arXiv preprint\n2411.07077] recently proposed stable one-synchronization and\ntwo-synchronization variants of BCGS, i.e., BCGSI+P-1S and BCGSI+P-2S. In this\nwork, we evaluate the performance of BCGSI+P-1S and BCGSI+P-2S on a distributed\nmemory system compared to other well-known low-synchronization BCGS variants.\nIn comparison to the classical reorthogonalized BCGS algorithm (BCGSI+),\nnumerical experiments demonstrate that BCGSI+P-1S and BCGSI+P-2S can achieve up\nto 4 times and 2 times speedups, respectively, and perform similarly to other\n(less stable) one-synchronization and two-synchronization variants. BCGSI+P-1S\nand BCGSI+P-2S are therefore recommended as the best choice in practice for\ncomputing an economic QR factorization on distributed memory systems due to\ntheir superior stability when compared to other variants with the same\nsynchronization cost.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e24\u79cd\u4f4e\u540c\u6b65\u6210\u672c\u7684BCGS\u53d8\u4f53\uff08BCGSI+P-1S\u548cBCGSI+P-2S\uff09\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u7a33\u5b9a\u6027\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u53d8\u4f53\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\uff0c\u5168\u5c40\u540c\u6b65\u6210\u672c\u662f\u6027\u80fd\u74f6\u9888\uff0c\u56e0\u6b64\u9700\u8981\u4f4e\u540c\u6b65\u4e14\u7a33\u5b9a\u7684\u6b63\u4ea4\u5316\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u6bd4\u8f83BCGSI+P-1S\u3001BCGSI+P-2S\u4e0e\u5176\u4ed6\u4f4e\u540c\u6b65BCGS\u53d8\u4f53\u7684\u6027\u80fd\u3002", "result": "BCGSI+P-1S\u548cBCGSI+P-2S\u5206\u522b\u5b9e\u73b0\u4e864\u500d\u548c2\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e14\u7a33\u5b9a\u6027\u4f18\u4e8e\u540c\u7c7b\u53d8\u4f53\u3002", "conclusion": "BCGSI+P-1S\u548cBCGSI+P-2S\u56e0\u5176\u4f4e\u540c\u6b65\u548c\u9ad8\u7a33\u5b9a\u6027\uff0c\u662f\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u7ecf\u6d4eQR\u5206\u89e3\u7684\u6700\u4f73\u9009\u62e9\u3002"}}
