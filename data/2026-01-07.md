<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Backwards Data-Flow Analysis using Prophecy Variable in the BuildIt System](https://arxiv.org/abs/2601.02653)
*Ajay Brahmakshatriya,Saman Amarasinghe,Martin Rinard*

Main category: cs.PL

TL;DR: 本文提出使用预言变量来预测程序未来执行信息，替代传统的反向程序分析，并在BuildIt系统中实现，显著降低了领域特定语言的实现工程开销。


<details>
  <summary>Details</summary>
Motivation: 许多程序转换和优化需要程序未来行为的信息。传统方法通过构建中间程序表示并使用反向程序分析来传播信息，但这种方法实现复杂且工程开销大。

Method: 使用预言变量预测程序未来执行信息，结合BuildIt系统的分阶段编译和重复前向程序执行，避免了反向分析和中间表示的开销。

Result: BuildIt系统成功实现了预言变量，能够支持需要未来执行信息的优化，同时大幅减少了领域特定语言实现的工程工作量。

Conclusion: 预言变量结合重复前向执行提供了一种轻量级替代传统反向程序分析的方法，在BuildIt系统中有效支持了需要未来信息的程序优化。

Abstract: Many program transformations and optimizations require information about the future behavior of the program. A standard way to obtain this information is to build an intermediate program representation, then use a backwards program analysis to propagate relevant information against the flow of control back to the transformation/optimization site. We instead propose to use prophecy variables, which predict information about the future execution of the program, to enable such transformations and optimizations. We implement prophecy variables in BuildIt, a lightweight domain specific language implementation system. BuildIt uses staged compilation to implement high performance domain specific languages embedded within a standard general purpose programming language (C++). The BuildIt first phase uses standard C++ program execution to generate optimized C, C++, and CUDA second phase code. This approach enables BuildIt to eliminate programming language implementation components such as parsers and intermediate representations, delivering a dramatic decrease in the engineering effort required to implement domain specific languages. The combination of prophecy variables and repeated forward program execution enables BuildIt to extend this approach to include transformations and optimizations that require information about the future execution of the program without backwards analyses and without the engineering overhead associated with implementing these analyses. We formalize the use of prophecy variables for this purpose, discuss the implementation of prophecy variables and repeated execution in BuildIt, and present experimental results for BuildIt computations that benefit from optimizations enabled by the information that prophecy variables provide.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)](https://arxiv.org/abs/2601.02898)
*Wim Vanderbauwhede,Lauritz Thamsen,José Cano*

Main category: cs.DC

TL;DR: LOCO 2024是第一届低碳计算国际研讨会论文集，聚焦于计算领域的碳减排技术和方法


<details>
  <summary>Details</summary>
Motivation: 随着计算系统能耗和碳排放问题日益突出，需要专门的研究平台来探讨低碳计算技术，以应对气候变化和可持续发展挑战

Method: 通过国际研讨会形式，汇集学术界和工业界专家，分享低碳计算领域的最新研究成果、技术方法和实践经验

Result: 成功举办了第一届低碳计算国际研讨会，形成了包含多篇相关论文的论文集，为低碳计算领域建立了学术交流平台

Conclusion: LOCO 2024为低碳计算研究提供了重要平台，促进了该领域的知识共享和合作，有助于推动计算系统向更环保、可持续的方向发展

Abstract: This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).

</details>


### [3] [Software-Defined Agentic Serving](https://arxiv.org/abs/2601.03197)
*Saurabh Agarwal,Marco Laju,Jayanth Srinivasa,Myungjin Lee,Aditya Akella*

Main category: cs.DC

TL;DR: 提出SDN启发的智能体服务框架，通过运行时状态动态控制通信属性，实现高效响应式多智能体LLM系统


<details>
  <summary>Details</summary>
Motivation: 随着多智能体LLM管道复杂性增加，现有服务范式无法适应动态服务条件。现有服务系统静态编码参数，而智能体服务系统应具备可编程性和系统感知能力

Method: 提出SDN（软件定义网络）启发的智能体服务框架，基于运行时状态动态控制通信关键属性，实现系统感知的智能体服务

Result: 该架构能够实现高效服务、响应式智能体系统，并为高级意图驱动的智能体服务铺平道路

Conclusion: SDN启发的可编程、系统感知的智能体服务框架是解决多智能体LLM管道动态服务需求的有效方案

Abstract: As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new SDN-inspired agentic serving framework that helps control the key attributes of communication based on runtime state. This architecture enables serving-efficient, responsive agent systems and paves the way for high-level intent-driven agentic serving.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [4] [Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification](https://arxiv.org/abs/2601.02613)
*Kuilian Yang,Li Zhang,Ahmed M. Eltawil,Khaled Nabil Salama*

Main category: cs.AR

TL;DR: 提出一种面向自动调制分类任务的稀疏感知SNN流式加速器，通过GOAP算法和预计算技术实现高吞吐量和低功耗，在FPGA上达到23.5MS/s的吞吐量


<details>
  <summary>Details</summary>
Motivation: 随着5G/6G和物联网的发展，频谱利用效率需求增加。自动调制分类在认知无线电中至关重要，但传统DNN计算和能耗高，SNN虽能效高但难以同时实现高吞吐和低功耗，特别是在硬件资源受限的边缘设备上

Method: 提出稀疏感知输出通道数据流式加速器(SAOCDS)，利用推理期间核固定的特性，采用门控一对多乘积(GOAP)算法仅计算非零输入-权重交集，将额外或空迭代预计算并嵌入推理数据流中，消除动态数据获取，实现完全流水线化、无控制的层间执行

Result: 在FPGA上实现，在RadioML 2016数据集上达到23.5MS/s吞吐量（约为基线吞吐量的两倍），同时降低动态功耗并保持相当的分类准确率

Conclusion: 该设计展示了在边缘认知无线电系统中实现实时、低功耗部署的强大潜力，通过结合稀疏利用和高吞吐量架构的优势，解决了传统方法在能效和性能之间的权衡问题

Abstract: The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.

</details>
