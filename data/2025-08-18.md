<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Generic Reduction-Based Interpreters (Extended Version)](https://arxiv.org/abs/2508.11297)
*Casper Bach*

Main category: cs.PL

TL;DR: 应用通用编程技术减少基于归约的解释器中的样板代码。


<details>
  <summary>Details</summary>
Motivation: 传统基于归约的解释器需要大量样板代码，增加了实现复杂度。

Method: 采用通用编程技术优化解释器的实现。

Result: 减少了样板代码，提高了开发效率。

Conclusion: 通用编程技术能有效简化基于归约的解释器的实现。

Abstract: Reduction-based interpreters are traditionally defined in terms of a one-step
reduction function which systematically decomposes a term into a potential
redex and context, contracts the redex, and recomposes it to construct the new
term to be further reduced. While implementing such interpreters follows a
systematic recipe, they often require interpreter engineers to write a
substantial amount of code -- much of it boilerplate. In this paper, we apply
well-known techniques from generic programming to reduce boilerplate code in
reduction-based interpreters.

</details>


### [2] [Towards Efficient Hash Maps in Functional Array Languages](https://arxiv.org/abs/2508.11443)
*William Henrich Due,Martin Elsman,Troels Henriksen*

Main category: cs.PL

TL;DR: 本文提出了一种数据并行的两级静态无冲突哈希映射实现，基于Fredman等人的构造方法，并通过Futhark实现。性能优于传统树/搜索方法，但与cuCollections库相比在构造速度上仍有差距。


<details>
  <summary>Details</summary>
Motivation: 研究如何在函数式数组语言中实现灵活、多态且抽象的哈希映射接口，特别是解决动态大小键的问题。

Method: 通过功能化Fredman等人的构造方法并扁平化，实现数据并行哈希映射，并在Futhark中实现。

Result: 性能优于传统方法，但在构造速度上不及cuCollections库。性能差异部分源于Futhark编译器的限制，部分源于数据并行编程模型的不足。

Conclusion: 探讨了函数式数组语言编程模型是否需要扩展以解决性能差距问题。

Abstract: We present a systematic derivation of a data-parallel implementation of
two-level, static and collision-free hash maps, by giving a functional
formulation of the Fredman et al. construction, and then flattening it. We
discuss the challenges of providing a flexible, polymorphic, and abstract
interface to hash maps in a functional array language, with particular
attention paid to the problem of dynamically sized keys, which we address by
associating each hash map with an arbitrary context. The algorithm is
implemented in Futhark, and the achieved GPU execution performance is compared
on simple benchmark problems. We find that our hash maps outperform
conventional tree/search-based approaches. Furthermore, our implementation is
compared against the state-of-the-art cuCollections library, which is
significantly faster for hash map construction, and to a lesser degree for
lookups. We explain to which extent the performance difference is due to
low-level code generation limitation in the Futhark compiler, and to which
extent it can be attributed to the data-parallel programming vocabulary not
providing the constructs necessary to express the equivalent of the algorithms
used by cuCollections. We end by reflecting to which extent the functional
array language programming model could, or should, be extended to address these
weaknesses.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [EMLIO: Minimizing I/O Latency and Energy Consumption for Large-Scale AI Training](https://arxiv.org/abs/2508.11035)
*Hasibul Jamil,MD S Q Zulkar Nine,Tevfik Kosar*

Main category: cs.DC

TL;DR: EMLIO是一种高效的机器学习I/O服务，旨在减少数据加载延迟和I/O能耗，适用于大规模深度学习任务。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模超过本地存储容量，GPU计算速度超过网络和磁盘延迟，大规模深度学习任务面临I/O瓶颈。现有系统虽优化了数据加载时间，但忽视了I/O的能耗问题。

Method: EMLIO在存储节点上部署轻量级数据服务守护进程，通过序列化和批量处理原始样本，使用TCP流传输并支持乱序预取，同时与GPU加速预处理无缝集成。

Result: 在本地磁盘、局域网（0.05 ms和10 ms RTT）和广域网（30 ms RTT）环境中，EMLIO比现有加载器快8.6倍，能耗降低10.9倍，且性能与能耗不受网络距离影响。

Conclusion: EMLIO的服务架构为下一代AI云提供了可扩展的能源感知I/O方案。

Abstract: Large-scale deep learning workloads increasingly suffer from I/O bottlenecks
as datasets grow beyond local storage capacities and GPU compute outpaces
network and disk latencies. While recent systems optimize data-loading time,
they overlook the energy cost of I/O - a critical factor at large scale. We
introduce EMLIO, an Efficient Machine Learning I/O service that jointly
minimizes end-to-end data-loading latency T and I/O energy consumption E across
variable-latency networked storage. EMLIO deploys a lightweight data-serving
daemon on storage nodes that serializes and batches raw samples, streams them
over TCP with out-of-order prefetching, and integrates seamlessly with
GPU-accelerated (NVIDIA DALI) preprocessing on the client side. In exhaustive
evaluations over local disk, LAN (0.05 ms & 10 ms RTT), and WAN (30 ms RTT)
environments, EMLIO delivers up to 8.6X faster I/O and 10.9X lower energy use
compared to state-of-the-art loaders, while maintaining constant performance
and energy profiles irrespective of network distance. EMLIO's service-based
architecture offers a scalable blueprint for energy-aware I/O in
next-generation AI clouds.

</details>


### [4] [Element and Everything Tokens: Two-Tier Architecture for Mobilizing Alternative Assets](https://arxiv.org/abs/2508.11266)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.DC

TL;DR: 提出一种双层代币化架构，通过元素代币和整体代币增强复杂资产的流动性和透明度。


<details>
  <summary>Details</summary>
Motivation: 传统框架难以交易或分割复杂资产（如矿山、发电厂等），需新方法提升其流动性和透明度。

Method: 引入元素代币（标准化、抵押的资产组件）和整体代币（资产的固定组合），支持双向转换和套利机制。

Result: 通过能源和工业案例展示，该方法使高价值项目可分割交易，类似股票或ETF。

Conclusion: 该架构降低投资门槛，改善价格发现，提供灵活融资，但需考虑实施和监管问题。

Abstract: Alternative assets such as mines, power plants, or infrastructure projects
are often large, heterogeneous bundles of resources, rights, and outputs whose
value is difficult to trade or fractionalize under traditional frameworks. This
paper proposes a novel two-tier tokenization architecture to enhance the
liquidity and transparency of such complex assets. We introduce the concepts of
Element Tokens and Everything Tokens: elemental tokens represent standardized,
fully collateralized components of an asset (e.g., outputs, rights, or
credits), while an everything token represents the entire asset as a fixed
combination of those elements. The architecture enables both fine-grained
partial ownership and integrated whole-asset ownership through a system of
two-way convertibility. We detail the design and mechanics of this system,
including an arbitrage mechanism that keeps the price of the composite token
aligned with the net asset value of its constituents. Through illustrative
examples in the energy and industrial sectors, we demonstrate that our approach
allows previously illiquid, high-value projects to be fractionalized and traded
akin to stocks or exchange-traded funds (ETFs). We discuss the benefits for
investors and asset owners, such as lower entry barriers, improved price
discovery, and flexible financing, as well as the considerations for
implementation and regulation.

</details>


### [5] [Inter-APU Communication on AMD MI300A Systems via Infinity Fabric: a Deep Dive](https://arxiv.org/abs/2508.11298)
*Gabin Schieffer,Jacob Wahlgren,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: 本文研究了AMD MI300A APU在多APU系统中的通信效率，通过设计基准测试比较了HIP API、MPI和RCCL库的性能，并优化了两个HPC应用。


<details>
  <summary>Details</summary>
Motivation: 随着GPU计算性能的提升，HPC应用中高效的数据移动成为关键。AMD MI300A APU通过集成CPU、GPU和HBM，旨在减少CPU-GPU数据传输开销。

Method: 设计了基准测试评估GPU直接内存访问、APU间数据传输和集体通信，比较了HIP API、MPI和RCCL库的效率。

Result: 研究揭示了优化多APU系统通信的关键设计选择，包括编程接口、分配器和数据传输策略。

Conclusion: 通过优化Quicksilver和CloverLeaf应用，验证了MI300A APU在HPC中的潜力。

Abstract: The ever-increasing compute performance of GPU accelerators drives up the
need for efficient data movements within HPC applications to sustain
performance. Proposed as a solution to alleviate CPU-GPU data movement, AMD
MI300A Accelerated Processing Unit (APU) combines CPU, GPU, and high-bandwidth
memory (HBM) within a single physical package. Leadership supercomputers, such
as El Capitan, group four APUs within a single compute node, using Infinity
Fabric Interconnect. In this work, we design specific benchmarks to evaluate
direct memory access from the GPU, explicit inter-APU data movement, and
collective multi-APU communication. We also compare the efficiency of HIP APIs,
MPI routines, and the GPU-specialized RCCL library. Our results highlight key
design choices for optimizing inter-APU communication on multi-APU AMD MI300A
systems with Infinity Fabric, including programming interfaces, allocators, and
data movement. Finally, we optimize two real HPC applications, Quicksilver and
CloverLeaf, and evaluate them on a four MI100A APU system.

</details>


### [6] [Space-efficient population protocols for exact majority in general graphs](https://arxiv.org/abs/2508.11384)
*Joel Rybicki,Jakob Solnerzik,Olivier Stietel,Robin Vacus*

Main category: cs.DC

TL;DR: 论文研究了在人口协议模型中的精确多数共识问题，改进了通用图的上界和下界，并提出了基于松弛时间和度不平衡的新协议。


<details>
  <summary>Details</summary>
Motivation: 研究精确多数共识在通用图中的性能界限，以优化协议的稳定时间和空间复杂度。

Method: 通过分析随机游走的松弛时间和图的度不平衡，设计新的协议，并给出时间复杂度和空间复杂度的理论界限。

Result: 提出了一个协议，其稳定时间为O(Δ/δ τ_rel log²n)，空间复杂度为O(log n (log(Δ/δ) + log(τ_rel/n)))。

Conclusion: 在正则扩展图中，协议的空间复杂度接近最优，稳定时间也接近最优，同时为常数状态协议提供了新的上界。

Abstract: We study exact majority consensus in the population protocol model. In this
model, the system is described by a graph $G = (V,E)$ with $n$ nodes, and in
each time step, a scheduler samples uniformly at random a pair of adjacent
nodes to interact. In the exact majority consensus task, each node is given a
binary input, and the goal is to design a protocol that almost surely reaches a
stable configuration, where all nodes output the majority input value.
  We give improved upper and lower bounds for the exact majority in general
graphs. First, we give asymptotically tight time lower bounds for general
(unbounded space) protocols. Second, we obtain new upper bounds parameterized
by the relaxation time $\tau_{\mathsf{rel}}$ of the random walk on $G$ induced
by the scheduler and the degree imbalance $\Delta/\delta$ of $G$. Specifically,
we give a protocol that stabilizes in $O\left( \tfrac{\Delta}{\delta}
\tau_{\mathsf{rel}} \log^2 n \right)$ steps in expectation and with high
probability and uses $O\left( \log n \cdot \left(
\log\left(\tfrac{\Delta}{\delta}\right) + \log
\left(\tfrac{\tau_{\mathsf{rel}}}{n}\right) \right) \right)$ states in any
graph with minimum degree at least $\delta$ and maximum degree at most
$\Delta$.
  For regular expander graphs, this matches the optimal space complexity of
$\Theta(\log n)$ for fast protocols in complete graphs [Alistarh et al., SODA
2016 and Doty et al., FOCS 2022] with a nearly optimal stabilization time of
$O(n \log^2 n)$ steps. Finally, we give a new upper bound of
$O(\tau_{\mathsf{rel}} \cdot n \log n)$ for the stabilization time of a
constant-state protocol.

</details>


### [7] [Time, Fences and the Ordering of Events in TSO](https://arxiv.org/abs/2508.11415)
*Raïssa Nataf,Yoram Moses*

Main category: cs.DC

TL;DR: 该论文提出了一种语义框架，用于精确描述在TSO内存模型下何时需要同步操作（如内存栅栏或原子操作），并引入了一种新的TSO特定occurs-before关系。


<details>
  <summary>Details</summary>
Motivation: TSO内存模型通过延迟写操作的可见性支持硬件优化，但增加了正确性推理的复杂性，需要同步操作来确保顺序一致性，而这些操作可能带来性能开销。

Method: 提出了一种新的TSO特定occurs-before关系，扩展了Lamport的happens-before关系，并通过定理证明事件间的时序顺序必须通过occurs-before链实现。

Result: 通过分析栅栏和原子操作在创建occurs-before链中的作用，明确了这些同步操作的必要性，并推广了线性化共享内存对象的先前下界。

Conclusion: 该研究为TSO模型中的信息流和因果关系提供了理论支持，扩展了异步系统的通信推理方法。

Abstract: The Total Store Order (TSO) is arguably the most widely used relaxed memory
model in multiprocessor architectures, widely implemented, for example in
Intel's x86 and x64 platforms. It allows processes to delay the visibility of
writes through store buffering. While this supports hardware-level
optimizations and makes a significant contribution to multiprocessor
efficiency, it complicates reasoning about correctness, as executions may
violate sequential consistency. Ensuring correct behavior often requires
inserting synchronization primitives such as memory fences ($F$) or atomic
read-modify-write ($RMW$) operations, but this approach can incur significant
performance costs. In this work, we develop a semantic framework that precisely
characterizes when such synchronization is necessary under TSO. We introduce a
novel TSO-specific occurs-before relation, which adapts Lamport's celebrated
happens-before relation from asynchronous message-passing systems to the TSO
setting. Our main result is a theorem that proves that the only way to ensure
that two events that take place at different sites are temporally ordered is by
having the execution create an occurs-before chain between the events. By
studying the role of fences and $RMW$s in creating occurs-before chains, we are
then able to capture cases in which these costly synchronization operations are
unavoidable. Since proper real-time ordering of events is a fundamental aspect
of consistency conditions such as Linearizability, our analysis provides a
sound theoretical understanding of essential aspects of the TSO model. In
particular, we are able to generalize prior lower bounds for linearizable
implementations of shared memory objects. Our results capture the structure of
information flow and causality in the TSO model by extending the standard
communication-based reasoning from asynchronous systems to the TSO memory
model.

</details>


### [8] [Efficient GPU-Centered Singular Value Decomposition Using the Divide-and-Conquer Method](https://arxiv.org/abs/2508.11467)
*Shifang Liu,Huiyuan Li,Hongjiao Sheng,Haoyuan Gui,Xiaoyu Zhang*

Main category: cs.DC

TL;DR: 提出了一种基于GPU的SVD算法，通过优化数据布局和计算流程，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统SVD方法在异构系统中存在计算速度慢和CPU-GPU数据传输频繁的问题，GPU的计算能力未得到充分利用。

Method: 设计了基于GPU的双对角分治（BDC）方法，重新规划算法和数据布局，完全在GPU上进行计算，减少数据传输，并优化BLAS利用率。

Result: 在AMD MI210和NVIDIA V100 GPU上，相比rocSOLVER/cuSOLVER和MAGMA，分别实现了最高1293.64x/7.47x和14.10x/12.38x的加速比。

Conclusion: 提出的GPU中心化SVD算法显著提升了计算效率，为矩阵分解问题提供了更高效的解决方案。

Abstract: Singular Value Decomposition (SVD) is a fundamental matrix factorization
technique in linear algebra, widely applied in numerous matrix-related
problems. However, traditional SVD approaches are hindered by slow panel
factorization and frequent CPU-GPU data transfers in heterogeneous systems,
despite advancements in GPU computational capabilities. In this paper, we
introduce a GPU-centered SVD algorithm, incorporating a novel GPU-based
bidiagonal divide-and-conquer (BDC) method. We reformulate the algorithm and
data layout of different steps for SVD computation, performing all panel-level
computations and trailing matrix updates entirely on GPU to eliminate CPU-GPU
data transfers. Furthermore, we integrate related computations to optimize BLAS
utilization, thereby increasing arithmetic intensity and fully leveraging the
computational capabilities of GPUs. Additionally, we introduce a newly
developed GPU-based BDC algorithm that restructures the workflow to eliminate
matrix-level CPU-GPU data transfers and enable asynchronous execution between
the CPU and GPU. Experimental results on AMD MI210 and NVIDIA V100 GPUs
demonstrate that our proposed method achieves speedups of up to 1293.64x/7.47x
and 14.10x/12.38x compared to rocSOLVER/cuSOLVER and MAGMA, respectively.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [9] [OpenCXD: An Open Real-Device-Guided Hybrid Evaluation Framework for CXL-SSDs](https://arxiv.org/abs/2508.11477)
*Hyunsun Chung,Junhyeok Park,Taewan Noh,Seonghoon Ahn,Kihwan Kim,Ming Zhao,Youngjae Kim*

Main category: cs.AR

TL;DR: OpenCXD是一个基于真实设备的混合评估框架，用于评估CXL-SSD性能，填补了仿真与硬件之间的差距。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏原生支持CXL.mem协议的SSD硬件，现有方法难以准确评估CXL-SSD性能，尤其是固件级交互和低层存储动态。

Method: OpenCXD结合了主机端的周期精确CXL.mem仿真器和运行真实固件的物理OpenSSD平台，实现仿真内存请求触发的固件执行。

Result: OpenCXD能够反映仿真无法观察到的设备级现象，为未来CXL-SSD固件设计提供关键见解。

Conclusion: OpenCXD为CXL-SSD性能评估提供了一种更接近硬件的方法，有助于优化固件设计。

Abstract: The advent of Compute Express Link (CXL) enables SSDs to participate in the
memory hierarchy as large-capacity, byte-addressable memory devices. These
CXL-enabled SSDs (CXL-SSDs) offer a promising new tier between DRAM and
traditional storage, combining NAND flash density with memory-like access
semantics. However, evaluating the performance of CXL-SSDs remains difficult
due to the lack of hardware that natively supports the CXL.mem protocol on
SSDs. As a result, most prior work relies on hybrid simulators combining CPU
models augmented with CXL.mem semantics and SSD simulators that approximate
internal flash behaviors. While effective for early-stage exploration, this
approach cannot faithfully model firmware-level interactions and low-level
storage dynamics critical to CXL-SSD performance. In this paper, we present
OpenCXD, a real-device-guided hybrid evaluation framework that bridges the gap
between simulation and hardware. OpenCXD integrates a cycle-accurate CXL.mem
simulator on the host side with a physical OpenSSD platform running real
firmware. This enables in-situ firmware execution triggered by simulated memory
requests. Through these contributions, OpenCXD reflects device-level phenomena
unobservable in simulation-only setups, providing critical insights for future
firmware design tailored to CXL-SSDs.

</details>
