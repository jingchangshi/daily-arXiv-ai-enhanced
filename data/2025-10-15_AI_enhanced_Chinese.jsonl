{"id": "2510.11751", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.11751", "abs": "https://arxiv.org/abs/2510.11751", "authors": ["Jan Pedersen", "Kevin Chalmers"], "title": "Verifying Correctness of Shared Channels in a Cooperatively Scheduled Process-Oriented Language", "comment": null, "summary": "Correct concurrent behaviour is important in understanding how components\nwill act within certain conditions. In this work. we analyse the behaviour of\nshared communicating channels within a coorporatively scheduled runtime. We use\nthe refinement checking and modelling tool FDR to develop both specifications\nof how such shared channels should behave and models of the implementations of\nthese channels in the cooperatively scheduled language ProcessJ. Our results\ndemonstrate that although we can certainly implement the correct behaviour of\nsuch channels, the outcome is dependant on having adequate resources available\nto execute all processes involved. We conclude that modelling the runtime\nenvironment of concurrent components is necessary to ensure components behave\nas specified in the real world.", "AI": {"tldr": "\u4f7f\u7528FDR\u5de5\u5177\u5206\u6790\u534f\u4f5c\u8c03\u5ea6\u8fd0\u884c\u65f6\u4e2d\u5171\u4eab\u901a\u4fe1\u901a\u9053\u7684\u884c\u4e3a\uff0c\u9a8c\u8bc1ProcessJ\u8bed\u8a00\u4e2d\u901a\u9053\u5b9e\u73b0\u7684\u6b63\u786e\u6027\uff0c\u53d1\u73b0\u6b63\u786e\u884c\u4e3a\u4f9d\u8d56\u4e8e\u5145\u8db3\u7684\u6267\u884c\u8d44\u6e90", "motivation": "\u7406\u89e3\u5e76\u53d1\u7ec4\u4ef6\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u5f88\u91cd\u8981\uff0c\u9700\u8981\u5206\u6790\u534f\u4f5c\u8c03\u5ea6\u8fd0\u884c\u65f6\u4e2d\u5171\u4eab\u901a\u4fe1\u901a\u9053\u7684\u884c\u4e3a", "method": "\u4f7f\u7528FDR\u7cbe\u5316\u68c0\u67e5\u548c\u5efa\u6a21\u5de5\u5177\uff0c\u5f00\u53d1\u5171\u4eab\u901a\u9053\u7684\u884c\u4e3a\u89c4\u8303\u548cProcessJ\u8bed\u8a00\u4e2d\u8fd9\u4e9b\u901a\u9053\u7684\u5b9e\u73b0\u6a21\u578b", "result": "\u867d\u7136\u53ef\u4ee5\u5b9e\u73b0\u6b63\u786e\u7684\u901a\u9053\u884c\u4e3a\uff0c\u4f46\u7ed3\u679c\u53d6\u51b3\u4e8e\u662f\u5426\u6709\u8db3\u591f\u8d44\u6e90\u6765\u6267\u884c\u6240\u6709\u76f8\u5173\u8fdb\u7a0b", "conclusion": "\u5efa\u6a21\u5e76\u53d1\u7ec4\u4ef6\u7684\u8fd0\u884c\u65f6\u73af\u5883\u5bf9\u4e8e\u786e\u4fdd\u7ec4\u4ef6\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u6309\u89c4\u8303\u884c\u4e3a\u662f\u5fc5\u8981\u7684"}}
{"id": "2510.11759", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11759", "abs": "https://arxiv.org/abs/2510.11759", "authors": ["Hongyu Lin", "Haolin Pan", "Haoran Luo", "Yuchen Li", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "AwareCompiler: Agentic Context-Aware Compiler Optimization via a Synergistic Knowledge-Data Driven Framework", "comment": null, "summary": "Compiler optimization is crucial for enhancing program performance by\ntransforming the sequence of optimization passes while maintaining correctness.\nDespite the promising potential of large language models (LLMs)-based agent for\nsoftware optimization, automating compiler optimization remains challenging due\nto: (1) semantic misalignment between abstract program representations and\nconcrete optimization passes, (2) inefficient interaction mechanisms between\nagents and compiler environments, and (3) reward sparsity from the extensive\ndecision-making process within large optimization spaces. This paper introduces\n\\textbf{AwareCompiler}, an agentic framework for compiler optimization that\naddresses these challenges through three key innovations: structured knowledge\nintegration and dataset construction, knowledge-driven adaptive pass\ngeneration, and data-driven hybrid training pipeline. Experimental results on\nstandard benchmarks demonstrate that AwareCompiler significantly outperforms\nexisting baselines in both performance and efficiency, highlighting the\neffectiveness of our synergistic knowledge-data-driven approach. Our code is\npublicly available at https://github.com/LHY-24/AwareCompiler.", "AI": {"tldr": "AwareCompiler\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7f16\u8bd1\u5668\u4f18\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u3001\u77e5\u8bc6\u9a71\u52a8\u81ea\u9002\u5e94pass\u751f\u6210\u548c\u6570\u636e\u9a71\u52a8\u6df7\u5408\u8bad\u7ec3\u6765\u89e3\u51b3\u8bed\u4e49\u5bf9\u9f50\u3001\u4ea4\u4e92\u6548\u7387\u548c\u5956\u52b1\u7a00\u758f\u6027\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u5316\u7f16\u8bd1\u5668\u4f18\u5316\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a(1)\u62bd\u8c61\u7a0b\u5e8f\u8868\u793a\u4e0e\u5177\u4f53\u4f18\u5316pass\u4e4b\u95f4\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\uff0c(2)\u4ee3\u7406\u4e0e\u7f16\u8bd1\u5668\u73af\u5883\u95f4\u7684\u4f4e\u6548\u4ea4\u4e92\u673a\u5236\uff0c(3)\u5927\u4f18\u5316\u7a7a\u95f4\u4e2d\u51b3\u7b56\u8fc7\u7a0b\u7684\u5956\u52b1\u7a00\u758f\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u4e0e\u6570\u636e\u96c6\u6784\u5efa\u3001\u77e5\u8bc6\u9a71\u52a8\u81ea\u9002\u5e94pass\u751f\u6210\u3001\u6570\u636e\u9a71\u52a8\u6df7\u5408\u8bad\u7ec3\u7ba1\u9053\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAwareCompiler\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u77e5\u8bc6-\u6570\u636e\u9a71\u52a8\u534f\u540c\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7f16\u8bd1\u5668\u4f18\u5316\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.12131", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.12131", "abs": "https://arxiv.org/abs/2510.12131", "authors": ["Haobin Ni", "Robbert van Renesse", "Greg Morrisett"], "title": "Functional Reasoning for Distributed Systems with Failures", "comment": null, "summary": "Distributed system theory literature often argues for correctness using an\ninformal, Hoare-like style of reasoning. While these arguments are intuitive,\nthey have not all been foolproof, and whether they directly correspond to\nformal proofs is in question. We formally ground this kind of reasoning and\nconnect it to standard formal approaches through language design and\nmeta-analysis, which leads to a functional style of compositional formal\nreasoning for a class of distributed systems, including cases involving\nByzantine faults. The core of our approach is twin languages: Sync and Async,\nwhich formalize the insight from distributed system theory that an asynchronous\nsystem can be reduced to a synchronous system for more straightforward\nreasoning under certain conditions. Sync describes a distributed system as a\nsingle, synchronous, data-parallel program. It restricts programs syntactically\nand has a functional denotational semantics suitable for Hoare-style formal\nreasoning. Async models a distributed system as a collection of interacting\nmonadic programs, one for each non-faulty node in the system. It has a standard\ntrace-based operational semantics, modeling asynchrony with interleaving. Sync\ncompiles to Async and can then be extracted to yield executable code. We prove\nthat any safety property proven for a Sync program in its denotational\nsemantics is preserved in the operational semantics of its compiled Async\nprograms. We implement the twin languages in Rocq and verify the safety\nproperties of two fault-tolerant consensus protocols: BOSCO and SeqPaxos.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8bbe\u8ba1Sync\u548cAsync\u4e24\u79cd\u8bed\u8a00\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u975e\u5f62\u5f0f\u5316Hoare\u98ce\u683c\u63a8\u7406\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u5e76\u8bc1\u660e\u4e86\u5728Sync\u4e2d\u8bc1\u660e\u7684\u5b89\u5168\u5c5e\u6027\u5728\u7f16\u8bd1\u5230Async\u540e\u4ecd\u7136\u4fdd\u6301\u3002", "motivation": "\u5206\u5e03\u5f0f\u7cfb\u7edf\u7406\u8bba\u4e2d\u4f7f\u7528\u7684\u975e\u5f62\u5f0f\u5316Hoare\u98ce\u683c\u63a8\u7406\u867d\u7136\u76f4\u89c2\uff0c\u4f46\u53ef\u80fd\u5b58\u5728\u9519\u8bef\uff0c\u4e14\u4e0e\u5f62\u5f0f\u5316\u8bc1\u660e\u7684\u5bf9\u5e94\u5173\u7cfb\u4e0d\u660e\u786e\uff0c\u9700\u8981\u5efa\u7acb\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "method": "\u8bbe\u8ba1Sync\u548cAsync\u4e24\u79cd\u8bed\u8a00\uff1aSync\u4f5c\u4e3a\u540c\u6b65\u6570\u636e\u5e76\u884c\u7a0b\u5e8f\uff0c\u5177\u6709\u51fd\u6570\u5f0f\u6307\u79f0\u8bed\u4e49\uff1bAsync\u4f5c\u4e3a\u5f02\u6b65\u4ea4\u4e92\u5f0f\u7a0b\u5e8f\u96c6\u5408\uff0c\u5177\u6709\u57fa\u4e8e\u8f68\u8ff9\u7684\u64cd\u4f5c\u8bed\u4e49\u3002Sync\u53ef\u7f16\u8bd1\u5230Async\uff0c\u5e76\u8bc1\u660e\u5b89\u5168\u5c5e\u6027\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u3002", "result": "\u5728Rocq\u4e2d\u5b9e\u73b0\u4e86\u8fd9\u4e24\u79cd\u8bed\u8a00\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4e24\u4e2a\u5bb9\u9519\u5171\u8bc6\u534f\u8bae\uff08BOSCO\u548cSeqPaxos\uff09\u7684\u5b89\u5168\u5c5e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u7ec4\u5408\u5f0f\u5f62\u5f0f\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u76f4\u89c2\u7684\u975e\u5f62\u5f0f\u5316\u63a8\u7406\u4e0e\u6807\u51c6\u5f62\u5f0f\u5316\u65b9\u6cd5\u8fde\u63a5\u8d77\u6765\uff0c\u9002\u7528\u4e8e\u5305\u62ec\u62dc\u5360\u5ead\u6545\u969c\u5728\u5185\u7684\u5404\u7c7b\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2510.12277", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.12277", "abs": "https://arxiv.org/abs/2510.12277", "authors": ["Thomas Benz", "Axel Vanoni", "Michael Rogenmoser", "Luca Benini"], "title": "A Direct Memory Access Controller (DMAC) for Irregular Data Transfers on RISC-V Linux Systems", "comment": "6 pages, 5 figures", "summary": "With the ever-growing heterogeneity in computing systems, driven by modern\nmachine learning applications, pressure is increasing on memory systems to\nhandle arbitrary and more demanding transfers efficiently. Descriptor-based\ndirect memory access controllers (DMACs) allow such transfers to be executed by\ndecoupling memory transfers from processing units. Classical descriptor-based\nDMACs are inefficient when handling arbitrary transfers of small unit sizes.\nExcessive descriptor size and the serialized nature of processing descriptors\nemployed by the DMAC lead to large static overheads when setting up transfers.\nTo tackle this inefficiency, we propose a descriptor-based DMAC optimized to\nefficiently handle arbitrary transfers of small unit sizes. We implement a\nlightweight descriptor format in an AXI4-based DMAC. We further increase\nperformance by implementing a low-overhead speculative descriptor prefetching\nscheme without additional latency penalties in the case of a misprediction. Our\nDMAC is integrated into a 64-bit Linux-capable RISC-V SoC and emulated on a\nKintex FPGA to evaluate its performance. Compared to an off-the-shelf\ndescriptor-based DMAC IP, we achieve 1.66x less latency launching transfers,\nincrease bus utilization up to 2.5x in an ideal memory system with\n64-byte-length transfers while requiring 11% fewer lookup tables, 23% fewer\nflip-flops, and no block RAMs. We can extend our lead in bus utilization to\n3.6x with 64-byte-length transfers in deep memory systems. We synthesized our\nDMAC in GlobalFoundries' GF12LP+ node, achieving a clock frequency of over 1.44\nGHz while occupying only 49.5 kGE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u63cf\u8ff0\u7b26DMA\u63a7\u5236\u5668\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u6548\u5904\u7406\u5c0f\u5355\u5143\u5927\u5c0f\u7684\u4efb\u610f\u4f20\u8f93\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63cf\u8ff0\u7b26\u683c\u5f0f\u548c\u63a8\u6d4b\u6027\u9884\u53d6\u65b9\u6848\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5e94\u7528\u9a71\u52a8\u7684\u8ba1\u7b97\u7cfb\u7edf\u5f02\u6784\u6027\u589e\u957f\uff0c\u5185\u5b58\u7cfb\u7edf\u9762\u4e34\u5904\u7406\u4efb\u610f\u4e14\u8981\u6c42\u66f4\u9ad8\u7684\u4f20\u8f93\u6548\u7387\u7684\u538b\u529b\u3002\u4f20\u7edf\u63cf\u8ff0\u7b26DMA\u5728\u5904\u7406\u5c0f\u5355\u5143\u4f20\u8f93\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u5b58\u5728\u63cf\u8ff0\u7b26\u8fc7\u5927\u548c\u4e32\u884c\u5904\u7406\u5bfc\u81f4\u7684\u9759\u6001\u5f00\u9500\u95ee\u9898\u3002", "method": "\u5728AXI4 DMA\u4e2d\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u63cf\u8ff0\u7b26\u683c\u5f0f\uff0c\u91c7\u7528\u4f4e\u5f00\u9500\u63a8\u6d4b\u6027\u63cf\u8ff0\u7b26\u9884\u53d6\u65b9\u6848\uff08\u5373\u4f7f\u9884\u6d4b\u9519\u8bef\u4e5f\u65e0\u989d\u5916\u5ef6\u8fdf\uff09\uff0c\u96c6\u6210\u523064\u4f4dLinux\u517c\u5bb9RISC-V SoC\u4e2d\u5e76\u5728Kintex FPGA\u4e0a\u8fdb\u884c\u4eff\u771f\u3002", "result": "\u76f8\u6bd4\u5546\u7528DMA IP\uff0c\u4f20\u8f93\u542f\u52a8\u5ef6\u8fdf\u964d\u4f4e1.66\u500d\uff0c64\u5b57\u8282\u4f20\u8f93\u65f6\u603b\u7ebf\u5229\u7528\u7387\u63d0\u53472.5\u500d\uff08\u7406\u60f3\u5185\u5b58\u7cfb\u7edf\uff09\u62163.6\u500d\uff08\u6df1\u5ea6\u5185\u5b58\u7cfb\u7edf\uff09\uff0c\u8d44\u6e90\u4f7f\u7528\u51cf\u5c1111%\u67e5\u627e\u8868\u300123%\u89e6\u53d1\u5668\u4e14\u65e0\u9700\u5757RAM\u3002\u5728GF12LP+\u5de5\u827a\u4e0b\u5b9e\u73b01.44GHz\u65f6\u949f\u9891\u7387\uff0c\u9762\u79ef\u4ec549.5kGE\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316DMA\u63a7\u5236\u5668\u80fd\u6709\u6548\u89e3\u51b3\u5c0f\u5355\u5143\u4f20\u8f93\u6548\u7387\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u3002"}}
{"id": "2510.12295", "categories": ["cs.PL", "cs.LO", "ACM F.3.2", "F.3.2"], "pdf": "https://arxiv.org/pdf/2510.12295", "abs": "https://arxiv.org/abs/2510.12295", "authors": ["Roberto M. Amadio"], "title": "Operational methods in semantics", "comment": null, "summary": "The focus of these lecture notes is on abstract models and basic ideas and\nresults that relate to the operational semantics of programming languages\nlargely conceived. The approach is to start with an abstract description of the\ncomputation steps of programs and then to build on top semantic equivalences,\nspecification languages, and static analyses. While other approaches to the\nsemantics of programming languages are possible, it appears that the\noperational one is particularly effective in that it requires a moderate level\nof mathematical sophistication and scales reasonably well to a large variety of\nprogramming features. In practice, operational semantics is a suitable\nframework to build portable language implementations and to specify and test\nprogram properties. It is also used routinely to tackle more ambitious tasks\nsuch as proving the correctness of a compiler or a static analyzer.", "AI": {"tldr": "\u8fd9\u4e9b\u8bb2\u4e49\u7b14\u8bb0\u805a\u7126\u4e8e\u7f16\u7a0b\u8bed\u8a00\u64cd\u4f5c\u8bed\u4e49\u7684\u62bd\u8c61\u6a21\u578b\u3001\u57fa\u672c\u601d\u60f3\u548c\u7ed3\u679c\uff0c\u91c7\u7528\u4ece\u7a0b\u5e8f\u8ba1\u7b97\u6b65\u9aa4\u7684\u62bd\u8c61\u63cf\u8ff0\u51fa\u53d1\uff0c\u9010\u6b65\u6784\u5efa\u8bed\u4e49\u7b49\u4ef7\u6027\u3001\u89c4\u8303\u8bed\u8a00\u548c\u9759\u6001\u5206\u6790\u7684\u65b9\u6cd5\u3002", "motivation": "\u64cd\u4f5c\u8bed\u4e49\u65b9\u6cd5\u9700\u8981\u9002\u5ea6\u7684\u6570\u5b66\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u5f88\u597d\u5730\u6269\u5c55\u5230\u5404\u79cd\u7f16\u7a0b\u7279\u6027\uff0c\u662f\u6784\u5efa\u53ef\u79fb\u690d\u8bed\u8a00\u5b9e\u73b0\u3001\u6307\u5b9a\u548c\u6d4b\u8bd5\u7a0b\u5e8f\u5c5e\u6027\u7684\u5408\u9002\u6846\u67b6\u3002", "method": "\u4ece\u7a0b\u5e8f\u8ba1\u7b97\u6b65\u9aa4\u7684\u62bd\u8c61\u63cf\u8ff0\u5f00\u59cb\uff0c\u9010\u6b65\u6784\u5efa\u8bed\u4e49\u7b49\u4ef7\u6027\u3001\u89c4\u8303\u8bed\u8a00\u548c\u9759\u6001\u5206\u6790\u3002", "result": "\u64cd\u4f5c\u8bed\u4e49\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u80fd\u591f\u5904\u7406\u4ece\u57fa\u672c\u8bed\u8a00\u5b9e\u73b0\u5230\u7f16\u8bd1\u5668\u6b63\u786e\u6027\u8bc1\u660e\u7b49\u66f4\u590d\u6742\u7684\u4efb\u52a1\u3002", "conclusion": "\u64cd\u4f5c\u8bed\u4e49\u662f\u7f16\u7a0b\u8bed\u8a00\u8bed\u4e49\u5b66\u4e2d\u7279\u522b\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5b83\u5e73\u8861\u4e86\u6570\u5b66\u4e25\u8c28\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u89c4\u6a21\u7684\u7f16\u7a0b\u8bed\u8a00\u5206\u6790\u548c\u5b9e\u73b0\u4efb\u52a1\u3002"}}
{"id": "2510.11938", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.11938", "abs": "https://arxiv.org/abs/2510.11938", "authors": ["Yanying Lin", "Shijie Peng", "Chengzhi Lu", "Chengzhong Xu", "Kejiang Ye"], "title": "FlexPipe: Adapting Dynamic LLM Serving Through Inflight Pipeline Refactoring in Fragmented Serverless Clusters", "comment": "EuroSys 26", "summary": "Serving Large Language Models (LLMs) in production faces significant\nchallenges from highly variable request patterns and severe resource\nfragmentation in serverless clusters. Current systems rely on static pipeline\nconfigurations that struggle to adapt to dynamic workload conditions, leading\nto substantial inefficiencies. We present FlexPipe, a novel system that\ndynamically reconfigures pipeline architectures during runtime to address these\nfundamental limitations. FlexPipe decomposes models into fine-grained stages\nand intelligently adjusts pipeline granularity based on real-time request\npattern analysis, implementing three key innovations: fine-grained model\npartitioning with preserved computational graph constraints, inflight pipeline\nrefactoring with consistent cache transitions, and topology-aware resource\nallocation that navigates GPU fragmentation. Comprehensive evaluation on an\n82-GPU cluster demonstrates that FlexPipe achieves up to 8.5x better resource\nefficiency while maintaining 38.3% lower latency compared to state-of-the-art\nsystems, reducing GPU reservation requirements from 75% to 30% of peak\ncapacity.", "AI": {"tldr": "FlexPipe\u901a\u8fc7\u52a8\u6001\u91cd\u6784\u6d41\u6c34\u7ebf\u67b6\u6784\uff0c\u5728\u8fd0\u884c\u65f6\u6839\u636e\u8bf7\u6c42\u6a21\u5f0f\u8c03\u6574\u6d41\u6c34\u7ebf\u7c92\u5ea6\uff0c\u89e3\u51b3\u4e86LLM\u670d\u52a1\u4e2d\u7684\u8d44\u6e90\u788e\u7247\u5316\u548c\u6548\u7387\u95ee\u9898", "motivation": "\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u6d41\u6c34\u7ebf\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5bfc\u81f4\u8d44\u6e90\u6548\u7387\u4f4e\u4e0b\u548cGPU\u788e\u7247\u5316\u95ee\u9898", "method": "\u5c06\u6a21\u578b\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u9636\u6bb5\uff0c\u57fa\u4e8e\u5b9e\u65f6\u8bf7\u6c42\u6a21\u5f0f\u5206\u6790\u667a\u80fd\u8c03\u6574\u6d41\u6c34\u7ebf\u7c92\u5ea6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u7ec6\u7c92\u5ea6\u6a21\u578b\u5206\u533a\u3001\u98de\u884c\u4e2d\u6d41\u6c34\u7ebf\u91cd\u6784\u548c\u62d3\u6251\u611f\u77e5\u8d44\u6e90\u5206\u914d", "result": "\u572882-GPU\u96c6\u7fa4\u4e0a\u8bc4\u4f30\uff0cFlexPipe\u5b9e\u73b0\u4e868.5\u500d\u8d44\u6e90\u6548\u7387\u63d0\u5347\uff0c\u5ef6\u8fdf\u964d\u4f4e38.3%\uff0cGPU\u9884\u7559\u9700\u6c42\u4ece\u5cf0\u503c\u5bb9\u91cf\u768475%\u964d\u81f330%", "conclusion": "FlexPipe\u901a\u8fc7\u52a8\u6001\u6d41\u6c34\u7ebf\u91cd\u6784\u663e\u8457\u63d0\u5347\u4e86LLM\u670d\u52a1\u7684\u8d44\u6e90\u6548\u7387\u548c\u6027\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u788e\u7247\u5316\u95ee\u9898"}}
{"id": "2510.12582", "categories": ["cs.PL", "cs.SE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.12582", "abs": "https://arxiv.org/abs/2510.12582", "authors": ["Mark Koch", "Alan Lawrence", "Kartik Singhal", "Seyon Sivarajah", "Ross Duncan"], "title": "GUPPY: Pythonic Quantum-Classical Programming", "comment": "Presented at the Fourth International Workshop on Programming\n  Languages for Quantum Computing (PLanQC 2024)", "summary": "We present ongoing work on Guppy, a domain-specific language embedded in\nPython that allows users to write high-level hybrid quantum programs with\ncomplex control flow in Pythonic syntax, aiming to run them on actual quantum\nhardware.", "AI": {"tldr": "Guppy\u662f\u4e00\u4e2a\u5d4c\u5165Python\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u7528\u4e8e\u7f16\u5199\u5177\u6709\u590d\u6742\u63a7\u5236\u6d41\u7684\u9ad8\u5c42\u6b21\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\uff0c\u76ee\u6807\u662f\u80fd\u5728\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u4e0a\u8fd0\u884c\u3002", "motivation": "\u91cf\u5b50\u7f16\u7a0b\u9700\u8981\u5904\u7406\u590d\u6742\u63a7\u5236\u6d41\uff0c\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u5728Pythonic\u8bed\u6cd5\u4e0b\u5b9e\u73b0\u9ad8\u5c42\u6b21\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u7684\u7f16\u5199\u548c\u786c\u4ef6\u6267\u884c\u3002", "method": "\u5f00\u53d1\u5d4c\u5165Python\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00Guppy\uff0c\u652f\u6301Pythonic\u8bed\u6cd5\u7f16\u5199\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\uff0c\u5305\u542b\u590d\u6742\u63a7\u5236\u6d41\u529f\u80fd\u3002", "result": "\u63d0\u51fa\u4e86Guppy\u8bed\u8a00\u6846\u67b6\uff0c\u80fd\u591f\u8868\u8fbe\u9ad8\u5c42\u6b21\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\uff0c\u4e3a\u5728\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u4e0a\u6267\u884c\u91cf\u5b50\u4ee3\u7801\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Guppy\u4f5c\u4e3a\u5d4c\u5165\u5f0fDSL\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u63d0\u4f9b\u4e86\u66f4\u81ea\u7136\u548c\u5f3a\u5927\u7684\u8868\u8fbe\u65b9\u5f0f\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2510.12166", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12166", "abs": "https://arxiv.org/abs/2510.12166", "authors": ["Kenneth Weiss", "Thomas M. Stitt", "Daryl Hawkins", "Olga Pearce", "Stephanie Brink", "Robert N. Rieben"], "title": "Comparing Cross-Platform Performance via Node-to-Node Scaling Studies", "comment": "16 pages; accepted to the International Journal of High Performance\n  Computing Applications (IJHPCA)", "summary": "Due to the increasing diversity of high-performance computing architectures,\nresearchers and practitioners are increasingly interested in comparing a code's\nperformance and scalability across different platforms. However, there is a\nlack of available guidance on how to actually set up and analyze such\ncross-platform studies. In this paper, we contend that the natural base unit of\ncomputing for such studies is a single compute node on each platform and offer\nguidance in setting up, running, and analyzing node-to-node scaling studies. We\npropose templates for presenting scaling results of these studies and provide\nseveral case studies highlighting the benefits of this approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5\u5355\u8ba1\u7b97\u8282\u70b9\u4f5c\u4e3a\u8de8\u5e73\u53f0\u6027\u80fd\u6bd4\u8f83\u7684\u57fa\u7840\u5355\u5143\uff0c\u5e76\u63d0\u4f9b\u4e86\u8282\u70b9\u5230\u8282\u70b9\u6269\u5c55\u7814\u7a76\u7684\u8bbe\u7f6e\u3001\u8fd0\u884c\u548c\u5206\u6790\u6307\u5bfc\u3002", "motivation": "\u7531\u4e8e\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u65e5\u76ca\u591a\u6837\u5316\uff0c\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u8d8a\u6765\u8d8a\u9700\u8981\u5728\u4e0d\u540c\u5e73\u53f0\u4e0a\u6bd4\u8f83\u4ee3\u7801\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7f3a\u4e4f\u5982\u4f55\u8fdb\u884c\u6b64\u7c7b\u8de8\u5e73\u53f0\u7814\u7a76\u7684\u6307\u5bfc\u3002", "method": "\u5c06\u5355\u8ba1\u7b97\u8282\u70b9\u4f5c\u4e3a\u8de8\u5e73\u53f0\u6bd4\u8f83\u7684\u81ea\u7136\u57fa\u7840\u5355\u5143\uff0c\u63d0\u4f9b\u8282\u70b9\u5230\u8282\u70b9\u6269\u5c55\u7814\u7a76\u7684\u8bbe\u7f6e\u3001\u8fd0\u884c\u548c\u5206\u6790\u6307\u5bfc\uff0c\u5305\u62ec\u7ed3\u679c\u5c55\u793a\u6a21\u677f\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u4ee5\u8282\u70b9\u4e3a\u57fa\u7840\u8fdb\u884c\u8de8\u5e73\u53f0\u6027\u80fd\u6bd4\u8f83\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4ee5\u5355\u8ba1\u7b97\u8282\u70b9\u4e3a\u57fa\u51c6\u8fdb\u884c\u8de8\u5e73\u53f0\u6269\u5c55\u7814\u7a76\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u67b6\u6784\u95f4\u7684\u6027\u80fd\u6bd4\u8f83\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.12196", "categories": ["cs.DC", "8W10"], "pdf": "https://arxiv.org/pdf/2510.12196", "abs": "https://arxiv.org/abs/2510.12196", "authors": ["Petr Samoldekin", "Christian Schulz", "Henning Woydt"], "title": "GPU-Accelerated Algorithms for Process Mapping", "comment": null, "summary": "Process mapping asks to assign vertices of a task graph to processing\nelements of a supercomputer such that the computational workload is balanced\nwhile the communication cost is minimized. Motivated by the recent success of\nGPU-based graph partitioners, we propose two GPU-accelerated algorithms for\nthis optimization problem. The first algorithm employs hierarchical\nmultisection, which partitions the task graph alongside the hierarchy of the\nsupercomputer. The method utilizes GPU-based graph partitioners to accelerate\nthe mapping process. The second algorithm integrates process mapping directly\ninto the modern multilevel graph partitioning pipeline. Vital phases like\ncoarsening and refinement are accelerated by exploiting the parallelism of\nGPUs. In our experiments, both methods achieve speedups exceeding 300 when\ncompared to state-of-the-art CPU-based algorithms. The first algorithm has, on\naverage, about 10 percent greater communication costs and thus remains\ncompetitive to CPU algorithms. The second approach is much faster, with a\ngeometric mean speedup of 77.6 and peak speedup of 598 at the cost of lower\nsolution quality. To our knowledge, these are the first GPU-based algorithms\nfor process mapping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cdGPU\u52a0\u901f\u7684\u8fdb\u7a0b\u6620\u5c04\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u5206\u914d\u4efb\u52a1\u56fe\u7684\u9876\u70b9\uff0c\u4ee5\u5e73\u8861\u8ba1\u7b97\u8d1f\u8f7d\u5e76\u6700\u5c0f\u5316\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u53d7GPU\u56fe\u50cf\u5206\u5272\u5668\u8fd1\u671f\u6210\u529f\u7684\u542f\u53d1\uff0c\u5f00\u53d1GPU\u52a0\u901f\u7684\u8fdb\u7a0b\u6620\u5c04\u7b97\u6cd5\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u7b2c\u4e00\u79cd\u7b97\u6cd5\u91c7\u7528\u5206\u5c42\u591a\u5206\u5272\uff0c\u6cbf\u8d85\u7ea7\u8ba1\u7b97\u673a\u5c42\u6b21\u7ed3\u6784\u5206\u5272\u4efb\u52a1\u56fe\uff1b\u7b2c\u4e8c\u79cd\u7b97\u6cd5\u5c06\u8fdb\u7a0b\u6620\u5c04\u76f4\u63a5\u96c6\u6210\u5230\u73b0\u4ee3\u591a\u7ea7\u56fe\u5206\u5272\u6d41\u7a0b\u4e2d\uff0c\u5229\u7528GPU\u5e76\u884c\u6027\u52a0\u901f\u5173\u952e\u9636\u6bb5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u7b97\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc7300\u500d\u7684\u52a0\u901f\u3002\u7b2c\u4e00\u79cd\u7b97\u6cd5\u901a\u4fe1\u6210\u672c\u5e73\u5747\u589e\u52a0\u7ea610%\uff0c\u7b2c\u4e8c\u79cd\u7b97\u6cd5\u901f\u5ea6\u66f4\u5feb\u4f46\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u8f83\u4f4e\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8eGPU\u7684\u8fdb\u7a0b\u6620\u5c04\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2510.12274", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12274", "abs": "https://arxiv.org/abs/2510.12274", "authors": ["Hao Jiang", "Meng Qin", "Ruijie Kuai", "Dandan Liang"], "title": "Metronome: Efficient Scheduling for Periodic Traffic Jobs with Network and Priority Awareness", "comment": "16 pages, 16 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "With the rapid growth in computing power demand, cloud native networks have\nemerged as a promising solution to address the challenges of efficient resource\ncoordination, particularly in coping with the dynamic fluctuations of network\nbandwidth in clusters. We propose Metronome, a network-aware and priority-aware\nscheduling mechanism for cloud native networks. This mechanism is designed to\nsupport jobs that exhibit periodic traffic patterns and dynamic bandwidth\ndemands, particularly in the context of distributed training. Specifically,\nMetronome employs a time-division multiplexing approach that leverages job\ntraffic characteristics to construct an elastic network resource allocation\nmodel, enabling efficient bandwidth sharing across multiple jobs. In addition,\nit incorporates a multi-objective optimization strategy, jointly considering\nlatency and job priorities to achieve globally optimal as well as dynamic\nresource allocation. Finally, Metronome adapts to the dynamic environment by\nmonitoring the cluster and performing reconfiguration operations. Extensive\nexperiments with 13 common machine learning models demonstrate that Metronome\ncan enhance cluster resource utilization while guaranteeing service\nperformance. Compared with the existing Kubernetes scheduling mechanisms across\nmultiple scenarios, Metronome reduces job completion time by up to 19.50% while\nimproving average bandwidth utilization by up to 23.20%.", "AI": {"tldr": "Metronome\u662f\u4e00\u4e2a\u9762\u5411\u4e91\u539f\u751f\u7f51\u7edc\u7684\u7f51\u7edc\u611f\u77e5\u548c\u4f18\u5148\u7ea7\u611f\u77e5\u8c03\u5ea6\u673a\u5236\uff0c\u901a\u8fc7\u65f6\u95f4\u5206\u590d\u7528\u548c\u591a\u76ee\u6807\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u8bad\u7ec3\u4f5c\u4e1a\u7684\u6027\u80fd\u548c\u96c6\u7fa4\u5e26\u5bbd\u5229\u7528\u7387\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u4e91\u539f\u751f\u7f51\u7edc\u9700\u8981\u89e3\u51b3\u9ad8\u6548\u8d44\u6e90\u534f\u8c03\u95ee\u9898\uff0c\u7279\u522b\u662f\u5e94\u5bf9\u96c6\u7fa4\u4e2d\u7f51\u7edc\u5e26\u5bbd\u52a8\u6001\u6ce2\u52a8\u7684\u6311\u6218\uff0c\u652f\u6301\u5177\u6709\u5468\u671f\u6027\u6d41\u91cf\u6a21\u5f0f\u548c\u52a8\u6001\u5e26\u5bbd\u9700\u6c42\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u4f5c\u4e1a\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u5206\u590d\u7528\u65b9\u6cd5\uff0c\u5229\u7528\u4f5c\u4e1a\u6d41\u91cf\u7279\u5f81\u6784\u5efa\u5f39\u6027\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u6a21\u578b\uff1b\u7ed3\u5408\u591a\u76ee\u6807\u4f18\u5316\u7b56\u7565\uff0c\u540c\u65f6\u8003\u8651\u5ef6\u8fdf\u548c\u4f5c\u4e1a\u4f18\u5148\u7ea7\uff1b\u901a\u8fc7\u76d1\u63a7\u96c6\u7fa4\u6267\u884c\u91cd\u914d\u7f6e\u64cd\u4f5c\u6765\u9002\u5e94\u52a8\u6001\u73af\u5883\u3002", "result": "\u572813\u4e2a\u5e38\u89c1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709Kubernetes\u8c03\u5ea6\u673a\u5236\uff0cMetronome\u53ef\u5c06\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u6700\u591a\u51cf\u5c1119.50%\uff0c\u5e73\u5747\u5e26\u5bbd\u5229\u7528\u7387\u6700\u591a\u63d0\u534723.20%\u3002", "conclusion": "Metronome\u80fd\u591f\u6709\u6548\u63d0\u5347\u96c6\u7fa4\u8d44\u6e90\u5229\u7528\u7387\u540c\u65f6\u4fdd\u8bc1\u670d\u52a1\u6027\u80fd\uff0c\u4e3a\u4e91\u539f\u751f\u7f51\u7edc\u4e2d\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u4f5c\u4e1a\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12354", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12354", "abs": "https://arxiv.org/abs/2510.12354", "authors": ["Sepideh Masoudi", "Mark Edward Michael Daly", "Jannis Kiesel", "Stefan Tai"], "title": "A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines", "comment": null, "summary": "As data mesh architectures gain traction in federated environments,\norganizations are increasingly building consumer-specific data-sharing\npipelines using modular, cloud-native transformation services. Prior work has\nshown that structuring these pipelines with reusable transformation stages\nenhances both scalability and energy efficiency. However, integrating\ntraditional cloud design patterns into such pipelines poses a challenge:\npredefining and embedding patterns can compromise modularity, reduce\nreusability, and conflict with the pipelines dynamic, consumer-driven nature.\nTo address this, we introduce a Kubernetes-based tool that enables the deferred\nand non-intrusive application of selected cloud design patterns without\nrequiring changes to service source code. The tool supports automated pattern\ninjection and collects energy consumption metrics, allowing developers to make\nenergy-aware decisions while preserving the flexible, composable structure of\nreusable data-sharing pipelines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKubernetes\u7684\u5de5\u5177\uff0c\u652f\u6301\u5728\u6570\u636e\u5171\u4eab\u7ba1\u9053\u4e2d\u5ef6\u8fdf\u3001\u975e\u4fb5\u5165\u5f0f\u5730\u5e94\u7528\u4e91\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u65e0\u9700\u4fee\u6539\u670d\u52a1\u6e90\u4ee3\u7801\uff0c\u540c\u65f6\u6536\u96c6\u80fd\u8017\u6307\u6807\u3002", "motivation": "\u5728\u8054\u90a6\u73af\u5883\u4e2d\u6784\u5efa\u6d88\u8d39\u8005\u7279\u5b9a\u6570\u636e\u5171\u4eab\u7ba1\u9053\u65f6\uff0c\u4f20\u7edf\u4e91\u8bbe\u8ba1\u6a21\u5f0f\u7684\u9884\u5b9a\u4e49\u548c\u5d4c\u5165\u4f1a\u635f\u5bb3\u6a21\u5757\u5316\u3001\u964d\u4f4e\u53ef\u91cd\u7528\u6027\uff0c\u4e0e\u7ba1\u9053\u52a8\u6001\u3001\u6d88\u8d39\u8005\u9a71\u52a8\u7684\u7279\u6027\u51b2\u7a81\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eKubernetes\u7684\u5de5\u5177\uff0c\u652f\u6301\u81ea\u52a8\u5316\u6a21\u5f0f\u6ce8\u5165\uff0c\u5141\u8bb8\u5ef6\u8fdf\u5e94\u7528\u9009\u5b9a\u7684\u4e91\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u65e0\u9700\u4fee\u6539\u670d\u52a1\u6e90\u4ee3\u7801\u3002", "result": "\u8be5\u5de5\u5177\u80fd\u591f\u975e\u4fb5\u5165\u5f0f\u5730\u5e94\u7528\u4e91\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u540c\u65f6\u6536\u96c6\u80fd\u8017\u6307\u6807\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u5728\u4fdd\u6301\u7ba1\u9053\u7075\u6d3b\u53ef\u7ec4\u5408\u7ed3\u6784\u7684\u540c\u65f6\u505a\u51fa\u80fd\u8017\u611f\u77e5\u51b3\u7b56\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u5728\u53ef\u91cd\u7528\u6570\u636e\u5171\u4eab\u7ba1\u9053\u4e2d\u96c6\u6210\u4e91\u8bbe\u8ba1\u6a21\u5f0f\u65f6\u7684\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\u6311\u6218\uff0c\u540c\u65f6\u652f\u6301\u80fd\u8017\u4f18\u5316\u3002"}}
{"id": "2510.12436", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.12436", "abs": "https://arxiv.org/abs/2510.12436", "authors": ["Valentin Seitz", "Jordy Trilaksono", "Marta Garcia-Gasulla"], "title": "TALP-Pages: An easy-to-integrate continuous performance monitoring framework", "comment": null, "summary": "Ensuring good performance is a key aspect in the development of codes that\ntarget HPC machines. As these codes are under active development, the necessity\nto detect performance degradation early in the development process becomes\napparent. In addition, having meaningful insight into application scaling\nbehavior tightly coupled to the development workflow is helpful. In this paper,\nwe introduce TALP-Pages, an easy-to-integrate framework that enables developers\nto get fast and in-repository feedback about their code performance using\nestablished fundamental performance and scaling factors. The framework relies\non TALP, which enables the on-the-fly collection of these metrics. Based on a\nfolder structure suited for CI which contains the files generated by TALP,\nTALP-Pages generates an HTML report with visualizations of the performance\nfactor regression as well as scaling-efficiency tables. We compare TALP-Pages\nto tracing-based tools in terms of overhead and post-processing requirements\nand find that TALP-Pages can produce the scaling-efficiency tables faster and\nunder tighter resource constraints. To showcase the ease of use and\neffectiveness of this approach, we extend the current CI setup of GENE-X with\nonly minimal changes required and showcase the ability to detect and explain a\nperformance improvement.", "AI": {"tldr": "TALP-Pages\u662f\u4e00\u4e2a\u6613\u4e8e\u96c6\u6210\u7684\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4ee3\u7801\u6027\u80fd\u7684\u5feb\u901f\u53cd\u9988\uff0c\u901a\u8fc7TALP\u5de5\u5177\u6536\u96c6\u6027\u80fd\u6307\u6807\u5e76\u751f\u6210HTML\u62a5\u544a\uff0c\u5e2e\u52a9\u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u65e9\u671f\u68c0\u6d4b\u6027\u80fd\u9000\u5316\u3002", "motivation": "HPC\u4ee3\u7801\u5f00\u53d1\u4e2d\u9700\u8981\u65e9\u671f\u68c0\u6d4b\u6027\u80fd\u9000\u5316\uff0c\u5e76\u6df1\u5165\u4e86\u89e3\u5e94\u7528\u6269\u5c55\u884c\u4e3a\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u5728\u5f00\u9500\u548c\u540e\u5904\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8eTALP\u5de5\u5177\u5b9e\u65f6\u6536\u96c6\u6027\u80fd\u6307\u6807\uff0c\u4f7f\u7528\u9002\u5408CI\u7684\u6587\u4ef6\u5939\u7ed3\u6784\u5b58\u50a8\u6570\u636e\uff0c\u751f\u6210\u5305\u542b\u6027\u80fd\u56e0\u5b50\u56de\u5f52\u53ef\u89c6\u5316\u548c\u6269\u5c55\u6548\u7387\u8868\u7684HTML\u62a5\u544a\u3002", "result": "\u4e0e\u57fa\u4e8e\u8ffd\u8e2a\u7684\u5de5\u5177\u76f8\u6bd4\uff0cTALP-Pages\u5728\u66f4\u4e25\u683c\u7684\u8d44\u6e90\u7ea6\u675f\u4e0b\u80fd\u66f4\u5feb\u751f\u6210\u6269\u5c55\u6548\u7387\u8868\uff0c\u5728GENE-X CI\u8bbe\u7f6e\u4e2d\u53ea\u9700\u6700\u5c0f\u6539\u52a8\u5373\u53ef\u96c6\u6210\u3002", "conclusion": "TALP-Pages\u63d0\u4f9b\u4e86\u4f4e\u5f00\u9500\u3001\u6613\u96c6\u6210\u7684\u6027\u80fd\u76d1\u63a7\u65b9\u6848\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u89e3\u91ca\u6027\u80fd\u53d8\u5316\uff0c\u9002\u5408\u96c6\u6210\u5230\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u3002"}}
{"id": "2510.12597", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12597", "abs": "https://arxiv.org/abs/2510.12597", "authors": ["Ilya Baldin", "Michael Goodrich", "Vardan Gyurjyan", "Graham Heyes", "Derek Howard", "Yatish Kumar", "David Lawrence", "Brad Sawatzky", "Stacey Sheldon", "Carl Timmer"], "title": "Low Latency, High Bandwidth Streaming of Experimental Data with EJFAT", "comment": null, "summary": "Thomas Jefferson National Accelerator Facility (JLab) has partnered with\nEnergy Sciences Network (ESnet) to define and implement an edge to compute\ncluster computational load balancing acceleration architecture. The ESnet-JLab\nFPGA Accelerated Transport (EJFAT) architecture focuses on FPGA acceleration to\naddress compression, fragmentation, UDP packet destination redirection (Network\nAddress Translation (NAT)) and decompression and reassembly.\n  EJFAT seamlessly integrates edge and cluster computing to support direct\nprocessing of streamed experimental data. This will directly benefit the JLab\nscience program as well as data centers of the future that require high\nthroughput and low latency for both time-critical data acquisition systems and\ndata center workflows.\n  The EJFAT project will be presented along with how it is synergistic with\nother DOE activities such as an Integrated Research Infrastructure (IRI), and\nrecent results using data sources at JLab, an EJFAT LB at ESnet, and\ncomputational cluster resources at Lawrence Berkeley National Laboratory\n(LBNL).", "AI": {"tldr": "EJFAT\u67b6\u6784\u901a\u8fc7FPGA\u52a0\u901f\u5b9e\u73b0\u8fb9\u7f18\u5230\u8ba1\u7b97\u96c6\u7fa4\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u652f\u6301\u5b9e\u9a8c\u6570\u636e\u6d41\u7684\u76f4\u63a5\u5904\u7406\uff0c\u4e3aJLab\u79d1\u5b66\u9879\u76ee\u548c\u672a\u6765\u6570\u636e\u4e2d\u5fc3\u63d0\u4f9b\u9ad8\u541e\u5410\u4f4e\u5ef6\u8fdf\u89e3\u51b3\u65b9\u6848", "motivation": "\u89e3\u51b3\u5b9e\u9a8c\u6570\u636e\u6d41\u5904\u7406\u4e2d\u7684\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\uff0c\u652f\u6301JLab\u79d1\u5b66\u9879\u76ee\u53ca\u672a\u6765\u6570\u636e\u4e2d\u5fc3\u7684\u5b9e\u65f6\u6570\u636e\u91c7\u96c6\u548c\u5904\u7406\u5de5\u4f5c\u6d41", "method": "\u91c7\u7528FPGA\u52a0\u901f\u6280\u672f\uff0c\u5b9e\u73b0\u538b\u7f29\u3001\u5206\u7247\u3001UDP\u5305\u76ee\u6807\u91cd\u5b9a\u5411(NAT)\u3001\u89e3\u538b\u7f29\u548c\u91cd\u7ec4\u7b49\u529f\u80fd\uff0c\u65e0\u7f1d\u96c6\u6210\u8fb9\u7f18\u548c\u96c6\u7fa4\u8ba1\u7b97", "result": "\u6210\u529f\u6784\u5efaEJFAT\u8d1f\u8f7d\u5747\u8861\u67b6\u6784\uff0c\u4e0eESnet\u3001LBNL\u7b49DOE\u8bbe\u65bd\u534f\u540c\u5de5\u4f5c\uff0c\u5728\u5b9e\u9645\u6570\u636e\u6e90\u4e0a\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd", "conclusion": "EJFAT\u67b6\u6784\u4e3a\u65f6\u95f4\u5173\u952e\u578b\u6570\u636e\u91c7\u96c6\u7cfb\u7edf\u548c\u6570\u636e\u4e2d\u5fc3\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u63a8\u5e7f\u5e94\u7528\u4ef7\u503c"}}
{"id": "2510.12705", "categories": ["cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2510.12705", "abs": "https://arxiv.org/abs/2510.12705", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Alan Edelman"], "title": "A GPU-resident Memory-Aware Algorithm for Accelerating Bidiagonalization of Banded Matrices", "comment": "13 pages, 7 figures, 3 tables", "summary": "The reduction of a banded matrix to a bidiagonal form is a crucial step in\nthe Singular Value Decomposition (SVD), a cornerstone of scientific computing\nand AI. Despite being a highly parallel algorithm, it was previously believed\nto be unsuitable for GPU computation because it is memory bandwidth-bound.\nRecent developments in GPU hardware, including larger L1 memory per Streaming\nMultiprocessor/Compute Unit, have changed that. We present the first GPU\nalgorithm for reducing a banded matrix to bidiagonal form as part of the\nNextLA.jl open-source software package. Our algorithm is based on previous\nCPU-based multicore parallel cache-efficient bulge chasing algorithms and\nadapted to optimize for GPU throughput. We leverage Julia Language's Array\nabstractions and KernelAbstractions to implement a single hardware- and data\nprecision-agnostic function on NVIDIA, AMD, Intel, and Apple Metal GPUs for\nhalf, single, and double precision, and examine performance optimization across\nhardware architectures and data precision. We also develop a hardware-aware\nperformance model and identify key hyperparameters, such as inner tilewidth and\nblock concurrency, that govern optimal GPU execution for bandwidth-bound\nworkloads. We demonstrate highly parallel bandwidth-bound algorithm on the GPU\ncan outperform CPU-based implementations: the GPU algorithm outperforms\nmultithreaded CPU High-Performance libraries PLASMA and SLATE as of matrix size\n1024 x 1024 and by a factor over 100 for matrices of 32k x 32k. In addition,\nthe performance of the algorithm increases linearly with matrix bandwidth size,\nmaking faster reduction of larger matrix bandwidths now also possible. With\nthis work, we break memory bandwidth barriers, as well as matrix bandwidth\nbarriers, resulting in orders-of-magnitude faster algorithms for the reduction\nof banded matrices to bidiagonal form on the GPU.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2aGPU\u7b97\u6cd5\uff0c\u7528\u4e8e\u5c06\u5e26\u72b6\u77e9\u9635\u7b80\u5316\u4e3a\u53cc\u5bf9\u89d2\u5f62\u5f0f\uff0c\u4f5c\u4e3aSVD\u8ba1\u7b97\u7684\u5173\u952e\u6b65\u9aa4\u3002\u8be5\u7b97\u6cd5\u514b\u670d\u4e86\u5185\u5b58\u5e26\u5bbd\u9650\u5236\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u4e86\u6bd4CPU\u5b9e\u73b0\u5feb100\u500d\u4ee5\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5e26\u72b6\u77e9\u9635\u5230\u53cc\u5bf9\u89d2\u5f62\u5f0f\u7684\u7ea6\u7b80\u662fSVD\u8ba1\u7b97\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f20\u7edf\u4e0a\u88ab\u8ba4\u4e3a\u4e0d\u9002\u5408GPU\u8ba1\u7b97\uff0c\u56e0\u4e3a\u5b83\u662f\u5185\u5b58\u5e26\u5bbd\u53d7\u9650\u7684\u3002\u4f46\u968f\u7740GPU\u786c\u4ef6\u53d1\u5c55\uff0c\u7279\u522b\u662fL1\u5185\u5b58\u7684\u589e\u52a0\uff0c\u4f7f\u5f97GPU\u5b9e\u73b0\u6210\u4e3a\u53ef\u80fd\u3002", "method": "\u57fa\u4e8eCPU\u591a\u6838\u5e76\u884c\u7f13\u5b58\u9ad8\u6548\u51f8\u8d77\u8ffd\u9010\u7b97\u6cd5\uff0c\u9002\u914d\u4f18\u5316GPU\u541e\u5410\u91cf\u3002\u4f7f\u7528Julia\u8bed\u8a00\u7684\u6570\u7ec4\u62bd\u8c61\u548cKernelAbstractions\uff0c\u5b9e\u73b0\u8de8NVIDIA\u3001AMD\u3001Intel\u548cApple Metal GPU\u7684\u786c\u4ef6\u548c\u6570\u636e\u7cbe\u5ea6\u65e0\u5173\u51fd\u6570\u3002", "result": "GPU\u7b97\u6cd5\u57281024x1024\u77e9\u9635\u5c3a\u5bf8\u4e0a\u8d85\u8d8a\u591a\u7ebf\u7a0bCPU\u9ad8\u6027\u80fd\u5e93PLASMA\u548cSLATE\uff0c\u572832k x 32k\u77e9\u9635\u4e0a\u6027\u80fd\u63d0\u5347\u8d85\u8fc7100\u500d\u3002\u7b97\u6cd5\u6027\u80fd\u968f\u77e9\u9635\u5e26\u5bbd\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7a81\u7834\u4e86\u5185\u5b58\u5e26\u5bbd\u548c\u77e9\u9635\u5e26\u5bbd\u7684\u9650\u5236\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u66f4\u5feb\u7684\u5e26\u72b6\u77e9\u9635\u5230\u53cc\u5bf9\u89d2\u5f62\u5f0f\u7684\u7ea6\u7b80\u7b97\u6cd5\u3002"}}
