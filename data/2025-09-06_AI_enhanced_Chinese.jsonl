{"id": "2509.03846", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03846", "abs": "https://arxiv.org/abs/2509.03846", "authors": ["Md Rownak Hossain Chowdhury", "Mostafizur Rahman"], "title": "Hardware-Aware Data and Instruction Mapping for AI Tasks: Balancing Parallelism, I/O and Memory Tradeoffs", "comment": null, "summary": "We introduce a mapping framework for deep learning inference that takes\nadvantage of predictable neural network behavior to plan both computation and\ncommunication ahead of time. The framework generates a unified stream of\ninstructions and data, enabling the hardware to execute operations and route\ninformation on its own, without frequent involvement from the host and with\nminimal off-chip memory use. This naturally reduces reliance on I/O, off-chip\nmemory, and host control. By leveraging fine-grained message passing on a\nprogrammable, message-based compute architecture, the framework keeps data\nmovement local and coordinates computation across the array using techniques\nsuch as stationary-weight reuse, in-array multicasting, and staged reductions.\nApplied to VGG-19, the framework sustains high utilization (88 to 92 percent),\nwith over 97 percent of messages generated internally and nearly 89 percent of\ntime consumed on-chip transfers. Computation throughput scales beyond 1 TFLOP/s\non larger arrays, while traffic reductions from reuse and local aggregation\nreach up to 100 MB per layer. Overall, the results highlight the effectiveness\nof streaming-based computation and show how our mapper enables this execution\nstyle by tightly coordinating data and instruction flow across the hardware.", "AI": {"tldr": "\u901a\u8fc7\u9884\u5148\u89c4\u5212\u8ba1\u7b97\u548c\u901a\u4fe1\u7684\u6d41\u5f0f\u6267\u884c\u6846\u67b6\uff0c\u5229\u7528\u6d88\u606f\u4f20\u9012\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\uff0c\u51cf\u5c11I/O\u548c\u4e3b\u673a\u5e72\u9884\uff0c\u8fbe\u5230\u9ad8\u5229\u7528\u7387\u548c\u4f4e\u5185\u5b58\u6d88\u8017", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u4e2d\u5e38\u89c1\u7684I/O\u74f6\u9888\u3001\u5185\u5b58\u5e0c\u7f3a\u548c\u4e3b\u673a\u5e72\u9884\u95ee\u9898\uff0c\u901a\u8fc7\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u884c\u4e3a\u6765\u4f18\u5316\u8ba1\u7b97\u548c\u901a\u4fe1", "method": "\u6784\u5efa\u7edf\u4e00\u7684\u6307\u4ee4\u548c\u6570\u636e\u6d41\uff0c\u91c7\u7528\u7a0b\u5e8f\u5316\u6d88\u606f\u57fa\u7840\u8ba1\u7b97\u67b6\u6784\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u6d88\u606f\u4f20\u9012\uff0c\u8fd0\u7528\u9759\u6001\u91cd\u7528\u3001\u6570\u7ec4\u5185\u591a\u64ad\u548c\u5206\u6bb5\u7ea6\u7b80\u7b49\u6280\u672f", "result": "\u5728VGG-19\u4e0a\u5b9e\u73b092%\u5229\u7528\u7387\uff0c97%\u6d88\u606f\u5185\u90e8\u751f\u6210\uff0c89%\u65f6\u95f4\u7528\u4e8e\u82af\u7247\u5185\u4f20\u8f93\uff0c\u8ba1\u7b97\u541e\u5410\u91cf\u8d851 TFLOP/s\uff0c\u91cd\u7528\u548c\u5c40\u90e8\u805a\u5408\u51cf\u5c11100MB/\u5c42", "conclusion": "\u6d41\u5f0f\u8ba1\u7b97\u65b9\u5f0f\u9ad8\u6548\u53ef\u884c\uff0c\u901a\u8fc7\u7d27\u5bc6\u534f\u8c03\u6570\u636e\u548c\u6307\u4ee4\u6d41\u53ef\u4ee5\u5b9e\u73b0\u81ea\u4e3b\u6267\u884c\uff0c\u663e\u8457\u51cf\u5c11\u5916\u90e8\u4f9d\u8d56"}}
{"id": "2509.04153", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04153", "abs": "https://arxiv.org/abs/2509.04153", "authors": ["Safa Mohammed Sali", "Mahmoud Meribout", "Ashiyana Abdul Majeed"], "title": "Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations", "comment": null, "summary": "This paper presents a comprehensive review of recent advances in deploying\nconvolutional neural networks (CNNs) for object detection, classification, and\ntracking on Field Programmable Gate Arrays (FPGAs). With the increasing demand\nfor real-time computer vision applications in domains such as autonomous\nvehicles, robotics, and surveillance, FPGAs have emerged as a powerful\nalternative to GPUs and ASICs due to their reconfigurability, low power\nconsumption, and deterministic latency. We critically examine state-of-the-art\nFPGA implementations of CNN-based vision tasks, covering algorithmic\ninnovations, hardware acceleration techniques, and the integration of\noptimization strategies like pruning, quantization, and sparsity-aware methods\nto maximize performance within hardware constraints. This survey also explores\nthe landscape of modern FPGA platforms, including classical LUT-DSP based\narchitectures, System-on-Chip (SoC) FPGAs, and Adaptive Compute Acceleration\nPlatforms (ACAPs), comparing their capabilities in handling deep learning\nworkloads. Furthermore, we review available software development tools such as\nVitis AI, FINN, and Intel FPGA AI Suite, which significantly streamline the\ndesign and deployment of AI models on FPGAs. The paper uniquely discusses\nhybrid architecture that combine GPUs and FPGAs for collaborative acceleration\nof AI inference, addressing challenges related to energy efficiency and\nthroughput. Additionally, we highlight hardware-software co-design practices,\ndataflow optimizations, and pipelined processing techniques essential for\nreal-time inference on resource-constrained devices. Through this survey,\nresearchers and engineers are equipped with insights to develop\nnext-generation, power-efficient, and high-performance vision systems optimized\nfor FPGA deployment in edge and embedded applications.", "AI": {"tldr": "\u7efc\u8ff0\u8bba\u6587\uff0c\u7cfb\u7edf\u56de\u987e\u4e86FPGA\u4e0aCNN\u76ee\u6807\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u8ddf\u8e2a\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u786c\u4ef6\u52a0\u901f\u6280\u672f\u3001\u4f18\u5316\u7b56\u7565\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u548c\u76d1\u63a7\u7b49\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u9700\u6c42\u7684\u589e\u957f\uff0cFPGA\u56e0\u5176\u53ef\u91cd\u6784\u6027\u3001\u4f4e\u529f\u8017\u548c\u786e\u5b9a\u6027\u5ef6\u8fdf\u7b49\u4f18\u52bf\uff0c\u6210\u4e3aGPU\u548cASIC\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5ba1\u67e5\u6700\u5148\u8fdb\u7684FPGA\u5b9e\u73b0\uff0c\u6db5\u76d6\u7b97\u6cd5\u521b\u65b0\u3001\u786c\u4ef6\u52a0\u901f\u6280\u672f\u3001\u526a\u679d\u3001\u91cf\u5316\u548c\u7a00\u758f\u611f\u77e5\u7b49\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u53ca\u73b0\u4ee3FPGA\u5e73\u53f0\u548c\u5f00\u53d1\u5de5\u5177\u7684\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u5168\u9762\u68b3\u7406\u4e86FPGA\u90e8\u7f72CNN\u7684\u6280\u672f\u73b0\u72b6\uff0c\u5305\u62ec\u6df7\u5408\u67b6\u6784\u3001\u6570\u636e\u6d41\u4f18\u5316\u548c\u6d41\u6c34\u7ebf\u5904\u7406\u7b49\u5173\u952e\u6280\u672f\uff0c\u4e3a\u5b9e\u65f6\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u5f00\u53d1\u4e0b\u4e00\u4ee3\u9ad8\u6548\u80fd\u3001\u4f4e\u529f\u8017\u89c6\u89c9\u7cfb\u7edf\u7684\u5173\u952e\u89c1\u89e3\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fb9\u7f18\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u7684FPGA\u90e8\u7f72\u3002"}}
{"id": "2509.04162", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04162", "abs": "https://arxiv.org/abs/2509.04162", "authors": ["Safa Mohammed Sali", "Mahmoud Meribout", "Ashiyana Abdul Majeed"], "title": "Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations", "comment": null, "summary": "Transformers and vision-language models (VLMs) have emerged as dominant\narchitectures in computer vision and multimodal AI, offering state-of-the-art\nperformance in tasks such as image classification, object detection, visual\nquestion answering, and caption generation. However, their high computational\ncomplexity, large memory footprints, and irregular data access patterns present\nsignificant challenges for deployment in latency- and power-constrained\nenvironments. Field-programmable gate arrays (FPGAs) provide an attractive\nhardware platform for such workloads due to their reconfigurability,\nfine-grained parallelism, and potential for energy-efficient acceleration. This\npaper presents a comprehensive review of design trade-offs, optimization\nstrategies, and implementation challenges for FPGA-based inference of\ntransformers and VLMs. We examine critical factors such as device-class\nselection, memory subsystem constraints, dataflow orchestration, quantization\nstrategies, sparsity exploitation, and toolchain choices, alongside\nmodality-specific issues unique to VLMs, including heterogeneous compute\nbalancing and cross-attention memory management. Additionally, we discuss\nemerging trends in hardware-algorithm co-design, highlighting innovations in\nattention mechanisms, compression, and modular overlays to improve efficiency\nand adaptability. Practical issues such as runtime flexibility, verification\noverhead, and the absence of standardized FPGA multimodal benchmarks are also\nconsidered. Finally, we outline future directions toward scalable, portable,\nand reconfigurable FPGA solutions that adapt to evolving model architectures\nwhile sustaining high utilization and predictable performance. This synthesis\noffers both a technical foundation and a forward-looking perspective to help\nbridge the gap between advanced multimodal AI models and efficient FPGA\ndeployment.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u57fa\u4e8eFPGA\u7684Transformer\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u8bbe\u8ba1\u6743\u8861\u3001\u4f18\u5316\u7b56\u7565\u548c\u5b9e\u73b0\u6311\u6218\uff0c\u5305\u62ec\u8bbe\u5907\u9009\u62e9\u3001\u5185\u5b58\u7ea6\u675f\u3001\u6570\u636e\u6d41\u7f16\u6392\u3001\u91cf\u5316\u7b56\u7565\u7b49\u5173\u952e\u6280\u672f\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u7684\u65b0\u8d8b\u52bf\u3002", "motivation": "Transformer\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u591a\u6a21\u6001AI\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u5927\u5185\u5b58\u5360\u7528\u548c\u4e0d\u89c4\u5219\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\u5728\u5ef6\u8fdf\u548c\u529f\u8017\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002FPGA\u56e0\u5176\u53ef\u91cd\u6784\u6027\u3001\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\u548c\u80fd\u6548\u4f18\u52bf\u6210\u4e3a\u7406\u60f3\u7684\u786c\u4ef6\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u7efc\u5408\u5206\u6790\u8bbe\u8ba1\u6743\u8861\u3001\u4f18\u5316\u7b56\u7565\u548c\u5b9e\u73b0\u6311\u6218\uff0c\u7814\u7a76\u8bbe\u5907\u7c7b\u522b\u9009\u62e9\u3001\u5185\u5b58\u5b50\u7cfb\u7edf\u7ea6\u675f\u3001\u6570\u636e\u6d41\u7f16\u6392\u3001\u91cf\u5316\u7b56\u7565\u3001\u7a00\u758f\u6027\u5229\u7528\u3001\u5de5\u5177\u94fe\u9009\u62e9\u7b49\u5173\u952e\u6280\u672f\uff0c\u4ee5\u53caVLMs\u7279\u6709\u7684\u6a21\u6001\u7279\u5b9a\u95ee\u9898\u5982\u5f02\u6784\u8ba1\u7b97\u5e73\u8861\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5185\u5b58\u7ba1\u7406\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9FPGA\u90e8\u7f72\u7684\u5168\u9762\u6280\u672f\u6846\u67b6\uff0c\u6db5\u76d6\u4e86\u4ece\u786c\u4ef6\u9009\u62e9\u5230\u7b97\u6cd5\u4f18\u5316\u7684\u5404\u4e2a\u5c42\u9762\uff0c\u4e3a\u9ad8\u6548\u90e8\u7f72\u591a\u6a21\u6001AI\u6a21\u578b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "FPGA\u4e3aTransformer\u548cVLMs\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u90e8\u7f72\u5e73\u53f0\uff0c\u901a\u8fc7\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u3001\u521b\u65b0\u6ce8\u610f\u529b\u673a\u5236\u3001\u538b\u7f29\u6280\u672f\u548c\u6a21\u5757\u5316\u8986\u76d6\u5c42\u7b49\u65b0\u5174\u8d8b\u52bf\uff0c\u672a\u6765\u5c06\u671d\u7740\u53ef\u6269\u5c55\u3001\u53ef\u79fb\u690d\u548c\u53ef\u91cd\u6784\u7684\u89e3\u51b3\u65b9\u6848\u53d1\u5c55\uff0c\u4ee5\u9002\u914d\u4e0d\u65ad\u6f14\u8fdb\u7684\u6a21\u578b\u67b6\u6784\u5e76\u4fdd\u6301\u9ad8\u5229\u7528\u7387\u548c\u53ef\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2509.04253", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.04253", "abs": "https://arxiv.org/abs/2509.04253", "authors": ["Siyuan He", "Songlin Jia", "Yuyan Bao", "Tiark Rompf"], "title": "When Lifetimes Liberate: A Type System for Arenas with Higher-Order Reachability Tracking", "comment": null, "summary": "Static resource management in higher-order functional languages remains\nelusive due to tensions between control, expressiveness, and flexibility.\nRegion-based systems [Grossman et al. 2002; Tofte et al. 2001] offer control\nover lifetimes and expressive in-region sharing, but restrict resources to\nlexical scopes. Rust, an instance of ownership types [Clarke et al. 2013],\noffers non-lexical lifetimes and robust safety guarantees, yet its global\ninvariants make common sharing patterns hard to express. Reachability types\n[Wei et al. 2024] enable reasoning about sharing and separation, but lack\npractical tools for controlling resource lifetimes.\n  In this work, we try to unify their strengths. Our solution enables grouping\nresources as arenas for arbitrary sharing and static guarantees of lexically\nscoped lifetimes. Crucially, arenas and lexical lifetimes are not the only\nchoice: users may also manage resources individually, with non-lexical\nlifetimes. Regardless of mode, resources share the same type, preserving the\nhigher-order parametric nature of the language.\n  Obtaining static safety guarantee in a higher-order language with flexible\nsharing is nontrivial. To this end, we propose two new extensions atop\nreachability types [Wei et al. 2024]. First, A<: features a novel\ntwo-dimensional store model to enable coarse-grained reachability tracking for\narbitrarily shared resources within arenas. Building on this, {A}<: establishes\nlexical lifetime control with static guarantees. As the first reachability\nformalism presented for lifetime control, {A}<: avoids the complication of\nflow-sensitive reasoning and retains expressive power and simplicity. Both\ncalculi are formalized and proven type safe in Rocq.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u533a\u57df\u7cfb\u7edf\u3001\u6240\u6709\u6743\u7c7b\u578b\u548c\u53ef\u8fbe\u6027\u7c7b\u578b\u7684\u4f18\u70b9\uff0c\u652f\u6301\u4efb\u610f\u5171\u4eab\u548c\u9759\u6001\u751f\u547d\u5468\u671f\u4fdd\u8bc1", "motivation": "\u89e3\u51b3\u9ad8\u9636\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\u9759\u6001\u8d44\u6e90\u7ba1\u7406\u7684\u6311\u6218\uff0c\u7edf\u4e00\u533a\u57df\u7cfb\u7edf\u7684\u8bcd\u6cd5\u751f\u547d\u5468\u671f\u63a7\u5236\u548c\u8868\u8fbe\u529b\uff0cRust\u7684\u975e\u8bcd\u6cd5\u751f\u547d\u5468\u671f\u548c\u5b89\u5168\u4fdd\u8bc1\uff0c\u4ee5\u53ca\u53ef\u8fbe\u6027\u7c7b\u578b\u7684\u5171\u4eab\u63a8\u7406\u80fd\u529b", "method": "\u5728\u53ef\u8fbe\u6027\u7c7b\u578b\u57fa\u7840\u4e0a\u63d0\u51fa\u4e24\u4e2a\u65b0\u6269\u5c55\uff1aA<:\u91c7\u7528\u65b0\u9898\u4e24\u7ef4\u5b58\u50a8\u6a21\u578b\u652f\u6301\u533a\u57df\u5185\u8d44\u6e90\u7684\u7c97\u7c92\u5ea6\u53ef\u8fbe\u6027\u8ddf\u8e2a\uff1b{A}<:\u5b9e\u73b0\u8bcd\u6cd5\u751f\u547d\u5468\u671f\u63a7\u5236\u548c\u9759\u6001\u4fdd\u8bc1", "result": "\u5efa\u7acb\u4e86\u7b2c\u4e00\u4e2a\u652f\u6301\u751f\u547d\u5468\u671f\u63a7\u5236\u7684\u53ef\u8fbe\u6027\u5f62\u5f0f\u7cfb\u7edf\uff0c\u907f\u514d\u4e86\u6d41\u6548\u5e94\u6027\u63a8\u7406\u7684\u590d\u6742\u6027\uff0c\u4fdd\u6301\u4e86\u8868\u8fbe\u529b\u548c\u7b80\u6d01\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u7ed3\u5408\u4e86\u4e0d\u540c\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u4e3a\u9ad8\u9636\u51fd\u6570\u5f0f\u8bed\u8a00\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u5b89\u5168\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6848"}}
{"id": "2509.04173", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04173", "abs": "https://arxiv.org/abs/2509.04173", "authors": ["Safa Sali", "Anis Meribout", "Ashiyana Majeed", "Mahmoud Meribout", "Juan Pablo", "Varun Tiwari", "Asma Baobaid"], "title": "Real-time Object Detection and Associated Hardware Accelerators Targeting Autonomous Vehicles: A Review", "comment": null, "summary": "The efficiency of object detectors depends on factors like detection\naccuracy, processing time, and computational resources. Processing time is\ncrucial for real-time applications, particularly for autonomous vehicles (AVs),\nwhere instantaneous responses are vital for safety. This review paper provides\na concise yet comprehensive survey of real-time object detection (OD)\nalgorithms for autonomous cars delving into their hardware accelerators (HAs).\nNon-neural network-based algorithms, which use statistical image processing,\nhave been entirely substituted by AI algorithms, such as different models of\nconvolutional neural networks (CNNs). Their intrinsically parallel features led\nthem to be deployable into edge-based HAs of various types, where GPUs and, to\na lesser extent, ASIC (application-specific integrated circuit) remain the most\nwidely used. Throughputs of hundreds of frames/s (fps) could be reached;\nhowever, handling object detection for all the cameras available in a typical\nAV requires further hardware and algorithmic improvements. The intensive\ncompetition between AV providers has limited the disclosure of algorithms,\nfirmware, and even hardware platform details. This remains a hurdle for\nresearchers, as commercial systems provide valuable insights while academics\nundergo lengthy training and testing on restricted datasets and road scenarios.\nConsequently, many AV research papers may not be reflected in end products,\nbeing developed under limited conditions. This paper surveys state-of-the-art\nOD algorithms and aims to bridge the gap with technologies in commercial AVs.\nTo our knowledge, this aspect has not been addressed in earlier surveys. Hence,\nthe paper serves as a tangible reference for researchers designing future\ngenerations of vehicles, expected to be fully autonomous for comfort and\nsafety.", "AI": {"tldr": "\u8fd9\u7bc7\u8bc4\u8bba\u6027\u8bba\u6587\u7cfb\u7edf\u8c03\u7814\u4e86\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u53ca\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u65e8\u5728\u627e\u5230\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u5904\u7406\u901f\u5ea6\u548c\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u7684\u5e73\u8861\u70b9\uff0c\u5e76\u7a81\u51fa\u4e86\u5546\u4e1a\u7cfb\u7edf\u4e0e\u5b66\u672f\u7814\u7a76\u4e4b\u95f4\u7684\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u5bf9\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u6709\u6781\u9ad8\u8981\u6c42\uff0c\u9700\u8981\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u5904\u7406\u901f\u5ea6\u548c\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002\u76ee\u524d\u5546\u4e1a\u7cfb\u7edf\u4e0e\u5b66\u672f\u7814\u7a76\u5b58\u5728\u660e\u663e\u4e0d\u5bf9\u79f0\u4fe1\u606f\uff0c\u5f88\u591a\u7814\u7a76\u6210\u679c\u65e0\u6cd5\u53cd\u6620\u5230\u5b9e\u9645\u4ea7\u54c1\u4e2d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u8c03\u7814\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff08\u4ee5CNN\u4e3a\u4e3b\uff09\u53ca\u786c\u4ef6\u52a0\u901f\u5668\uff08\u4e3b\u8981\u4e3aGPU\u548cASIC\uff09\uff0c\u5206\u6790\u5176\u5e76\u884c\u7279\u6027\u3001\u90e8\u7f72\u80fd\u529b\u548c\u5904\u7406\u901f\u5ea6\u3002", "result": "\u73b0\u6709\u7b97\u6cd5\u5728\u786c\u4ef6\u52a0\u901f\u5668\u4e0a\u53ef\u8fbe\u5230\u6bcf\u79d2\u767e\u5f20\u5e27\u7684\u5904\u7406\u901f\u5ea6\uff0c\u4f46\u5bf9\u4e8e\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u591a\u6444\u50cf\u5934\u7684\u5168\u9762\u68c0\u6d4b\u9700\u6c42\uff0c\u4ecd\u9700\u66f4\u591a\u786c\u4ef6\u548c\u7b97\u6cd5\u4f18\u5316\u3002\u7814\u7a76\u53d1\u73b0\u5546\u4e1a\u7cfb\u7edf\u4e0e\u5b66\u672f\u7814\u7a76\u5b58\u5728\u660e\u663e\u9694\u95f4\u3002", "conclusion": "\u8fd9\u7bc7\u8bc4\u8bba\u586b\u8865\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5546\u4e1a\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u6280\u672f\u4e4b\u95f4\u7684\u77e5\u8bc6\u5dee\u8ddd\uff0c\u4e3a\u672a\u6765\u5168\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u53c2\u8003\u3002\u8be5\u8bba\u6587\u662f\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5c06\u5546\u4e1a\u5e94\u7528\u60c5\u51b5\u7eb3\u5165\u5230\u5b66\u672f\u8bc4\u8bba\u4e2d\u3002"}}
{"id": "2509.03653", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.03653", "abs": "https://arxiv.org/abs/2509.03653", "authors": ["Siddharth Samsi", "Dan Campbell", "Emanuel Scoullos", "Oded Green"], "title": "Combining Performance and Productivity: Accelerating the Network Sensing Graph Challenge with GPUs and Commodity Data Science Software", "comment": null, "summary": "The HPEC Graph Challenge is a collection of benchmarks representing complex\nworkloads that test the hardware and software components of HPC systems, which\ntraditional benchmarks, such as LINPACK, do not. The first benchmark, Subgraph\nIsomorphism, focused on several compute-bound and memory-bound kernels. The\nmost recent of the challenges, the Anonymized Network Sensing Graph Challenge,\nrepresents a shift in direction, as it represents a longer end-to-end workload\nthat requires many more software components, including, but not limited to,\ndata I/O, data structures for representing graph data, and a wide range of\nfunctions for data preparation and network analysis. A notable feature of this\nnew graph challenge is the use of GraphBLAS to represent the computational\naspects of the problem statement. In this paper, we show an alternative\ninterpretation of the GraphBLAS formulations using the language of data\nscience. With this formulation, we show that the new graph challenge can be\nimplemented using off-the-shelf ETL tools available in open-source, enterprise\nsoftware such as NVIDIA's RAPIDS ecosystem. Using off-the-shelf software,\nRAPIDS cuDF and cupy, we enable significant software acceleration without\nrequiring any specific HPC code and show speedups, over the same code running\nwith Pandas on the CPU, of 147x-509x on an NVIDIA A100 GPU, 243x-1269X for an\nNVIDIA H100 GPU, and 332X-2185X for an NVIDIA H200 GPU.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u79d1\u5b66\u8bed\u8a00\u7684GraphBLAS\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7NVIDIA RAPIDS\u751f\u6001\u7cfb\u7edf\u7684\u5f00\u6e90\u5546\u4e1a\u8f6f\u4ef6\u5b9e\u73b0\u4e86HPEC\u56fe\u8c1c\u9898\uff0c\u5728GPU\u4e0a\u83b7\u5f97\u4e86147-2185\u500d\u7684\u6027\u80fd\u52a0\u901f\u3002", "motivation": "\u4f20\u7edfHPC\u6d4b\u8bd5\u5982LINPACK\u65e0\u6cd5\u6d4b\u8bd5\u590d\u6742\u5de5\u4f5c\u8d1f\u8377\uff0cHPEC\u56fe\u8c1c\u9898\u9700\u8981\u66f4\u591a\u8f6f\u4ef6\u7ec4\u4ef6\u548c\u6574\u4f53\u5de5\u4f5c\u6d41\u7a0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6570\u636e\u79d1\u5b66\u8bed\u8a00\u91cd\u65b0\u89e3\u91caGraphBLAS\u5f62\u5f0f\uff0c\u901a\u8fc7NVIDIA RAPIDS\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5f00\u6e90\u5546\u4e1a\u8f6f\u4ef6\uff08RAPIDS cuDF\u548ccupy\uff09\u5b9e\u73b0\u56fe\u8c1c\u9898\uff0c\u65e0\u9700\u4e13\u95e8\u7684HPC\u4ee3\u7801\u3002", "result": "\u5728NVIDIA GPU\u4e0a\u83b7\u5f97\u663e\u8457\u6027\u80fd\u52a0\u901f\uff1aA100 GPU 147-509\u500d\uff0cH100 GPU 243-1269\u500d\uff0cH200 GPU 332-2185\u500d\uff0c\u76f8\u6bd4CPU\u4e0a\u7684Pandas\u5b9e\u73b0\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u79d1\u5b66\u8bed\u8a00\u548c\u5f00\u6e90\u5546\u4e1a\u8f6f\u4ef6\u53ef\u4ee5\u9ad8\u6548\u5b9e\u73b0\u590d\u6742\u7684HPC\u56fe\u8c1c\u9898\uff0c\u63d0\u4f9b\u4e86\u4e0d\u9700\u4e13\u95e8HPC\u4ee3\u7801\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.03755", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.03755", "abs": "https://arxiv.org/abs/2509.03755", "authors": ["John Augustine", "Soumyottam Chatterjee", "Valerie King", "Manish Kumar", "Shachar Meir", "David Peleg"], "title": "Distributed Download from an External Data Source in Asynchronous Faulty Settings", "comment": null, "summary": "The distributedData Retrieval (DR) model consists of $k$ peers connected by a\ncomplete peer-to-peer communication network, and a trusted external data source\nthat stores an array $\\textbf{X}$ of $n$ bits ($n \\gg k$). Up to $\\beta k$ of\nthe peers might fail in any execution (for $\\beta \\in [0, 1)$). Peers can\nobtain the information either by inexpensive messages passed among themselves\nor through expensive queries to the source array $\\textbf{X}$. In the DR model,\nwe focus on designing protocols that minimize the number of queries performed\nby any nonfaulty peer (a measure referred to as query complexity) while\nmaximizing the resilience parameter $\\beta$.\n  The Download problem requires each nonfaulty peer to correctly learn the\nentire array $\\textbf{X}$. Earlier work on this problem focused on synchronous\ncommunication networks and established several deterministic and randomized\nupper and lower bounds. Our work is the first to extend the study of\ndistributed data retrieval to asynchronous communication networks. We address\nthe Download problem under both the Byzantine and crash failure models. We\npresent query-optimal deterministic solutions in an asynchronous model that can\ntolerate any fixed fraction $\\beta<1$ of crash faults. In the Byzantine failure\nmodel, it is known that deterministic protocols incur a query complexity of\n$\\Omega(n)$ per peer, even under synchrony. We extend this lower bound to\nrandomized protocols in the asynchronous model for $\\beta \\geq 1/2$, and\nfurther show that for $\\beta < 1/2$, a randomized protocol exists with\nnear-optimal query complexity. To the best of our knowledge, this is the first\nwork to address the Download problem in asynchronous communication networks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76\u5f02\u6b65\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u5206\u5e03\u5f0f\u6570\u636e\u68c0\u7d22\u95ee\u9898\uff0c\u9488\u5bf9\u4e0b\u8f7d\u95ee\u9898\u5728\u62dc\u5360\u5ead\u548c\u5d29\u6e83\u6545\u969c\u6a21\u578b\u4e0b\u63d0\u51fa\u67e5\u8be2\u6700\u4f18\u7684\u786e\u5b9a\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5efa\u7acb\u4e86\u968f\u673a\u534f\u8bae\u7684\u4e0b\u754c\u548c\u4e0a\u754c\u3002", "motivation": "\u6269\u5c55\u5206\u5e03\u5f0f\u6570\u636e\u68c0\u7d22\u7814\u7a76\u5230\u5f02\u6b65\u901a\u4fe1\u7f51\u7edc\uff0c\u89e3\u51b3\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u540c\u6b65\u7f51\u7edc\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u5982\u4f55\u6700\u5c0f\u5316\u67e5\u8be2\u590d\u6742\u5ea6\u540c\u65f6\u6700\u5927\u5316\u5bb9\u9519\u80fd\u529b\u3002", "method": "\u5728\u5f02\u6b65\u901a\u4fe1\u6a21\u578b\u4e2d\u8bbe\u8ba1\u786e\u5b9a\u6027\u534f\u8bae\u5904\u7406\u5d29\u6e83\u6545\u969c\uff0c\u5206\u6790\u968f\u673a\u534f\u8bae\u5728\u62dc\u5360\u5ead\u6545\u969c\u4e0b\u7684\u6027\u80fd\uff0c\u5efa\u7acb\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u7406\u8bba\u4e0b\u754c\u548c\u4e0a\u754c\u3002", "result": "\u5bf9\u4e8e\u5d29\u6e83\u6545\u969c\uff0c\u63d0\u51fa\u4e86\u80fd\u5bb9\u5fcd\u4efb\u610f\u56fa\u5b9a\u6bd4\u4f8b\u03b2<1\u6545\u969c\u7684\u67e5\u8be2\u6700\u4f18\u786e\u5b9a\u6027\u65b9\u6848\uff1b\u5bf9\u4e8e\u62dc\u5360\u5ead\u6545\u969c\uff0c\u8bc1\u660e\u4e86\u968f\u673a\u534f\u8bae\u5728\u03b2\u22651/2\u65f6\u7684\u03a9(n)\u4e0b\u754c\uff0c\u5e76\u5728\u03b2<1/2\u65f6\u7ed9\u51fa\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u968f\u673a\u534f\u8bae\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u89e3\u51b3\u5f02\u6b65\u7f51\u7edc\u4e2d\u4e0b\u8f7d\u95ee\u9898\u7684\u5de5\u4f5c\uff0c\u4e3a\u5f02\u6b65\u5206\u5e03\u5f0f\u6570\u636e\u68c0\u7d22\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u6545\u969c\u6a21\u578b\u4e0b\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u4f18\u5316\u3002"}}
{"id": "2509.04004", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.04004", "abs": "https://arxiv.org/abs/2509.04004", "authors": ["Avisek Sharma", "Satakshi Ghosh", "Buddhadeb Sau"], "title": "Gathering of asynchronous robots on circle with limited visibility using finite communication", "comment": null, "summary": "This work addresses the gathering problem for a set of autonomous, anonymous,\nand homogeneous robots with limited visibility operating in a continuous\ncircle. The robots are initially placed at distinct positions, forming a\nrotationally asymmetric configuration. The robots agree on the clockwise\ndirection. In the $\\theta$-visibility model, a robot can only see those robots\non the circle that are at an angular distance $<\\theta$ from it. Di Luna\n\\textit{et. al.} [DISC'20] have shown that, in $\\pi/2$ visibility, gathering is\nimpossible. In addition, they provided an algorithm for robots with $\\pi$\nvisibility, operating under a semi-synchronous scheduler. In the $\\pi$\nvisibility model, only one point, the point at the angular distance $\\pi$ is\nremoved from the visibility. Ghosh \\textit{et. al.} [SSS'23] provided a\ngathering algorithm for $\\pi$ visibility model with robot having finite memory\n($\\mathcal{FSTA}$), operating under a special asynchronous scheduler.\n  If the robots can see all points on the circle, then the gathering can be\ndone by electing a leader in the weakest robot model under a fully asynchronous\nscheduler. However, previous works have shown that even the removal of one\npoint from the visibility makes gathering difficult. In both works, the robots\nhad rigid movement. In this work, we propose an algorithm that solves the\ngathering problem under the $\\pi$-visibility model for robots that have finite\ncommunication ability ($\\mathcal{FCOM}$). In this work the robot movement is\nnon-rigid and the robots work under a fully asynchronous scheduler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u03c0-\u53ef\u89c1\u6027\u6a21\u578b\u4e0b\u89e3\u51b3\u673a\u5668\u4eba\u805a\u96c6\u95ee\u9898\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u6709\u9650\u901a\u4fe1\u80fd\u529b(\u2131COM)\u7684\u673a\u5668\u4eba\u5728\u5b8c\u5168\u5f02\u6b65\u8c03\u5ea6\u5668\u4e0b\u5b9e\u73b0\u975e\u521a\u6027\u79fb\u52a8\u7684\u805a\u96c6\u3002", "motivation": "\u89e3\u51b3\u6709\u9650\u53ef\u89c1\u6027\u73af\u5883\u4e0b\u81ea\u4e3b\u533f\u540d\u673a\u5668\u4eba\u7684\u805a\u96c6\u95ee\u9898\u3002\u4e4b\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u4ece\u53ef\u89c1\u6027\u4e2d\u79fb\u9664\u4e00\u4e2a\u70b9\uff08\u03c0\u53ef\u89c1\u6027\uff09\uff0c\u805a\u96c6\u4e5f\u53d8\u5f97\u56f0\u96be\uff0c\u4e14\u73b0\u6709\u7b97\u6cd5\u9700\u8981\u7279\u6b8a\u8c03\u5ea6\u5668\u6216\u6709\u9650\u5185\u5b58\u3002\u672c\u6587\u65e8\u5728\u5728\u5b8c\u5168\u5f02\u6b65\u8c03\u5ea6\u5668\u4e0b\u4f7f\u7528\u6709\u9650\u901a\u4fe1\u80fd\u529b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6709\u9650\u901a\u4fe1\u80fd\u529b(\u2131COM)\u7684\u7b97\u6cd5\uff0c\u5728\u03c0-\u53ef\u89c1\u6027\u6a21\u578b\u4e0b\u5b9e\u73b0\u673a\u5668\u4eba\u805a\u96c6\u3002\u673a\u5668\u4eba\u5177\u6709\u975e\u521a\u6027\u79fb\u52a8\u7279\u6027\uff0c\u5de5\u4f5c\u5728\u5b8c\u5168\u5f02\u6b65\u8c03\u5ea6\u5668\u73af\u5883\u4e2d\u3002", "result": "\u6210\u529f\u89e3\u51b3\u4e86\u03c0-\u53ef\u89c1\u6027\u6a21\u578b\u4e0b\u7684\u673a\u5668\u4eba\u805a\u96c6\u95ee\u9898\uff0c\u76f8\u6bd4\u4e4b\u524d\u9700\u8981\u7279\u6b8a\u5f02\u6b65\u8c03\u5ea6\u5668\u6216\u6709\u9650\u5185\u5b58\u7684\u65b9\u6848\uff0c\u672c\u7b97\u6cd5\u5728\u5b8c\u5168\u5f02\u6b65\u8c03\u5ea6\u5668\u4e0b\u4f7f\u7528\u6709\u9650\u901a\u4fe1\u80fd\u529b\u5373\u53ef\u5b9e\u73b0\u805a\u96c6\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u8bc1\u660e\u4e86\u5728\u03c0-\u53ef\u89c1\u6027\u9650\u5236\u4e0b\uff0c\u901a\u8fc7\u6709\u9650\u901a\u4fe1\u80fd\u529b\u53ef\u4ee5\u5728\u5b8c\u5168\u5f02\u6b65\u73af\u5883\u4e2d\u5b9e\u73b0\u673a\u5668\u4eba\u805a\u96c6\uff0c\u4e3a\u975e\u521a\u6027\u79fb\u52a8\u673a\u5668\u4eba\u7684\u805a\u96c6\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.04038", "categories": ["cs.DC", "math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.04038", "abs": "https://arxiv.org/abs/2509.04038", "authors": ["Benjamin Heymann"], "title": "Counterfactual simulations for large scale systems with burnout variables", "comment": null, "summary": "We consider large-scale systems influenced by burnout variables - state\nvariables that start active, shape dynamics, and irreversibly deactivate once\ncertain conditions are met. Simulating what-if scenarios in such systems is\ncomputationally demanding, as alternative trajectories often require sequential\nprocessing, which does not scale very well. This challenge arises in settings\nlike online advertising, because of campaigns budgets, complicating\ncounterfactual analysis despite rich data availability. We introduce a new type\nof algorithms based on what we refer to as uncertainty relaxation, that enables\nefficient parallel computation, significantly improving scalability for\ncounterfactual estimation in systems with burnout variables.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u677e\u5f1b\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u5e76\u884c\u8ba1\u7b97\u5177\u6709burnout\u53d8\u91cf\u7684\u7cfb\u7edf\u4e2d\u7684\u53cd\u4e8b\u5b9e\u4f30\u8ba1", "motivation": "\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u5b58\u5728burnout\u53d8\u91cf\uff08\u6fc0\u6d3b\u540e\u4e0d\u53ef\u9006\u5931\u6d3b\uff09\uff0c\u4f20\u7edf\u987a\u5e8f\u5904\u7406\u53cd\u4e8b\u5b9e\u573a\u666f\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u7279\u522b\u662f\u5728\u5728\u7ebf\u5e7f\u544a\u7b49\u5e94\u7528\u4e2d", "method": "\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u677e\u5f1b\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u8ba1\u7b97\u66ff\u4ee3\u987a\u5e8f\u5904\u7406\uff0c\u63d0\u9ad8\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u7684\u53ef\u6269\u5c55\u6027", "result": "\u663e\u8457\u63d0\u5347\u4e86\u5177\u6709burnout\u53d8\u91cf\u7cfb\u7edf\u7684\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u8ba1\u7b97\u6548\u7387", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u677e\u5f1b\u7b97\u6cd5\u4e3a\u5904\u7406\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u53cd\u4e8b\u5b9e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.04084", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.04084", "abs": "https://arxiv.org/abs/2509.04084", "authors": ["Chenxuan Yao", "Yuchong Hu", "Feifan Liu", "Zhengyu Liu", "Dan Feng"], "title": "LowDiff: Efficient Frequent Checkpointing via Low-Cost Differential for High-Performance Distributed Training Systems", "comment": null, "summary": "Distributed training of large deep-learning models often leads to failures,\nso checkpointing is commonly employed for recovery. State-of-the-art studies\nfocus on frequent checkpointing for fast recovery from failures. However, it\ngenerates numerous checkpoints, incurring substantial costs and thus degrading\ntraining performance. Recently, differential checkpointing has been proposed to\nreduce costs, but it is limited to recommendation systems, so its application\nto general distributed training systems remains unexplored.\n  This paper proposes LowDiff, an efficient frequent checkpointing framework\nthat \\textit{reuses} compressed gradients, serving as differential checkpoints\nto reduce cost. Furthermore, LowDiff incorporates a batched gradient write\noptimization to persist these differentials to storage efficiently. It also\ndynamically tunes both the checkpoint frequency and the batching size to\nmaximize performance. We further enhance LowDiff with a layer-wise gradient\nreusing and snapshotting approach and a CPU-based asynchronous persistence\nstrategy, enabling frequent checkpointing without gradient compression.\nExperiments on various workloads show that LowDiff can achieve checkpointing\nfrequency up to per iteration with less than 3.1\\% runtime overhead.", "AI": {"tldr": "LowDiff\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u9891\u7e41\u68c0\u67e5\u70b9\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u7528\u538b\u7f29\u68af\u5ea6\u4f5c\u4e3a\u5dee\u5f02\u68c0\u67e5\u70b9\u6765\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u91c7\u7528\u6279\u91cf\u68af\u5ea6\u5199\u5165\u4f18\u5316\u548c\u52a8\u6001\u8c03\u53c2\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u6bcf\u8fed\u4ee3\u68c0\u67e5\u70b9\u9891\u7387\u4e14\u8fd0\u884c\u65f6\u5f00\u9500\u5c0f\u4e8e3.1%", "motivation": "\u5206\u5e03\u5f0f\u5927\u6a21\u578b\u8bad\u7ec3\u7ecf\u5e38\u5931\u8d25\u9700\u8981\u68c0\u67e5\u70b9\u6062\u590d\uff0c\u73b0\u6709\u9891\u7e41\u68c0\u67e5\u70b9\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\uff0c\u800c\u5dee\u5f02\u68c0\u67e5\u70b9\u6280\u672f\u76ee\u524d\u4ec5\u9650\u4e8e\u63a8\u8350\u7cfb\u7edf\uff0c\u9700\u8981\u6269\u5c55\u5230\u901a\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf", "method": "\u63d0\u51faLowDiff\u6846\u67b6\uff1a1)\u91cd\u7528\u538b\u7f29\u68af\u5ea6\u4f5c\u4e3a\u5dee\u5f02\u68c0\u67e5\u70b9 2)\u6279\u91cf\u68af\u5ea6\u5199\u5165\u4f18\u5316 3)\u52a8\u6001\u8c03\u6574\u68c0\u67e5\u70b9\u9891\u7387\u548c\u6279\u91cf\u5927\u5c0f 4)\u5206\u5c42\u68af\u5ea6\u91cd\u7528\u548c\u5feb\u7167\u65b9\u6cd5 5)CPU\u5f02\u6b65\u6301\u4e45\u5316\u7b56\u7565", "result": "\u5728\u5404\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLowDiff\u53ef\u4ee5\u5b9e\u73b0\u6bcf\u8fed\u4ee3\u68c0\u67e5\u70b9\u9891\u7387\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u5c0f\u4e8e3.1%", "conclusion": "LowDiff\u901a\u8fc7\u521b\u65b0\u6027\u5730\u91cd\u7528\u538b\u7f29\u68af\u5ea6\u548c\u4f18\u5316\u7b56\u7565\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u9891\u7e41\u68c0\u67e5\u70b9\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u6210\u672c\u548c\u6027\u80fd\u5f00\u9500"}}
{"id": "2509.04085", "categories": ["cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.04085", "abs": "https://arxiv.org/abs/2509.04085", "authors": ["Stanly Wilson", "Kwabena Adu-Duodu", "Yinhao Li", "Ringo Sham", "Yingli Wang", "Ellis Solaiman", "Charith Perera", "Rajiv Ranjan", "Omer Rana"], "title": "Trustworthy Second-hand Marketplace for Built Environment", "comment": null, "summary": "The construction industry faces significant challenges regarding material\nwaste and sustainable practices, necessitating innovative solutions that\nintegrate automation, traceability, and decentralised decision-making to enable\nefficient material reuse. This paper presents a blockchain-enabled digital\nmarketplace for sustainable construction material reuse, ensuring transparency\nand traceability using InterPlanetary File System (IPFS). The proposed\nframework enhances trust and accountability in material exchange, addressing\nkey challenges in industrial automation and circular supply chains. A framework\nhas been developed to demonstrate the operational processes of the marketplace,\nillustrating its practical application and effectiveness. Our contributions\nshow how the marketplace can facilitate the efficient and trustworthy exchange\nof reusable materials, representing a substantial step towards more sustainable\nconstruction practices.", "AI": {"tldr": "\u57fa\u4e8e\u533a\u5757\u94fe\u548cIPFS\u7684\u6570\u5b57\u5316\u5e02\u573a\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u53ef\u8ffd\u6eaf\u6027\u63d0\u9ad8\u5efa\u7b51\u6750\u6599\u91cd\u7528\u6548\u7387\u548c\u4fe1\u4efb\u5ea6", "motivation": "\u5efa\u7b51\u884c\u4e1a\u9762\u4e34\u6750\u6599\u6d6a\u8d39\u548c\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u9700\u8981\u96c6\u6210\u81ea\u52a8\u5316\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53bb\u4e2d\u5fc3\u5316\u51b3\u7b56\u7684\u521b\u65b0\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u548cInterPlanetary File System (IPFS)\u7684\u6570\u5b57\u5316\u5e02\u573a\u5e73\u53f0\u6846\u67b6\uff0c\u786e\u4fdd\u6750\u6599\u4ea4\u6362\u7684\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027", "result": "\u5e73\u53f0\u6846\u67b6\u6f14\u793a\u4e86\u5e02\u573a\u7684\u8fd0\u8425\u8fc7\u7a0b\uff0c\u663e\u793a\u5176\u5b9e\u9645\u5e94\u7528\u548c\u6548\u679c\uff0c\u80fd\u591f\u4fc3\u8fdb\u53ef\u91cd\u7528\u6750\u6599\u7684\u9ad8\u6548\u3001\u53ef\u4fe1\u4efb\u4ea4\u6362", "conclusion": "\u8be5\u7814\u7a76\u4ee3\u8868\u4e86\u5411\u66f4\u53ef\u6301\u7eed\u5efa\u7b51\u5b9e\u8df5\u8fdb\u884c\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u6280\u672f\u63d0\u9ad8\u4e86\u6750\u6599\u4ea4\u6362\u4e2d\u7684\u4fe1\u4efb\u548c\u8d23\u4efb\u5236"}}
{"id": "2509.04383", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.04383", "abs": "https://arxiv.org/abs/2509.04383", "authors": ["Serafino Cicerone", "Alessia Di Fonso", "Gabriele Di Stefano", "Alfredo Navarra"], "title": "On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs", "comment": "18 pages, 6 figures", "summary": "The OBLOT model has been extensively studied in theoretical swarm robotics.\nIt assumes weak capabilities for the involved mobile robots, such as they are\nanonymous, disoriented, no memory of past events (oblivious), and silent. Their\nonly means of (implicit) communication is transferred to their positioning,\ni.e., stigmergic information. These limited capabilities make the design of\ndistributed algorithms a challenging task. Over the last two decades, numerous\nresearch papers have addressed the question of which tasks can be accomplished\nwithin this model. Nevertheless, as it usually happens in distributed\ncomputing, also in OBLOT the computational power available to the robots is\nneglected as the main cost measures for the designed algorithms refer to the\nnumber of movements or the number of rounds required. In this paper, we prove\nthat for synchronous robots moving on finite graphs, the unlimited\ncomputational power (other than finite time) has a significant impact. In fact,\nby exploiting it, we provide a definitive resolution algorithm that applies to\na wide class of problems while guaranteeing the minimum number of moves and\nrounds.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5728\u540c\u6b65\u673a\u5668\u4eba\u5728\u6709\u9650\u56fe\u4e0a\u79fb\u52a8\u65f6\uff0c\u65e0\u9650\u8ba1\u7b97\u80fd\u529b\u5bf9OBLOT\u6a21\u578b\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u8bc1\u6700\u5c11\u79fb\u52a8\u548c\u8f6e\u6570\u7684\u901a\u7528\u89e3\u51b3\u7b97\u6cd5", "motivation": "OBLOT\u6a21\u578b\u4e2d\u7684\u673a\u5668\u4eba\u80fd\u529b\u6709\u9650\uff0c\u4f20\u7edf\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u79fb\u52a8\u6b21\u6570\u548c\u8f6e\u6570\u6210\u672c\uff0c\u800c\u5ffd\u89c6\u4e86\u8ba1\u7b97\u80fd\u529b\u7684\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u65e0\u9650\u8ba1\u7b97\u80fd\u529b\u5bf9\u7b97\u6cd5\u6027\u80fd\u7684\u5f71\u54cd", "method": "\u5229\u7528\u540c\u6b65\u673a\u5668\u4eba\u5728\u6709\u9650\u56fe\u4e0a\u7684\u65e0\u9650\u8ba1\u7b97\u80fd\u529b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u901a\u7528\u7684\u786e\u5b9a\u6027\u89e3\u51b3\u7b97\u6cd5", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5e94\u7528\u4e8e\u5e7f\u6cdb\u7684\u95ee\u9898\u7c7b\u522b\uff0c\u540c\u65f6\u4fdd\u8bc1\u6700\u5c11\u79fb\u52a8\u6b21\u6570\u548c\u8f6e\u6570\uff0c\u8bc1\u660e\u4e86\u65e0\u9650\u8ba1\u7b97\u80fd\u529b\u5728OBLOT\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027", "conclusion": "\u65e0\u9650\u8ba1\u7b97\u80fd\u529b\u5728OBLOT\u6a21\u578b\u4e2d\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u901a\u8fc7\u5408\u7406\u5229\u7528\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u6700\u4f18\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u4e3a\u7406\u8bba\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u601d\u8def"}}
