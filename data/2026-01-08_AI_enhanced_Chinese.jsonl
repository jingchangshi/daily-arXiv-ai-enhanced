{"id": "2601.03390", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.03390", "abs": "https://arxiv.org/abs/2601.03390", "authors": ["Daniel Qian", "Xiyu Hao", "Jinkun Geng", "Yuncheng Yao", "Aurojit Panda", "Jinyang Li", "Anirudh Sivaraman"], "title": "Revisiting Speculative Leaderless Protocols for Low-Latency BFT Replication", "comment": null, "summary": "As Byzantine Fault Tolerant (BFT) protocols begin to be used in permissioned blockchains for user-facing applications such as payments, it is crucial that they provide low latency. In pursuit of low latency, some recently proposed BFT consensus protocols employ a leaderless optimistic fast path, in which clients broadcast their requests directly to replicas without first serializing requests at a leader, resulting in an end-to-end commit latency of 2 message delays ($2\u0394$) during fault-free, synchronous periods. However, such a fast path only works if there is no contention: concurrent contending requests can cause replicas to diverge if they receive conflicting requests in different orders, triggering costly recovery procedures.\n  In this work, we present Aspen, a leaderless BFT protocol that achieves a near-optimal latency of $2\u0394+ \\varepsilon$, where $\\varepsilon$ indicates a short waiting delay. Aspen removes the no-contention condition by utilizing a best-effort sequencing layer based on loosely synchronized clocks and network delay estimates. Aspen requires $n = 3f + 2p + 1$ replicas to cope with up to $f$ Byzantine nodes. The $2p$ extra nodes allow Aspen's fast path to proceed even if up to $p$ replicas diverge due to unpredictable network delays. When its optimistic conditions do not hold, Aspen falls back to PBFT-style protocol, guaranteeing safety and liveness under partial synchrony. In experiments with wide-area distributed replicas, Aspen commits requests in less than 75 ms, a 1.2 to 3.3$\\times$ improvement compared to previous protocols, while supporting 19,000 requests per second.", "AI": {"tldr": "Aspen\u662f\u4e00\u4e2a\u65e0\u9886\u5bfc\u8005\u7684\u62dc\u5360\u5ead\u5bb9\u9519\u534f\u8bae\uff0c\u901a\u8fc7\u57fa\u4e8e\u677e\u6563\u540c\u6b65\u65f6\u949f\u548c\u7f51\u7edc\u5ef6\u8fdf\u4f30\u8ba1\u7684\u5c3d\u529b\u6392\u5e8f\u5c42\uff0c\u5728\u65e0\u51b2\u7a81\u6761\u4ef6\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u76842\u0394+\u03b5\u5ef6\u8fdf\uff0c\u6bd4\u73b0\u6709\u534f\u8bae\u5feb1.2-3.3\u500d\u3002", "motivation": "\u968f\u7740BFT\u534f\u8bae\u5728\u9762\u5411\u7528\u6237\u7684\u8bb8\u53ef\u533a\u5757\u94fe\u5e94\u7528\uff08\u5982\u652f\u4ed8\uff09\u4e2d\u4f7f\u7528\uff0c\u4f4e\u5ef6\u8fdf\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u65e0\u9886\u5bfc\u8005\u4e50\u89c2\u5feb\u901f\u8def\u5f84\u534f\u8bae\u53ea\u5728\u65e0\u51b2\u7a81\u6761\u4ef6\u4e0b\u5de5\u4f5c\uff0c\u5e76\u53d1\u51b2\u7a81\u8bf7\u6c42\u4f1a\u5bfc\u81f4\u526f\u672c\u5206\u6b67\u5e76\u89e6\u53d1\u6602\u8d35\u7684\u6062\u590d\u8fc7\u7a0b\u3002", "method": "Aspen\u91c7\u7528\u65e0\u9886\u5bfc\u8005\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u677e\u6563\u540c\u6b65\u65f6\u949f\u548c\u7f51\u7edc\u5ef6\u8fdf\u4f30\u8ba1\u7684\u5c3d\u529b\u6392\u5e8f\u5c42\u6765\u79fb\u9664\u65e0\u51b2\u7a81\u6761\u4ef6\u3002\u534f\u8bae\u9700\u8981n=3f+2p+1\u4e2a\u526f\u672c\u4ee5\u5bb9\u5fcdf\u4e2a\u62dc\u5360\u5ead\u8282\u70b9\uff0c\u5176\u4e2d2p\u4e2a\u989d\u5916\u526f\u672c\u5141\u8bb8\u5feb\u901f\u8def\u5f84\u5728\u6700\u591ap\u4e2a\u526f\u672c\u56e0\u7f51\u7edc\u5ef6\u8fdf\u800c\u5206\u6b67\u65f6\u7ee7\u7eed\u5de5\u4f5c\u3002\u5f53\u4e50\u89c2\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u56de\u9000\u5230PBFT\u98ce\u683c\u534f\u8bae\u3002", "result": "\u5728\u5e7f\u57df\u5206\u5e03\u5f0f\u526f\u672c\u5b9e\u9a8c\u4e2d\uff0cAspen\u572875\u6beb\u79d2\u5185\u63d0\u4ea4\u8bf7\u6c42\uff0c\u6bd4\u5148\u524d\u534f\u8bae\u5feb1.2-3.3\u500d\uff0c\u540c\u65f6\u652f\u6301\u6bcf\u79d219,000\u4e2a\u8bf7\u6c42\u3002", "conclusion": "Aspen\u901a\u8fc7\u521b\u65b0\u7684\u5c3d\u529b\u6392\u5e8f\u5c42\u5b9e\u73b0\u4e86\u65e0\u9886\u5bfc\u8005BFT\u534f\u8bae\u7684\u4f4e\u5ef6\u8fdf\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u548c\u6d3b\u8dc3\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u9700\u8981\u4f4e\u5ef6\u8fdf\u7684\u8bb8\u53ef\u533a\u5757\u94fe\u5e94\u7528\u3002"}}
{"id": "2601.03862", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.03862", "abs": "https://arxiv.org/abs/2601.03862", "authors": ["Francesco D'Amato", "Roberto Saltini", "Thanh-Hai Tran", "Yann Vonlanthen", "Luca Zanolini"], "title": "Majorum: Ebb-and-Flow Consensus with Dynamic Quorums", "comment": null, "summary": "Dynamic availability is the ability of a consensus protocol to remain live despite honest participants going offline and later rejoining. A well-known limitation is that dynamically available protocols, on their own, cannot provide strong safety guarantees during network partitions or extended asynchrony. Ebb-and-flow protocols [SP21] address this by combining a dynamically available protocol with a partially synchronous finality protocol that irrevocably finalizes a prefix.\n  We present Majorum, an ebb-and-flow construction whose dynamically available component builds on a quorum-based protocol (TOB-SVD). Under optimistic conditions, Majorum finalizes blocks in as few as three slots while requiring only a single voting phase per slot. In particular, when conditions remain favourable, each slot finalizes the next block extending the previously finalized one.", "AI": {"tldr": "Majorum\u662f\u4e00\u79cdebb-and-flow\u534f\u8bae\uff0c\u7ed3\u5408\u4e86\u52a8\u6001\u53ef\u7528\u6027\u534f\u8bae\u548c\u90e8\u5206\u540c\u6b65\u6700\u7ec8\u6027\u534f\u8bae\uff0c\u5728\u4e50\u89c2\u6761\u4ef6\u4e0b\u53ea\u97003\u4e2a\u65f6\u9699\u5373\u53ef\u6700\u7ec8\u786e\u5b9a\u533a\u5757\uff0c\u6bcf\u4e2a\u65f6\u9699\u4ec5\u9700\u4e00\u8f6e\u6295\u7968\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u53ef\u7528\u6027\u534f\u8bae\u5728\u7f51\u7edc\u5206\u533a\u6216\u5f02\u6b65\u671f\u95f4\u65e0\u6cd5\u63d0\u4f9b\u5f3a\u5b89\u5168\u6027\u4fdd\u8bc1\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u53ef\u7528\u6027\u548c\u6700\u7ec8\u6027\u534f\u8bae\u6765\u63d0\u4f9b\u66f4\u597d\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "method": "\u91c7\u7528ebb-and-flow\u67b6\u6784\uff0c\u7ed3\u5408\u57fa\u4e8e\u4ef2\u88c1\u7684\u52a8\u6001\u53ef\u7528\u6027\u534f\u8bae\uff08TOB-SVD\uff09\u548c\u90e8\u5206\u540c\u6b65\u6700\u7ec8\u6027\u534f\u8bae\uff0c\u5728\u4e50\u89c2\u6761\u4ef6\u4e0b\u6bcf\u4e2a\u65f6\u9699\u53ea\u9700\u4e00\u8f6e\u6295\u7968\u5373\u53ef\u6700\u7ec8\u786e\u5b9a\u533a\u5757\u3002", "result": "\u5728\u4e50\u89c2\u6761\u4ef6\u4e0b\uff0cMajorum\u53ea\u97003\u4e2a\u65f6\u9699\u5373\u53ef\u6700\u7ec8\u786e\u5b9a\u533a\u5757\uff0c\u6bcf\u4e2a\u65f6\u9699\u4ec5\u9700\u4e00\u8f6e\u6295\u7968\uff0c\u4e14\u80fd\u8fde\u7eed\u6700\u7ec8\u5316\u6269\u5c55\u5148\u524d\u5df2\u6700\u7ec8\u786e\u5b9a\u7684\u533a\u5757\u3002", "conclusion": "Majorum\u901a\u8fc7ebb-and-flow\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u53ef\u7528\u6027\u534f\u8bae\u7684\u5b89\u5168\u9650\u5236\uff0c\u5728\u4fdd\u6301\u52a8\u6001\u53ef\u7528\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6700\u7ec8\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2601.03992", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03992", "abs": "https://arxiv.org/abs/2601.03992", "authors": ["Qi Wu", "Chao Fang", "Jiayuan Chen", "Ye Lin", "Yueqi Zhang", "Yichuan Bai", "Yuan Du", "Li Du"], "title": "A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems", "comment": "To appear in 2026 Design, Automation and Test in Europe Conference (DATE 2026)", "summary": "Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9\u8fb9\u7f18GPU-NDP\u7cfb\u7edf\u7684MoE\u63a8\u7406\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5f20\u91cf\u5e76\u884c\u3001\u8d1f\u8f7d\u5747\u8861\u8c03\u5ea6\u548c\u65e0\u6570\u636e\u96c6\u9884\u53d6\u7b56\u7565\uff0c\u5b9e\u73b02.41\u500d\u5e73\u5747\u52a0\u901f", "motivation": "MoE\u6a21\u578b\u5728\u8fb9\u7f18\u90e8\u7f72\u65f6\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a1) NDP\u5355\u5143\u95f4\u8d1f\u8f7d\u4e0d\u5747\u8861\uff08\u4e13\u5bb6\u9009\u62e9\u4e0d\u5747\u5300\u548c\u4e13\u5bb6\u5e76\u884c\uff09\uff1b2) NDP\u5355\u5143\u5185GPU\u5229\u7528\u7387\u4e0d\u8db3\uff1b3) \u9700\u8981\u5927\u91cf\u6570\u636e\u9884\u5206\u6790\u6765\u9884\u6d4b\u4e0d\u53ef\u9884\u6d4b\u7684\u4e13\u5bb6\u6fc0\u6d3b\u6a21\u5f0f", "method": "\u63d0\u51fa\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u4f18\u5316\uff1a1) \u5229\u7528MoE\u63a8\u7406\u4e2d\u672a\u5145\u5206\u63a2\u7d22\u7684\u5f20\u91cf\u5e76\u884c\uff0c\u5728\u8fb9\u7f18\u4f4e\u6279\u91cf\u573a\u666f\u4e0b\u8de8\u591a\u4e2aNDP\u5355\u5143\u5206\u533a\u8ba1\u7b97\u5927\u578b\u4e13\u5bb6\u53c2\u6570\uff1b2) \u8d1f\u8f7d\u5747\u8861\u611f\u77e5\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5728NDP\u5355\u5143\u548cGPU\u95f4\u5206\u914d\u4e13\u5bb6\u8ba1\u7b97\u4ee5\u6700\u5927\u5316\u8d44\u6e90\u5229\u7528\u7387\uff1b3) \u65e0\u6570\u636e\u96c6\u9884\u53d6\u7b56\u7565\uff0c\u4e3b\u52a8\u52a0\u8f7d\u9891\u7e41\u8bbf\u95ee\u7684\u4e13\u5bb6\u4ee5\u6700\u5c0f\u5316\u6fc0\u6d3b\u5ef6\u8fdf", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u4f7fGPU-NDP\u7cfb\u7edf\u5728\u7aef\u5230\u7aef\u5ef6\u8fdf\u4e0a\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5e73\u5747\u52a0\u901f2.41\u500d\uff0c\u6700\u9ad8\u8fbe2.56\u500d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684MoE\u63a8\u7406\u6548\u7387", "conclusion": "\u63d0\u51fa\u7684\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18GPU-NDP\u7cfb\u7edf\u4e2dMoE\u63a8\u7406\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u5f20\u91cf\u5e76\u884c\u3001\u8d1f\u8f7d\u5747\u8861\u8c03\u5ea6\u548c\u667a\u80fd\u9884\u53d6\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387"}}
{"id": "2601.04071", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04071", "abs": "https://arxiv.org/abs/2601.04071", "authors": ["Tiancheng Hu", "Chenxi Wang", "Ting Cao", "Jin Qin", "Lei Chen", "Xinyu Xiao", "Junhao Hu", "Hongliang Tian", "Shoumeng Yan", "Huimin Cui", "Quan Chen", "Tao Xie"], "title": "Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale", "comment": null, "summary": "Existing GPU-sharing techniques, including spatial and temporal sharing, aim to improve utilization but face challenges in simultaneously ensuring SLO adherence and maximizing efficiency due to the lack of fine-grained task scheduling on closed-source GPUs. This paper presents Hummingbird, an SLO-oriented GPU scheduling system that overcomes these challenges by enabling microsecond-scale preemption on closed-source GPUs while effectively harvesting idle GPU time slices. Comprehensive evaluations across diverse GPU architectures reveal that Hummingbird improves the SLO attainment of high-priority tasks by 9.7x and 3.5x compared to the state-of-the-art spatial and temporal-sharing approaches. When compared to executing exclusively, the SLO attainment of the high-priority task, collocating with low-priority tasks on Hummingbird, only drops by less than 1%. Meanwhile, the throughput of the low-priority task outperforms the state-of-the-art temporal-sharing approaches by 2.4x. Hummingbird demonstrates significant effectiveness in ensuring the SLO while enhancing GPU utilization.", "AI": {"tldr": "Hummingbird\u662f\u4e00\u4e2a\u9762\u5411SLO\u7684GPU\u8c03\u5ea6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u95ed\u6e90GPU\u4e0a\u5b9e\u73b0\u5fae\u79d2\u7ea7\u62a2\u5360\uff0c\u540c\u65f6\u6709\u6548\u5229\u7528\u7a7a\u95f2GPU\u65f6\u95f4\u7247\uff0c\u663e\u8457\u63d0\u5347\u9ad8\u4f18\u5148\u7ea7\u4efb\u52a1\u7684SLO\u8fbe\u6210\u7387\uff0c\u540c\u65f6\u63d0\u9ad8\u4f4e\u4f18\u5148\u7ea7\u4efb\u52a1\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709GPU\u5171\u4eab\u6280\u672f\uff08\u5305\u62ec\u7a7a\u95f4\u548c\u65f6\u95f4\u5171\u4eab\uff09\u5728\u63d0\u9ad8\u5229\u7528\u7387\u7684\u540c\u65f6\uff0c\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u95ed\u6e90GPU\u7684\u7ec6\u7c92\u5ea6\u4efb\u52a1\u8c03\u5ea6\uff0c\u96be\u4ee5\u540c\u65f6\u786e\u4fddSLO\uff08\u670d\u52a1\u6c34\u5e73\u76ee\u6807\uff09\u9075\u5b88\u548c\u6700\u5927\u5316\u6548\u7387\u3002", "method": "Hummingbird\u901a\u8fc7\u5728\u95ed\u6e90GPU\u4e0a\u5b9e\u73b0\u5fae\u79d2\u7ea7\u62a2\u5360\u673a\u5236\uff0c\u540c\u65f6\u6709\u6548\u6536\u96c6\u548c\u5229\u7528\u7a7a\u95f2GPU\u65f6\u95f4\u7247\uff0c\u5b9e\u73b0SLO\u5bfc\u5411\u7684GPU\u8c03\u5ea6\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u5171\u4eab\u65b9\u6cd5\u76f8\u6bd4\uff0cHummingbird\u5c06\u9ad8\u4f18\u5148\u7ea7\u4efb\u52a1\u7684SLO\u8fbe\u6210\u7387\u5206\u522b\u63d0\u9ad8\u4e869.7\u500d\u548c3.5\u500d\u3002\u9ad8\u4f18\u5148\u7ea7\u4efb\u52a1\u4e0e\u4f4e\u4f18\u5148\u7ea7\u4efb\u52a1\u5171\u5b58\u65f6\uff0cSLO\u8fbe\u6210\u7387\u4ec5\u4e0b\u964d\u4e0d\u52301%\u3002\u4f4e\u4f18\u5148\u7ea7\u4efb\u52a1\u7684\u541e\u5410\u91cf\u6bd4\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5171\u4eab\u65b9\u6cd5\u9ad8\u51fa2.4\u500d\u3002", "conclusion": "Hummingbird\u5728\u786e\u4fddSLO\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86GPU\u5229\u7528\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u5728GPU\u8c03\u5ea6\u65b9\u9762\u7684\u663e\u8457\u6709\u6548\u6027\u3002"}}
{"id": "2601.03708", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03708", "abs": "https://arxiv.org/abs/2601.03708", "authors": ["Qingyun Zou", "Jiahao Cui", "Nuo Chen", "Bingsheng He", "Weng-Fai Wong"], "title": "MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark", "comment": null, "summary": "Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \\textbf{MHRC-Bench}, consisting of \\textbf{MHRC-Bench-Train} and \\textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.", "AI": {"tldr": "MHRC-Bench\u662f\u9996\u4e2a\u9488\u5bf9\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\u7684\u591a\u8bed\u8a00\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u57fa\u51c6\uff0c\u5305\u542b\u8bad\u7ec3\u548c\u8bc4\u4f30\u4e24\u90e8\u5206\uff0c\u8986\u76d6\u4e09\u79cd\u4e3b\u8981\u786c\u4ef6\u8bbe\u8ba1\u7f16\u7801\u98ce\u683c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ee3\u7801\u7ed3\u6784\u548c\u786c\u4ef6\u8bed\u4e49\u6807\u6ce8\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u8f6f\u4ef6\u4ee3\u7801\uff0c\u5ffd\u89c6\u4e86\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff0c\u800cLLMs\u5728\u901a\u7528\u7f16\u7a0b\u8bed\u8a00\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u786c\u4ef6\u4ee3\u7801\u8865\u5168\u65b9\u9762\u7f3a\u4e4f\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u521b\u5efaMHRC-Bench\u57fa\u51c6\uff0c\u5305\u542bMHRC-Bench-Train\u548cMHRC-Bench-Eval\u4e24\u90e8\u5206\uff0c\u9488\u5bf9\u4e09\u79cd\u4e3b\u8981\u786c\u4ef6\u8bbe\u8ba1\u7f16\u7801\u98ce\u683c\uff0c\u901a\u8fc7\u5177\u4f53\u8bed\u6cd5\u6811\u5206\u6790\u4e3a\u6bcf\u4e2a\u8865\u5168\u76ee\u6807\u6807\u6ce8\u4ee3\u7801\u7ed3\u6784\u7ea7\u548c\u786c\u4ef6\u5bfc\u5411\u7684\u8bed\u4e49\u6807\u7b7e\u3002", "result": "\u5728MHRC-Bench-Eval\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u8bc4\u4f30\u7ed3\u679c\u548c\u5206\u6790\u8bc1\u660e\u4e86MHRC-Bench\u7684\u6709\u6548\u6027\u3002", "conclusion": "MHRC-Bench\u586b\u8865\u4e86\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLMs\u5728\u786c\u4ef6\u4ee3\u7801\u8865\u5168\u65b9\u9762\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.04123", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04123", "abs": "https://arxiv.org/abs/2601.04123", "authors": ["Francisco Ponce", "Simone Gazza", "Andrea D'Iapico", "Roberto Amadini", "Antonio Brogi", "Stefano Forti", "Saverio Giallorenzo", "Pierluigi Plebani", "Davide Usai", "Monica Vitali", "Gianluigi Zavattaro", "Jacopo Soldani"], "title": "Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum", "comment": "Submitted to Cluster Computing", "summary": "Deploying microservice-based applications (MSAs) on heterogeneous and dynamic Cloud-Edge infrastructures requires balancing conflicting objectives, such as failure resilience, performance, and environmental sustainability. In this article, we introduce the FREEDA toolchain, designed to automate the failure-resilient and carbon-efficient deployment of MSAs over the Cloud-Edge Continuum.\n  The FREEDA toolchain continuously adapts deployment configurations to changing operational conditions, resource availability, and sustainability constraints, aiming to maintain the MSA quality and service continuity while reducing carbon emissions. We also introduce an experimental suite using diverse simulated and emulated scenarios to validate the effectiveness of the toolchain against real-world challenges, including resource exhaustion, node failures, and carbon intensity fluctuations. The results demonstrate FREEDA's capability to autonomously reconfigure deployments by migrating services, adjusting flavour selections, or rebalancing workloads, successfully achieving an optimal balance among resilience, efficiency, and environmental impact.", "AI": {"tldr": "FREEDA\u5de5\u5177\u94fe\u7528\u4e8e\u5728\u4e91\u8fb9\u8fde\u7eed\u4f53\u4e0a\u81ea\u52a8\u5316\u90e8\u7f72\u5fae\u670d\u52a1\u5e94\u7528\uff0c\u5e73\u8861\u6545\u969c\u6062\u590d\u529b\u3001\u6027\u80fd\u548c\u78b3\u6548\u7387\u7b49\u51b2\u7a81\u76ee\u6807", "motivation": "\u5728\u5f02\u6784\u52a8\u6001\u7684\u4e91\u8fb9\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u5fae\u670d\u52a1\u5e94\u7528\u9700\u8981\u5e73\u8861\u51b2\u7a81\u76ee\u6807\uff1a\u6545\u969c\u6062\u590d\u529b\u3001\u6027\u80fd\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027", "method": "\u5f00\u53d1FREEDA\u5de5\u5177\u94fe\uff0c\u6301\u7eed\u9002\u5e94\u53d8\u5316\u7684\u64cd\u4f5c\u6761\u4ef6\u3001\u8d44\u6e90\u53ef\u7528\u6027\u548c\u53ef\u6301\u7eed\u6027\u7ea6\u675f\uff0c\u4f7f\u7528\u6a21\u62df\u548c\u4eff\u771f\u573a\u666f\u9a8c\u8bc1\u6709\u6548\u6027", "result": "FREEDA\u80fd\u591f\u81ea\u4e3b\u91cd\u65b0\u914d\u7f6e\u90e8\u7f72\uff0c\u901a\u8fc7\u8fc1\u79fb\u670d\u52a1\u3001\u8c03\u6574\u914d\u7f6e\u6216\u91cd\u65b0\u5e73\u8861\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6210\u529f\u5b9e\u73b0\u6062\u590d\u529b\u3001\u6548\u7387\u548c\u73af\u5883\u5f71\u54cd\u4e4b\u95f4\u7684\u6700\u4f18\u5e73\u8861", "conclusion": "FREEDA\u5de5\u5177\u94fe\u6709\u6548\u89e3\u51b3\u4e86\u4e91\u8fb9\u8fde\u7eed\u4f53\u4e0a\u5fae\u670d\u52a1\u5e94\u7528\u7684\u6545\u969c\u6062\u590d\u548c\u78b3\u6548\u7387\u90e8\u7f72\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u81ea\u4e3b\u9002\u5e94\u53d8\u5316\u6761\u4ef6\u7684\u80fd\u529b"}}
{"id": "2601.03768", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.03768", "abs": "https://arxiv.org/abs/2601.03768", "authors": ["Yichen Xu", "Martin Odersky"], "title": "Agentic Proof Automation: A Case Study", "comment": null, "summary": "Proof engineering is notoriously labor-intensive: proofs that are straightforward on paper often require lengthy scripts in theorem provers. Recent advances in large language models (LLMs) create new opportunities for proof automation: modern LLMs not only generate proof scripts, but also support agentic behavior, exploring codebases and iteratively refining their outputs against prover feedback. These advances enable an emerging scheme where LLM-based agents undertake most proof engineering under human guidance. Humans provide mathematical insight (definitions, theorems, proof strategies); agents handle the mechanical work of proof development. We call this scheme agentic proof automation. We present this scheme through a case study: mechanizing the semantic type soundness of a sophisticated formal system, System Capless, in Lean 4, comprising over 14,000 lines of code. Using off-the-shelf LLM agents with a single lightweight proof-checking tool, the agents completed 189 proof engineering tasks with an 87% success rate, only 16% requiring human intervention. The case study demonstrates that agents are capable proof engineers that substantially boost productivity, though they fall short in creative reasoning and still require human guidance in certain cases. We release an interactive explorer where readers can examine all agent interactions; the mechanization is open-sourced for experiments and extensions.", "AI": {"tldr": "LLM\u4ee3\u7406\u5728\u4eba\u7c7b\u6307\u5bfc\u4e0b\u5b8c\u6210\u5927\u90e8\u5206\u8bc1\u660e\u5de5\u7a0b\u5de5\u4f5c\uff0c\u6210\u529f\u5b9e\u73b0\u590d\u6742\u7cfb\u7edf\u7c7b\u578b\u5b89\u5168\u6027\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u8bc1\u660e\u5de5\u7a0b\u6548\u7387", "motivation": "\u8bc1\u660e\u5de5\u7a0b\u52b3\u52a8\u5bc6\u96c6\uff0c\u4f20\u7edf\u8bc1\u660e\u811a\u672c\u5197\u957f\uff1bLLM\u7684\u8fdb\u6b65\u4e3a\u8bc1\u660e\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u901a\u8fc7\u4ee3\u7406\u884c\u4e3a\u53ef\u4ee5\u63a2\u7d22\u4ee3\u7801\u5e93\u5e76\u8fed\u4ee3\u4f18\u5316\u8f93\u51fa", "method": "\u63d0\u51fa\"\u4ee3\u7406\u5f0f\u8bc1\u660e\u81ea\u52a8\u5316\"\u65b9\u6848\uff1a\u4eba\u7c7b\u63d0\u4f9b\u6570\u5b66\u6d1e\u5bdf\uff08\u5b9a\u4e49\u3001\u5b9a\u7406\u3001\u8bc1\u660e\u7b56\u7565\uff09\uff0cLLM\u4ee3\u7406\u5904\u7406\u8bc1\u660e\u5f00\u53d1\u7684\u673a\u68b0\u5de5\u4f5c\uff1b\u4f7f\u7528\u73b0\u6210\u7684LLM\u4ee3\u7406\u548c\u8f7b\u91cf\u7ea7\u8bc1\u660e\u68c0\u67e5\u5de5\u5177\uff0c\u5728Lean 4\u4e2d\u5f62\u5f0f\u5316System Capless\u7684\u8bed\u4e49\u7c7b\u578b\u5b89\u5168\u6027", "result": "\u4ee3\u7406\u5b8c\u6210\u4e86189\u4e2a\u8bc1\u660e\u5de5\u7a0b\u4efb\u52a1\uff0c\u6210\u529f\u738787%\uff0c\u4ec516%\u9700\u8981\u4eba\u5de5\u5e72\u9884\uff1b\u5b9e\u73b0\u4e86\u8d85\u8fc714,000\u884c\u4ee3\u7801\u7684\u5f62\u5f0f\u5316\u7cfb\u7edf", "conclusion": "\u4ee3\u7406\u662f\u80fd\u529b\u5f3a\u7684\u8bc1\u660e\u5de5\u7a0b\u5e08\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u751f\u4ea7\u529b\uff0c\u4f46\u5728\u521b\u9020\u6027\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4ecd\u9700\u4eba\u7c7b\u6307\u5bfc"}}
{"id": "2601.03836", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03836", "abs": "https://arxiv.org/abs/2601.03836", "authors": ["Ivan Perez", "Angel Herranz"], "title": "Logic Programming with Extensible Types", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Logic programming languages present clear advantages in terms of declarativeness and conciseness. However, the ideas of logic programming have been met with resistance in other programming communities, and have not generally been adopted by other paradigms and languages. This paper proposes a novel way to incorporate logic programming in an existing codebase in a typed functional programming language. Our approach integrates with the host language without sacrificing static typing, and leverages strengths of typed functional programming such as polymorphism and higher-order. We do so by combining three ideas. First, we use the extensible types technique to allow values of the host language to contain logic variables. Second, we implement a unification algorithm that works for any data structure that supports certain operations.Third, we introduce a domain-specific language to define and query predicates. We demonstrate our proposal via a series of examples, and provide aids to make the notation convenient for users, showing that the proposed approach is not just technically possible but also practical. Our ideas have been implemented in the language Haskell with very good results.", "AI": {"tldr": "\u5728Haskell\u4e2d\u5b9e\u73b0\u903b\u8f91\u7f16\u7a0b\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7c7b\u578b\u3001\u901a\u7528\u7edf\u4e00\u7b97\u6cd5\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u4fdd\u6301\u9759\u6001\u7c7b\u578b\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\u4f18\u52bf", "motivation": "\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u5728\u58f0\u660e\u6027\u548c\u7b80\u6d01\u6027\u65b9\u9762\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4f46\u5176\u601d\u60f3\u5728\u5176\u4ed6\u7f16\u7a0b\u793e\u533a\u53d7\u5230\u62b5\u5236\uff0c\u672a\u80fd\u88ab\u5176\u4ed6\u8303\u5f0f\u548c\u8bed\u8a00\u666e\u904d\u91c7\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5728\u73b0\u6709\u7c7b\u578b\u5316\u51fd\u6570\u5f0f\u7f16\u7a0b\u4ee3\u7801\u5e93\u4e2d\u878d\u5165\u903b\u8f91\u7f16\u7a0b\u3002", "method": "\u7ed3\u5408\u4e09\u4e2a\u6838\u5fc3\u601d\u60f3\uff1a1) \u4f7f\u7528\u53ef\u6269\u5c55\u7c7b\u578b\u6280\u672f\uff0c\u5141\u8bb8\u5bbf\u4e3b\u8bed\u8a00\u503c\u5305\u542b\u903b\u8f91\u53d8\u91cf\uff1b2) \u5b9e\u73b0\u9002\u7528\u4e8e\u4efb\u4f55\u652f\u6301\u7279\u5b9a\u64cd\u4f5c\u7684\u6570\u636e\u7ed3\u6784\u7684\u7edf\u4e00\u7b97\u6cd5\uff1b3) \u5f15\u5165\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6765\u5b9a\u4e49\u548c\u67e5\u8be2\u8c13\u8bcd\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u793a\u4f8b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f7f\u7b26\u53f7\u8868\u793a\u5bf9\u7528\u6237\u66f4\u65b9\u4fbf\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u6280\u672f\u4e0a\u53ef\u884c\uff0c\u800c\u4e14\u5b9e\u7528\u3002\u8be5\u601d\u60f3\u5df2\u5728Haskell\u8bed\u8a00\u4e2d\u5b9e\u73b0\u5e76\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7c7b\u578b\u5316\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u4e2d\u96c6\u6210\u903b\u8f91\u7f16\u7a0b\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u5bbf\u4e3b\u8bed\u8a00\u65e0\u7f1d\u96c6\u6210\uff0c\u4e0d\u727a\u7272\u9759\u6001\u7c7b\u578b\uff0c\u540c\u65f6\u5229\u7528\u7c7b\u578b\u5316\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u4f18\u52bf\u5982\u591a\u6001\u6027\u548c\u9ad8\u9636\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u6280\u672f\u53ef\u884c\u6027\u548c\u5b9e\u7528\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2601.03854", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03854", "abs": "https://arxiv.org/abs/2601.03854", "authors": ["Ziyi Yang", "George P\u00eerlea", "Ilya Sergey"], "title": "Inductive First-Order Formula Synthesis by ASP: A Case Study in Invariant Inference", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "We present a framework for synthesising formulas in first-order logic (FOL) from examples, which unifies and advances state-of-the-art approaches for inference of transition system invariants. To do so, we study and categorise the existing methodologies, encoding techniques in their formula synthesis via answer set programming (ASP). Based on the derived categorisation, we propose orthogonal slices, a new technique for formula enumeration that partitions the search space into manageable chunks, enabling two approaches for incremental candidate pruning. Using a combination of existing techniques for first-order (FO) invariant synthesis and the orthogonal slices implemented in our framework FORCE, we significantly accelerate a state-of-the-art algorithm for distributed system invariant inference. We also show that our approach facilitates composition of different invariant inference frameworks, allowing for novel optimisations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ece\u793a\u4f8b\u5408\u6210\u4e00\u9636\u903b\u8f91\u516c\u5f0f\u7684\u6846\u67b6\uff0c\u7edf\u4e00\u5e76\u63a8\u8fdb\u4e86\u63a8\u7406\u8f6c\u6362\u7cfb\u7edf\u4e0d\u53d8\u91cf\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u5207\u7247\u6280\u672f\u663e\u8457\u52a0\u901f\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e0d\u53d8\u91cf\u7684\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u9636\u903b\u8f91\u516c\u5f0f\u5408\u6210\u65b9\u6cd5\u5728\u63a8\u7406\u8f6c\u6362\u7cfb\u7edf\u4e0d\u53d8\u91cf\u65f6\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u7edf\u4e00\u73b0\u6709\u65b9\u6cd5\u5e76\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u641c\u7d22\u7a7a\u95f4\u5212\u5206\u6280\u672f\u6765\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "1. \u7814\u7a76\u5e76\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7f16\u7801\u516c\u5f0f\u5408\u6210\uff1b2. \u63d0\u51fa\u6b63\u4ea4\u5207\u7247\u6280\u672f\uff0c\u5c06\u641c\u7d22\u7a7a\u95f4\u5212\u5206\u4e3a\u53ef\u7ba1\u7406\u7684\u5757\uff1b3. \u5b9e\u73b0\u4e24\u79cd\u589e\u91cf\u5019\u9009\u526a\u679d\u65b9\u6cd5\uff1b4. \u5728FORCE\u6846\u67b6\u4e2d\u7ed3\u5408\u73b0\u6709FO\u4e0d\u53d8\u91cf\u5408\u6210\u6280\u672f\u548c\u6b63\u4ea4\u5207\u7247\u3002", "result": "1. \u663e\u8457\u52a0\u901f\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e0d\u53d8\u91cf\u63a8\u7406\u7684\u6700\u5148\u8fdb\u7b97\u6cd5\uff1b2. \u4fc3\u8fdb\u4e86\u4e0d\u540c\u4e0d\u53d8\u91cf\u63a8\u7406\u6846\u67b6\u7684\u7ec4\u5408\uff0c\u5b9e\u73b0\u4e86\u65b0\u9896\u7684\u4f18\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u5207\u7247\u6280\u672f\u6709\u6548\u52a0\u901f\u4e86\u4e00\u9636\u903b\u8f91\u516c\u5f0f\u5408\u6210\uff0c\u4e3a\u4e0d\u53d8\u91cf\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u652f\u6301\u4e0d\u540c\u6846\u67b6\u7684\u7ec4\u5408\u4f18\u5316\u3002"}}
{"id": "2601.03897", "categories": ["cs.PL", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.03897", "abs": "https://arxiv.org/abs/2601.03897", "authors": ["Ziad Ismaili Alaoui", "Detlef Plump"], "title": "Implementing Binary Search Trees in GP 2 (Extended Abstract)", "comment": "In Proceedings GCM 2025, arXiv:2601.03249", "summary": "We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.", "AI": {"tldr": "\u5728GP 2\u56fe\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u652f\u6301\u63d2\u5165\u3001\u5220\u9664\u548c\u67e5\u8be2\u64cd\u4f5c\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e0e\u547d\u4ee4\u5f0f\u8bed\u8a00\u5b9e\u73b0\u76f8\u5f53", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u89c4\u5219\u57fa\u7840\u7684\u56fe\u7f16\u7a0b\u8bed\u8a00GP 2\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u7ed3\u6784\uff0c\u7279\u522b\u662f\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u4ee5\u9a8c\u8bc1\u56fe\u7f16\u7a0b\u8bed\u8a00\u5728\u5b9e\u73b0\u7ecf\u5178\u7b97\u6cd5\u6570\u636e\u7ed3\u6784\u65b9\u9762\u7684\u80fd\u529b", "method": "\u4f7f\u7528GP 2\u7684\u6839\u56fe\u8f6c\u6362\u89c4\u5219\u6765\u5b9e\u73b0\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u901a\u8fc7\u56fe\u53d8\u6362\u89c4\u5219\u6765\u6267\u884c\u63d2\u5165\u3001\u5220\u9664\u548c\u67e5\u8be2\u64cd\u4f5c", "result": "\u5b9e\u73b0\u4e86\u4e8c\u53c9\u641c\u7d22\u6811\u7684\u57fa\u672c\u64cd\u4f5c\uff0c\u6700\u574f\u60c5\u51b5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n)\uff0c\u5e73\u5747\u60c5\u51b5\u4e0b\u4e3aO(log n)\uff0c\u4e0e\u547d\u4ee4\u5f0f\u8bed\u8a00\u5b9e\u73b0\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u76f8\u5339\u914d", "conclusion": "\u5728GP 2\u56fe\u7f16\u7a0b\u8bed\u8a00\u4e2d\u6210\u529f\u5b9e\u73b0\u4e86\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u8bc1\u660e\u4e86\u56fe\u7f16\u7a0b\u8bed\u8a00\u80fd\u591f\u5b9e\u73b0\u4e0e\u4f20\u7edf\u547d\u4ee4\u5f0f\u8bed\u8a00\u76f8\u5f53\u6548\u7387\u7684\u6570\u636e\u7ed3\u6784\u7b97\u6cd5"}}
{"id": "2601.04085", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04085", "abs": "https://arxiv.org/abs/2601.04085", "authors": ["Jingwen Xu", "Yiyang Lu", "Changze Lv", "Zisu Huang", "Zhengkang Guo", "Zhengyuan Wang", "Muzhao Tian", "Xuanjing Huang", "Xiaoqing Zheng"], "title": "CSSG: Measuring Code Similarity with Semantic Graphs", "comment": null, "summary": "Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.", "AI": {"tldr": "CSSG\u662f\u4e00\u79cd\u57fa\u4e8e\u7a0b\u5e8f\u4f9d\u8d56\u56fe\u7684\u65b0\u578b\u4ee3\u7801\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u76f8\u6bd4\u57fa\u4e8e\u5b57\u7b26\u4e32\u91cd\u53e0\u6216\u8bed\u6cd5\u6811\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u4ee3\u7801\u7684\u6df1\u5c42\u8bed\u4e49\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff08\u5982BLEU\u3001CodeBLEU\u3001TSED\uff09\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u5b57\u7b26\u4e32\u91cd\u53e0\u6216\u62bd\u8c61\u8bed\u6cd5\u6811\u7ed3\u6784\uff0c\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u7a0b\u5e8f\u4e4b\u95f4\u7684\u6df1\u5c42\u8bed\u4e49\u5173\u7cfb\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u8bed\u4e49\u611f\u77e5\u7684\u4ee3\u7801\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCSSG\uff08\u57fa\u4e8e\u8bed\u4e49\u56fe\u7684\u4ee3\u7801\u76f8\u4f3c\u6027\uff09\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5229\u7528\u7a0b\u5e8f\u4f9d\u8d56\u56fe\u663e\u5f0f\u5efa\u6a21\u63a7\u5236\u4f9d\u8d56\u548c\u53d8\u91cf\u4ea4\u4e92\uff0c\u63d0\u4f9b\u8bed\u4e49\u611f\u77e5\u7684\u4ee3\u7801\u8868\u793a\u3002", "result": "\u5728CodeContests+\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCSSG\u5728\u5355\u8bed\u8a00\u548c\u8de8\u8bed\u8a00\u8bbe\u7f6e\u4e0b\uff0c\u5728\u533a\u5206\u66f4\u76f8\u4f3c\u4ee3\u7801\u548c\u8f83\u4e0d\u76f8\u4f3c\u4ee3\u7801\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\u3002", "conclusion": "\u4f9d\u8d56\u611f\u77e5\u7684\u56fe\u8868\u793a\u76f8\u6bd4\u8868\u9762\u7ea7\u6216\u57fa\u4e8e\u8bed\u6cd5\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4ee3\u7801\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u3002"}}
