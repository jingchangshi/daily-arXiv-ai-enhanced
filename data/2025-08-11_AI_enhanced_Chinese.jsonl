{"id": "2508.05997", "categories": ["cs.PL", "cs.LO", "I.2.2; I.2.4"], "pdf": "https://arxiv.org/pdf/2508.05997", "abs": "https://arxiv.org/abs/2508.05997", "authors": ["Aditi Kabra", "Jonathan Laurent", "Stefan Mitsch", "Andr\u00e9 Platzer"], "title": "Hybrid Game Control Envelope Synthesis", "comment": null, "summary": "Control problems for embedded systems like cars and trains can be modeled by\ntwo-player hybrid games. Control envelopes, which are families of safe control\nsolutions, correspond to nondeterministic winning policies of hybrid games,\nwhere each deterministic specialization of the policy is a control solution.\nThis paper synthesizes nondeterministic winning policies for hybrid games that\nare as permissive as possible. It introduces subvalue maps, a compositional\nrepresentation of such policies that enables verification and synthesis along\nthe structure of the game. An inductive logical characterization in\ndifferential game logic (dGL) checks whether a subvalue map induces a sound\ncontrol envelope which always induces a winning play. A policy is said to win\nif it always achieves the desirable outcome when the player follows it, no\nmatter what actions the opponent plays. The maximal subvalue map, which allows\nthe most action options while still winning, is shown to exist and satisfy a\nlogical characterization. A family of algorithms for nondeterministic policy\nsynthesis can be obtained from the inductive subvalue map soundness\ncharacterization. An implementation of these findings is evaluated on examples\nthat use the expressivity of dGL to model a range of diverse control\nchallenges.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff08\u5982\u6c7d\u8f66\u548c\u706b\u8f66\uff09\u7684\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u73a9\u5bb6\u6df7\u5408\u6e38\u620f\u5efa\u6a21\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c3d\u53ef\u80fd\u5bbd\u677e\u7684\u975e\u786e\u5b9a\u6027\u83b7\u80dc\u7b56\u7565\u5408\u6210\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u590d\u6742\u63a7\u5236\u95ee\u9898\u7684\u9700\u6c42\uff0c\u901a\u8fc7\u6df7\u5408\u6e38\u620f\u6a21\u578b\u5b9e\u73b0\u5b89\u5168\u63a7\u5236\u3002", "method": "\u5f15\u5165\u5b50\u503c\u6620\u5c04\u4f5c\u4e3a\u7b56\u7565\u7684\u7ec4\u6210\u8868\u793a\uff0c\u7ed3\u5408\u5fae\u5206\u6e38\u620f\u903b\u8f91\uff08dGL\uff09\u8fdb\u884c\u9a8c\u8bc1\u548c\u5408\u6210\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u5927\u5b50\u503c\u6620\u5c04\u7684\u5b58\u5728\u6027\u53ca\u5176\u903b\u8f91\u7279\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5173\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u5316\u63a7\u5236\u6311\u6218\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u8868\u8fbe\u529b\u3002"}}
{"id": "2508.05797", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2508.05797", "abs": "https://arxiv.org/abs/2508.05797", "authors": ["Sreeharsha Udayashankar", "Abdelrahman Baba", "Samer Al-Kiswany"], "title": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions", "comment": "Under review. This is the follow-up work to our FAST 2025 paper,\n  \"VectorCDC: Accelerating Data Deduplication with Vector Instructions\". The\n  associated code is available at https://github.com/UWASL/dedup-bench", "summary": "Content-defined Chunking (CDC) algorithms dictate the overall space savings\nthat deduplication systems achieve. However, due to their need to scan each\nfile in its entirety, they are slow and often the main performance bottleneck\nwithin data deduplication. We present VectorCDC, a method to accelerate\nhashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our\nevaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,\nachieving 8.35x - 26.2x higher throughput than existing vector-accelerated\ntechniques without affecting the deduplication space savings.", "AI": {"tldr": "VectorCDC\u5229\u7528\u5411\u91cfCPU\u6307\u4ee4\u52a0\u901f\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e0d\u5f71\u54cd\u53bb\u91cd\u7a7a\u95f4\u8282\u7701\u3002", "motivation": "CDC\u7b97\u6cd5\u56e0\u9700\u626b\u63cf\u6574\u4e2a\u6587\u4ef6\u800c\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u4e9f\u9700\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5411\u91cfCPU\u6307\u4ee4\uff08\u5982SSE/AVX\uff09\u4f18\u5316\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u79cdCPU\u4e0a\u5b9e\u73b08.35x-26.2x\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4e0d\u5f71\u54cd\u53bb\u91cd\u6548\u679c\u3002", "conclusion": "VectorCDC\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u517c\u5bb9\u6027\u5f3a\u7684CDC\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2508.05821", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.05821", "abs": "https://arxiv.org/abs/2508.05821", "authors": ["Shadman Sakib", "Ajay Katangur", "Rahul Dubey"], "title": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization", "comment": "Accepted for publication in 2025 IEEE Cloud Summit", "summary": "Cloud computing has grown rapidly in recent years, mainly due to the sharp\nincrease in data transferred over the internet. This growth makes load\nbalancing a key part of cloud systems, as it helps distribute user requests\nacross servers to maintain performance, prevent overload, and ensure a smooth\nuser experience. Despite its importance, managing server resources and keeping\nworkloads balanced over time remains a major challenge in cloud environments.\nThis paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that\nallocates workloads to virtual machines based on real-time performance metrics.\nThe objective is to enhance resource utilization and overall system efficiency.\nThe method was thoroughly tested using the CloudSim 7G platform, comparing its\nperformance against the throttled load balancing strategy. Evaluations were\nconducted across a variety of workloads and scenarios, demonstrating the\nSBDLB's ability to adapt dynamically to workload fluctuations while optimizing\nresource usage. The proposed method outperformed the throttled strategy,\nimproving average response times by 34% and 37% in different scenarios. It also\nreduced data center processing times by an average of 13%. Over a 24-hour\nsimulation, the method decreased operational costs by 15%, promoting a more\nenergy-efficient and sustainable cloud infrastructure through reduced energy\nconsumption.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u7684\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u5668\uff08SBDLB\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e91\u8ba1\u7b97\u7684\u8d44\u6e90\u5229\u7528\u7387\u548c\u7cfb\u7edf\u6548\u7387\u3002", "motivation": "\u968f\u7740\u4e91\u8ba1\u7b97\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8d1f\u8f7d\u5747\u8861\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u52a8\u6001\u5206\u914d\u7528\u6237\u8bf7\u6c42\u4ee5\u7ef4\u6301\u6027\u80fd\u548c\u9632\u6b62\u670d\u52a1\u5668\u8fc7\u8f7d\u3002", "method": "\u91c7\u7528Score-Based Dynamic Load Balancer\uff08SBDLB\uff09\uff0c\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u5206\u914d\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u5728CloudSim 7G\u5e73\u53f0\u4e0a\u4e0e\u8282\u6d41\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "SBDLB\u5728\u591a\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u63d0\u534734%-37%\uff0c\u6570\u636e\u4e2d\u5fc3\u5904\u7406\u65f6\u95f4\u51cf\u5c1113%\uff0c24\u5c0f\u65f6\u6a21\u62df\u4e2d\u8fd0\u8425\u6210\u672c\u964d\u4f4e15%\u3002", "conclusion": "SBDLB\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\uff0c\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e91\u8ba1\u7b97\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2508.05779", "categories": ["cs.AR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.05779", "abs": "https://arxiv.org/abs/2508.05779", "authors": ["Pengyu Liu", "Mingkuan Xu", "Hengyun Zhou", "Hanrui Wang", "Umut A. Acar", "Yunong Shi"], "title": "ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays", "comment": null, "summary": "Recent progress on concatenated codes, especially many-hypercube codes,\nachieves unprecedented space efficiency. Yet two critical challenges persist in\npractice. First, these codes lack efficient implementations of addressable\nlogical gates. Second, the required high degree of parallelism and long-range\ninteractions pose significant challenges for current hardware platforms. In\nthis paper, we propose an efficient compilation approach for concatenated\ncodes, specifically many-hypercube codes, targeted at neutral atom arrays,\nwhich provide the necessary parallelism and long-range interactions. Our\napproach builds on two key innovations. First, we introduce\nAutomorphism-assisted Hierarchical Addressing (AHA) logical CNOT gates that\nsignificantly reduce spacetime overhead compared to conventional\ndistillation-based methods. Second, we develop Virtual Atom Intermediate\nRepresentation (VAIR) that enables level-wise optimization and legalization. We\nimplement these innovations in ConiQ, a hardware-aware quantum compiler\ndesigned to compile fault-tolerant quantum circuits for neutral atom arrays\nusing many-hypercube codes. Our evaluation demonstrates that ConiQ achieves up\nto 2000x reduction in spacetime overhead and up to 10^6x reduction in\ncompilation time compared to state-of-the-art compilers, with our AHA gates\nproviding an additional overhead reduction of up to 20x. These results\nestablish concatenated codes as a promising approach for fault-tolerant quantum\ncomputing in the near future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e2d\u6027\u539f\u5b50\u9635\u5217\u7684\u9ad8\u6548\u7f16\u8bd1\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u65f6\u7a7a\u5f00\u9500\u548c\u7f16\u8bd1\u65f6\u95f4\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7ea7\u8054\u7801\u5728\u5b9e\u73b0\u53ef\u5bfb\u5740\u903b\u8f91\u95e8\u548c\u9ad8\u5e76\u884c\u6027\u9700\u6c42\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165AHA\u903b\u8f91CNOT\u95e8\u548cVAIR\u4e2d\u95f4\u8868\u793a\uff0c\u901a\u8fc7ConiQ\u7f16\u8bd1\u5668\u4f18\u5316\u3002", "result": "\u65f6\u7a7a\u5f00\u9500\u964d\u4f4e2000\u500d\uff0c\u7f16\u8bd1\u65f6\u95f4\u51cf\u5c1110^6\u500d\uff0cAHA\u95e8\u989d\u5916\u964d\u4f4e20\u500d\u5f00\u9500\u3002", "conclusion": "\u7ea7\u8054\u7801\u4e3a\u8fd1\u671f\u7684\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.05904", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.05904", "abs": "https://arxiv.org/abs/2508.05904", "authors": ["Brandon Baker", "Elliott Brossard", "Chenwei Xie", "Zihao Ye", "Deen Liu", "Yijun Xie", "Arthur Zwiegincew", "Nitya Kumar Sharma", "Gaurav Jain", "Eugene Retunsky", "Mike Halcrow", "Derek Denny-Brown", "Istvan Cseri", "Tyler Akidau", "Yuxiong He"], "title": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data", "comment": "12 pages, 6 figures, accepted in ICDCS 2025", "summary": "Snowflake revolutionized data analytics with an elastic architecture that\ndecouples compute and storage, enabling scalable solutions supporting data\narchitectures like data lake, data warehouse, data lakehouse, and data mesh.\nBuilding on this foundation, Snowflake has advanced its AI Data Cloud vision by\nintroducing Snowpark, a managed turnkey solution that supports data engineering\nand AI and ML workloads using Python and other programming languages.\n  This paper outlines Snowpark's design objectives towards high performance,\nstrong security and governance, and ease of use. We detail the architecture of\nSnowpark, highlighting its elastic scalability and seamless integration with\nSnowflake core compute infrastructure. This includes leveraging Snowflake\ncontrol plane for distributed computing and employing a secure sandbox for\nisolating Snowflake SQL workloads from Snowpark executions. Additionally, we\npresent core innovations in Snowpark that drive further performance\nenhancements, such as query initialization latency reduction through Python\npackage caching, improved workload scheduling for customized workloads, and\ndata skew management via efficient row redistribution. Finally, we showcase\nreal-world case studies that illustrate Snowpark's efficiency and effectiveness\nfor large-scale data engineering and AI and ML tasks.", "AI": {"tldr": "Snowpark\u662fSnowflake\u63a8\u51fa\u7684\u4e00\u4e2a\u6258\u7ba1\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u3001\u5f3a\u5b89\u5168\u6027\u548c\u6613\u7528\u6027\u3002", "motivation": "Snowflake\u5e0c\u671b\u901a\u8fc7Snowpark\u6269\u5c55\u5176AI Data Cloud\u613f\u666f\uff0c\u652f\u6301\u66f4\u591a\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\uff09\u548c\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "Snowpark\u91c7\u7528\u5f39\u6027\u53ef\u6269\u5c55\u67b6\u6784\uff0c\u4e0eSnowflake\u6838\u5fc3\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u65e0\u7f1d\u96c6\u6210\uff0c\u5229\u7528\u63a7\u5236\u5e73\u9762\u8fdb\u884c\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0c\u5e76\u901a\u8fc7\u5b89\u5168\u6c99\u7bb1\u9694\u79bbSQL\u548cSnowpark\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "Snowpark\u901a\u8fc7Python\u5305\u7f13\u5b58\u51cf\u5c11\u67e5\u8be2\u5ef6\u8fdf\uff0c\u4f18\u5316\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\uff0c\u5e76\u9ad8\u6548\u7ba1\u7406\u6570\u636e\u503e\u659c\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86Snowpark\u5728\u5927\u89c4\u6a21\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2508.06047", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.06047", "abs": "https://arxiv.org/abs/2508.06047", "authors": ["Suresh Purini", "Siddhant Garg", "Mudit Gaur", "Sankalp Bhat", "Sohan Mupparapu", "Arun Ravindran"], "title": "ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis", "comment": "Published in 7th ACM/IEEE International Symposium on Machine Learning\n  for CAD", "summary": "Modern SoC datapaths include deeply pipelined, domain-specific accelerators,\nbut their RTL implementation and verification are still mostly done by hand.\nWhile large language models (LLMs) exhibit advanced code-generation abilities\nfor programming languages like Python, their application to Verilog-like RTL\nremains in its nascent stage. This is reflected in the simple arithmetic and\ncontrol circuits currently used to evaluate generative capabilities in existing\nbenchmarks. In this paper, we introduce ArchXBench, a six-level benchmark suite\nthat encompasses complex arithmetic circuits and other advanced digital\nsubsystems drawn from domains such as cryptography, image processing, machine\nlearning, and signal processing. Architecturally, some of these designs are\npurely combinational, others are multi-cycle or pipelined, and many require\nhierarchical composition of modules. For each benchmark, we provide a problem\ndescription, design specification, and testbench, enabling rapid research in\nthe area of LLM-driven agentic approaches for complex digital systems design.\n  Using zero-shot prompting with Claude Sonnet 4, GPT 4.1, o4-mini-high, and\nDeepSeek R1 under a pass@5 criterion, we observed that o4-mini-high\nsuccessfully solves the largest number of benchmarks, 16 out of 30, spanning\nLevels 1, 2, and 3. From Level 4 onward, however, all models consistently fail,\nhighlighting a clear gap in the capabilities of current state-of-the-art LLMs\nand prompting/agentic approaches.", "AI": {"tldr": "ArchXBench\u662f\u4e00\u4e2a\u516d\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u590d\u6742\u6570\u5b57\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524dLLM\u5728\u9ad8\u7ea7\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\u3002", "motivation": "\u73b0\u4ee3SoC\u6570\u636e\u8def\u5f84\u4e2d\uff0cRTL\u5b9e\u73b0\u548c\u9a8c\u8bc1\u4ecd\u4f9d\u8d56\u624b\u5de5\uff0cLLM\u5728Verilog\u7c7bRTL\u4e2d\u7684\u5e94\u7528\u5c1a\u4e0d\u6210\u719f\uff0c\u9700\u8981\u66f4\u590d\u6742\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u5f15\u5165ArchXBench\u57fa\u51c6\u5957\u4ef6\uff0c\u5305\u542b\u590d\u6742\u7b97\u672f\u7535\u8def\u548c\u9ad8\u7ea7\u6570\u5b57\u5b50\u7cfb\u7edf\uff0c\u63d0\u4f9b\u95ee\u9898\u63cf\u8ff0\u3001\u8bbe\u8ba1\u89c4\u8303\u548c\u6d4b\u8bd5\u5e73\u53f0\u3002", "result": "\u5728\u96f6\u6837\u672c\u63d0\u793a\u4e0b\uff0co4-mini-high\u572830\u4e2a\u57fa\u51c6\u4e2d\u89e3\u51b3\u4e8616\u4e2a\uff08\u7ea7\u522b1-3\uff09\uff0c\u4f46\u4ece\u7ea7\u522b4\u5f00\u59cb\u6240\u6709\u6a21\u578b\u5747\u5931\u8d25\u3002", "conclusion": "\u5f53\u524dLLM\u548c\u63d0\u793a/\u4ee3\u7406\u65b9\u6cd5\u5728\u590d\u6742\u6570\u5b57\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.06001", "categories": ["cs.DC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06001", "abs": "https://arxiv.org/abs/2508.06001", "authors": ["Kai Zhang", "Peng Wang", "Sai Bi", "Jianming Zhang", "Yuanjun Xiong"], "title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "comment": "Code is available at https://github.com/Kai-46/KnapFormer/", "summary": "We present KnapFormer, an efficient and versatile framework to combine\nworkload balancing and sequence parallelism in distributed training of\nDiffusion Transformers (DiT). KnapFormer builds on the insight that strong\nsynergy exists between sequence parallelism and the need to address the\nsignificant token imbalance across ranks. This imbalance arises from\nvariable-length text inputs and varying visual token counts in mixed-resolution\nand image-video joint training. KnapFormer redistributes tokens by first\ngathering sequence length metadata across all ranks in a balancing group and\nsolving a global knapsack problem. The solver aims to minimize the variances of\ntotal workload per-GPU, while accounting for the effect of sequence\nparallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the\nload-balancing decision process and utilizing a simple semi-empirical workload\nmodel, KnapFormers achieves minimal communication overhead and less than 1%\nworkload discrepancy in real-world training workloads with sequence length\nvarying from a few hundred to tens of thousands. It eliminates straggler\neffects and achieves 2x to 3x speedup when training state-of-the-art diffusion\nmodels like FLUX on mixed-resolution and image-video joint data corpora. We\nopen-source the KnapFormer implementation at\nhttps://github.com/Kai-46/KnapFormer/", "AI": {"tldr": "KnapFormer\u662f\u4e00\u4e2a\u9ad8\u6548\u6846\u67b6\uff0c\u7ed3\u5408\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u548c\u5e8f\u5217\u5e76\u884c\u6027\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u8bad\u7ec3Diffusion Transformers\uff08DiT\uff09\u3002\u5b83\u901a\u8fc7\u89e3\u51b3\u5168\u5c40\u80cc\u5305\u95ee\u9898\u91cd\u65b0\u5206\u914d\u4ee4\u724c\uff0c\u51cf\u5c11\u5de5\u4f5c\u8d1f\u8f7d\u5dee\u5f02\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u3002", "motivation": "\u5728\u6df7\u5408\u5206\u8fa8\u7387\u548c\u56fe\u50cf-\u89c6\u9891\u8054\u5408\u8bad\u7ec3\u4e2d\uff0c\u53ef\u53d8\u957f\u5ea6\u6587\u672c\u8f93\u5165\u548c\u89c6\u89c9\u4ee4\u724c\u6570\u91cf\u5bfc\u81f4\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u5e73\u8861\uff0c\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u3002KnapFormer\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "KnapFormer\u901a\u8fc7\u6536\u96c6\u5e8f\u5217\u957f\u5ea6\u5143\u6570\u636e\u5e76\u89e3\u51b3\u5168\u5c40\u80cc\u5305\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u6bcfGPU\u5de5\u4f5c\u8d1f\u8f7d\u7684\u65b9\u5dee\uff0c\u540c\u65f6\u7ed3\u5408\u5e8f\u5217\u5e76\u884c\u6027\u3002", "result": "\u5728\u771f\u5b9e\u8bad\u7ec3\u4efb\u52a1\u4e2d\uff0cKnapFormer\u5b9e\u73b0\u5c0f\u4e8e1%\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5dee\u5f02\uff0c\u6d88\u9664\u62d6\u5c3e\u6548\u5e94\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53472\u81f33\u500d\u3002", "conclusion": "KnapFormer\u901a\u8fc7\u9ad8\u6548\u8d1f\u8f7d\u5e73\u8861\u548c\u5e8f\u5217\u5e76\u884c\u6027\uff0c\u663e\u8457\u63d0\u5347Diffusion Transformers\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u9002\u7528\u4e8e\u590d\u6742\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2508.06344", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.06344", "abs": "https://arxiv.org/abs/2508.06344", "authors": ["Robin Sehm", "Christian Ewert", "Rainer Buchty", "Mladen Berekovic", "Saleh Mulhem"], "title": "Nail: Not Another Fault-Injection Framework for Chisel-generated RTL", "comment": "PREPRINT - accepted In Proceedings of the 28th Euromicro Conference\n  Series on Digital System Design (DSD)", "summary": "Fault simulation and emulation are essential techniques for evaluating the\ndependability of integrated circuits, enabling early-stage vulnerability\nanalysis and supporting the implementation of effective mitigation strategies.\nHigh-level hardware description languages such as Chisel facilitate the rapid\ndevelopment of complex fault scenarios with minimal modification to the design.\nHowever, existing Chisel-based fault injection (FI) frameworks are limited by\ncoarse-grained, instruction-level controllability, restricting the precision of\nfault modeling. This work introduces Nail, a Chisel-based open-source FI\nframework that overcomes these limitations by introducing state-based faults.\nThis approach enables fault scenarios that depend on specific system states,\nrather than solely on instruction-level triggers, thereby removing the need for\nprecise timing of fault activation. For greater controllability, Nail allows\nusers to arbitrarily modify internal trigger states via software at runtime. To\nsupport this, Nail automatically generates a software interface, offering\nstraightforward access to the instrumented design. This enables fine-tuning of\nfault parameters during active FI campaigns - a feature particularly beneficial\nfor FPGA emulation, where synthesis is time-consuming. Utilizing these\nfeatures, Nail narrows the gap between the high speed of emulation-based FI\nframeworks, the usability of software-based approaches, and the controllability\nachieved in simulation. We demonstrate Nail's state-based FI and software\nframework by modeling a faulty general-purpose register in a RISC-V processor.\nAlthough this might appear straightforward, it requires state-dependent FI and\nwas previously impossible without fundamental changes to the design. The\napproach was validated in both simulation and FPGA emulation, where the\naddition of Nail introduced less than 1% resource overhead.", "AI": {"tldr": "Nail\u662f\u4e00\u4e2a\u57fa\u4e8eChisel\u7684\u5f00\u6e90\u6545\u969c\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u4f9d\u8d56\u7684\u6545\u969c\u6a21\u578b\u548c\u8fd0\u884c\u65f6\u8f6f\u4ef6\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86\u6545\u969c\u6a21\u62df\u7684\u7cbe\u786e\u6027\u548c\u53ef\u63a7\u6027\u3002", "motivation": "\u73b0\u6709Chisel\u6545\u969c\u6ce8\u5165\u6846\u67b6\u5728\u6307\u4ee4\u7ea7\u63a7\u5236\u4e0a\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u9650\u5236\u4e86\u6545\u969c\u5efa\u6a21\u7684\u7cbe\u786e\u6027\u3002", "method": "Nail\u5f15\u5165\u72b6\u6001\u4f9d\u8d56\u7684\u6545\u969c\u6a21\u578b\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u901a\u8fc7\u8f6f\u4ef6\u4fee\u6539\u89e6\u53d1\u72b6\u6001\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u63a5\u53e3\u3002", "result": "\u5728RISC-V\u5904\u7406\u5668\u4e0a\u9a8c\u8bc1\u4e86\u72b6\u6001\u4f9d\u8d56\u6545\u969c\u6ce8\u5165\uff0c\u4eff\u771f\u548cFPGA\u6a21\u62df\u4e2d\u8d44\u6e90\u5f00\u9500\u4f4e\u4e8e1%\u3002", "conclusion": "Nail\u586b\u8865\u4e86\u4eff\u771f\u901f\u5ea6\u3001\u8f6f\u4ef6\u6613\u7528\u6027\u548c\u6a21\u62df\u53ef\u63a7\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.06024", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.06024", "abs": "https://arxiv.org/abs/2508.06024", "authors": ["Zheming Yang", "Yunqing Hu", "Sheng Sun", "Wen Ji"], "title": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference", "comment": "9 pages, 8 figures", "summary": "The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to\nscale up model capacity while maintaining inference efficiency. However,\ndeploying MoE models across heterogeneous end-cloud environments poses new\nchallenges in expert scheduling, communication overhead, and resource\nheterogeneity. In this paper, we propose EC2MoE, an adaptive framework for\nscalable MoE inference via end-cloud pipeline collaboration. First, we design a\nhardware-aware lightweight group gate network that enhances expert selection\nand computational efficiency. By incorporating a hardware-aware local expert\nselection mechanism, the system adaptively filters candidate experts based on\nreal-time device profiles. A lightweight group gate module then integrates\nlocal and global gating outputs to achieve high-quality expert routing with\nminimal overhead. Second, we develop a pipeline optimization mechanism based on\nendcloud collaboration to accelerate MoE inference. This includes an\nencoder-decoder structure based on low-rank compression, which reduces\ntransmission and computation costs. And a route-aware heuristic pipeline\nscheduling algorithm that dynamically allocates inference stages across devices\naccording to workload and network topology. Extensive experiments show that\nEC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by\n53% to 67% while maintaining high accuracy compared to state-of-the-art\nmethods. It also maintains good scalability under dynamic load and network\nenvironments.", "AI": {"tldr": "EC2MoE\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u7aef\u4e91\u534f\u4f5c\u4f18\u5316\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u4e13\u5bb6\u8c03\u5ea6\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u5f02\u6784\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3MoE\u6a21\u578b\u5728\u5f02\u6784\u7aef\u4e91\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\u7684\u4e13\u5bb6\u8c03\u5ea6\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u5f02\u6784\u6027\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u786c\u4ef6\u611f\u77e5\u7684\u8f7b\u91cf\u7ea7\u7ec4\u95e8\u7f51\u7edc\u548c\u7aef\u4e91\u534f\u4f5c\u7684\u6d41\u6c34\u7ebf\u4f18\u5316\u673a\u5236\uff0c\u5305\u62ec\u4f4e\u79e9\u538b\u7f29\u548c\u52a8\u6001\u8c03\u5ea6\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEC2MoE\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u541e\u5410\u91cf\u63d0\u53472.2x\u81f35.1x\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e53%\u81f367%\u3002", "conclusion": "EC2MoE\u5728\u52a8\u6001\u8d1f\u8f7d\u548c\u7f51\u7edc\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2508.06297", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.06297", "abs": "https://arxiv.org/abs/2508.06297", "authors": ["Yanyu Liu", "Jingying Fu", "Sixiang Liu", "Yitian Zou", "You Fu", "Jiehan Zhou", "Shouhua Zhang"], "title": "KV Cache Compression for Inference Efficiency in LLMs: A Review", "comment": "12 pages", "summary": "Withtherapid advancement of large language models (LLMs), the context length\nfor inference has been continuously increasing, leading to an exponential\ngrowth in the demand for Key-Value (KV) caching. This has resulted in a\nsignificant memory bottleneck, limiting the inference efficiency and\nscalability of the models. Therefore, optimizing the KV cache during inference\nis crucial for enhancing performance and efficiency. This review systematically\nexamines current KV cache optimization techniques, including compression\nstrategies such as selective token strategies, quantization, and attention\ncompression. We evaluate the effectiveness, trade-offs, and application\nscenarios of these methods, providing a comprehensive analysis of their impact\non memory usage and inference speed. We focus on identifying the limitations\nand challenges of existing methods, such as compatibility issues with different\nmodels and tasks. Additionally, this review highlights future research\ndirections, including hybrid optimization techniques, adaptive dynamic\nstrategies, and software-hardware co-design. These approaches aim to improve\ninference efficiency and promote the practical application of large language\nmodels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2d\u952e\u503c\uff08KV\uff09\u7f13\u5b58\u7684\u4f18\u5316\u6280\u672f\uff0c\u5206\u6790\u4e86\u538b\u7f29\u7b56\u7565\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740LLMs\u63a8\u7406\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u589e\u52a0\uff0cKV\u7f13\u5b58\u9700\u6c42\u5448\u6307\u6570\u589e\u957f\uff0c\u5bfc\u81f4\u5185\u5b58\u74f6\u9888\uff0c\u5f71\u54cd\u63a8\u7406\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002\u56e0\u6b64\uff0c\u4f18\u5316KV\u7f13\u5b58\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7cfb\u7edf\u5ba1\u67e5\u4e86\u5f53\u524dKV\u7f13\u5b58\u4f18\u5316\u6280\u672f\uff0c\u5305\u62ec\u9009\u62e9\u6027\u4ee4\u724c\u7b56\u7565\u3001\u91cf\u5316\u548c\u6ce8\u610f\u529b\u538b\u7f29\u7b49\u538b\u7f29\u7b56\u7565\uff0c\u5e76\u8bc4\u4f30\u5176\u6548\u679c\u3001\u6743\u8861\u548c\u5e94\u7528\u573a\u666f\u3002", "result": "\u5206\u6790\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u901f\u5ea6\u7684\u5f71\u54cd\uff0c\u6307\u51fa\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u548c\u6311\u6218\uff0c\u5982\u4e0e\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u7684\u517c\u5bb9\u6027\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u6df7\u5408\u4f18\u5316\u6280\u672f\u3001\u81ea\u9002\u5e94\u52a8\u6001\u7b56\u7565\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u5e76\u4fc3\u8fdbLLMs\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.06339", "categories": ["cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2508.06339", "abs": "https://arxiv.org/abs/2508.06339", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Valentin Churavy", "Alan Edelman"], "title": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision", "comment": "12 pages, 6 figures, 4 tables", "summary": "This paper presents a portable, GPU-accelerated implementation of a QR-based\nsingular value computation algorithm in Julia. The singular value ecomposition\n(SVD) is a fundamental numerical tool in scientific computing and machine\nlearning, providing optimal low-rank matrix approximations. Its importance has\nincreased even more in large-scale machine learning pipelines, including large\nlanguage models (LLMs), where it enables low-rank adaptation (LoRA). The\nimplemented algorithm is based on the classic two-stage QR reduction,\nconsisting of successive matrix reduction to band form and bidiagonal form. Our\nimplementation leverages Julia's multiple dispatch and metaprogramming\ncapabilities, integrating with the GPUArrays and KernelAbstractions frameworks\nto provide a unified type and hardware-agnostic function. It supports diverse\nGPU architectures and data types, and is, to our knowledge, the first\nGPU-accelerated singular value implementation to support Apple Metal GPUs and\nhalf precision. Performance results on multiple GPU backends and data types\ndemonstrate that portability does not require sacrificing performance: the\nunified function outperforms most linear algebra libraries (MAGMA, SLATE,\nrocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%\nof the performance of cuSOLVER for large matrices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eJulia\u7684\u4fbf\u643a\u5f0f\u3001GPU\u52a0\u901f\u7684QR\u5947\u5f02\u503c\u8ba1\u7b97\u7b97\u6cd5\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u79cdGPU\u67b6\u6784\u548c\u6570\u636e\u7c7b\u578b\uff0c\u6027\u80fd\u4f18\u4e8e\u591a\u6570\u7ebf\u6027\u4ee3\u6570\u5e93\u3002", "motivation": "\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u662f\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u57fa\u7840\u5de5\u5177\uff0c\u5c24\u5176\u5728\u5927\u578b\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982LLMs\uff09\u4e2d\u7528\u4e8e\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u3002\u73b0\u6709\u5b9e\u73b0\u7f3a\u4e4f\u5bf9Apple Metal GPU\u548c\u534a\u7cbe\u5ea6\u7684\u652f\u6301\uff0c\u4e14\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u7ecf\u5178\u7684\u4e24\u9636\u6bb5QR\u7ea6\u7b80\u7b97\u6cd5\uff0c\u7ed3\u5408Julia\u7684\u591a\u91cd\u5206\u6d3e\u548c\u5143\u7f16\u7a0b\u80fd\u529b\uff0c\u96c6\u6210GPUArrays\u548cKernelAbstractions\u6846\u67b6\uff0c\u5b9e\u73b0\u786c\u4ef6\u65e0\u5173\u7684\u7edf\u4e00\u51fd\u6570\u3002", "result": "\u5728\u591a\u79cdGPU\u540e\u7aef\u548c\u6570\u636e\u7c7b\u578b\u4e0a\uff0c\u6027\u80fd\u4f18\u4e8eMAGMA\u3001SLATE\u7b49\u5e93\uff0c\u5bf9\u5927\u578b\u77e9\u9635\uff08>1024x1024\uff09\u8fbe\u5230cuSOLVER\u768480%-90%\u6027\u80fd\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u8bc1\u660e\u4e86\u4fbf\u643a\u6027\u4e0d\u727a\u7272\u6027\u80fd\uff0c\u9996\u6b21\u652f\u6301Apple Metal GPU\u548c\u534a\u7cbe\u5ea6\uff0c\u4e3a\u5927\u89c4\u6a21SVD\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06406", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06406", "abs": "https://arxiv.org/abs/2508.06406", "authors": ["Murtaza Rangwala", "Venugopal K R", "Rajkumar Buyya"], "title": "Blockchain-Enabled Federated Learning", "comment": "32 pages, 6 figures, chapter for edited book (Federated Learning:\n  Foundations and Applications)", "summary": "Blockchain-enabled federated learning (BCFL) addresses fundamental challenges\nof trust, privacy, and coordination in collaborative AI systems. This chapter\nprovides comprehensive architectural analysis of BCFL systems through a\nsystematic four-dimensional taxonomy examining coordination structures,\nconsensus mechanisms, storage architectures, and trust models. We analyze\ndesign patterns from blockchain-verified centralized coordination to fully\ndecentralized peer-to-peer networks, evaluating trade-offs in scalability,\nsecurity, and performance. Through detailed examination of consensus mechanisms\ndesigned for federated learning contexts, including Proof of Quality and Proof\nof Federated Learning, we demonstrate how computational work can be repurposed\nfrom arbitrary cryptographic puzzles to productive machine learning tasks. The\nchapter addresses critical storage challenges by examining multi-tier\narchitectures that balance blockchain's transaction constraints with neural\nnetworks' large parameter requirements while maintaining cryptographic\nintegrity. A technical case study of the TrustMesh framework illustrates\npractical implementation considerations in BCFL systems through distributed\nimage classification training, demonstrating effective collaborative learning\nacross IoT devices with highly non-IID data distributions while maintaining\ncomplete transparency and fault tolerance. Analysis of real-world deployments\nacross healthcare consortiums, financial services, and IoT security\napplications validates the practical viability of BCFL systems, achieving\nperformance comparable to centralized approaches while providing enhanced\nsecurity guarantees and enabling new models of trustless collaborative\nintelligence.", "AI": {"tldr": "\u533a\u5757\u94fe\u8054\u90a6\u5b66\u4e60\uff08BCFL\uff09\u901a\u8fc7\u56db\u7ef4\u5206\u7c7b\u6cd5\u5206\u6790\u67b6\u6784\uff0c\u89e3\u51b3\u534f\u4f5cAI\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u9690\u79c1\u548c\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u534f\u4f5cAI\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u9690\u79c1\u548c\u534f\u8c03\u6311\u6218\u3002", "method": "\u901a\u8fc7\u56db\u7ef4\u5206\u7c7b\u6cd5\uff08\u534f\u8c03\u7ed3\u6784\u3001\u5171\u8bc6\u673a\u5236\u3001\u5b58\u50a8\u67b6\u6784\u548c\u4fe1\u4efb\u6a21\u578b\uff09\u5206\u6790BCFL\u7cfb\u7edf\uff0c\u7814\u7a76\u8bbe\u8ba1\u6a21\u5f0f\u548c\u5171\u8bc6\u673a\u5236\u3002", "result": "\u5c55\u793a\u4e86BCFL\u5728\u533b\u7597\u3001\u91d1\u878d\u548c\u7269\u8054\u7f51\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u6027\u80fd\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002", "conclusion": "BCFL\u7cfb\u7edf\u5728\u534f\u4f5c\u667a\u80fd\u4e2d\u5b9e\u73b0\u4e86\u900f\u660e\u6027\u548c\u5bb9\u9519\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
