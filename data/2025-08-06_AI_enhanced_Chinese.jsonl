{"id": "2508.02857", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.02857", "abs": "https://arxiv.org/abs/2508.02857", "authors": ["Mikhail Mints", "Finn Voichick", "Leonidas Lampropoulos", "Robert Rand"], "title": "Compositional Quantum Control Flow with Efficient Compilation in Qunity", "comment": "88 pages, 30 figures", "summary": "Most existing quantum programming languages are based on the quantum circuit\nmodel of computation, as higher-level abstractions are particularly challenging\nto implement - especially ones relating to quantum control flow. The Qunity\nlanguage, proposed by Voichick et al., offered such an abstraction in the form\nof a quantum control construct, with great care taken to ensure that the\nresulting language is still realizable. However, Qunity lacked a working\nimplementation, and the originally proposed compilation procedure was very\ninefficient, with even simple quantum algorithms compiling to unreasonably\nlarge circuits.\n  In this work, we focus on the efficient compilation of high-level quantum\ncontrol flow constructs, using Qunity as our starting point. We introduce a\nwider range of abstractions on top of Qunity's core language that offer\ncompelling trade-offs compared to its existing control construct. We create a\ncomplete implementation of a Qunity compiler, which converts high-level Qunity\ncode into the quantum assembly language OpenQASM 3. We develop optimization\ntechniques for multiple stages of the Qunity compilation procedure, including\nboth low-level circuit optimizations as well as methods that consider the\nhigh-level structure of a Qunity program, greatly reducing the number of qubits\nand gates used by the compiler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u91cf\u5b50\u63a7\u5236\u6d41\u6784\u9020\u7f16\u8bd1\u65b9\u6cd5\uff0c\u57fa\u4e8eQunity\u8bed\u8a00\uff0c\u901a\u8fc7\u4f18\u5316\u6280\u672f\u663e\u8457\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u548c\u95e8\u7684\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u6548\u7684\u9ad8\u5c42\u62bd\u8c61\u5b9e\u73b0\uff0c\u5c24\u5176\u662f\u91cf\u5b50\u63a7\u5236\u6d41\u6784\u9020\uff0cQunity\u867d\u6709\u63d0\u51fa\u4f46\u7f3a\u4e4f\u5b9e\u73b0\u4e14\u7f16\u8bd1\u6548\u7387\u4f4e\u3002", "method": "\u5728Qunity\u57fa\u7840\u4e0a\u5f15\u5165\u66f4\u591a\u62bd\u8c61\u6784\u9020\uff0c\u5f00\u53d1\u5b8c\u6574\u7684\u7f16\u8bd1\u5668\u5b9e\u73b0\uff0c\u5e76\u4f18\u5316\u7f16\u8bd1\u6d41\u7a0b\u7684\u591a\u4e2a\u9636\u6bb5\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684Qunity\u7f16\u8bd1\u5668\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u548c\u95e8\u7684\u6570\u91cf\uff0c\u751f\u6210OpenQASM 3\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6280\u672f\uff0c\u6210\u529f\u63d0\u5347\u4e86\u91cf\u5b50\u63a7\u5236\u6d41\u6784\u9020\u7684\u7f16\u8bd1\u6548\u7387\uff0c\u4e3a\u9ad8\u5c42\u91cf\u5b50\u7f16\u7a0b\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.03558", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03558", "abs": "https://arxiv.org/abs/2508.03558", "authors": ["M Zafir Sadik Khan", "Nowfel Mashnoor", "Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation", "comment": "Accepted to the IEEE International Conference on Computer Design\n  (ICCD 2025)", "summary": "In today's rapidly evolving field of electronic design automation (EDA), the\ncomplexity of hardware designs is increasing, necessitating more sophisticated\nautomation solutions. High-level synthesis (HLS), as a pivotal solution,\nautomates hardware designs from high-level abstractions (e.g., C/C++). However,\nit faces significant challenges, particularly in design space exploration and\noptimization. While large language models (LLMs) have shown notable\ncapabilities in code generation, their application to HLS has been limited due\nto the scarcity of (publicly) available HLS code datasets. Hence, research in\nthis domain has primarily focused on techniques such as prompt engineering and\nretrieval-augmented generation (RAG). To overcome this limitation, this paper\nintroduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS\ncode generation. Our method includes three key advancements: (i) We implement\nVerilog-to-C/C++ porting, converting verified and synthesizable Verilog codes\ninto corresponding C, creating a dataset of 16.7K HLS codes; (ii) We implement\na fine-tuning strategy, which is based on instruction prompting to code\ngeneration guided by abstract syntax tree (AST); (iii) We develop a\nsemi-automated evaluation framework using VerilogEval to assess the\nfunctionality of the generated HLS code. Our experiments show that SAGE-HLS,\nfined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100% success rate\nin code synthesizability and a 75% success rate in functional correctness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSAGE-HLS\uff0c\u4e00\u79cd\u9488\u5bf9HLS\u4ee3\u7801\u751f\u6210\u7684\u5fae\u8c03LLM\uff0c\u89e3\u51b3\u4e86HLS\u9886\u57df\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u901a\u8fc7Verilog-to-C/C++\u8f6c\u6362\u3001AST\u5f15\u5bfc\u7684\u5fae\u8c03\u7b56\u7565\u548c\u534a\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6210\u529f\u7387\u7684\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u7531\u4e8eHLS\u9886\u57df\u516c\u5f00\u4ee3\u7801\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u73b0\u6709LLM\u5728HLS\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e94\u7528\u53d7\u9650\uff0c\u4e9f\u9700\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9HLS\u7684\u5fae\u8c03\u6a21\u578b\u3002", "method": "1. \u901a\u8fc7Verilog-to-C/C++\u8f6c\u6362\u521b\u5efa16.7K HLS\u4ee3\u7801\u6570\u636e\u96c6\uff1b2. \u57fa\u4e8eAST\u7684\u6307\u4ee4\u63d0\u793a\u5fae\u8c03\u7b56\u7565\uff1b3. \u4f7f\u7528VerilogEval\u534a\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "result": "SAGE-HLS\u5728QwenCoder (2.5) 7B\u6a21\u578b\u4e0a\u5fae\u8c03\u540e\uff0c\u4ee3\u7801\u53ef\u5408\u6210\u7387\u63a5\u8fd1100%\uff0c\u529f\u80fd\u6b63\u786e\u7387\u8fbe75%\u3002", "conclusion": "SAGE-HLS\u4e3a\u89e3\u51b3HLS\u4ee3\u7801\u751f\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u529f\u80fd\u6027\u3002"}}
{"id": "2508.03640", "categories": ["cs.PL", "D.3.2;D.3.4;K.3.1"], "pdf": "https://arxiv.org/pdf/2508.03640", "abs": "https://arxiv.org/abs/2508.03640", "authors": ["Pedro Vasconcelos"], "title": "Teaching Introductory Functional Programming Using Haskelite", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "Learning functional programming requires learning a substitution-based\ncomputational model. While substitution should be a familiar concept from\nhigh-school algebra, students often have difficulty applying it to new\nsettings, such as recursive definitions, algebraic data types and higher-order\nfunctions. Step-by-step interpreters have been shown to help beginners by\nclarifying misconceptions and improving understanding.\n  This paper reports on the experience of using a step-by-step tracing\ninterpreter for a subset of Haskell while teaching an introductory functional\nprogramming course at the University of Porto. We describe the use of the\ninterpreter, present some feedback obtained from students, reflect on the\nlessons learned and point directions for further work.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6559\u6388\u51fd\u6570\u5f0f\u7f16\u7a0b\u65f6\u4f7f\u7528\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u7684\u7ecf\u9a8c\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u9012\u5f52\u3001\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u548c\u9ad8\u9636\u51fd\u6570\u65b9\u9762\u7684\u6548\u679c\u3002", "motivation": "\u5b66\u751f\u5728\u5b66\u4e60\u51fd\u6570\u5f0f\u7f16\u7a0b\u65f6\u5bf9\u66ff\u6362\u6982\u5ff5\u7684\u5e94\u7528\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u9012\u5f52\u5b9a\u4e49\u3001\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u548c\u9ad8\u9636\u51fd\u6570\u7b49\u65b0\u573a\u666f\u4e2d\u3002\u9010\u6b65\u89e3\u91ca\u5668\u88ab\u8bc1\u660e\u80fd\u5e2e\u52a9\u521d\u5b66\u8005\u6f84\u6e05\u8bef\u89e3\u5e76\u63d0\u5347\u7406\u89e3\u3002", "method": "\u5728\u6ce2\u5c14\u56fe\u5927\u5b66\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\u5165\u95e8\u8bfe\u7a0b\u4e2d\uff0c\u4f7f\u7528\u4e86\u4e00\u4e2a\u9488\u5bf9Haskell\u5b50\u96c6\u7684\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\uff0c\u5e76\u6536\u96c6\u4e86\u5b66\u751f\u7684\u53cd\u9988\u3002", "result": "\u5b66\u751f\u53cd\u9988\u8868\u660e\u9010\u6b65\u89e3\u91ca\u5668\u6709\u52a9\u4e8e\u7406\u89e3\u590d\u6742\u6982\u5ff5\uff0c\u8bfe\u7a0b\u7ecf\u9a8c\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u5728\u6559\u5b66\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u5176\u5e94\u7528\u3002"}}
{"id": "2508.02705", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02705", "abs": "https://arxiv.org/abs/2508.02705", "authors": ["Wei Li", "Limei Hu", "Feng Chen", "Ye Yao"], "title": "Low-Communication Resilient Distributed Estimation Algorithm Based on Memory Mechanism", "comment": null, "summary": "In multi-task adversarial networks, the accurate estimation of unknown\nparameters in a distributed algorithm is hindered by attacked nodes or links.\nTo tackle this challenge, this brief proposes a low-communication resilient\ndistributed estimation algorithm. First, a node selection strategy based on\nreputation is introduced that allows nodes to communicate with more reliable\nsubset of neighbors. Subsequently, to discern trustworthy intermediate\nestimates, the Weighted Support Vector Data Description (W-SVDD) model is\nemployed to train the memory data. This trained model contributes to reinforce\nthe resilience of the distributed estimation process against the impact of\nattacked nodes or links. Additionally, an event-triggered mechanism is\nintroduced to minimize ineffective updates to the W-SVDD model, and a suitable\nthreshold is derived based on assumptions. The convergence of the algorithm is\nanalyzed. Finally, simulation results demonstrate that the proposed algorithm\nachieves superior performance with less communication cost compared to other\nalgorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u901a\u4fe1\u7684\u5f39\u6027\u5206\u5e03\u5f0f\u4f30\u8ba1\u7b97\u6cd5\uff0c\u901a\u8fc7\u4fe1\u8a89\u8282\u70b9\u9009\u62e9\u548cW-SVDD\u6a21\u578b\u589e\u5f3a\u6297\u653b\u51fb\u80fd\u529b\uff0c\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u591a\u4efb\u52a1\u5bf9\u6297\u7f51\u7edc\u4e2d\u56e0\u53d7\u653b\u51fb\u8282\u70b9\u6216\u94fe\u8def\u5bfc\u81f4\u7684\u53c2\u6570\u4f30\u8ba1\u4e0d\u51c6\u786e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4fe1\u8a89\u8282\u70b9\u9009\u62e9\u7b56\u7565\u548cW-SVDD\u6a21\u578b\u8bad\u7ec3\u6570\u636e\uff0c\u5f15\u5165\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\u51cf\u5c11\u65e0\u6548\u66f4\u65b0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u7b97\u6cd5\u5728\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u7684\u540c\u65f6\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u901a\u8fc7\u4fe1\u8a89\u9009\u62e9\u548cW-SVDD\u6a21\u578b\u6709\u6548\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u4f30\u8ba1\u7684\u5f39\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.02977", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2508.02977", "abs": "https://arxiv.org/abs/2508.02977", "authors": ["Dongho Yoon", "Gungyu Lee", "Jaewon Chang", "Yunjae Lee", "Dongjae Lee", "Minsoo Rhu"], "title": "Mamba-X: An End-to-End Vision Mamba Accelerator for Edge Computing Devices", "comment": "Accepted for publication at the 44th International Conference on\n  Computer-Aided Design (ICCAD), 2025", "summary": "Transformers have proven effective in language modeling but are limited by\nhigh computational and memory demands that grow quadratically with input\nsequence length. State space models (SSMs) offer a promising alternative by\nreducing attention complexity from $O(L^2)$ to $O(L)$ while also lowering\noverall memory consumption. Vision Mamba adapts the SSM approach for computer\nvision tasks, achieving lower latency and memory consumption than traditional\ntransformer models. However, deploying Vision Mamba on edge devices is\nchallenging due to its sequential scan operations, which hinder GPU efficiency.\nWe propose Mamba-X, an end-to-end Vision Mamba accelerator that includes a\nsystolic scan array to maximize parallelism and minimize memory traffic, along\nwith a hybrid, hardware-friendly quantization technique to reduce memory usage\nand improve hardware efficiency without sacrificing accuracy.", "AI": {"tldr": "Vision Mamba\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u4f46GPU\u6548\u7387\u53d7\u9650\u3002Mamba-X\u901a\u8fc7\u5e76\u884c\u626b\u63cf\u9635\u5217\u548c\u91cf\u5316\u6280\u672f\u4f18\u5316\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3Transformer\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9ad8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316Vision Mamba\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u6548\u7387\u3002", "method": "\u63d0\u51faMamba-X\u52a0\u901f\u5668\uff0c\u91c7\u7528\u5e76\u884c\u626b\u63cf\u9635\u5217\u548c\u6df7\u5408\u91cf\u5316\u6280\u672f\u3002", "result": "\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u5185\u5b58\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "Mamba-X\u4e3aVision Mamba\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.02708", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02708", "abs": "https://arxiv.org/abs/2508.02708", "authors": ["Mario Scrocca", "Marco Grassi", "Alessio Carenini", "Jean-Paul Calbimonte", "Darko Anicic", "Irene Celino"], "title": "A DataOps Toolbox Enabling Continuous Semantic Integration of Devices for Edge-Cloud AI Applications", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution will\n  be published in The Semantic Web - ISWC 2025", "summary": "The implementation of AI-based applications in complex environments often\nrequires the collaboration of several devices spanning from edge to cloud.\nIdentifying the required devices and configuring them to collaborate is a\nchallenge relevant to different scenarios, like industrial shopfloors, road\ninfrastructures, and healthcare therapies. We discuss the design and\nimplementation of a DataOps toolbox leveraging Semantic Web technologies and a\nlow-code mechanism to address heterogeneous data interoperability requirements\nin the development of such applications. The toolbox supports a continuous\nsemantic integration approach to tackle various types of devices, data formats,\nand semantics, as well as different communication interfaces. The paper\npresents the application of the toolbox to three use cases from different\ndomains, the DataOps pipelines implemented, and how they guarantee\ninteroperability of static nodes' information and runtime data exchanges.\nFinally, we discuss the results from the piloting activities in the use cases\nand the lessons learned.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49Web\u6280\u672f\u548c\u4f4e\u4ee3\u7801\u673a\u5236\u7684DataOps\u5de5\u5177\u7bb1\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e2dAI\u5e94\u7528\u7684\u591a\u8bbe\u5907\u534f\u4f5c\u4e0e\u6570\u636e\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u590d\u6742\u73af\u5883\u4e2d\uff08\u5982\u5de5\u4e1a\u8f66\u95f4\u3001\u9053\u8def\u57fa\u7840\u8bbe\u65bd\u548c\u533b\u7597\u6cbb\u7597\uff09\u5b9e\u73b0AI\u5e94\u7528\u65f6\uff0c\u591a\u8bbe\u5907\u534f\u4f5c\u4e0e\u5f02\u6784\u6570\u636e\u4e92\u64cd\u4f5c\u6027\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2aDataOps\u5de5\u5177\u7bb1\uff0c\u91c7\u7528\u8bed\u4e49Web\u6280\u672f\u548c\u4f4e\u4ee3\u7801\u673a\u5236\uff0c\u652f\u6301\u6301\u7eed\u8bed\u4e49\u96c6\u6210\uff0c\u4ee5\u5904\u7406\u591a\u79cd\u8bbe\u5907\u3001\u6570\u636e\u683c\u5f0f\u3001\u8bed\u4e49\u548c\u901a\u4fe1\u63a5\u53e3\u3002", "result": "\u5de5\u5177\u7bb1\u5728\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u7528\u4f8b\u4e2d\u6210\u529f\u5e94\u7528\uff0c\u5b9e\u73b0\u4e86\u9759\u6001\u8282\u70b9\u4fe1\u606f\u548c\u8fd0\u884c\u65f6\u6570\u636e\u4ea4\u6362\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "\u901a\u8fc7\u8bd5\u70b9\u6d3b\u52a8\u9a8c\u8bc1\u4e86\u5de5\u5177\u7bb1\u7684\u6709\u6548\u6027\uff0c\u5e76\u603b\u7ed3\u4e86\u76f8\u5173\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2508.02992", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.02992", "abs": "https://arxiv.org/abs/2508.02992", "authors": ["Peijing Li", "Muhammad Shahir Abdurraman", "Rachel Cleaveland", "Sergey Legtchenko", "Philip Levis", "Ioan Stefanovici", "Thierry Tambe", "David Tennenhouse", "Caroline Trippel"], "title": "Towards Memory Specialization: A Case for Long-Term and Short-Term RAM", "comment": "9 pages, 3 figures", "summary": "Both SRAM and DRAM have stopped scaling: there is no technical roadmap to\nreduce their cost (per byte/GB). As a result, memory now dominates system cost.\nThis paper argues for a paradigm shift from today's simple memory hierarchy\ntoward specialized memory architectures that exploit application-specific\naccess patterns. Rather than relying solely on traditional off-chip DRAM and\non-chip SRAM, we envisage memory systems equipped with additional types of\nmemory whose performance trade-offs benefit workloads through non-hierarchical\noptimization. We propose two new memory classes deserving explicit OS support:\nlong-term RAM (LtRAM) optimized for read-intensive data with long lifetimes,\nand short-term RAM (StRAM) designed for transient, frequently-accessed data\nwith short lifetimes. We explore underlying device technologies that could\nimplement these classes, including their evolution and their potential\nintegration into current system designs given emerging workload requirements.\nWe identify critical research challenges to realize what we believe is a\nnecessary evolution toward more efficient and scalable computing systems\ncapable of meeting future demands.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u4f20\u7edf\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u8f6c\u5411\u5229\u7528\u5e94\u7528\u7279\u5b9a\u8bbf\u95ee\u6a21\u5f0f\u7684\u4e13\u7528\u5185\u5b58\u67b6\u6784\uff0c\u5f15\u5165LtRAM\u548cStRAM\u4e24\u7c7b\u65b0\u5185\u5b58\uff0c\u5e76\u63a2\u8ba8\u5176\u5b9e\u73b0\u6280\u672f\u548c\u7814\u7a76\u6311\u6218\u3002", "motivation": "\u5185\u5b58\u6210\u672c\u505c\u6b62\u4e0b\u964d\uff0c\u6210\u4e3a\u7cfb\u7edf\u6210\u672c\u4e3b\u5bfc\uff0c\u9700\u901a\u8fc7\u4e13\u7528\u5185\u5b58\u67b6\u6784\u4f18\u5316\u5e94\u7528\u6027\u80fd\u3002", "method": "\u63d0\u51faLtRAM\u548cStRAM\u4e24\u7c7b\u65b0\u5185\u5b58\uff0c\u63a2\u8ba8\u5176\u8bbe\u5907\u6280\u672f\u548c\u7cfb\u7edf\u96c6\u6210\u65b9\u6848\u3002", "result": "\u8bc6\u522b\u4e86\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u8ba1\u7b97\u7cfb\u7edf\u7684\u5173\u952e\u7814\u7a76\u6311\u6218\u3002", "conclusion": "\u4e13\u7528\u5185\u5b58\u67b6\u6784\u662f\u672a\u6765\u8ba1\u7b97\u7cfb\u7edf\u9ad8\u6548\u6269\u5c55\u7684\u5fc5\u8981\u65b9\u5411\u3002"}}
{"id": "2508.02866", "categories": ["cs.DC", "cs.DB", "68T42, 68T30, 68P20, 68Q85, 68M14,", "D.2.12; H.2.4; I.2.11; C.2.4; H.3.4"], "pdf": "https://arxiv.org/pdf/2508.02866", "abs": "https://arxiv.org/abs/2508.02866", "authors": ["Renan Souza", "Amal Gueroudji", "Stephen DeWitt", "Daniel Rosendo", "Tirthankar Ghosal", "Robert Ross", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows", "comment": "Paper under peer-reviewed evaluation", "summary": "Foundation models, such as Large Language Models (LLMs), are increasingly\nused as core components of AI agents in complex, large-scale workflows across\nfederated and heterogeneous environments. In agentic workflows, autonomous\nagents plan tasks, interact with humans and peers, and shape scientific\noutcomes. This makes transparency, traceability, reproducibility, and\nreliability essential. However, AI-based agents can hallucinate or reason\nincorrectly, and their decisions may propagate errors through the workflow,\nespecially when one agent's output feeds into another's input. Therefore,\nfine-grained provenance is essential to link agent decisions, their end-to-end\ncontext, and downstream impacts. While provenance techniques have long\nsupported reproducibility and workflow data understanding, they fail to capture\nand relate agent-centric metadata (prompts, responses, and decisions) with the\nrest of the workflow. In this paper, we introduce PROV-AGENT, a provenance\nmodel that extends W3C PROV and leverages the Model Context Protocol (MCP) to\nintegrate agent interactions into end-to-end workflow provenance. Our\ncontributions include: (1) a provenance model tailored for agentic workflows,\n(2) a near real-time, open-source system for capturing agentic provenance, and\n(3) a cross-facility evaluation spanning edge, cloud, and HPC environments,\ndemonstrating support for critical provenance queries and agent reliability\nanalysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPROV-AGENT\u6a21\u578b\uff0c\u6269\u5c55W3C PROV\u4ee5\u652f\u6301AI\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u7ec6\u7c92\u5ea6\u6eaf\u6e90\uff0c\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002", "motivation": "AI\u4ee3\u7406\u5728\u590d\u6742\u5de5\u4f5c\u6d41\u4e2d\u53ef\u80fd\u4ea7\u751f\u9519\u8bef\u6216\u5e7b\u89c9\uff0c\u5176\u51b3\u7b56\u53ef\u80fd\u4f20\u64ad\u9519\u8bef\uff0c\u56e0\u6b64\u9700\u8981\u7ec6\u7c92\u5ea6\u6eaf\u6e90\u4ee5\u8ffd\u8e2a\u4ee3\u7406\u51b3\u7b56\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u6269\u5c55W3C PROV\u5e76\u5229\u7528MCP\u534f\u8bae\uff0c\u63d0\u51faPROV-AGENT\u6a21\u578b\uff0c\u5b9e\u65f6\u6355\u83b7\u4ee3\u7406\u4ea4\u4e92\u7684\u6eaf\u6e90\u6570\u636e\u3002", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90\u7cfb\u7edf\u652f\u6301\u5b9e\u65f6\u6eaf\u6e90\uff0c\u5e76\u5728\u591a\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5173\u952e\u6eaf\u6e90\u67e5\u8be2\u548c\u4ee3\u7406\u53ef\u9760\u6027\u5206\u6790\u3002", "conclusion": "PROV-AGENT\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86AI\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u6eaf\u6e90\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.03418", "categories": ["cs.DC", "cs.LO", "68W15, 03B42, 03B70, 68Q60, 68Q85, 68M15"], "pdf": "https://arxiv.org/pdf/2508.03418", "abs": "https://arxiv.org/abs/2508.03418", "authors": ["Ron van der Meyden"], "title": "Optimal Simultaneous Byzantine Agreement, Common Knowledge and Limited Information Exchange", "comment": null, "summary": "In order to develop solutions that perform actions as early as possible,\nanalysis of distributed algorithms using epistemic logic has generally\nconcentrated on ``full information protocols'', which may be inefficient with\nrespect to space and computation time. The paper reconsiders the epistemic\nanalysis of the problem of Simultaneous Byzantine Agreement with respect to\nweaker, but more practical, exchanges of information. The paper first clarifies\nsome issues concerning both the specification of this problem and the knowledge\nbased program characterizing its solution, concerning the distinction between\nthe notions of ``nonfaulty'' and ``not yet failed'', on which there are\nvariances in the literature. It is then shown that, when implemented relative\nto a given failure model and an information exchange protocol satisfying\ncertain conditions, this knowledge based program yields a protocol that is\noptimal relative to solutions using the same information exchange. Conditions\nare also identified under which this implementation is also an optimum, but an\nexample is provided that shows this does not hold in general.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u57fa\u4e8e\u8ba4\u77e5\u903b\u8f91\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u66f4\u5b9e\u7528\u7684\u4fe1\u606f\u4ea4\u6362\u65b9\u5f0f\uff0c\u89e3\u51b3\u4e86\u540c\u65f6\u62dc\u5360\u5ead\u534f\u8bae\u95ee\u9898\u4e2d\u7684\u4e00\u4e9b\u6a21\u7cca\u70b9\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u5176\u89e3\u51b3\u65b9\u6848\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u2018\u5168\u4fe1\u606f\u534f\u8bae\u2019\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\u5206\u6790\u5728\u7a7a\u95f4\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u66f4\u5b9e\u7528\u7684\u4fe1\u606f\u4ea4\u6362\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u8ba4\u77e5\u903b\u8f91\u5206\u6790\u540c\u65f6\u62dc\u5360\u5ead\u534f\u8bae\u95ee\u9898\uff0c\u660e\u786e\u2018\u975e\u6545\u969c\u2019\u4e0e\u2018\u5c1a\u672a\u6545\u969c\u2019\u7684\u533a\u522b\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b9e\u73b0\u57fa\u4e8e\u77e5\u8bc6\u7684\u7a0b\u5e8f\u3002", "result": "\u5728\u7279\u5b9a\u5931\u8d25\u6a21\u578b\u548c\u4fe1\u606f\u4ea4\u6362\u534f\u8bae\u4e0b\uff0c\u8be5\u65b9\u6848\u76f8\u5bf9\u4e8e\u540c\u7c7b\u4fe1\u606f\u4ea4\u6362\u7684\u89e3\u51b3\u65b9\u6848\u662f\u6700\u4f18\u7684\uff0c\u4f46\u5e76\u975e\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u6210\u7acb\u3002", "conclusion": "\u8bba\u6587\u4e3a\u540c\u65f6\u62dc\u5360\u5ead\u534f\u8bae\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u6ce8\u610f\u5176\u9002\u7528\u6761\u4ef6\u3002"}}
{"id": "2508.03513", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2508.03513", "abs": "https://arxiv.org/abs/2508.03513", "authors": ["Zhu Zhu", "Yu Sun", "Dhatri Parakal", "Bo Fang", "Steven Farrell", "Gregory H. Bauer", "Brett Bode", "Ian T. Foster", "Michael E. Papka", "William Gropp", "Zhao Zhang", "Lishan Yang"], "title": "Understanding the Landscape of Ampere GPU Memory Errors", "comment": null, "summary": "Graphics Processing Units (GPUs) have become a de facto solution for\naccelerating high-performance computing (HPC) applications. Understanding their\nmemory error behavior is an essential step toward achieving efficient and\nreliable HPC systems. In this work, we present a large-scale\ncross-supercomputer study to characterize GPU memory reliability, covering\nthree supercomputers - Delta, Polaris, and Perlmutter - all equipped with\nNVIDIA A100 GPUs. We examine error logs spanning 67.77 million GPU device-hours\nacross 10,693 GPUs. We compare error rates and mean-time-between-errors (MTBE)\nand highlight both shared and distinct error characteristics among these three\nsystems. Based on these observations and analyses, we discuss the implications\nand lessons learned, focusing on the reliable operation of supercomputers, the\nchoice of checkpointing interval, and the comparison of reliability\ncharacteristics with those of previous-generation GPUs. Our characterization\nstudy provides valuable insights into fault-tolerant HPC system design and\noperation, enabling more efficient execution of HPC applications.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u8de8\u8d85\u7ea7\u8ba1\u7b97\u673a\u7814\u7a76\uff0c\u5206\u6790\u4e86NVIDIA A100 GPU\u7684\u5185\u5b58\u53ef\u9760\u6027\uff0c\u6bd4\u8f83\u4e86Delta\u3001Polaris\u548cPerlmutter\u4e09\u53f0\u8d85\u7ea7\u8ba1\u7b97\u673a\u7684\u9519\u8bef\u7387\u4e0eMTBE\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u8bbe\u8ba1\u7684\u542f\u793a\u3002", "motivation": "GPU\u5df2\u6210\u4e3a\u52a0\u901f\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e94\u7528\u7684\u4e3b\u8981\u5de5\u5177\uff0c\u4e86\u89e3\u5176\u5185\u5b58\u9519\u8bef\u884c\u4e3a\u5bf9\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684HPC\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u8986\u76d6\u4e86\u4e09\u53f0\u914d\u5907NVIDIA A100 GPU\u7684\u8d85\u7ea7\u8ba1\u7b97\u673a\uff08Delta\u3001Polaris\u548cPerlmutter\uff09\uff0c\u5206\u6790\u4e8667.77\u767e\u4e07GPU\u8bbe\u5907\u5c0f\u65f6\u7684\u6570\u636e\uff0c\u6bd4\u8f83\u4e86\u9519\u8bef\u7387\u548cMTBE\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u4e09\u53f0\u7cfb\u7edf\u7684\u5171\u4eab\u548c\u72ec\u7279\u9519\u8bef\u7279\u5f81\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u8d85\u7ea7\u8ba1\u7b97\u673a\u53ef\u9760\u8fd0\u884c\u3001\u68c0\u67e5\u70b9\u95f4\u9694\u9009\u62e9\u4ee5\u53ca\u4e0e\u4e0a\u4e00\u4ee3GPU\u53ef\u9760\u6027\u6bd4\u8f83\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5bb9\u9519HPC\u7cfb\u7edf\u8bbe\u8ba1\u548c\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u66f4\u9ad8\u6548\u5730\u6267\u884cHPC\u5e94\u7528\u3002"}}
{"id": "2508.03567", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2508.03567", "abs": "https://arxiv.org/abs/2508.03567", "authors": ["Oscar Ferraz", "Vitor Silva", "Gabriel Falcao"], "title": "In-Memory Non-Binary LDPC Decoding", "comment": "23 pages, 10 figures, and 4 tables", "summary": "Low-density parity-check (LDPC) codes are an important feature of several\ncommunication and storage applications, offering a flexible and effective\nmethod for error correction. These codes are computationally complex and\nrequire the exploitation of parallel processing to meet real-time constraints.\nAs advancements in arithmetic and logic unit technology allowed for higher\nperformance of computing systems, memory technology has not kept the same pace\nof development, creating a data movement bottleneck and affecting parallel\nprocessing systems more dramatically. To alleviate the severity of this\nbottleneck, several solutions have been proposed, namely the processing\nin-memory (PiM) paradigm that involves the design of compute units to where (or\nnear) the data is stored, utilizing thousands of low-complexity processing\nunits to perform out bit-wise and simple arithmetic operations. This paper\npresents a novel efficient solution for near-memory non-binary LDPC decoders in\nthe UPMEM system, for the best of our knowledge the first real hardware\nPiM-based non-binary LDPC decoder that is benchmarked against low-power GPU\nparallel solutions highly optimized for throughput performance. PiM-based\nnon-binary LDPC decoders can achieve 76 Mbit/s of decoding throughput, which is\neven competitive when compared against implementations running in edge GPUs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u5185\u5b58\u5904\u7406\uff08PiM\uff09\u7684\u975e\u4e8c\u8fdb\u5236LDPC\u89e3\u7801\u5668\uff0c\u9996\u6b21\u5728UPMEM\u7cfb\u7edf\u4e2d\u5b9e\u73b0\uff0c\u6027\u80fd\u4f18\u4e8e\u4f4e\u529f\u8017GPU\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "LDPC\u7801\u5728\u901a\u4fe1\u548c\u5b58\u50a8\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u4e14\u53d7\u9650\u4e8e\u6570\u636e\u79fb\u52a8\u74f6\u9888\u3002PiM\u8303\u5f0f\u901a\u8fc7\u5c06\u8ba1\u7b97\u5355\u5143\u8bbe\u8ba1\u5728\u6570\u636e\u5b58\u50a8\u4f4d\u7f6e\u9644\u8fd1\uff0c\u7f13\u89e3\u4e86\u8fd9\u4e00\u74f6\u9888\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u9ad8\u6548\u7684\u8fd1\u5185\u5b58\u975e\u4e8c\u8fdb\u5236LDPC\u89e3\u7801\u5668\uff0c\u5229\u7528UPMEM\u7cfb\u7edf\u4e2d\u7684\u4f4e\u590d\u6742\u5ea6\u5904\u7406\u5355\u5143\u8fdb\u884c\u4f4d\u7ea7\u548c\u7b80\u5355\u7b97\u672f\u64cd\u4f5c\u3002", "result": "PiM\u975e\u4e8c\u8fdb\u5236LDPC\u89e3\u7801\u5668\u5b9e\u73b0\u4e8676 Mbit/s\u7684\u89e3\u7801\u541e\u5410\u91cf\uff0c\u6027\u80fd\u4f18\u4e8e\u8fb9\u7f18GPU\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86PiM\u5728\u975e\u4e8c\u8fdb\u5236LDPC\u89e3\u7801\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u89e3\u7801\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.03611", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03611", "abs": "https://arxiv.org/abs/2508.03611", "authors": ["Wei Da", "Evangelia Kalyvianaki"], "title": "Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling", "comment": "12 pages, 8 figures excluding appendix", "summary": "This paper presents Block, a distributed scheduling framework designed to\noptimize load balancing and auto-provisioning across instances in large\nlanguage model serving frameworks by leveraging contextual information from\nincoming requests. Unlike popular model serving systems that rely on monolithic\nand heuristic task schedulers, Block operates as a fully distributed,\nstateless, and predictive scheduling system to achieve low overhead,\nreliability, and scalability. It leverages the deterministic and predictable\ncharacteristics of LLM inferences, such as host configurations, response\nlengths, and hardware performance, to make scheduling decisions based on\naccurately predicted metrics. Evaluation on a 12 GPUs cluster shows that Block\nsignificantly outperforms heuristic schedulers, boosting serving capacity by up\nto 16.7\\% and reducing P99 tail latency by up to 49.5\\%. These performance\ngains remain consistent across diverse models, workloads and configurations.\nCode and data are open-sourced.", "AI": {"tldr": "Block\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u8bf7\u6c42\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u6846\u67b6\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u81ea\u52a8\u914d\u7f6e\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\u4f9d\u8d56\u5355\u4e00\u4e14\u542f\u53d1\u5f0f\u7684\u4efb\u52a1\u8c03\u5ea6\u5668\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4f4e\u5f00\u9500\u3001\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u9700\u6c42\u3002", "method": "Block\u91c7\u7528\u5b8c\u5168\u5206\u5e03\u5f0f\u3001\u65e0\u72b6\u6001\u548c\u9884\u6d4b\u6027\u8c03\u5ea6\u7cfb\u7edf\uff0c\u5229\u7528LLM\u63a8\u7406\u7684\u786e\u5b9a\u6027\u7279\u5f81\uff08\u5982\u4e3b\u673a\u914d\u7f6e\u3001\u54cd\u5e94\u957f\u5ea6\u548c\u786c\u4ef6\u6027\u80fd\uff09\u8fdb\u884c\u8c03\u5ea6\u51b3\u7b56\u3002", "result": "\u572812\u4e2aGPU\u96c6\u7fa4\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cBlock\u663e\u8457\u4f18\u4e8e\u542f\u53d1\u5f0f\u8c03\u5ea6\u5668\uff0c\u670d\u52a1\u5bb9\u91cf\u63d0\u534716.7%\uff0cP99\u5c3e\u90e8\u5ef6\u8fdf\u964d\u4f4e49.5%\u3002", "conclusion": "Block\u5728\u591a\u6837\u5316\u6a21\u578b\u3001\u8d1f\u8f7d\u548c\u914d\u7f6e\u4e0b\u5747\u8868\u73b0\u7a33\u5b9a\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
