{"id": "2510.25278", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.25278", "abs": "https://arxiv.org/abs/2510.25278", "authors": ["Kunming Shao", "Zhipeng Liao", "Jiangnan Yu", "Liang Zhao", "Qiwei Li", "Xijie Huang", "Jingyu He", "Fengshi Tian", "Yi Zou", "Xiaomeng Wang", "Tim Kwang-Ting Cheng", "Chi-Ying Tsui"], "title": "DIRC-RAG: Accelerating Edge RAG with Robust High-Density and High-Loading-Bandwidth Digital In-ReRAM Computation", "comment": "Accepted by 2025 IEEE/ACM ISLPED", "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge retrieval but faces challenges on edge devices\ndue to high storage, energy, and latency demands. Computing-in-Memory (CIM)\noffers a promising solution by storing document embeddings in CIM macros and\nenabling in-situ parallel retrievals but is constrained by either low memory\ndensity or limited computational accuracy. To address these challenges, we\npresent DIRCRAG, a novel edge RAG acceleration architecture leveraging Digital\nIn-ReRAM Computation (DIRC). DIRC integrates a high-density multi-level ReRAM\nsubarray with an SRAM cell, utilizing SRAM and differential sensing for robust\nReRAM readout and digital multiply-accumulate (MAC) operations. By storing all\ndocument embeddings within the CIM macro, DIRC achieves ultra-low-power,\nsingle-cycle data loading, substantially reducing both energy consumption and\nlatency compared to offchip DRAM. A query-stationary (QS) dataflow is supported\nfor RAG tasks, minimizing on-chip data movement and reducing SRAM buffer\nrequirements. We introduce error optimization for the DIRC ReRAM-SRAM cell by\nextracting the bit-wise spatial error distribution of the ReRAM subarray and\napplying targeted bit-wise data remapping. An error detection circuit is also\nimplemented to enhance readout resilience against deviceand circuit-level\nvariations. Simulation results demonstrate that DIRC-RAG under TSMC40nm process\nachieves an on-chip non-volatile memory density of 5.18Mb/mm2 and a throughput\nof 131 TOPS. It delivers a 4MB retrieval latency of 5.6{\\mu}s/query and an\nenergy consumption of 0.956{\\mu}J/query, while maintaining the retrieval\nprecision.", "AI": {"tldr": "DIRCRAG\u662f\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57In-ReRAM\u8ba1\u7b97\u7684\u65b0\u578b\u8fb9\u7f18RAG\u52a0\u901f\u67b6\u6784\uff0c\u901a\u8fc7\u96c6\u6210\u9ad8\u5bc6\u5ea6\u591a\u7ea7ReRAM\u5b50\u9635\u5217\u548cSRAM\u5355\u5143\uff0c\u5b9e\u73b0\u8d85\u4f4e\u529f\u8017\u3001\u5355\u5468\u671f\u6570\u636e\u52a0\u8f7d\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u4e0aRAG\u7cfb\u7edf\u9762\u4e34\u7684\u9ad8\u5b58\u50a8\u3001\u9ad8\u80fd\u8017\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u73b0\u6709CIM\u6280\u672f\u5185\u5b58\u5bc6\u5ea6\u4f4e\u6216\u8ba1\u7b97\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6570\u5b57In-ReRAM\u8ba1\u7b97(DIRC)\u67b6\u6784\uff0c\u96c6\u6210ReRAM\u548cSRAM\uff0c\u652f\u6301\u67e5\u8be2\u9759\u6b62\u6570\u636e\u6d41\uff0c\u901a\u8fc7\u4f4d\u7ea7\u7a7a\u95f4\u8bef\u5dee\u5206\u5e03\u63d0\u53d6\u548c\u9488\u5bf9\u6027\u6570\u636e\u91cd\u6620\u5c04\u8fdb\u884c\u8bef\u5dee\u4f18\u5316\uff0c\u5e76\u5b9e\u73b0\u8bef\u5dee\u68c0\u6d4b\u7535\u8def\u3002", "result": "\u5728TSMC40nm\u5de5\u827a\u4e0b\uff0cDIRC-RAG\u5b9e\u73b05.18Mb/mm\u00b2\u7684\u7247\u4e0a\u975e\u6613\u5931\u6027\u5185\u5b58\u5bc6\u5ea6\u548c131 TOPS\u7684\u541e\u5410\u91cf\uff0c4MB\u68c0\u7d22\u5ef6\u8fdf\u4e3a5.6\u03bcs/\u67e5\u8be2\uff0c\u80fd\u8017\u4e3a0.956\u03bcJ/\u67e5\u8be2\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u7cbe\u5ea6\u3002", "conclusion": "DIRCRAG\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18RAG\u7cfb\u7edf\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u77e5\u8bc6\u68c0\u7d22\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25112", "categories": ["cs.PL", "cs.DC", "cs.LO", "math.AT", "68Q85, 55P99, 68N30, 55U10", "D.2.4; F.3.1; D.1.3; F.1.2"], "pdf": "https://arxiv.org/pdf/2510.25112", "abs": "https://arxiv.org/abs/2510.25112", "authors": ["Di Zhang"], "title": "The Singularity Theory of Concurrent Programs: A Topological Characterization and Detection of Deadlocks and Livelocks", "comment": "10 pages", "summary": "This paper introduces a novel paradigm for the analysis and verification of\nconcurrent programs -- the Singularity Theory. We model the execution space of\na concurrent program as a branched topological space, where program states are\npoints and state transitions are paths. Within this framework, we characterize\ndeadlocks as attractors and livelocks as non-contractible loops in the\nexecution space. By employing tools from algebraic topology, particularly\nhomotopy and homology groups, we define a series of concurrent topological\ninvariants to systematically detect and classify these concurrent\n\"singularities\" without exhaustively traversing all states. This work aims to\nestablish a geometric and topological foundation for concurrent program\nverification, transcending the limitations of traditional model checking.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u53d1\u7a0b\u5e8f\u5206\u6790\u7684\u5947\u70b9\u7406\u8bba\uff0c\u5c06\u6267\u884c\u7a7a\u95f4\u5efa\u6a21\u4e3a\u5206\u652f\u62d3\u6251\u7a7a\u95f4\uff0c\u4f7f\u7528\u4ee3\u6570\u62d3\u6251\u5de5\u5177\u68c0\u6d4b\u6b7b\u9501\u548c\u6d3b\u9501\u3002", "motivation": "\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u5efa\u7acb\u51e0\u4f55\u548c\u62d3\u6251\u57fa\u7840\uff0c\u8d85\u8d8a\u4f20\u7edf\u6a21\u578b\u68c0\u6d4b\u7684\u5c40\u9650\u6027\u3002", "method": "\u5c06\u7a0b\u5e8f\u6267\u884c\u7a7a\u95f4\u5efa\u6a21\u4e3a\u5206\u652f\u62d3\u6251\u7a7a\u95f4\uff0c\u4f7f\u7528\u540c\u4f26\u548c\u540c\u8c03\u7fa4\u7b49\u4ee3\u6570\u62d3\u6251\u5de5\u5177\u5b9a\u4e49\u5e76\u53d1\u62d3\u6251\u4e0d\u53d8\u91cf\u3002", "result": "\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u68c0\u6d4b\u548c\u5206\u7c7b\u5e76\u53d1\"\u5947\u70b9\"\uff08\u6b7b\u9501\u548c\u6d3b\u9501\uff09\uff0c\u65e0\u9700\u7a77\u4e3e\u904d\u5386\u6240\u6709\u72b6\u6001\u3002", "conclusion": "\u5947\u70b9\u7406\u8bba\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u62d3\u6251\u6846\u67b6\uff0c\u6709\u671b\u6539\u8fdb\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2510.25369", "categories": ["cs.PL", "cs.FL", "cs.LO", "math.LO", "F.3.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.25369", "abs": "https://arxiv.org/abs/2510.25369", "authors": ["Elliot Bobrow", "Bryan Ford", "Stefan Milenkovi\u0107"], "title": "Have a thing? Reasoning around recursion with dynamic typing in grounded arithmetic", "comment": null, "summary": "Neither the classical nor intuitionistic logic traditions are\nperfectly-aligned with the purpose of reasoning about computation, in that\nneither logical tradition can normally permit the direct expression of\narbitrary general-recursive functions without inconsistency. We introduce\ngrounded arithmetic or GA, a minimalistic but nonetheless powerful foundation\nfor formal reasoning that allows the direct expression of arbitrary recursive\ndefinitions. GA adjusts the traditional inference rules such that terms that\nexpress nonterminating computations harmlessly denote no semantic value (i.e.,\n\"bottom\") instead of leading into logical paradox or inconsistency. Recursive\nfunctions may be proven terminating in GA essentially by \"dynamically typing\"\nterms, or equivalently, symbolically reverse-executing the computations they\ndenote via GA's inference rules. Once recursive functions have been proven\nterminating, logical reasoning about their results reduce to the familiar\nclassical rules. A mechanically-checked consistency proof in Isabelle/HOL\nexists for the basic quantifier-free fragment of GA. Quantifiers may be added\natop this foundation as ordinary computations, whose inference rules are thus\nadmissible and do not introduce new inconsistency risks. While GA is only a\nfirst step towards richly-typed grounded deduction practical for everyday use\nin manual or automated computational reasoning, it shows the promise that the\nexpressive freedom of arbitrary recursive definition can in principle be\nincorporated into formal systems.", "AI": {"tldr": "GA\uff08\u57fa\u7840\u7b97\u672f\uff09\u662f\u4e00\u79cd\u652f\u6301\u4efb\u610f\u9012\u5f52\u51fd\u6570\u5b9a\u4e49\u7684\u5f62\u5f0f\u63a8\u7406\u57fa\u7840\u7cfb\u7edf\uff0c\u901a\u8fc7\u8c03\u6574\u63a8\u7406\u89c4\u5219\u4f7f\u975e\u7ec8\u6b62\u8ba1\u7b97\u65e0\u5bb3\u5730\u8868\u793a\"\u5e95\u90e8\"\u503c\uff0c\u907f\u514d\u903b\u8f91\u6096\u8bba\u3002", "motivation": "\u4f20\u7edf\u903b\u8f91\u7cfb\u7edf\uff08\u7ecf\u5178\u548c\u76f4\u89c9\u4e3b\u4e49\u903b\u8f91\uff09\u65e0\u6cd5\u76f4\u63a5\u8868\u8fbe\u4efb\u610f\u4e00\u822c\u9012\u5f52\u51fd\u6570\u800c\u4e0d\u5bfc\u81f4\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5b89\u5168\u5904\u7406\u975e\u7ec8\u6b62\u8ba1\u7b97\u7684\u5f62\u5f0f\u63a8\u7406\u57fa\u7840\u3002", "method": "\u8c03\u6574\u4f20\u7edf\u63a8\u7406\u89c4\u5219\uff0c\u4f7f\u8868\u793a\u975e\u7ec8\u6b62\u8ba1\u7b97\u7684\u9879\u65e0\u5bb3\u5730\u8868\u793a\u8bed\u4e49\u503c\"\u5e95\u90e8\"\uff1b\u901a\u8fc7\"\u52a8\u6001\u7c7b\u578b\"\u6216\u7b26\u53f7\u53cd\u5411\u6267\u884c\u8ba1\u7b97\u6765\u8bc1\u660e\u9012\u5f52\u51fd\u6570\u7ec8\u6b62\u6027\uff1b\u5728Isabelle/HOL\u4e2d\u673a\u68b0\u9a8c\u8bc1\u4e00\u81f4\u6027\u3002", "result": "\u5f00\u53d1\u4e86GA\u7cfb\u7edf\uff0c\u652f\u6301\u4efb\u610f\u9012\u5f52\u5b9a\u4e49\u800c\u4e0d\u5f15\u5165\u4e0d\u4e00\u81f4\u6027\uff1b\u63d0\u4f9b\u4e86\u673a\u68b0\u9a8c\u8bc1\u7684\u4e00\u81f4\u6027\u8bc1\u660e\uff1b\u7ec8\u6b62\u6027\u8bc1\u660e\u540e\u53ef\u4f7f\u7528\u7ecf\u5178\u63a8\u7406\u89c4\u5219\u3002", "conclusion": "GA\u5c55\u793a\u4e86\u5c06\u4efb\u610f\u9012\u5f52\u5b9a\u4e49\u7684\u8868\u8fbe\u81ea\u7531\u878d\u5165\u5f62\u5f0f\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u65e5\u5e38\u8ba1\u7b97\u63a8\u7406\u7684\u624b\u52a8\u6216\u81ea\u52a8\u5316\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24943", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24943", "abs": "https://arxiv.org/abs/2510.24943", "authors": ["Alfonso Ladino-Rincon", "Stephen W. Nesbitt"], "title": "Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives", "comment": "8 pages, 3 figures", "summary": "We introduce Radar DataTree, the first dataset-level framework that extends\nthe WMO FM-301 standard from individual radar volume scans to time-resolved,\nanalysis-ready archives. Weather radar data are among the most scientifically\nvaluable yet structurally underutilized Earth observation datasets. Despite\nwidespread public availability, radar archives remain fragmented,\nvendor-specific, and poorly aligned with FAIR (Findable, Accessible,\nInteroperable, Reusable) principles, hindering large-scale research,\nreproducibility, and cloud-native computation. Radar DataTree addresses these\nlimitations with a scalable, open-source architecture that transforms\noperational radar archives into FAIR-compliant, cloud-optimized datasets. Built\non the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,\nRadar DataTree organizes radar volume scans as hierarchical, metadata-rich\nstructures and serializes them to Zarr for scalable analysis. Coupled with\nIcechunk for ACID-compliant storage and versioning, this architecture enables\nefficient, parallel computation across thousands of radar scans with minimal\npreprocessing. We demonstrate significant performance gains in case studies\nincluding Quasi-Vertical Profile (QVP) and precipitation accumulation\nworkflows, and release all tools and datasets openly via the Raw2Zarr\nrepository. This work contributes a reproducible and extensible foundation for\nradar data stewardship, high-performance geoscience, and AI-ready weather\ninfrastructure.", "AI": {"tldr": "Radar DataTree\u662f\u9996\u4e2a\u5c06WMO FM-301\u6807\u51c6\u4ece\u5355\u6b21\u96f7\u8fbe\u4f53\u626b\u63cf\u6269\u5c55\u5230\u65f6\u95f4\u5e8f\u5217\u3001\u5206\u6790\u5c31\u7eea\u5b58\u6863\u7684\u6570\u636e\u96c6\u7ea7\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u96f7\u8fbe\u6570\u636e\u788e\u7247\u5316\u3001\u4e0d\u517c\u5bb9FAIR\u539f\u5219\u7684\u95ee\u9898\u3002", "motivation": "\u5929\u6c14\u96f7\u8fbe\u6570\u636e\u662f\u79d1\u5b66\u4ef7\u503c\u6700\u9ad8\u4f46\u7ed3\u6784\u5229\u7528\u4e0d\u8db3\u7684\u5730\u7403\u89c2\u6d4b\u6570\u636e\u96c6\u4e4b\u4e00\u3002\u5c3d\u7ba1\u516c\u5f00\u53ef\u7528\uff0c\u4f46\u96f7\u8fbe\u5b58\u6863\u4ecd\u5b58\u5728\u788e\u7247\u5316\u3001\u4f9b\u5e94\u5546\u7279\u5b9a\u3001\u4e0d\u7b26\u5408FAIR\u539f\u5219\u7b49\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u7814\u7a76\u3001\u53ef\u91cd\u590d\u6027\u548c\u4e91\u539f\u751f\u8ba1\u7b97\u3002", "method": "\u57fa\u4e8eFM-301/CfRadial 2.1\u6807\u51c6\uff0c\u4f7f\u7528xarray DataTree\u6784\u5efa\u53ef\u6269\u5c55\u7684\u5f00\u6e90\u67b6\u6784\uff0c\u5c06\u96f7\u8fbe\u4f53\u626b\u63cf\u7ec4\u7ec7\u4e3a\u5206\u5c42\u3001\u5143\u6570\u636e\u4e30\u5bcc\u7684\u7ed3\u6784\uff0c\u5e76\u5e8f\u5217\u5316\u4e3aZarr\u683c\u5f0f\u3002\u7ed3\u5408Icechunk\u5b9e\u73b0ACID\u517c\u5bb9\u5b58\u50a8\u548c\u7248\u672c\u63a7\u5236\u3002", "result": "\u5728\u51c6\u5782\u76f4\u5256\u9762(QVP)\u548c\u964d\u6c34\u7d2f\u79ef\u5de5\u4f5c\u6d41\u7b49\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6240\u6709\u5de5\u5177\u548c\u6570\u636e\u96c6\u901a\u8fc7Raw2Zarr\u4ed3\u5e93\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u96f7\u8fbe\u6570\u636e\u7ba1\u7406\u3001\u9ad8\u6027\u80fd\u5730\u7403\u79d1\u5b66\u548cAI\u5c31\u7eea\u7684\u5929\u6c14\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.25170", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25170", "abs": "https://arxiv.org/abs/2510.25170", "authors": ["Kewei Wang", "Claire Songhyun Lee", "Sunwoo Lee", "Vishu Gupta", "Jan Balewski", "Alex Sim", "Peter Nugent", "Ankit Agrawal", "Alok Choudhary", "Kesheng Wu", "Wei-keng Liao"], "title": "Multi-Resolution Model Fusion for Accelerating the Convolutional Neural Network Training", "comment": null, "summary": "Neural networks are rapidly gaining popularity in scientific research, but\ntraining the models is often very time-consuming. Particularly when the\ntraining data samples are large high-dimensional arrays, efficient training\nmethodologies that can reduce the computational costs are crucial. To reduce\nthe training cost, we propose a Multi-Resolution Model Fusion (MRMF) method\nthat combines models trained on reduced-resolution data and then refined with\ndata in the original resolution. We demonstrate that these reduced-resolution\nmodels and datasets could be generated quickly. More importantly, the proposed\napproach reduces the training time by speeding up the model convergence in each\nfusion stage before switching to the final stage of finetuning with data in its\noriginal resolution. This strategy ensures the final model retains\nhigh-resolution insights while benefiting from the computational efficiency of\nlower-resolution training. Our experiment results demonstrate that the\nmulti-resolution model fusion method can significantly reduce end-to-end\ntraining time while maintaining the same model accuracy. Evaluated using two\nreal-world scientific applications, CosmoFlow and Neuron Inverter, the proposed\nmethod improves the training time by up to 47% and 44%, respectively, as\ncompared to the original resolution training, while the model accuracy is not\naffected.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387\u8bad\u7ec3\u7684\u6a21\u578b\u548c\u539f\u59cb\u5206\u8fa8\u7387\u5fae\u8c03\uff0c\u663e\u8457\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65f6\u95f4\u800c\u4e0d\u5f71\u54cd\u7cbe\u5ea6\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u8bad\u7ec3\u9ad8\u7ef4\u5927\u6837\u672c\u6570\u636e\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff1a\u5148\u8bad\u7ec3\u964d\u5206\u8fa8\u7387\u6570\u636e\u7684\u6a21\u578b\uff0c\u7136\u540e\u4e0e\u539f\u59cb\u5206\u8fa8\u7387\u6570\u636e\u878d\u5408\u7cbe\u70bc\uff0c\u901a\u8fc7\u52a0\u901f\u6bcf\u4e2a\u878d\u5408\u9636\u6bb5\u7684\u6536\u655b\u6765\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u5728CosmoFlow\u548cNeuron Inverter\u4e24\u4e2a\u5b9e\u9645\u79d1\u5b66\u5e94\u7528\u4e2d\uff0c\u8bad\u7ec3\u65f6\u95f4\u5206\u522b\u51cf\u5c1147%\u548c44%\uff0c\u6a21\u578b\u7cbe\u5ea6\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\uff0c\u786e\u4fdd\u6700\u7ec8\u6a21\u578b\u65e2\u4fdd\u7559\u9ad8\u5206\u8fa8\u7387\u4fe1\u606f\u53c8\u53d7\u76ca\u4e8e\u4f4e\u5206\u8fa8\u7387\u8bad\u7ec3\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.25258", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25258", "abs": "https://arxiv.org/abs/2510.25258", "authors": ["Xinru Tang", "Jingxiang Hou", "Dingcheng Jiang", "Taiquan Wei", "Jiaxin Liu", "Jinyi Deng", "Huizheng Wang", "Qize Yang", "Haoran Shang", "Chao Li", "Yang Hu", "Shouyi Yin"], "title": "MoEntwine: Unleashing the Potential of Wafer-scale Chips for Large-scale Expert Parallel Inference", "comment": null, "summary": "As large language models (LLMs) continue to scale up, mixture-of-experts\n(MoE) has become a common technology in SOTA models. MoE models rely on expert\nparallelism (EP) to alleviate memory bottleneck, which introduces all-to-all\ncommunication to dispatch and combine tokens across devices. However, in\nwidely-adopted GPU clusters, high-overhead cross-node communication makes\nall-to-all expensive, hindering the adoption of EP. Recently, wafer-scale chips\n(WSCs) have emerged as a platform integrating numerous devices on a wafer-sized\ninterposer. WSCs provide a unified high-performance network connecting all\ndevices, presenting a promising potential for hosting MoE models. Yet, their\nnetwork is restricted to a mesh topology, causing imbalanced communication\npressure and performance loss. Moreover, the lack of on-wafer disk leads to\nhigh-overhead expert migration on the critical path.\n  To fully unleash this potential, we first propose Entwined Ring Mapping\n(ER-Mapping), which co-designs the mapping of attention and MoE layers to\nbalance communication pressure and achieve better performance. We find that\nunder ER-Mapping, the distribution of cold and hot links in the attention and\nMoE layers is complementary. Therefore, to hide the migration overhead, we\npropose the Non-invasive Balancer (NI-Balancer), which splits a complete expert\nmigration into multiple steps and alternately utilizes the cold links of both\nlayers. Evaluation shows ER-Mapping achieves communication reduction up to 62%.\nNI-Balancer further delivers 54% and 22% improvements in MoE computation and\ncommunication, respectively. Compared with the SOTA NVL72 supernode, the WSC\nplatform delivers an average 39% higher per-device MoE performance owing to its\nscalability to larger EP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faER-Mapping\u548cNI-Balancer\u65b9\u6cd5\uff0c\u5728\u6676\u5706\u7ea7\u82af\u7247\u4e0a\u4f18\u5316\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u901a\u4fe1\u6548\u7387\u548c\u4e13\u5bb6\u8fc1\u79fb\u5f00\u9500\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4f9d\u8d56\u4e13\u5bb6\u5e76\u884c\u6280\u672f\uff0c\u4f46GPU\u96c6\u7fa4\u4e2d\u8de8\u8282\u70b9\u901a\u4fe1\u5f00\u9500\u5927\u3002\u6676\u5706\u7ea7\u82af\u7247\u63d0\u4f9b\u9ad8\u6027\u80fd\u7f51\u7edc\u4f46\u53d7\u9650\u4e8e\u7f51\u683c\u62d3\u6251\uff0c\u5b58\u5728\u901a\u4fe1\u538b\u529b\u4e0d\u5747\u8861\u548c\u4e13\u5bb6\u8fc1\u79fb\u5f00\u9500\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faER-Mapping\u65b9\u6cd5\u5171\u540c\u8bbe\u8ba1\u6ce8\u610f\u529b\u5c42\u548cMoE\u5c42\u7684\u6620\u5c04\u4ee5\u5e73\u8861\u901a\u4fe1\u538b\u529b\uff1b\u63d0\u51faNI-Balancer\u5c06\u5b8c\u6574\u4e13\u5bb6\u8fc1\u79fb\u5206\u89e3\u4e3a\u591a\u6b65\u9aa4\uff0c\u4ea4\u66ff\u5229\u7528\u4e24\u5c42\u7684\u51b7\u94fe\u63a5\u6765\u9690\u85cf\u8fc1\u79fb\u5f00\u9500\u3002", "result": "ER-Mapping\u5b9e\u73b0\u9ad8\u8fbe62%\u7684\u901a\u4fe1\u51cf\u5c11\uff1bNI-Balancer\u5728MoE\u8ba1\u7b97\u548c\u901a\u4fe1\u65b9\u9762\u5206\u522b\u5e26\u676554%\u548c22%\u7684\u6539\u8fdb\uff1b\u76f8\u6bd4NVL72\u8d85\u7ea7\u8282\u70b9\uff0c\u6676\u5706\u7ea7\u82af\u7247\u5e73\u53f0\u5e73\u5747\u63d0\u4f9b39%\u66f4\u9ad8\u7684\u6bcf\u8bbe\u5907MoE\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7ER-Mapping\u548cNI-Balancer\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u6676\u5706\u7ea7\u82af\u7247\u5e73\u53f0\u80fd\u591f\u5145\u5206\u53d1\u6325\u5176\u5927\u89c4\u6a21\u4e13\u5bb6\u5e76\u884c\u7684\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2510.25277", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25277", "abs": "https://arxiv.org/abs/2510.25277", "authors": ["Simon S\u00fcwer", "Mai Khanh Mai", "Christoph Klein", "Nicola G\u00f6tzenberger", "Denis Dali\u0107", "Andreas Maier", "Jan Baumbach"], "title": "A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon", "comment": null, "summary": "The integration of clinical data offers significant potential for the\ndevelopment of personalized medicine. However, its use is severely restricted\nby the General Data Protection Regulation (GDPR), especially for small cohorts\nwith rare diseases. High-quality, structured data is essential for the\ndevelopment of predictive medical AI. In this case study, we propose a novel,\nmulti-stage approach to secure AI training: (1) The model is designed on a\nsimulated clinical knowledge graph (cKG). This graph is used exclusively to\nrepresent the structural characteristics of the real cKG without revealing any\nsensitive content. (2) The model is then integrated into the FeatureCloud (FC)\nfederated learning framework, where it is prepared in a single-client\nconfiguration within a protected execution environment. (3) Training then takes\nplace within the hospital environment on the real cKG, either under the direct\nsupervision of hospital staff or via a fully automated pipeline controlled by\nthe hospital. (4) Finally, verified evaluation scripts are executed, which only\nreturn aggregated performance metrics. This enables immediate performance\nfeedback without sensitive patient data or individual predictions, leaving the\nclinic. A fundamental element of this approach involves the incorporation of a\ncKG, which serves to organize multi-omics and patient data within the context\nof real-world hospital environments. This approach was successfully validated\nduring the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner\nChildren's Hospital (HCH-LMU): 50 students developed models for patient\nclassification and diagnosis without access to real data. Deploying secure\nalgorithms via federated frameworks, such as the FC framework, could be a\npractical way of achieving privacy-preserving AI in healthcare.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u7684\u5b89\u5168AI\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u8bbe\u8ba1\u6a21\u578b\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u8bad\u7ec3\uff0c\u5e76\u5728\u533b\u9662\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9645\u8bad\u7ec3\uff0c\u4ec5\u8fd4\u56de\u805a\u5408\u6027\u80fd\u6307\u6807\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u533b\u7597AI\u5f00\u53d1\u3002", "motivation": "\u4e34\u5e8a\u6570\u636e\u6574\u5408\u5bf9\u4e2a\u6027\u5316\u533b\u7597\u53d1\u5c55\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u53d7GDPR\u4e25\u683c\u9650\u5236\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7f55\u89c1\u75be\u75c5\u7684\u5c0f\u578b\u961f\u5217\u3002\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u6570\u636e\u5bf9\u9884\u6d4b\u6027\u533b\u7597AI\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u56db\u9636\u6bb5\u65b9\u6cd5\uff1a(1)\u5728\u6a21\u62df\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8bbe\u8ba1\u6a21\u578b\uff1b(2)\u5728FeatureCloud\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u96c6\u6210\u6a21\u578b\uff1b(3)\u5728\u533b\u9662\u73af\u5883\u4e2d\u5bf9\u771f\u5b9e\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u8bad\u7ec3\uff1b(4)\u6267\u884c\u9a8c\u8bc1\u8bc4\u4f30\u811a\u672c\u4ec5\u8fd4\u56de\u805a\u5408\u6027\u80fd\u6307\u6807\u3002", "result": "\u5728TUM.ai Makeathon 2024\u6311\u6218\u4e2d\u6210\u529f\u9a8c\u8bc1\uff1a50\u540d\u5b66\u751f\u65e0\u9700\u8bbf\u95ee\u771f\u5b9e\u6570\u636e\u5373\u53ef\u5f00\u53d1\u60a3\u8005\u5206\u7c7b\u548c\u8bca\u65ad\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u90e8\u7f72\u5b89\u5168\u7b97\u6cd5\u662f\u5b9e\u73b0\u533b\u7597\u4fdd\u5065\u9886\u57df\u9690\u79c1\u4fdd\u62a4AI\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2510.25362", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25362", "abs": "https://arxiv.org/abs/2510.25362", "authors": ["Georgios L. Stavrinides", "Helen D. Karatza"], "title": "Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges", "comment": "This version of the manuscript has been accepted for publication in\n  Modeling and Simulation in HPC and Cloud Systems, ser. Studies in Big Data,\n  after peer review (Author Accepted Manuscript). It is not the final published\n  version (Version of Record) and does not reflect any post-acceptance\n  improvements. The Version of Record is available online at\n  https://doi.org/10.1007/978-3-319-73767-6_2", "summary": "With the explosive growth of big data, workloads tend to get more complex and\ncomputationally demanding. Such applications are processed on distributed\ninterconnected resources that are becoming larger in scale and computational\ncapacity. Data-intensive applications may have different degrees of parallelism\nand must effectively exploit data locality. Furthermore, they may impose\nseveral Quality of Service requirements, such as time constraints and\nresilience against failures, as well as other objectives, like energy\nefficiency. These features of the workloads, as well as the inherent\ncharacteristics of the computing resources required to process them, present\nmajor challenges that require the employment of effective scheduling\ntechniques. In this chapter, a classification of data-intensive workloads is\nproposed and an overview of the most commonly used approaches for their\nscheduling in large-scale distributed systems is given. We present novel\nstrategies that have been proposed in the literature and shed light on open\nchallenges and future directions.", "AI": {"tldr": "\u672c\u7ae0\u63d0\u51fa\u4e86\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u7c7b\uff0c\u5e76\u6982\u8ff0\u4e86\u5728\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u8c03\u5ea6\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u540c\u65f6\u4ecb\u7ecd\u4e86\u6587\u732e\u4e2d\u7684\u65b0\u7b56\u7565\u5e76\u6307\u51fa\u4e86\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u6570\u636e\u7684\u7206\u70b8\u5f0f\u589e\u957f\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u548c\u8ba1\u7b97\u5bc6\u96c6\uff0c\u8fd9\u4e9b\u5e94\u7528\u5728\u5206\u5e03\u5f0f\u4e92\u8fde\u8d44\u6e90\u4e0a\u5904\u7406\uff0c\u8fd9\u4e9b\u8d44\u6e90\u5728\u89c4\u6a21\u548c\u8ba1\u7b97\u80fd\u529b\u4e0a\u53d8\u5f97\u8d8a\u6765\u8d8a\u5927\u3002\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u5177\u6709\u4e0d\u540c\u7684\u5e76\u884c\u5ea6\uff0c\u5fc5\u987b\u6709\u6548\u5229\u7528\u6570\u636e\u5c40\u90e8\u6027\uff0c\u5e76\u53ef\u80fd\u65bd\u52a0\u591a\u79cd\u670d\u52a1\u8d28\u91cf\u8981\u6c42\uff0c\u5982\u65f6\u95f4\u7ea6\u675f\u548c\u5bb9\u9519\u6027\uff0c\u4ee5\u53ca\u5176\u4ed6\u76ee\u6807\uff0c\u5982\u80fd\u6548\u3002\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7279\u6027\u4ee5\u53ca\u5904\u7406\u5b83\u4eec\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u7684\u56fa\u6709\u7279\u6027\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u91c7\u7528\u6709\u6548\u7684\u8c03\u5ea6\u6280\u672f\u3002", "method": "\u63d0\u51fa\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u7c7b\uff0c\u5e76\u6982\u8ff0\u5728\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u8c03\u5ea6\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5e38\u7528\u65b9\u6cd5\u3002\u4ecb\u7ecd\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u65b0\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u7c7b\u6846\u67b6\u548c\u8c03\u5ea6\u65b9\u6cd5\u6982\u8ff0\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u7684\u7814\u7a76\u8fdb\u5c55\u548c\u53ef\u7528\u7684\u8c03\u5ea6\u7b56\u7565\u3002", "conclusion": "\u672c\u7ae0\u9610\u660e\u4e86\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u9886\u57df\u7684\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u6709\u6548\u8c03\u5ea6\u6280\u672f\u5728\u5904\u7406\u590d\u6742\u5927\u6570\u636e\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.25451", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25451", "abs": "https://arxiv.org/abs/2510.25451", "authors": ["St\u00e9phane Devismes", "Yoann Dieudonn\u00e9", "Arnaud Labourel"], "title": "Can Like Attract Like? A Study of Homonymous Gathering in Networks", "comment": null, "summary": "A team of mobile agents, starting from distinct nodes of a network, have to\nmeet at the same node and declare that they all met. Agents execute the same\nalgorithm, which they start when activated by an adversary or by an agent\nentering their initial node. When activated, agents traverse edges of the\nnetwork in synchronous rounds. Their perception and communication are strictly\nlocal. This task, known as gathering, is a central problem in distributed\nmobile systems. Most prior work focuses on minimizing its time complexity,\ni.e., the worst-case number of rounds between the start of the earliest agent\nand the task completion. To break possible symmetries, deterministic solutions\ntypically assume that agents have pairwise distinct IDs, called labels, known\nonly to themselves. But must all labels be pairwise distinct to guarantee\ndeterministic gathering?\n  We address this question by considering agents that may share the same label.\nA team L is said to be gatherable if, for every initial setting of L, there is\nan algorithm that solves gathering. Our contribution is threefold. (1) We give\na full characterization of the gatherable teams. (2) We design an algorithm\nthat gathers all of them in poly$(n,\\log\\lambda)$ time, where $n$ (resp.\n$\\lambda$) is the graph order (resp. the smallest label in L). This algorithm\nrequires the agents to initially share only $O(\\log \\log \\log \\mu)$ bits of\ncommon knowledge, where $\\mu$ is the largest label multiplicity in L. (3) We\nshow this dependency is almost optimal to get a poly$(n,\\log\\lambda)$-time\ncomplexity.\n  As a by-product, we get the first deterministic poly$(n,\\log\\lambda)$-time\nalgorithm requiring no common knowledge to gather any team when all labels are\ndistinct. Known to be achievable for two-agent teams, extending this to any\nteam size faced a major challenge: termination detection. Our techniques to\naddress it may be of independent interest.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u79fb\u52a8\u667a\u80fd\u4f53\u5728\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\u7684\u805a\u96c6\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5f53\u667a\u80fd\u4f53\u53ef\u80fd\u5171\u4eab\u76f8\u540c\u6807\u7b7e\u65f6\u7684\u786e\u5b9a\u6027\u805a\u96c6\u7b97\u6cd5\u3002\u7ed9\u51fa\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u5b8c\u6574\u7279\u5f81\u63cf\u8ff0\uff0c\u8bbe\u8ba1\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u9700\u5171\u4eab\u4fe1\u606f\u91cf\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u4f20\u7edf\u786e\u5b9a\u6027\u805a\u96c6\u7b97\u6cd5\u5047\u8bbe\u667a\u80fd\u4f53\u5177\u6709\u4e92\u4e0d\u76f8\u540c\u7684\u6807\u7b7e\u6765\u6253\u7834\u5bf9\u79f0\u6027\u3002\u672c\u6587\u7814\u7a76\u5f53\u667a\u80fd\u4f53\u53ef\u80fd\u5171\u4eab\u76f8\u540c\u6807\u7b7e\u65f6\uff0c\u662f\u5426\u4ecd\u80fd\u4fdd\u8bc1\u786e\u5b9a\u6027\u805a\u96c6\uff0c\u4ee5\u53ca\u9700\u8981\u591a\u5c11\u5171\u4eab\u4fe1\u606f\u624d\u80fd\u5b9e\u73b0\u9ad8\u6548\u805a\u96c6\u3002", "method": "\u9996\u5148\u5b8c\u5168\u523b\u753b\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u7279\u5f81\u3002\u7136\u540e\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b97\u6cd5\uff0c\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u805a\u96c6\u6240\u6709\u53ef\u805a\u96c6\u56e2\u961f\uff0c\u4ec5\u9700O(log log log \u03bc)\u6bd4\u7279\u7684\u521d\u59cb\u5171\u4eab\u77e5\u8bc6\uff0c\u5176\u4e2d\u03bc\u662f\u6807\u7b7e\u7684\u6700\u5927\u91cd\u590d\u6b21\u6570\u3002", "result": "\u83b7\u5f97\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u5b8c\u6574\u7279\u5f81\u63cf\u8ff0\uff1b\u8bbe\u8ba1\u4e86poly(n,log\u03bb)\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u805a\u96c6\u7b97\u6cd5\uff1b\u8bc1\u660e\u4e86\u6240\u9700\u5171\u4eab\u4fe1\u606f\u91cf\u7684\u51e0\u4e4e\u6700\u4f18\u6027\uff1b\u5f97\u5230\u4e86\u9996\u4e2a\u65e0\u9700\u5171\u4eab\u77e5\u8bc6\u5373\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u805a\u96c6\u4efb\u610f\u89c4\u6a21\u4e0d\u540c\u6807\u7b7e\u56e2\u961f\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "conclusion": "\u5373\u4f7f\u667a\u80fd\u4f53\u5171\u4eab\u76f8\u540c\u6807\u7b7e\uff0c\u53ea\u8981\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\uff0c\u4ecd\u80fd\u5b9e\u73b0\u786e\u5b9a\u6027\u805a\u96c6\u3002\u6240\u9700\u5171\u4eab\u4fe1\u606f\u91cf\u6781\u5c0f\u4e14\u51e0\u4e4e\u6700\u4f18\uff0c\u89e3\u51b3\u4e86\u7ec8\u6b62\u68c0\u6d4b\u8fd9\u4e00\u4e3b\u8981\u6311\u6218\uff0c\u6280\u672f\u65b9\u6cd5\u5177\u6709\u72ec\u7acb\u4ef7\u503c\u3002"}}
{"id": "2510.25757", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25757", "abs": "https://arxiv.org/abs/2510.25757", "authors": ["Jonas Spenger", "Kolya Krafeld", "Ruben van Gemeren", "Philipp Haller", "Paris Carbone"], "title": "Holon Streaming: Global Aggregations with Windowed CRDTs", "comment": "10 pages, 9 figures, 2 tables, 2 listings, 2 algorithms", "summary": "Scaling global aggregations is a challenge for exactly-once stream processing\nsystems. Current systems implement these either by computing the aggregation in\na single task instance, or by static aggregation trees, which limits\nscalability and may become a bottleneck. Moreover, the end-to-end latency is\ndetermined by the slowest path in the tree, and failures and reconfiguration\ncause large latency spikes due to the centralized coordination. Towards these\nissues, we present Holon Streaming, an exactly-once stream processing system\nfor global aggregations. Its deterministic programming model uses windowed\nconflict-free replicated data types (Windowed CRDTs), a novel abstraction for\nshared replicated state. Windowed CRDTs make computing global aggregations\nscalable. Furthermore, their guarantees such as determinism and convergence\nenable the design of efficient failure recovery algorithms by decentralized\ncoordination. Our evaluation shows a 5x lower latency and 2x higher throughput\nthan an existing stream processing system on global aggregation workloads, with\nan 11x latency reduction under failure scenarios. The paper demonstrates the\neffectiveness of decentralized coordination with determinism, and the utility\nof Windowed CRDTs for global aggregations.", "AI": {"tldr": "Holon Streaming\u662f\u4e00\u4e2a\u652f\u6301\u7cbe\u786e\u4e00\u6b21\u8bed\u4e49\u7684\u6d41\u5904\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u7a97\u53e3\u5316\u65e0\u51b2\u7a81\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08Windowed CRDTs\uff09\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5168\u5c40\u805a\u5408\u8ba1\u7b97\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u5177\u6709\u66f4\u4f4e\u5ef6\u8fdf\u548c\u66f4\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u6d41\u5904\u7406\u7cfb\u7edf\u5728\u5168\u5c40\u805a\u5408\u8ba1\u7b97\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u8981\u4e48\u5728\u5355\u4e2a\u4efb\u52a1\u5b9e\u4f8b\u4e2d\u8ba1\u7b97\uff0c\u8981\u4e48\u4f7f\u7528\u9759\u6001\u805a\u5408\u6811\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u9ad8\u4e14\u6545\u969c\u6062\u590d\u65f6\u5ef6\u8fdf\u5cf0\u503c\u5927\u3002", "method": "\u63d0\u51fa\u786e\u5b9a\u6027\u7f16\u7a0b\u6a21\u578b\uff0c\u4f7f\u7528\u7a97\u53e3\u5316\u65e0\u51b2\u7a81\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08Windowed CRDTs\uff09\u4f5c\u4e3a\u5171\u4eab\u590d\u5236\u72b6\u6001\u7684\u65b0\u62bd\u8c61\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7684\u9ad8\u6548\u6545\u969c\u6062\u590d\u7b97\u6cd5\u3002", "result": "\u5728\u5168\u5c40\u805a\u5408\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0c\u76f8\u6bd4\u73b0\u6709\u6d41\u5904\u7406\u7cfb\u7edf\uff0c\u5ef6\u8fdf\u964d\u4f4e5\u500d\uff0c\u541e\u5410\u91cf\u63d0\u9ad82\u500d\uff0c\u6545\u969c\u573a\u666f\u4e0b\u5ef6\u8fdf\u51cf\u5c1111\u500d\u3002", "conclusion": "\u8bc1\u660e\u4e86\u786e\u5b9a\u6027\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53caWindowed CRDTs\u5728\u5168\u5c40\u805a\u5408\u8ba1\u7b97\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
