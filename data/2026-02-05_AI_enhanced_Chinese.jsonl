{"id": "2602.04100", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.04100", "abs": "https://arxiv.org/abs/2602.04100", "authors": ["Maccoy Merrell", "Lei Wang", "Stavros Kalafatis", "Paul V. Gratz"], "title": "SPPAM: Signature Pattern Prediction and Access-Map Prefetcher", "comment": "5 pages, 6 figures, submitted to the 4th Data Prefetching Championship co-located at HPCA 2026", "summary": "The discrepancy between processor speed and memory system performance continues to limit the performance of many workloads. To address the issue, one effective and well studied technique is cache prefetching. Many prefetching designs have been proposed, with varying approaches and effectiveness. For example, SPP is a popular prefetcher that leverages confidence throttled recursion to speculate on the future path of program's references, however it is very susceptible to the reference reordering of higher-level caches and the OoO core. Orthogonally, AMPM is another popular approach to prefetching which uses reordering-resistant access maps to identify patterns within a region, but is unable to speculate beyond that region. In this paper, we propose SPPAM, a new approach to prefetching, inspired by prior works such as SPP and AMPM, while addressing their limitations. SPPAM utilizes online-learning to build a set of access-map patterns. These patterns are used in a speculative lookahead which is throttled by a confidence metric. Targeting the second-level cache, SPPAM alongside state-of-the-art prefetchers Berti and Bingo improve system performance by 31.4% over no prefetching and 6.2% over the baseline of Berti and Pythia.", "AI": {"tldr": "SPPAM\u662f\u4e00\u79cd\u65b0\u7684\u7f13\u5b58\u9884\u53d6\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86SPP\u548cAMPM\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u6784\u5efa\u8bbf\u95ee\u6a21\u5f0f\u56fe\uff0c\u5e76\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u8c03\u8282\u7684\u63a8\u6d4b\u6027\u524d\u77bb\u673a\u5236\uff0c\u5728\u4e8c\u7ea7\u7f13\u5b58\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5904\u7406\u5668\u901f\u5ea6\u4e0e\u5185\u5b58\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u6301\u7eed\u9650\u5236\u7740\u8bb8\u591a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u3002\u73b0\u6709\u7684\u9884\u53d6\u6280\u672f\u5982SPP\u548cAMPM\u5404\u6709\u5c40\u9650\u6027\uff1aSPP\u5bf9\u9ad8\u5c42\u7f13\u5b58\u548c\u4e71\u5e8f\u6838\u5fc3\u7684\u5f15\u7528\u91cd\u6392\u5e8f\u975e\u5e38\u654f\u611f\uff1bAMPM\u867d\u7136\u5bf9\u91cd\u6392\u5e8f\u6709\u62b5\u6297\u529b\uff0c\u4f46\u65e0\u6cd5\u63a8\u6d4b\u8d85\u51fa\u533a\u57df\u8303\u56f4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\u5e76\u514b\u670d\u5176\u5c40\u9650\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "SPPAM\u91c7\u7528\u5728\u7ebf\u5b66\u4e60\u6784\u5efa\u4e00\u7ec4\u8bbf\u95ee\u6a21\u5f0f\u56fe\uff08access-map patterns\uff09\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u56fe\u7528\u4e8e\u7f6e\u4fe1\u5ea6\u8c03\u8282\u7684\u63a8\u6d4b\u6027\u524d\u77bb\uff08speculative lookahead\uff09\u3002\u8be5\u65b9\u6cd5\u9488\u5bf9\u4e8c\u7ea7\u7f13\u5b58\uff0c\u7ed3\u5408\u4e86SPP\u7684\u63a8\u6d4b\u80fd\u529b\u548cAMPM\u5bf9\u91cd\u6392\u5e8f\u7684\u62b5\u6297\u529b\u3002", "result": "SPPAM\u4e0e\u6700\u5148\u8fdb\u7684\u9884\u53d6\u5668Berti\u548cBingo\u7ed3\u5408\uff0c\u5728\u65e0\u9884\u53d6\u57fa\u7840\u4e0a\u63d0\u5347\u7cfb\u7edf\u6027\u80fd31.4%\uff0c\u5728Berti\u548cPythia\u57fa\u7ebf\u57fa\u7840\u4e0a\u63d0\u53476.2%\u3002", "conclusion": "SPPAM\u6210\u529f\u7ed3\u5408\u4e86SPP\u548cAMPM\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u8bbf\u95ee\u6a21\u5f0f\u56fe\u548c\u7f6e\u4fe1\u5ea6\u8c03\u8282\u7684\u63a8\u6d4b\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u9884\u53d6\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u5728\u4e8c\u7ea7\u7f13\u5b58\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2602.04415", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04415", "abs": "https://arxiv.org/abs/2602.04415", "authors": ["Anh Kiet Pham", "Van Truong Vo", "Vu Trung Duong Le", "Tuan Hai Vu", "Hoai Luan Pham", "Van Tinh Nguyen", "Yasuhiko Nakashima"], "title": "Crypto-RV: High-Efficiency FPGA-Based RISC-V Cryptographic Co-Processor for IoT Security", "comment": "This paper is submitted to COOL Chips 29", "summary": "Cryptographic operations are critical for securing IoT, edge computing, and autonomous systems. However, current RISC-V platforms lack efficient hardware support for comprehensive cryptographic algorithm families and post-quantum cryptography. This paper presents Crypto-RV, a RISC-V co-processor architecture that unifies support for SHA-256, SHA-512, SM3, SHA3-256, SHAKE-128, SHAKE-256 AES-128, HARAKA-256, and HARAKA-512 within a single 64-bit datapath. Crypto-RV introduces three key architectural innovations: a high-bandwidth internal buffer (128x64-bit), cryptography-specialized execution units with four-stage pipelined datapaths, and a double-buffering mechanism with adaptive scheduling optimized for large-hash. Implemented on Xilinx ZCU102 FPGA at 160 MHz with 0.851 W dynamic power, Crypto-RV achieves 165 times to 1,061 times speedup over baseline RISC-V cores, 5.8 times to 17.4 times better energy efficiency compared to powerful CPUs. The design occupies only 34,704 LUTs, 37,329 FFs, and 22 BRAMs demonstrating viability for high-performance, energy-efficient cryptographic processing in resource-constrained IoT environments.", "AI": {"tldr": "Crypto-RV\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684RISC-V\u534f\u5904\u7406\u5668\u67b6\u6784\uff0c\u652f\u6301\u591a\u79cd\u52a0\u5bc6\u7b97\u6cd5\u548c\u6297\u91cf\u5b50\u5bc6\u7801\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u7684\u52a0\u5bc6\u5904\u7406\u3002", "motivation": "\u5f53\u524dRISC-V\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u5168\u9762\u52a0\u5bc6\u7b97\u6cd5\u5bb6\u65cf\u548c\u6297\u91cf\u5b50\u5bc6\u7801\u7684\u9ad8\u6548\u786c\u4ef6\u652f\u6301\uff0c\u800c\u52a0\u5bc6\u64cd\u4f5c\u5bf9\u4e8eIoT\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faCrypto-RV\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u9ad8\u5e26\u5bbd\u5185\u90e8\u7f13\u51b2\u533a\uff08128x64\u4f4d\uff09\u3001\u4e13\u95e8\u5316\u7684\u52a0\u5bc6\u6267\u884c\u5355\u5143\uff08\u56db\u9636\u6bb5\u6d41\u6c34\u7ebf\u6570\u636e\u8def\u5f84\uff09\u3001\u4ee5\u53ca\u9488\u5bf9\u5927\u54c8\u5e0c\u4f18\u5316\u7684\u53cc\u7f13\u51b2\u673a\u5236\u548c\u81ea\u9002\u5e94\u8c03\u5ea6\u3002", "result": "\u5728Xilinx ZCU102 FPGA\u4e0a\u5b9e\u73b0\uff0c\u8fd0\u884c\u9891\u7387160MHz\uff0c\u52a8\u6001\u529f\u80170.851W\uff0c\u76f8\u6bd4\u57fa\u7ebfRISC-V\u6838\u5fc3\u83b7\u5f97165-1061\u500d\u52a0\u901f\uff0c\u76f8\u6bd4\u5f3a\u5927CPU\u83b7\u5f975.8-17.4\u500d\u80fd\u6548\u63d0\u5347\uff0c\u4ec5\u5360\u752834,704 LUTs\u300137,329 FFs\u548c22 BRAMs\u3002", "conclusion": "Crypto-RV\u5c55\u793a\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u52a0\u5bc6\u5904\u7406\u7684\u53ef\u884c\u6027\uff0c\u4e3aRISC-V\u5e73\u53f0\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u52a0\u5bc6\u786c\u4ef6\u652f\u6301\u3002"}}
{"id": "2602.04595", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.04595", "abs": "https://arxiv.org/abs/2602.04595", "authors": ["Xinyu Wang", "Jieyu Li", "Yanan Sun", "Weifeng He"], "title": "Harmonia: Algorithm-Hardware Co-Design for Memory- and Compute-Efficient BFP-based LLM Inference", "comment": null, "summary": "Large Language Models (LLMs) are powerful but incur high memory and computation costs. Quantization is an effective solution, with INT weights and FP activations being widely adopted to preserve accuracy. Prior works further reduce FP overhead by using block floating point (BFP) activations in linear layers, but fail to extend BFP to attention layers due to severe accuracy degradation, limiting overall efficiency. To address this challenge, we propose Harmonia, an algorithm-hardware co-design framework that enables all-layer BFP activations with a configurable hardware architecture. First, we systematically explore BFP configurations to achieve a better trade-off between accuracy and activation compression across all layers. Second, to reduce KV-cache storage and computation in attention layers, we introduce an asymmetric bit-allocation strategy and computations in attention layers,we introduce an asymmetric bit-allocation strategy combined with a hybrid offline-online outlier smoothing technique. This allow aggressive KV-cache compression from FP16 to 4-bit-mantissa BFP with only 0.3% average accuracy loss. Third, to fully exploit all-layer BFP activations, we design dedicated hardware components, including a reconfigurable PE supporting mixed data formats (BFP-INT and BPF-BFP), a real-time FP16-to-BFP converter, and a tiling-aware dataflow to reduce memory traffic. We evaluate Harmonia on GEMM operations in both linear and attention layers across eight widely used LLMs. Compared with prior works, Harmonia achieves 3.84x (up to 5.05x) higher area efficiency, 2.03x (up to 3.90x) better energy efficiency, and 3.08x (up to 4.62x) speedup on average.", "AI": {"tldr": "Harmonia\uff1a\u4e00\u79cd\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6240\u6709\u5c42\u4f7f\u7528\u53ef\u914d\u7f6e\u7684\u5757\u6d6e\u70b9\u6570\uff08BFP\uff09\u6fc0\u6d3b\uff0c\u5b9e\u73b0LLM\u7684\u9ad8\u6548\u91cf\u5316\uff0c\u7279\u522b\u89e3\u51b3\u4e86\u6ce8\u610f\u529b\u5c42\u4e2dBFP\u5e94\u7528\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u91cf\u5316\u662f\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u65e0\u6cd5\u5c06\u5757\u6d6e\u70b9\u6570\uff08BFP\uff09\u6fc0\u6d3b\u6269\u5c55\u5230\u6ce8\u610f\u529b\u5c42\uff0c\u5bfc\u81f4\u4e25\u91cd\u7cbe\u5ea6\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u6574\u4f53\u6548\u7387\u3002", "method": "1. \u7cfb\u7edf\u63a2\u7d22BFP\u914d\u7f6e\uff0c\u5728\u6240\u6709\u5c42\u5b9e\u73b0\u7cbe\u5ea6\u4e0e\u6fc0\u6d3b\u538b\u7f29\u7684\u66f4\u597d\u6743\u8861\uff1b2. \u5f15\u5165\u975e\u5bf9\u79f0\u4f4d\u5206\u914d\u7b56\u7565\u548c\u6df7\u5408\u79bb\u7ebf-\u5728\u7ebf\u5f02\u5e38\u503c\u5e73\u6ed1\u6280\u672f\uff0c\u5b9e\u73b0KV\u7f13\u5b58\u4eceFP16\u52304\u4f4d\u5c3e\u6570BFP\u7684\u6fc0\u8fdb\u538b\u7f29\uff1b3. \u8bbe\u8ba1\u4e13\u7528\u786c\u4ef6\u7ec4\u4ef6\uff0c\u5305\u62ec\u652f\u6301\u6df7\u5408\u6570\u636e\u683c\u5f0f\u7684\u53ef\u91cd\u6784PE\u3001\u5b9e\u65f6FP16\u5230BFP\u8f6c\u6362\u5668\u548c\u5206\u5757\u611f\u77e5\u6570\u636e\u6d41\u3002", "result": "\u57288\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u7684\u7ebf\u6027\u548c\u6ce8\u610f\u529b\u5c42GEMM\u64cd\u4f5c\u4e2d\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\uff0cHarmonia\u5e73\u5747\u5b9e\u73b03.84\u500d\uff08\u6700\u9ad85.05\u500d\uff09\u7684\u9762\u79ef\u6548\u7387\u63d0\u5347\u30012.03\u500d\uff08\u6700\u9ad83.90\u500d\uff09\u7684\u80fd\u6548\u63d0\u5347\u548c3.08\u500d\uff08\u6700\u9ad84.62\u500d\uff09\u7684\u52a0\u901f\u3002", "conclusion": "Harmonia\u6210\u529f\u89e3\u51b3\u4e86\u6ce8\u610f\u529b\u5c42\u5e94\u7528BFP\u6fc0\u6d3b\u7684\u7cbe\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u6240\u6709\u5c42BFP\u6fc0\u6d3b\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2602.04013", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.04013", "abs": "https://arxiv.org/abs/2602.04013", "authors": ["Petr Kuznetsov", "Pierre Sutra", "Guillermo Toyos-Marfurt"], "title": "Pending Conflicts Make Progress Impossible", "comment": "9 pages, 2 figures", "summary": "In this work, we study progress conditions for commutativity-aware, linearizable implementations of shared objects. Motivated by the observation that commuting operations can be executed in parallel, we introduce conflict-obstruction-freedom: a process is guaranteed to complete its operation if it runs for long enough without encountering step contention with conflicting (non-commuting) operations. This condition generalizes obstruction-freedom and wait-freedom by allowing progress as long as step contention is only induced by commuting operations. We prove that conflict-obstruction-free universal constructions are impossible to implement in the asynchronous read-write shared memory model. This result exposes a fundamental limitation of conflict-aware universal constructions: the mere invocation of conflicting operations imposes a synchronization cost. Progress requires eventual resolution of pending conflicts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5171\u4eab\u5bf9\u8c61\u7684\u53ef\u4ea4\u6362\u611f\u77e5\u7ebf\u6027\u5316\u5b9e\u73b0\u7684\u8fdb\u5c55\u6761\u4ef6\uff0c\u63d0\u51fa\u51b2\u7a81\u963b\u585e\u81ea\u7531\u7684\u6982\u5ff5\uff0c\u4f46\u8bc1\u660e\u5728\u5f02\u6b65\u8bfb\u5199\u5171\u4eab\u5185\u5b58\u6a21\u578b\u4e2d\u65e0\u6cd5\u5b9e\u73b0\u51b2\u7a81\u963b\u585e\u81ea\u7531\u7684\u901a\u7528\u6784\u9020", "motivation": "\u89c2\u5bdf\u5230\u53ef\u4ea4\u6362\u64cd\u4f5c\u53ef\u4ee5\u5e76\u884c\u6267\u884c\uff0c\u5e0c\u671b\u901a\u8fc7\u5229\u7528\u64cd\u4f5c\u7684\u4ea4\u6362\u6027\u6765\u6539\u8fdb\u5171\u4eab\u5bf9\u8c61\u5b9e\u73b0\u7684\u8fdb\u5c55\u6761\u4ef6\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u540c\u6b65\u5f00\u9500", "method": "\u5f15\u5165\u51b2\u7a81\u963b\u585e\u81ea\u7531\u7684\u6982\u5ff5\uff1a\u5982\u679c\u4e00\u4e2a\u8fdb\u7a0b\u5728\u8db3\u591f\u957f\u7684\u65f6\u95f4\u5185\u8fd0\u884c\u800c\u6ca1\u6709\u9047\u5230\u4e0e\u51b2\u7a81\uff08\u4e0d\u53ef\u4ea4\u6362\uff09\u64cd\u4f5c\u7684\u6b65\u9aa4\u4e89\u7528\uff0c\u5219\u4fdd\u8bc1\u5b8c\u6210\u5176\u64cd\u4f5c\u3002\u8fd9\u901a\u8fc7\u5141\u8bb8\u53ea\u8981\u6b65\u9aa4\u4e89\u7528\u4ec5\u7531\u53ef\u4ea4\u6362\u64cd\u4f5c\u5f15\u8d77\u5c31\u80fd\u53d6\u5f97\u8fdb\u5c55\uff0c\u6765\u63a8\u5e7f\u963b\u585e\u81ea\u7531\u548c\u7b49\u5f85\u81ea\u7531", "result": "\u8bc1\u660e\u5728\u5f02\u6b65\u8bfb\u5199\u5171\u4eab\u5185\u5b58\u6a21\u578b\u4e2d\uff0c\u51b2\u7a81\u963b\u585e\u81ea\u7531\u7684\u901a\u7528\u6784\u9020\u662f\u4e0d\u53ef\u80fd\u5b9e\u73b0\u7684\u3002\u8fd9\u4e00\u7ed3\u679c\u63ed\u793a\u4e86\u51b2\u7a81\u611f\u77e5\u901a\u7528\u6784\u9020\u7684\u57fa\u672c\u9650\u5236\uff1a\u4ec5\u4ec5\u662f\u51b2\u7a81\u64cd\u4f5c\u7684\u8c03\u7528\u5c31\u4f1a\u5e26\u6765\u540c\u6b65\u6210\u672c", "conclusion": "\u8fdb\u5c55\u9700\u8981\u6700\u7ec8\u89e3\u51b3\u5f85\u5904\u7406\u7684\u51b2\u7a81\uff0c\u51b2\u7a81\u611f\u77e5\u7684\u901a\u7528\u6784\u9020\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u51b2\u7a81\u64cd\u4f5c\u5e26\u6765\u7684\u540c\u6b65\u5f00\u9500"}}
{"id": "2602.04652", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.04652", "abs": "https://arxiv.org/abs/2602.04652", "authors": ["Ryan Barker", "Fatemeh Afghah"], "title": "Six Times to Spare: LDPC Acceleration on DGX Spark for AI-Native Open RAN", "comment": "6 pages, 2 figures, 1 table, 1 equation", "summary": "Low-density parity-check (LDPC) decoding is one of the most computationally intensive kernels in the 5G New Radio (NR) physical layer and must complete within a 0.5\\,ms transmission time interval while sharing the budget with FFT, channel estimation, demapping, HARQ, and MAC scheduling. Many open and proprietary stacks still execute LDPC on general-purpose CPUs, raising concerns about missed-slot events and limited scalability as bandwidths, modulation orders, and user multiplexing increase. This paper empirically quantifies the benefit of offloading 5G-style LDPC5G decoding from a Grace CPU to the integrated Blackwell GB10 GPU on an NVIDIA DGX~Spark platform. Using NVIDIA Sionna PHY/SYS on TensorFlow, we construct an NR-like link-level chain with an LDPC5G encoder/decoder, 16-QAM modulation, and AWGN, and sweep both the number of codewords decoded in parallel and the number of belief-propagation iterations, timing only the decoding phase while logging CPU and GPU utilization and power. Across the sweep we observe an average GPU/CPU throughput speedup of approximately $6\\times$, with per-codeword CPU latency reaching $\\approx 0.71$\\,ms at 20 iterations (exceeding the 0.5\\,ms slot), while the GB10 GPU remains within 6--24\\% of the slot for the same workloads. Resource-usage measurements show that CPU-based LDPC decoding often consumes around ten Grace cores, whereas GPU-based decoding adds only $\\approx10-15$\\,W over GPU idle while leaving most CPU capacity available for higher-layer tasks. Because our implementation relies on high-level Sionna layers rather than hand-tuned CUDA, these results represent conservative lower bounds on achievable accelerator performance and provide a reusable, scriptable methodology for evaluating LDPC and other physical-layer kernels on future Grace/Blackwell and Aerial/ACAR/AODT platforms.", "AI": {"tldr": "\u8bba\u6587\u5b9e\u8bc1\u91cf\u5316\u4e86\u5c065G LDPC\u89e3\u7801\u4eceGrace CPU\u5378\u8f7d\u5230Blackwell GB10 GPU\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5728DGX Spark\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u7ea66\u500d\u7684\u541e\u5410\u91cf\u52a0\u901f\uff0cGPU\u89e3\u7801\u5ef6\u8fdf\u4fdd\u6301\u57280.5ms\u65f6\u9699\u5185\uff0c\u800cCPU\u89e3\u7801\u4f1a\u8d85\u65f6\u3002", "motivation": "5G NR\u7269\u7406\u5c42\u4e2d\u7684LDPC\u89e3\u7801\u662f\u8ba1\u7b97\u6700\u5bc6\u96c6\u7684\u6838\u5fc3\u4e4b\u4e00\uff0c\u5fc5\u987b\u57280.5ms\u4f20\u8f93\u65f6\u95f4\u95f4\u9694\u5185\u5b8c\u6210\u3002\u8bb8\u591a\u73b0\u6709\u7cfb\u7edf\u4ecd\u5728\u901a\u7528CPU\u4e0a\u6267\u884cLDPC\u89e3\u7801\uff0c\u968f\u7740\u5e26\u5bbd\u3001\u8c03\u5236\u9636\u6570\u548c\u7528\u6237\u590d\u7528\u7684\u589e\u52a0\uff0c\u5b58\u5728\u65f6\u9699\u9519\u8fc7\u548c\u53ef\u6269\u5c55\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528NVIDIA Sionna PHY/SYS\u5728TensorFlow\u4e0a\u6784\u5efaNR\u7c7b\u94fe\u8def\u7ea7\u94fe\uff0c\u5305\u542bLDPC5G\u7f16\u7801\u5668/\u89e3\u7801\u5668\u300116-QAM\u8c03\u5236\u548cAWGN\u4fe1\u9053\u3002\u901a\u8fc7\u626b\u63cf\u5e76\u884c\u89e3\u7801\u7684\u7801\u5b57\u6570\u91cf\u548c\u7f6e\u4fe1\u4f20\u64ad\u8fed\u4ee3\u6b21\u6570\uff0c\u4ec5\u6d4b\u91cf\u89e3\u7801\u9636\u6bb5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8bb0\u5f55CPU\u548cGPU\u5229\u7528\u7387\u548c\u529f\u8017\u3002", "result": "GPU/CPU\u541e\u5410\u91cf\u52a0\u901f\u6bd4\u5e73\u5747\u7ea6\u4e3a6\u500d\u3002CPU\u89e3\u7801\u5ef6\u8fdf\u572820\u6b21\u8fed\u4ee3\u65f6\u8fbe\u5230\u7ea60.71ms\uff08\u8d85\u8fc70.5ms\u65f6\u9699\uff09\uff0c\u800cGB10 GPU\u5728\u76f8\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u5728\u65f6\u9699\u76846-24%\u8303\u56f4\u5185\u3002CPU\u89e3\u7801\u901a\u5e38\u6d88\u8017\u7ea610\u4e2aGrace\u6838\u5fc3\uff0c\u800cGPU\u89e3\u7801\u4ec5\u6bd4GPU\u7a7a\u95f2\u72b6\u6001\u589e\u52a010-15W\u529f\u8017\u3002", "conclusion": "GPU\u5378\u8f7dLDPC\u89e3\u7801\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u6ee1\u8db3\u65f6\u9699\u8981\u6c42\uff0c\u540c\u65f6\u91ca\u653eCPU\u8d44\u6e90\u7528\u4e8e\u66f4\u9ad8\u5c42\u4efb\u52a1\u3002\u57fa\u4e8e\u9ad8\u7ea7Sionna\u5c42\u7684\u5b9e\u73b0\u4ee3\u8868\u4e86\u53ef\u5b9e\u73b0\u7684\u52a0\u901f\u5668\u6027\u80fd\u7684\u4fdd\u5b88\u4e0b\u9650\uff0c\u4e3a\u672a\u6765\u5e73\u53f0\u4e0a\u7684\u7269\u7406\u5c42\u5185\u6838\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u3001\u53ef\u811a\u672c\u5316\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.04697", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.04697", "abs": "https://arxiv.org/abs/2602.04697", "authors": ["Davide Basile", "Valerio Goretti", "Luca Barbaro", "Hajo A. Reijers", "Claudio Di Ciccio"], "title": "A TEE-based Approach for Preserving Data Secrecy in Process Mining with Decentralized Sources", "comment": "arXiv admin note: text overlap with arXiv:2312.12105", "summary": "Process mining techniques enable organizations to gain insights into their business processes through the analysis of execution records (event logs) stored by information systems. While most process mining efforts focus on intra-organizational scenarios, many real-world business processes span multiple independent organizations. Inter-organizational process mining, though, faces significant challenges, particularly regarding confidentiality guarantees: The analysis of data can reveal information that the participating organizations may not consent to disclose to one another, or to a third party hosting process mining services. To overcome this issue, this paper presents CONFINE, an approach for secrecy-preserving inter-organizational process mining. CONFINE leverages Trusted Execution Environments (TEEs) to deploy trusted applications that are capable of securely mining multi-party event logs while preserving data secrecy. We propose an architecture supporting a four-stage protocol to secure data exchange and processing, allowing for protected transfer and aggregation of unaltered process data across organizational boundaries. To avoid out-of-memory errors due to the limited capacity of TEEs, our protocol employs a segmentation-based strategy, whereby event logs are transmitted to TEEs in smaller batches. We conduct a formal verification of correctness and a security analysis of the guarantees provided by the TEE core. We evaluate our implementation on real-world and synthetic data, showing that the proposed approach can handle realistic workloads. The results indicate logarithmic memory growth with respect to the event log size and linear growth with the number of provisioning organizations, highlighting scalability properties and opportunities for further optimization.", "AI": {"tldr": "CONFINE\uff1a\u57fa\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u7684\u4fdd\u5bc6\u6027\u4fdd\u62a4\u8de8\u7ec4\u7ec7\u6d41\u7a0b\u6316\u6398\u65b9\u6cd5\uff0c\u901a\u8fc7\u56db\u9636\u6bb5\u534f\u8bae\u5b9e\u73b0\u5b89\u5168\u6570\u636e\u4ea4\u6362\u548c\u5904\u7406\uff0c\u907f\u514d\u5185\u5b58\u6ea2\u51fa\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u3002", "motivation": "\u8de8\u7ec4\u7ec7\u6d41\u7a0b\u6316\u6398\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u4fdd\u5bc6\u6027\u95ee\u9898\uff1a\u6570\u636e\u5206\u6790\u53ef\u80fd\u6cc4\u9732\u53c2\u4e0e\u7ec4\u7ec7\u4e0d\u613f\u5411\u5f7c\u6b64\u6216\u7b2c\u4e09\u65b9\u62ab\u9732\u7684\u4fe1\u606f\u3002\u73b0\u6709\u6d41\u7a0b\u6316\u6398\u4e3b\u8981\u5173\u6ce8\u7ec4\u7ec7\u5185\u573a\u666f\uff0c\u800c\u73b0\u5b9e\u4e1a\u52a1\u6d41\u7a0b\u5e38\u8de8\u8d8a\u591a\u4e2a\u72ec\u7acb\u7ec4\u7ec7\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u4fdd\u5bc6\u6027\u9650\u5236\u3002", "method": "\u63d0\u51faCONFINE\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u90e8\u7f72\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\uff0c\u5b89\u5168\u5730\u6316\u6398\u591a\u65b9\u4e8b\u4ef6\u65e5\u5fd7\u540c\u65f6\u4fdd\u6301\u6570\u636e\u4fdd\u5bc6\u6027\u3002\u91c7\u7528\u56db\u9636\u6bb5\u534f\u8bae\u4fdd\u62a4\u6570\u636e\u4f20\u8f93\u548c\u5904\u7406\uff0c\u901a\u8fc7\u5206\u6bb5\u7b56\u7565\u5c06\u4e8b\u4ef6\u65e5\u5fd7\u5206\u6279\u4f20\u8f93\u5230TEE\u4ee5\u907f\u514d\u5185\u5b58\u6ea2\u51fa\u3002", "result": "\u5bf9\u5b9e\u73b0\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u5b89\u5168\u5206\u6790\uff0c\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u4e0a\u8bc4\u4f30\u8868\u660e\u65b9\u6cd5\u80fd\u5904\u7406\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u3002\u7ed3\u679c\u663e\u793a\u5185\u5b58\u589e\u957f\u4e0e\u4e8b\u4ef6\u65e5\u5fd7\u5927\u5c0f\u5448\u5bf9\u6570\u5173\u7cfb\uff0c\u4e0e\u4f9b\u5e94\u7ec4\u7ec7\u6570\u91cf\u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CONFINE\u4e3a\u8de8\u7ec4\u7ec7\u6d41\u7a0b\u6316\u6398\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4fdd\u5bc6\u6027\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528TEE\u6280\u672f\u5b9e\u73b0\u5b89\u5168\u6570\u636e\u5904\u7406\uff0c\u5206\u6bb5\u7b56\u7565\u89e3\u51b3\u4e86\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u6f5c\u529b\u3002"}}
