{"id": "2509.18583", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.18583", "abs": "https://arxiv.org/abs/2509.18583", "authors": ["Liyi Li", "Fenfen An", "Federico Zahariev", "Zhi Xiang Chong", "Amr Sabry", "Mark Gordon"], "title": "A Verified Compiler for Quantum Simulation", "comment": "Paper accepted to the Quantum Programming Languages (QPL) 2025\n  conference; available from: https://qpl2025.github.io/accepted/", "summary": "Hamiltonian simulation is a central application of quantum computing, with\nsignificant potential in modeling physical systems and solving complex\noptimization problems. Existing compilers for such simulations typically focus\non low-level representations based on Pauli operators, limiting programmability\nand offering no formal guarantees of correctness across the compilation\npipeline. We introduce QBlue, a high-level, formally verified framework for\ncompiling Hamiltonian simulations. QBlue is based on the formalism of second\nquantization, which provides a natural and expressive way to describe quantum\nparticle systems using creation and annihilation operators. To ensure safety\nand correctness, QBlue includes a type system that tracks particle types and\nenforces Hermitian structure. The framework supports compilation to both\ndigital and analog quantum circuits and captures multiple layers of semantics,\nfrom static constraints to dynamic evolution. All components of QBlue,\nincluding its language design, type system, and compilation correctness, are\nfully mechanized in the Rocq proof framework, making it the first end-to-end\nverified compiler for second-quantized Hamiltonian simulation.", "AI": {"tldr": "QBlue\u662f\u4e00\u4e2a\u7528\u4e8e\u54c8\u5bc6\u987f\u91cf\u6a21\u62df\u7684\u9ad8\u5c42\u6b21\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7f16\u8bd1\u6846\u67b6\uff0c\u57fa\u4e8e\u4e8c\u6b21\u91cf\u5b50\u5316\u5f62\u5f0f\uff0c\u63d0\u4f9b\u7c7b\u578b\u7cfb\u7edf\u786e\u4fdd\u6b63\u786e\u6027\uff0c\u5e76\u652f\u6301\u7f16\u8bd1\u5230\u6570\u5b57\u548c\u6a21\u62df\u91cf\u5b50\u7535\u8def\u3002", "motivation": "\u73b0\u6709\u7684\u54c8\u5bc6\u987f\u91cf\u6a21\u62df\u7f16\u8bd1\u5668\u901a\u5e38\u57fa\u4e8e\u4f4e\u5c42\u6b21\u7684\u6ce1\u5229\u7b97\u7b26\u8868\u793a\uff0c\u9650\u5236\u4e86\u53ef\u7f16\u7a0b\u6027\u4e14\u7f3a\u4e4f\u7f16\u8bd1\u7ba1\u9053\u7684\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u4fdd\u8bc1\u3002", "method": "\u57fa\u4e8e\u4e8c\u6b21\u91cf\u5b50\u5316\u5f62\u5f0f\uff0c\u4f7f\u7528\u4ea7\u751f\u548c\u6e6e\u706d\u7b97\u7b26\u63cf\u8ff0\u91cf\u5b50\u7c92\u5b50\u7cfb\u7edf\uff1b\u5305\u542b\u7c7b\u578b\u7cfb\u7edf\u8ddf\u8e2a\u7c92\u5b50\u7c7b\u578b\u5e76\u5f3a\u5236\u5384\u7c73\u7ed3\u6784\uff1b\u652f\u6301\u7f16\u8bd1\u5230\u6570\u5b57\u548c\u6a21\u62df\u91cf\u5b50\u7535\u8def\uff1b\u5728Rocq\u8bc1\u660e\u6846\u67b6\u4e2d\u5b8c\u5168\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "result": "QBlue\u662f\u7b2c\u4e00\u4e2a\u7aef\u5230\u7aef\u9a8c\u8bc1\u7684\u4e8c\u6b21\u91cf\u5b50\u5316\u54c8\u5bc6\u987f\u91cf\u6a21\u62df\u7f16\u8bd1\u5668\uff0c\u63d0\u4f9b\u4e86\u4ece\u9759\u6001\u7ea6\u675f\u5230\u52a8\u6001\u6f14\u5316\u7684\u591a\u5c42\u8bed\u4e49\u6355\u83b7\u3002", "conclusion": "QBlue\u6846\u67b6\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u89e3\u51b3\u4e86\u54c8\u5bc6\u987f\u91cf\u6a21\u62df\u7f16\u8bd1\u5668\u7684\u6b63\u786e\u6027\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u5728\u7269\u7406\u7cfb\u7edf\u5efa\u6a21\u548c\u4f18\u5316\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\u3002"}}
{"id": "2509.18295", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.18295", "abs": "https://arxiv.org/abs/2509.18295", "authors": ["Allen Boston", "Biruk Seyoum", "Luca Carloni", "Pierre-Emmanuel Gaillardon"], "title": "Lightweight Congruence Profiling for Early Design Exploration of Heterogeneous FPGAs", "comment": "This paper has been accepted for presentation at VLSI-SoC in October", "summary": "Field-Programmable Gate Arrays (FPGAs) have evolved from uniform logic arrays\ninto heterogeneous fabrics integrating digital signal processors (DSPs),\nmemories, and specialized accelerators to support emerging workloads such as\nmachine learning. While these enhancements improve power, performance, and area\n(PPA), they complicate design space exploration and application optimization\ndue to complex resource interactions.\n  To address these challenges, we propose a lightweight profiling methodology\ninspired by the Roofline model. It introduces three congruence scores that\nquickly identify bottlenecks related to heterogeneous resources, fabric, and\napplication logic. Evaluated on the Koios and VPR benchmark suites using a\nStratix 10 like FPGA, this approach enables efficient FPGA architecture\nco-design to improve heterogeneous FPGA performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eRoofline\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e00\u81f4\u6027\u8bc4\u5206\u5feb\u901f\u8bc6\u522b\u5f02\u6784FPGA\u4e2d\u7684\u6027\u80fd\u74f6\u9888", "motivation": "FPGA\u4ece\u5747\u5300\u903b\u8f91\u9635\u5217\u53d1\u5c55\u4e3a\u96c6\u6210DSP\u3001\u5b58\u50a8\u5668\u548c\u4e13\u7528\u52a0\u901f\u5668\u7684\u5f02\u6784\u67b6\u6784\uff0c\u8fd9\u867d\u7136\u6539\u5584\u4e86PPA\uff08\u529f\u8017\u3001\u6027\u80fd\u3001\u9762\u79ef\uff09\uff0c\u4f46\u7531\u4e8e\u590d\u6742\u7684\u8d44\u6e90\u4ea4\u4e92\uff0c\u589e\u52a0\u4e86\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u548c\u5e94\u7528\u4f18\u5316\u7684\u96be\u5ea6", "method": "\u53d7Roofline\u6a21\u578b\u542f\u53d1\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5206\u6790\u65b9\u6cd5\uff0c\u5f15\u5165\u4e09\u4e2a\u4e00\u81f4\u6027\u8bc4\u5206\u6765\u8bc6\u522b\u5f02\u6784\u8d44\u6e90\u3001\u67b6\u6784\u548c\u5e94\u7528\u903b\u8f91\u76f8\u5173\u7684\u74f6\u9888\u3002\u5728Stratix 10\u7c7b\u4f3cFPGA\u4e0a\u4f7f\u7528Koios\u548cVPR\u57fa\u51c6\u5957\u4ef6\u8fdb\u884c\u8bc4\u4f30", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522bFPGA\u5f02\u6784\u67b6\u6784\u4e2d\u7684\u6027\u80fd\u74f6\u9888", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u9ad8\u6548\u7684FPGA\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5f02\u6784FPGA\u7684\u6027\u80fd"}}
{"id": "2509.18472", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18472", "abs": "https://arxiv.org/abs/2509.18472", "authors": ["Atanu Barai", "Kamalavasan Kamalakkannan", "Patrick Diehl", "Maxim Moraru", "Jered Dominguez-Trujillo", "Howard Pritchard", "Nandakishore Santhi", "Farzad Fatollahi-Fard", "Galen Shipman"], "title": "Bridging Simulation and Silicon: A Study of RISC-V Hardware and FireSim Simulation", "comment": null, "summary": "RISC-V ISA-based processors have recently emerged as both powerful and\nenergy-efficient computing platforms. The release of the MILK-V Pioneer marked\na significant milestone as the first desktop-grade RISC-V system. With\nincreasing engagement from both academia and industry, such platforms exhibit\nstrong potential for adoption in high-performance computing (HPC) environments.\n  The open-source, FPGA-accelerated FireSim framework has emerged as a flexible\nand scalable tool for architectural exploration, enabling simulation of various\nsystem configurations using RISC-V cores. Despite its capabilities, there\nremains a lack of systematic evaluation regarding the feasibility and\nperformance prediction accuracy of FireSim when compared to physical hardware.\n  In this study, we address this gap by modeling a commercially available\nsingle-board computer and a desktop-grade RISC-V CPU within FireSim. To ensure\nfidelity between simulation and real hardware, we first measure the performance\nof a series of benchmarks to compare runtime behavior under single-core and\nfour-core configurations. Based on the closest matching simulation parameters,\nwe subsequently evaluate performance using a representative mini-application\nand the LAMMPS molecular dynamics code.\n  Our findings indicate that while FireSim provides valuable insights into\narchitectural performance trends, discrepancies remain between simulated and\nmeasured runtimes. These deviations stem from both inherent limitations of the\nsimulation environment and the restricted availability of detailed performance\nspecifications from CPU manufacturers, which hinder precise configuration\nmatching.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86FireSim\u6846\u67b6\u5728RISC-V\u5904\u7406\u5668\u6027\u80fd\u9884\u6d4b\u65b9\u9762\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u5bf9\u6bd4\u6a21\u62df\u7ed3\u679c\u4e0e\u771f\u5b9e\u786c\u4ef6\u6027\u80fd\uff0c\u53d1\u73b0\u867d\u7136FireSim\u80fd\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u67b6\u6784\u6027\u80fd\u8d8b\u52bf\uff0c\u4f46\u6a21\u62df\u4e0e\u5b9e\u6d4b\u8fd0\u884c\u65f6\u95f4\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "RISC-V ISA\u5904\u7406\u5668\u4f5c\u4e3a\u5f3a\u5927\u4e14\u8282\u80fd\u7684\u8ba1\u7b97\u5e73\u53f0\u663e\u793a\u51fa\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002FireSim\u4f5c\u4e3a\u5f00\u6e90FPGA\u52a0\u901f\u6846\u67b6\u867d\u7136\u7075\u6d3b\u53ef\u6269\u5c55\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5728RISC-V\u5e73\u53f0\u4e0a\u6027\u80fd\u9884\u6d4b\u51c6\u786e\u6027\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u901a\u8fc7FireSim\u6a21\u62df\u5546\u4e1a\u5355\u677f\u8ba1\u7b97\u673a\u548c\u684c\u9762\u7ea7RISC-V CPU\uff0c\u9996\u5148\u6d4b\u91cf\u57fa\u51c6\u6d4b\u8bd5\u5728\u5355\u6838\u548c\u56db\u6838\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\u4ee5\u6bd4\u8f83\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u7136\u540e\u4f7f\u7528\u4ee3\u8868\u6027\u5c0f\u578b\u5e94\u7528\u548cLAMMPS\u5206\u5b50\u52a8\u529b\u5b66\u4ee3\u7801\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0FireSim\u80fd\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u67b6\u6784\u6027\u80fd\u8d8b\u52bf\u6d1e\u5bdf\uff0c\u4f46\u6a21\u62df\u8fd0\u884c\u65f6\u95f4\u4e0e\u5b9e\u6d4b\u7ed3\u679c\u5b58\u5728\u504f\u5dee\uff0c\u8fd9\u4e9b\u5dee\u5f02\u6e90\u4e8e\u6a21\u62df\u73af\u5883\u7684\u56fa\u6709\u9650\u5236\u4ee5\u53caCPU\u5236\u9020\u5546\u63d0\u4f9b\u7684\u8be6\u7ec6\u6027\u80fd\u89c4\u683c\u4fe1\u606f\u6709\u9650\u3002", "conclusion": "FireSim\u662fRISC-V\u67b6\u6784\u63a2\u7d22\u7684\u6709\u7528\u5de5\u5177\uff0c\u4f46\u9700\u8981\u66f4\u7cbe\u786e\u7684\u914d\u7f6e\u5339\u914d\u548c\u66f4\u8be6\u7ec6\u7684\u786c\u4ef6\u89c4\u683c\u4fe1\u606f\u6765\u63d0\u9ad8\u6a21\u62df\u51c6\u786e\u6027\u3002"}}
{"id": "2509.18355", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18355", "abs": "https://arxiv.org/abs/2509.18355", "authors": ["P. Ramkumar", "S. S. Bharadwaj"], "title": "Chiplet-Based RISC-V SoC with Modular AI Acceleration", "comment": "3 pages, 3 figures and 2 tables", "summary": "Achieving high performance, energy efficiency, and cost-effectiveness while\nmaintaining architectural flexibility is a critical challenge in the\ndevelopment and deployment of edge AI devices. Monolithic SoC designs struggle\nwith this complex balance mainly due to low manufacturing yields (below 16%) at\nadvanced 360 mm^2 process nodes. This paper presents a novel chiplet-based\nRISC-V SoC architecture that addresses these limitations through modular AI\nacceleration and intelligent system level optimization. Our proposed design\nintegrates 4 different key innovations in a 30mm x 30mm silicon interposer:\nadaptive cross-chiplet Dynamic Voltage and Frequency Scaling (DVFS); AI-aware\nUniversal Chiplet Interconnect Express (UCIe) protocol extensions featuring\nstreaming flow control units and compression-aware transfers; distributed\ncryptographic security across heterogeneous chiplets; and intelligent\nsensor-driven load migration. The proposed architecture integrates a 7nm RISC-V\nCPU chiplet with dual 5nm AI accelerators (15 TOPS INT8 each), 16GB HBM3 memory\nstacks, and dedicated power management controllers. Experimental results across\nindustry standard benchmarks like MobileNetV2, ResNet-50 and real-time video\nprocessing demonstrate significant performance improvements. The AI-optimized\nconfiguration achieves ~14.7% latency reduction, 17.3% throughput improvement,\nand 16.2% power reduction compared to previous basic chiplet implementations.\nThese improvements collectively translate to a 40.1% efficiency gain\ncorresponding to ~3.5 mJ per MobileNetV2 inference (860 mW/244 images/s), while\nmaintaining sub-5ms real-time capability across all experimented workloads.\nThese performance upgrades demonstrate that modular chiplet designs can achieve\nnear-monolithic computational density while enabling cost efficiency,\nscalability and upgradeability, crucial for next-generation edge AI device\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u82af\u7247\u7684RISC-V SoC\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316AI\u52a0\u901f\u548c\u667a\u80fd\u7cfb\u7edf\u7ea7\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18AI\u8bbe\u5907\u5728\u6027\u80fd\u3001\u80fd\u6548\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u5355\u7247SoC\u8bbe\u8ba1\u5728\u5148\u8fdb\u5de5\u827a\u8282\u70b9\u4e0b\u5236\u9020\u826f\u7387\u4f4e\uff08\u4f4e\u4e8e16%\uff09\uff0c\u96be\u4ee5\u5e73\u8861\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u548c\u6210\u672c\u6548\u76ca\u3002\u9700\u8981\u4e00\u79cd\u65b0\u7684\u67b6\u6784\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u91c7\u7528\u5c0f\u82af\u7247\u67b6\u6784\uff0c\u572830mm x 30mm\u7845\u4e2d\u4ecb\u5c42\u4e0a\u96c6\u62104\u9879\u5173\u952e\u6280\u672f\uff1a\u81ea\u9002\u5e94\u8de8\u82af\u7247\u52a8\u6001\u7535\u538b\u9891\u7387\u8c03\u8282\u3001AI\u611f\u77e5\u7684UCIe\u534f\u8bae\u6269\u5c55\u3001\u5206\u5e03\u5f0f\u52a0\u5bc6\u5b89\u5168\u3001\u667a\u80fd\u4f20\u611f\u5668\u9a71\u52a8\u7684\u8d1f\u8f7d\u8fc1\u79fb\u3002\u96c6\u62107nm RISC-V CPU\u82af\u7247\u3001\u53cc5nm AI\u52a0\u901f\u5668\uff08\u540415 TOPS INT8\uff09\u300116GB HBM3\u5185\u5b58\u548c\u4e13\u7528\u7535\u6e90\u7ba1\u7406\u63a7\u5236\u5668\u3002", "result": "\u5728MobileNetV2\u3001ResNet-50\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAI\u4f18\u5316\u914d\u7f6e\u76f8\u6bd4\u57fa\u7840\u5c0f\u82af\u7247\u5b9e\u73b0\u5b9e\u73b0\u4e8614.7%\u5ef6\u8fdf\u964d\u4f4e\u300117.3%\u541e\u5410\u91cf\u63d0\u5347\u300116.2%\u529f\u8017\u964d\u4f4e\uff0c\u603b\u4f53\u6548\u7387\u63d0\u534740.1%\uff0c\u8fbe\u5230\u6bcfMobileNetV2\u63a8\u74063.5mJ\uff08860mW/244 images/s\uff09\uff0c\u6240\u6709\u5de5\u4f5c\u8d1f\u8f7d\u5747\u4fdd\u6301\u4e9a5ms\u5b9e\u65f6\u80fd\u529b\u3002", "conclusion": "\u6a21\u5757\u5316\u5c0f\u82af\u7247\u8bbe\u8ba1\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u5355\u7247\u7684\u8ba1\u7b97\u5bc6\u5ea6\uff0c\u540c\u65f6\u5177\u5907\u6210\u672c\u6548\u76ca\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u5347\u7ea7\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8fb9\u7f18AI\u8bbe\u5907\u5e94\u7528\u63d0\u4f9b\u4e86\u5173\u952e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18735", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18735", "abs": "https://arxiv.org/abs/2509.18735", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Muhammad Ali Jamshed", "Dean F. Hougen", "John M. Cioffi"], "title": "6G Twin: Hybrid Gaussian Radio Fields for Channel Estimation and Non-Linear Precoder Design for Radio Access Networks", "comment": "Submitted to IEEE Transactions on Wireless Communications", "summary": "This work introduces 6G Twin, the first end-to-end artificial intelligence\n(AI)-native radio access network (RAN) design that unifies (i) neural Gaussian\nRadio Fields (GRF) for compressed channel state information (CSI) acquisition,\n(ii) continual channel prediction with handover persistence, and (iii) an\nenergy-optimal nonlinear precoder (minPMAC). GRF replaces dense pilots with a\nsparse Gaussian field, cutting pilot overhead by about 100x while delivering\n1.1 ms inference and less than 2 minutes on-site training, thus enabling\nmillisecond-scale closed-loop operation. A replay-driven continual learner\nsustains accuracy under mobility and cell transitions, improving channel\nnormalized mean square error (NMSE) by more than 10 dB over frozen predictors\nand an additional 2-5 dB over uniform replay, thereby stabilizing performance\nacross UMi/UMa handovers. Finally, minPMAC solves a convex, order-free MAC\nprecoder design that recovers the globally optimal order from Broadcast Channel\n(BC) duals and minimizes transmit energy subject to minimum-rate guarantees,\nachieving 4-10 times lower energy (scenario dependent) with monotonically\nincreasing bits per joule as SNR grows. This translates to up to 5 times higher\ndata rate at comparable power or the same rates at substantially lower power.\nTogether, these components form a practical, GPU-ready framework that attains\nreal-time CSI, robust tracking in dynamic networks with efficient handovers,\nand state-of-the-art throughput-energy tradeoffs under 3GPP-style settings.", "AI": {"tldr": "6G Twin\u662f\u9996\u4e2a\u7aef\u5230\u7aefAI\u539f\u751f\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u8bbe\u8ba1\uff0c\u901a\u8fc7\u795e\u7ecf\u9ad8\u65af\u65e0\u7ebf\u7535\u573a\u538b\u7f29\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u3001\u6301\u7eed\u4fe1\u9053\u9884\u6d4b\u548c\u80fd\u91cf\u6700\u4f18\u975e\u7ebf\u6027\u9884\u7f16\u7801\u5668\uff0c\u5b9e\u73b0100\u500d\u5bfc\u9891\u5f00\u9500\u964d\u4f4e\u3001\u6beb\u79d2\u7ea7\u95ed\u73af\u64cd\u4f5c\u548c4-10\u500d\u80fd\u8017\u964d\u4f4e\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfRAN\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u52a8\u6001\u7f51\u7edc\u4e2d\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u5f00\u9500\u5927\u3001\u9884\u6d4b\u4e0d\u51c6\u786e\u4ee5\u53ca\u80fd\u91cf\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u5b9e\u65f6\u3001\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u9ad8\u65af\u65e0\u7ebf\u7535\u573a\uff08GRF\uff09\u66ff\u4ee3\u5bc6\u96c6\u5bfc\u9891\u8fdb\u884c\u538b\u7f29CSI\u83b7\u53d6\uff0c\u4f7f\u7528\u91cd\u653e\u9a71\u52a8\u7684\u6301\u7eed\u5b66\u4e60\u5668\u8fdb\u884c\u4fe1\u9053\u9884\u6d4b\u548c\u5207\u6362\u6301\u4e45\u6027\uff0c\u8bbe\u8ba1\u6700\u5c0f\u529f\u7387\u591a\u5740\u63a5\u5165\u9884\u7f16\u7801\u5668\uff08minPMAC\uff09\u8fdb\u884c\u80fd\u91cf\u6700\u4f18\u975e\u7ebf\u6027\u9884\u7f16\u7801\u3002", "result": "GRF\u5c06\u5bfc\u9891\u5f00\u9500\u964d\u4f4e\u7ea6100\u500d\uff0c\u63a8\u7406\u65f6\u95f41.1\u6beb\u79d2\uff0c\u73b0\u573a\u8bad\u7ec3\u5c11\u4e8e2\u5206\u949f\uff1b\u6301\u7eed\u5b66\u4e60\u5668\u5728\u79fb\u52a8\u6027\u548c\u5c0f\u533a\u5207\u6362\u4e0b\u5c06\u4fe1\u9053NMSE\u6539\u5584\u8d85\u8fc710dB\uff1bminPMAC\u5b9e\u73b04-10\u500d\u80fd\u8017\u964d\u4f4e\uff0c\u5728\u53ef\u6bd4\u529f\u7387\u4e0b\u6570\u636e\u901f\u7387\u63d0\u5347\u9ad8\u8fbe5\u500d\u3002", "conclusion": "6G Twin\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684GPU\u5c31\u7eea\u6846\u67b6\uff0c\u57283GPP\u6807\u51c6\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u5b9e\u65f6CSI\u3001\u52a8\u6001\u7f51\u7edc\u4e2d\u7684\u9c81\u68d2\u8ddf\u8e2a\u548c\u6700\u4f18\u7684\u541e\u5410\u91cf-\u80fd\u91cf\u6743\u8861\uff0c\u4e3a6G\u7f51\u7edc\u90e8\u7f72\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.18869", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18869", "abs": "https://arxiv.org/abs/2509.18869", "authors": ["Baiqiang Wang", "Dongfang Zhao", "Nathan R Tallent", "Luanzheng Guo"], "title": "On The Reproducibility Limitations of RAG Systems", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is increasingly employed in generative\nAI-driven scientific workflows to integrate rapidly evolving scientific\nknowledge bases, yet its reliability is frequently compromised by\nnon-determinism in their retrieval components. This paper introduces ReproRAG,\na comprehensive benchmarking framework designed to systematically measure and\nquantify the reproducibility of vector-based retrieval systems. ReproRAG\ninvestigates sources of uncertainty across the entire pipeline, including\ndifferent embedding models, precision, retrieval algorithms, hardware\nconfigurations, and distributed execution environments. Utilizing a suite of\nmetrics, such as Exact Match Rate, Jaccard Similarity, and Kendall's Tau, the\nproposed framework effectively characterizes the trade-offs between\nreproducibility and performance. Our large-scale empirical study reveals\ncritical insights; for instance, we observe that different embedding models\nhave remarkable impact on RAG reproducibility. The open-sourced ReproRAG\nframework provides researchers and engineers productive tools to validate\ndeployments, benchmark reproducibility, and make informed design decisions,\nthereby fostering more trustworthy AI for science.", "AI": {"tldr": "ReproRAG\u662f\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u6d4b\u91cf\u548c\u91cf\u5316\u57fa\u4e8e\u5411\u91cf\u7684\u68c0\u7d22\u7cfb\u7edf\u53ef\u91cd\u73b0\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3RAG\u7cfb\u7edf\u4e2d\u68c0\u7d22\u7ec4\u4ef6\u975e\u786e\u5b9a\u6027\u5bfc\u81f4\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "RAG\u5728\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u53ef\u9760\u6027\u5e38\u56e0\u68c0\u7d22\u7ec4\u4ef6\u7684\u975e\u786e\u5b9a\u6027\u800c\u53d7\u635f\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u53ef\u91cd\u73b0\u6027\u3002", "method": "ReproRAG\u6846\u67b6\u901a\u8fc7\u5206\u6790\u5d4c\u5165\u6a21\u578b\u3001\u7cbe\u5ea6\u3001\u68c0\u7d22\u7b97\u6cd5\u3001\u786c\u4ef6\u914d\u7f6e\u548c\u5206\u5e03\u5f0f\u6267\u884c\u73af\u5883\u7b49\u6574\u4e2a\u6d41\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\uff0c\u4f7f\u7528\u7cbe\u786e\u5339\u914d\u7387\u3001Jaccard\u76f8\u4f3c\u5ea6\u548cKendall's Tau\u7b49\u6307\u6807\u6765\u91cf\u5316\u53ef\u91cd\u73b0\u6027\u3002", "result": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u5bf9RAG\u53ef\u91cd\u73b0\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u53ef\u91cd\u73b0\u6027\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5f00\u6e90ReproRAG\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u90e8\u7f72\u3001\u57fa\u51c6\u6d4b\u8bd5\u53ef\u91cd\u73b0\u6027\u548c\u505a\u51fa\u660e\u667a\u8bbe\u8ba1\u51b3\u7b56\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u4fe1\u7684\u79d1\u5b66AI\u7cfb\u7edf\u3002"}}
{"id": "2509.18957", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18957", "abs": "https://arxiv.org/abs/2509.18957", "authors": ["Shengye Song", "Minxian Xu", "Kan Hu", "Wenxia Guo", "Kejiang Ye"], "title": "TD3-Sched: Learning to Orchestrate Container-based Cloud-Edge Resources via Distributed Reinforcement Learning", "comment": "14 pages, 5 figures", "summary": "Resource scheduling in cloud-edge systems is challenging as edge nodes run\nlatency-sensitive workloads under tight resource constraints, while existing\ncentralized schedulers can suffer from performance bottlenecks and user\nexperience degradation. To address the issues of distributed decisions in\ncloud-edge environments, we present TD3-Sched, a distributed reinforcement\nlearning (DRL) scheduler based on Twin Delayed Deep Deterministic Policy\nGradient (TD3) for continuous control of CPU and memory allocation, which can\nachieve optimized decisions for resource provisioning under dynamic workloads.\nOn a realistic cloud-edge testbed with SockShop application and Alibaba traces,\nTD3-Sched achieves reductions of 17.9% to 38.6% in latency under same loads\ncompared with other reinforcement-learning and rule-based baselines, and 16% to\n31.6% under high loads. TD3-Sched also shows superior Service Level Objective\n(SLO) compliance with only 0.47% violations. These results indicate faster\nconvergence, lower latency, and more stable performance while preserving\nservice quality in container-based cloud-edge environment compared with the\nbaselines.", "AI": {"tldr": "TD3-Sched\u662f\u4e00\u4e2a\u57fa\u4e8eTD3\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u5e03\u5f0f\u8c03\u5ea6\u5668\uff0c\u7528\u4e8e\u4e91\u8fb9\u7cfb\u7edf\u4e2dCPU\u548c\u5185\u5b58\u8d44\u6e90\u7684\u8fde\u7eed\u63a7\u5236\u5206\u914d\uff0c\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u4f18\u5316\u51b3\u7b56", "motivation": "\u4e91\u8fb9\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u8c03\u5ea6\u9762\u4e34\u6311\u6218\uff0c\u8fb9\u7f18\u8282\u70b9\u8fd0\u884c\u5ef6\u8fdf\u654f\u611f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e14\u8d44\u6e90\u53d7\u9650\uff0c\u800c\u73b0\u6709\u7684\u96c6\u4e2d\u5f0f\u8c03\u5ea6\u5668\u5b58\u5728\u6027\u80fd\u74f6\u9888\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\u95ee\u9898", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eTwin Delayed Deep Deterministic Policy Gradient (TD3)\u7684\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u8c03\u5ea6\u5668TD3-Sched\uff0c\u7528\u4e8eCPU\u548c\u5185\u5b58\u5206\u914d\u7684\u8fde\u7eed\u63a7\u5236", "result": "\u5728\u771f\u5b9e\u4e91\u8fb9\u6d4b\u8bd5\u5e73\u53f0\u4e0a\uff0cTD3-Sched\u76f8\u6bd4\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u76f8\u540c\u8d1f\u8f7d\u4e0b\u5ef6\u8fdf\u964d\u4f4e17.9%-38.6%\uff0c\u9ad8\u8d1f\u8f7d\u4e0b\u964d\u4f4e16%-31.6%\uff0cSLO\u8fdd\u89c4\u7387\u4ec5\u4e3a0.47%", "conclusion": "TD3-Sched\u5728\u5bb9\u5668\u5316\u4e91\u8fb9\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u670d\u52a1\u8d28\u91cf"}}
{"id": "2509.19086", "categories": ["cs.DC", "D.4.1; C.4; C.1.4; D.1.3"], "pdf": "https://arxiv.org/pdf/2509.19086", "abs": "https://arxiv.org/abs/2509.19086", "authors": ["Michal Konopa", "Jan Fesl", "Ladislav Ber\u00e1nek"], "title": "Scheduler-Driven Job Atomization", "comment": "22 pages", "summary": "Modern GPU clusters, particularly those built on NVIDIA's Multi-Instance GPU\n(MIG) architecture, often suffer from inefficiencies because jobs are treated\nas rigid, indivisible blocks that occupy a fixed slice until completion. The\nreliance on static peak memory estimates exacerbates fragmentation,\nunderutilization, and job rejections. We propose Scheduler-Driven Job\nAtomization (SJA), a new paradigm that establishes a bidirectional interaction\nbetween scheduler and jobs. In SJA, the scheduler advertises available\nexecution gaps, and jobs respond by signaling interest if they can potentially\ngenerate a subjob that fits the offered time-capacity window. The scheduler may\ncollect multiple signals for the same slot and, based on its allocation policy\n(e.g., fairness, efficiency, or SLA priorities), selects which job is granted\nthe slot. Only then does the chosen job materialize a safe, self-contained\nsubjob tailored to that opportunity. Unlike migration or preemption, SJA\nproactively shapes workloads before execution, thereby avoiding costly state\ntransfers and unpredictable interruptions. It aims to increase GPU utilization,\nreduce wait times, and minimize migration overhead by aligning jobs with\nopportunities in real time, ensuring that each admitted subjob is correct by\nconstruction. This paper is presented as a concept paper: it introduces the\nparadigm, defines its building blocks, and outlines future research directions,\nrather than offering a full experimental evaluation.", "AI": {"tldr": "\u63d0\u51faScheduler-Driven Job Atomization (SJA)\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8c03\u5ea6\u5668\u4e0e\u4f5c\u4e1a\u7684\u53cc\u5411\u4ea4\u4e92\uff0c\u5c06\u4f5c\u4e1a\u5206\u89e3\u4e3a\u53ef\u9002\u914d\u6267\u884c\u95f4\u9699\u7684\u5b50\u4f5c\u4e1a\uff0c\u63d0\u9ad8GPU\u96c6\u7fa4\u5229\u7528\u7387", "motivation": "\u73b0\u4ee3GPU\u96c6\u7fa4\uff08\u7279\u522b\u662f\u57fa\u4e8eNVIDIA MIG\u67b6\u6784\u7684\uff09\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u4f5c\u4e1a\u88ab\u89c6\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u521a\u6027\u5757\uff0c\u4f9d\u8d56\u9759\u6001\u5cf0\u503c\u5185\u5b58\u4f30\u8ba1\u5bfc\u81f4\u788e\u7247\u5316\u3001\u5229\u7528\u7387\u4e0d\u8db3\u548c\u4f5c\u4e1a\u62d2\u7edd", "method": "SJA\u5efa\u7acb\u8c03\u5ea6\u5668\u4e0e\u4f5c\u4e1a\u7684\u53cc\u5411\u4ea4\u4e92\uff1a\u8c03\u5ea6\u5668\u53d1\u5e03\u53ef\u7528\u6267\u884c\u95f4\u9699\uff0c\u4f5c\u4e1a\u54cd\u5e94\u8868\u793a\u80fd\u5426\u751f\u6210\u9002\u914d\u8be5\u65f6\u95f4\u5bb9\u91cf\u7a97\u53e3\u7684\u5b50\u4f5c\u4e1a\uff0c\u8c03\u5ea6\u5668\u57fa\u4e8e\u5206\u914d\u7b56\u7565\u9009\u62e9\u4f5c\u4e1a\u5e76\u751f\u6210\u5b89\u5168\u81ea\u5305\u542b\u7684\u5b50\u4f5c\u4e1a", "result": "\u8be5\u65b9\u6cd5\u4e3b\u52a8\u5728\u4f5c\u4e1a\u6267\u884c\u524d\u8fdb\u884c\u5de5\u4f5c\u8d1f\u8f7d\u6574\u5f62\uff0c\u907f\u514d\u6602\u8d35\u7684\u72b6\u6001\u8f6c\u79fb\u548c\u4e0d\u53ef\u9884\u6d4b\u7684\u4e2d\u65ad\uff0c\u65e8\u5728\u63d0\u9ad8GPU\u5229\u7528\u7387\u3001\u51cf\u5c11\u7b49\u5f85\u65f6\u95f4\u548c\u6700\u5c0f\u5316\u8fc1\u79fb\u5f00\u9500", "conclusion": "\u672c\u6587\u4f5c\u4e3a\u6982\u5ff5\u8bba\u6587\u4ecb\u7ecd\u4e86SJA\u8303\u5f0f\uff0c\u5b9a\u4e49\u4e86\u5176\u6784\u5efa\u6a21\u5757\u5e76\u6982\u8ff0\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5c1a\u672a\u63d0\u4f9b\u5b8c\u6574\u7684\u5b9e\u9a8c\u8bc4\u4f30"}}
{"id": "2509.19150", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.19150", "abs": "https://arxiv.org/abs/2509.19150", "authors": ["Harikrishna Tummalapalli", "Riccardo Balin", "Christine M. Simpson", "Andrew Park", "Aymen Alsaadi", "Andrew E. Shao", "Wesley Brewer", "Shantenu Jha"], "title": "In-Transit Data Transport Strategies for Coupled AI-Simulation Workflow Patterns", "comment": null, "summary": "Coupled AI-Simulation workflows are becoming the major workloads for HPC\nfacilities, and their increasing complexity necessitates new tools for\nperformance analysis and prototyping of new in-situ workflows. We present\nSimAI-Bench, a tool designed to both prototype and evaluate these coupled\nworkflows. In this paper, we use SimAI-Bench to benchmark the data transport\nperformance of two common patterns on the Aurora supercomputer: a one-to-one\nworkflow with co-located simulation and AI training instances, and a\nmany-to-one workflow where a single AI model is trained from an ensemble of\nsimulations. For the one-to-one pattern, our analysis shows that node-local and\nDragonHPC data staging strategies provide excellent performance compared Redis\nand Lustre file system. For the many-to-one pattern, we find that data\ntransport becomes a dominant bottleneck as the ensemble size grows. Our\nevaluation reveals that file system is the optimal solution among the tested\nstrategies for the many-to-one pattern.", "AI": {"tldr": "SimAI-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u539f\u578b\u8bbe\u8ba1\u548c\u8bc4\u4f30\u8026\u5408AI-\u4eff\u771f\u5de5\u4f5c\u6d41\u7a0b\u7684\u5de5\u5177\uff0c\u5728Aurora\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u6d4b\u8bd5\u4e86\u4e24\u79cd\u5e38\u89c1\u6a21\u5f0f\u7684\u6570\u636e\u4f20\u8f93\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u8026\u5408AI-\u4eff\u771f\u5de5\u4f5c\u6d41\u7a0b\u5728HPC\u8bbe\u65bd\u4e2d\u6210\u4e3a\u4e3b\u8981\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5176\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u9700\u8981\u65b0\u7684\u6027\u80fd\u5206\u6790\u548c\u539f\u578b\u8bbe\u8ba1\u5de5\u5177\u3002", "method": "\u4f7f\u7528SimAI-Bench\u5de5\u5177\u5728Aurora\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u5bf9\u4e24\u79cd\u6a21\u5f0f\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff1a\u4e00\u5bf9\u4e00\u5de5\u4f5c\u6d41\u7a0b\uff08\u4eff\u771f\u4e0eAI\u8bad\u7ec3\u5b9e\u4f8b\u5171\u7f6e\uff09\u548c\u591a\u5bf9\u4e00\u5de5\u4f5c\u6d41\u7a0b\uff08\u4ece\u4eff\u771f\u96c6\u5408\u8bad\u7ec3\u5355\u4e2aAI\u6a21\u578b\uff09\u3002", "result": "\u5bf9\u4e8e\u4e00\u5bf9\u4e00\u6a21\u5f0f\uff0c\u8282\u70b9\u672c\u5730\u548cDragonHPC\u6570\u636e\u6682\u5b58\u7b56\u7565\u6bd4Redis\u548cLustre\u6587\u4ef6\u7cfb\u7edf\u6027\u80fd\u66f4\u4f18\uff1b\u5bf9\u4e8e\u591a\u5bf9\u4e00\u6a21\u5f0f\uff0c\u968f\u7740\u96c6\u5408\u89c4\u6a21\u589e\u5927\uff0c\u6570\u636e\u4f20\u8f93\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\uff0c\u6587\u4ef6\u7cfb\u7edf\u662f\u6700\u4f73\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SimAI-Bench\u662f\u8bc4\u4f30\u8026\u5408AI-\u4eff\u771f\u5de5\u4f5c\u6d41\u7a0b\u7684\u6709\u6548\u5de5\u5177\uff0c\u4e0d\u540c\u6a21\u5f0f\u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u4f20\u8f93\u7b56\u7565\u4f18\u5316\u3002"}}
{"id": "2509.19187", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.19187", "abs": "https://arxiv.org/abs/2509.19187", "authors": ["J\u00e9r\u00e9mie Chalopin", "Yi-Jun Chang", "Lyuting Chen", "Giuseppe A. Di Luna", "Haoran Zhou"], "title": "Non-Uniform Content-Oblivious Leader Election on Oriented Asynchronous Rings", "comment": null, "summary": "We study the leader election problem in oriented ring networks under\ncontent-oblivious asynchronous message-passing systems, where an adversary may\narbitrarily corrupt message contents.\n  Frei et al. (DISC 2024) presented a uniform terminating leader election\nalgorithm for oriented rings in this setting, with message complexity $O(n\n\\cdot \\mathsf{ID}_{\\max})$ on a ring of size $n$, where $\\mathsf{ID}_{\\max}$ is\nthe largest identifier in the system, this result has been recently extended by\nChalopin et al. (DISC 2025) to unoriented rings.\n  In this paper, we investigate the message complexity of leader election on\nring networks in the content-oblivious model, showing that no uniform algorithm\ncan solve the problem if each process is limited to sending a constant number\nof messages in one direction.\n  Interestingly, this limitation hinges on the uniformity assumption. In the\nnon-uniform setting, where processes know an upper bound $U \\geq n$ on the ring\nsize, we present an algorithm with message complexity $O(n \\cdot U \\cdot\n\\mathsf{ID}_{\\min})$, in which each process sends $O(U \\cdot\n\\mathsf{ID}_{\\min})$ messages clockwise and only three messages\ncounter-clockwise. Here, $\\mathsf{ID}_{\\min}$ is the smallest identifier in the\nsystem. This dependence on the identifiers compares favorably with the\ndependence on $\\mathsf{ID}_{\\max}$ of Frei et al.\n  We also show a non-uniform algorithm where each process sends $O(U \\cdot\n\\log\\mathsf{ID}_{\\min})$ messages in one direction and\n$O(\\log\\mathsf{ID}_{\\min})$ in the other. The factor $\\log \\mathsf{ID}_{\\min}$\nis optimal, matching the lower bound of Frei et al.\n  Finally, in the anonymous setting, where processes do not have identifiers,\nwe propose a randomized algorithm where each process sends only $O(\\log^2 U)$\nmessages, with a success probability of $1 - U^{-c}$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9762\u5411\u73af\u7f51\u7edc\u4e2d\u7684\u9886\u5bfc\u8005\u9009\u4e3e\u95ee\u9898\uff0c\u5728\u5185\u5bb9\u4e0d\u53ef\u77e5\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u7cfb\u7edf\u4e2d\uff0c\u5bf9\u624b\u53ef\u80fd\u4efb\u610f\u7834\u574f\u6d88\u606f\u5185\u5bb9\u3002\u8bba\u6587\u5206\u6790\u4e86\u6d88\u606f\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u4e86\u5728\u5747\u5300\u7b97\u6cd5\u4e2d\u6bcf\u4e2a\u8fdb\u7a0b\u53ea\u80fd\u53d1\u9001\u6052\u5b9a\u6570\u91cf\u6d88\u606f\u7684\u9650\u5236\u4e0b\u65e0\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u5728\u975e\u5747\u5300\u8bbe\u7f6e\u4e0b\u63d0\u51fa\u4e86\u6539\u8fdb\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u5185\u5bb9\u4e0d\u53ef\u77e5\u6a21\u578b\u4e0b\u73af\u7f51\u7edc\u4e2d\u9886\u5bfc\u8005\u9009\u4e3e\u7684\u6d88\u606f\u590d\u6742\u5ea6\uff0c\u63a2\u7d22\u5728\u6d88\u606f\u6570\u91cf\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6bd4\u8f83\u5747\u5300\u4e0e\u975e\u5747\u5300\u7b97\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u5747\u5300\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u975e\u5747\u5300\u7b97\u6cd5\u5229\u7528\u73af\u5927\u5c0f\u4e0a\u754cU\u548c\u6700\u5c0f\u6807\u8bc6\u7b26ID_min\u6765\u4f18\u5316\u6d88\u606f\u590d\u6742\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u968f\u673a\u5316\u7b97\u6cd5\u5904\u7406\u533f\u540d\u8bbe\u7f6e\u3002", "result": "\u8bc1\u660e\u4e86\u5747\u5300\u7b97\u6cd5\u5728\u6052\u5b9a\u6d88\u606f\u9650\u5236\u4e0b\u4e0d\u53ef\u884c\uff1b\u63d0\u51fa\u4e86\u6d88\u606f\u590d\u6742\u5ea6\u4e3aO(n\u00b7U\u00b7ID_min)\u7684\u975e\u5747\u5300\u7b97\u6cd5\uff1b\u5c55\u793a\u4e86\u6700\u4f18\u7684O(log ID_min)\u56e0\u5b50\u7b97\u6cd5\uff1b\u8bbe\u8ba1\u4e86\u533f\u540d\u8bbe\u7f6e\u7684\u968f\u673a\u5316\u7b97\u6cd5\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u4ec5\u53d1\u9001O(log\u00b2 U)\u6d88\u606f\u3002", "conclusion": "\u9886\u5bfc\u8005\u9009\u4e3e\u5728\u5185\u5bb9\u4e0d\u53ef\u77e5\u73af\u7f51\u7edc\u4e2d\u7684\u53ef\u884c\u6027\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5747\u5300\u6027\u5047\u8bbe\uff0c\u975e\u5747\u5300\u8bbe\u7f6e\u5141\u8bb8\u66f4\u9ad8\u6548\u7684\u6d88\u606f\u590d\u6742\u5ea6\uff0c\u800c\u533f\u540d\u8bbe\u7f6e\u53ef\u901a\u8fc7\u968f\u673a\u5316\u5b9e\u73b0\u4f4e\u6d88\u606f\u5f00\u9500\u3002"}}
{"id": "2509.19294", "categories": ["cs.DC", "astro-ph.IM", "D.1.3; J.2"], "pdf": "https://arxiv.org/pdf/2509.19294", "abs": "https://arxiv.org/abs/2509.19294", "authors": ["Jenny Lynn Almerol", "Elisabetta Boella", "Mario Spera", "Daniele Gregori"], "title": "Accelerating Gravitational $N$-Body Simulations Using the RISC-V-Based Tenstorrent Wormhole", "comment": null, "summary": "Although originally developed primarily for artificial intelligence\nworkloads, RISC-V-based accelerators are also emerging as attractive platforms\nfor high-performance scientific computing. In this work, we present our\napproach to accelerating an astrophysical $N$-body code on the RISC-V-based\nWormhole n300 card developed by Tenstorrent. Our results show that this\nplatform can be highly competitive for astrophysical simulations employing this\nclass of algorithms, delivering more than a $2 \\times$ speedup and\napproximately $2 \\times$ energy savings compared to a highly optimized CPU\nimplementation of the same code.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5728RISC-V\u67b6\u6784\u7684Wormhole n300\u52a0\u901f\u5361\u4e0a\u52a0\u901f\u5929\u4f53\u7269\u7406N\u4f53\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f18\u5316CPU\u5b9e\u73b0\u53ef\u83b7\u5f972\u500d\u4ee5\u4e0a\u901f\u5ea6\u63d0\u5347\u548c\u7ea62\u500d\u80fd\u8017\u8282\u7701\u3002", "motivation": "RISC-V\u52a0\u901f\u5668\u867d\u7136\u6700\u521d\u4e3aAI\u5de5\u4f5c\u8d1f\u8f7d\u5f00\u53d1\uff0c\u4f46\u6b63\u6210\u4e3a\u9ad8\u6027\u80fd\u79d1\u5b66\u8ba1\u7b97\u7684\u6709\u5438\u5f15\u529b\u7684\u5e73\u53f0\uff0c\u7279\u522b\u662f\u5728\u5929\u4f53\u7269\u7406\u6a21\u62df\u9886\u57df\u3002", "method": "\u5728Tenstorrent\u5f00\u53d1\u7684RISC-V\u67b6\u6784Wormhole n300\u52a0\u901f\u5361\u4e0a\u5b9e\u73b0\u5929\u4f53\u7269\u7406N\u4f53\u4ee3\u7801\u7684\u52a0\u901f\u65b9\u6cd5\u3002", "result": "\u8be5\u5e73\u53f0\u5728\u5929\u4f53\u7269\u7406\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u76f8\u6bd4\u9ad8\u5ea6\u4f18\u5316\u7684CPU\u5b9e\u73b0\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc72\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c\u7ea62\u500d\u7684\u80fd\u8017\u8282\u7701\u3002", "conclusion": "RISC-V\u52a0\u901f\u5668\u5e73\u53f0\u5bf9\u4e8e\u91c7\u7528\u6b64\u7c7b\u7b97\u6cd5\u7684\u5929\u4f53\u7269\u7406\u6a21\u62df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u90fd\u4f18\u4e8e\u4f20\u7edfCPU\u5b9e\u73b0\u3002"}}
