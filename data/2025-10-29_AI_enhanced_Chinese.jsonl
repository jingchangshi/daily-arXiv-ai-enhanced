{"id": "2510.24112", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.24112", "abs": "https://arxiv.org/abs/2510.24112", "authors": ["Junchi Wu", "Xinfei Wan", "Zhuoran Li", "Yuyang Jin", "Guangyu Sun", "Yun Liang", "Diyu Zhou", "Youwei Zhuo"], "title": "SlowPoke: Understanding and Detecting On-Chip Fail-Slow Failures in Many-Core Systems", "comment": "15 pages, 15 figures", "summary": "Many-core architectures are essential for high-performance computing, but\ntheir performance is undermined by widespread fail-slow failures. Detecting\nsuch failures on-chip is challenging, as prior methods from distributed systems\nare unsuitable due to strict memory limits and their inability to track\nfailures across the hardware topology. This paper introduces SlowPoke, a\nlightweight, hardware-aware framework for practical on-chip fail-slow\ndetection. SlowPoke combines compiler-based instrumentation for low-overhead\nmonitoring, on-the-fly trace compression to operate within kilobytes of memory,\nand a novel topology-aware ranking algorithm to pinpoint a failure's root\ncause. We evaluate SlowPoke on a wide range of representative many-core\nworkloads, and the results demonstrate that SlowPoke reduces the storage\noverhead of detection traces by an average of 115.9$\\times$, while achieving an\naverage fail-slow detection accuracy of 86.77% and a false positive rate (FPR)\nof 12.11%. More importantly, SlowPoke scales effectively across different\nmany-core architectures, making it practical for large-scale deployments.", "AI": {"tldr": "SlowPoke\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u786c\u4ef6\u611f\u77e5\u7684\u7247\u4e0a\u6545\u969c\u6162\u901f\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u63d2\u6869\u3001\u5b9e\u65f6\u8ddf\u8e2a\u538b\u7f29\u548c\u62d3\u6251\u611f\u77e5\u6392\u540d\u7b97\u6cd5\uff0c\u5728\u591a\u6838\u67b6\u6784\u4e2d\u9ad8\u6548\u68c0\u6d4b\u6545\u969c\u6162\u901f\u95ee\u9898\u3002", "motivation": "\u591a\u6838\u67b6\u6784\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6545\u969c\u6162\u901f\u95ee\u9898\u4f1a\u4e25\u91cd\u524a\u5f31\u5176\u6027\u80fd\u3002\u73b0\u6709\u5206\u5e03\u5f0f\u7cfb\u7edf\u65b9\u6cd5\u56e0\u5185\u5b58\u9650\u5236\u4e25\u683c\u4e14\u65e0\u6cd5\u8ddf\u8e2a\u786c\u4ef6\u62d3\u6251\u6545\u969c\u800c\u4e0d\u9002\u7528\u3002", "method": "\u7ed3\u5408\u7f16\u8bd1\u5668\u63d2\u6869\u8fdb\u884c\u4f4e\u5f00\u9500\u76d1\u63a7\uff0c\u4f7f\u7528\u5b9e\u65f6\u8ddf\u8e2a\u538b\u7f29\u5728\u5343\u5b57\u8282\u5185\u5b58\u5185\u8fd0\u884c\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u62d3\u6251\u611f\u77e5\u6392\u540d\u7b97\u6cd5\u5b9a\u4f4d\u6545\u969c\u6839\u672c\u539f\u56e0\u3002", "result": "\u5728\u4ee3\u8868\u6027\u591a\u6838\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cSlowPoke\u5c06\u68c0\u6d4b\u8ddf\u8e2a\u7684\u5b58\u50a8\u5f00\u9500\u5e73\u5747\u964d\u4f4e115.9\u500d\uff0c\u6545\u969c\u6162\u901f\u68c0\u6d4b\u51c6\u786e\u7387\u5e73\u5747\u8fbe86.77%\uff0c\u8bef\u62a5\u7387\u4e3a12.11%\u3002", "conclusion": "SlowPoke\u5728\u4e0d\u540c\u591a\u6838\u67b6\u6784\u4e0a\u90fd\u80fd\u6709\u6548\u6269\u5c55\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u90e8\u7f72\u3002"}}
{"id": "2510.24113", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24113", "abs": "https://arxiv.org/abs/2510.24113", "authors": ["Arnav Shukla", "Harsh Sharma", "Srikant Bharadwaj", "Vinayak Abrol", "Sujay Deb"], "title": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators", "comment": null, "summary": "Heterogeneous chiplet-based systems improve scaling by disag-gregating\nCPUs/GPUs and emerging technologies (HBM/DRAM).However this on-package\ndisaggregation introduces a latency inNetwork-on-Interposer(NoI). We observe\nthat in modern large-modelinference, parameters and activations routinely move\nbackand forth from HBM/DRAM, injecting large, bursty flows into theinterposer.\nThese memory-driven transfers inflate tail latency andviolate Service Level\nAgreements (SLAs) across k-ary n-cube base-line NoI topologies. To address this\ngap we introduce an InterferenceScore (IS) that quantifies worst-case slowdown\nunder contention.We then formulate NoI synthesis as a multi-objective\noptimization(MOO) problem. We develop PARL (Partition-Aware\nReinforcementLearner), a topology generator that balances throughput,\nlatency,and power. PARL-generated topologies reduce contention at the memory\ncut, meet SLAs, and cut worst-case slowdown to 1.2 times while maintaining\ncompetitive mean throughput relative to link-rich meshes. Overall, this\nreframes NoI design for heterogeneouschiplet accelerators with workload-aware\nobjectives.", "AI": {"tldr": "\u63d0\u51faPARL\u65b9\u6cd5\u89e3\u51b3chiplet\u7cfb\u7edf\u4e2d\u5185\u5b58\u9a71\u52a8\u4f20\u8f93\u5bfc\u81f4\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u751f\u6210\u62d3\u6251\u7ed3\u6784\uff0c\u5728\u4fdd\u6301\u541e\u5410\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6700\u574f\u60c5\u51b5\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u4ee3\u5927\u6a21\u578b\u63a8\u7406\u4e2d\u53c2\u6570\u548c\u6fc0\u6d3b\u503c\u5728HBM/DRAM\u95f4\u9891\u7e41\u79fb\u52a8\uff0c\u5728interposer\u7f51\u7edc\u4e2d\u4ea7\u751f\u7a81\u53d1\u6027\u5927\u6d41\u91cf\uff0c\u5bfc\u81f4\u5c3e\u90e8\u5ef6\u8fdf\u589e\u52a0\u5e76\u8fdd\u53cdSLA\u3002", "method": "\u5f15\u5165\u5e72\u6270\u8bc4\u5206\u91cf\u5316\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u5ef6\u8fdf\u589e\u52a0\uff0c\u5c06NoI\u5408\u6210\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1PARL\u62d3\u6251\u751f\u6210\u5668\u5e73\u8861\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u529f\u8017\u3002", "result": "PARL\u751f\u6210\u7684\u62d3\u6251\u7ed3\u6784\u5728\u5185\u5b58\u5207\u5206\u5904\u51cf\u5c11\u7ade\u4e89\uff0c\u6ee1\u8db3SLA\u8981\u6c42\uff0c\u5c06\u6700\u574f\u60c5\u51b5\u5ef6\u8fdf\u964d\u4f4e\u81f31.2\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5bcc\u94fe\u63a5mesh\u76f8\u5f53\u7684\u5747\u503c\u541e\u5410\u91cf\u3002", "conclusion": "\u91cd\u65b0\u6784\u5efa\u4e86\u9762\u5411\u5f02\u6784chiplet\u52a0\u901f\u5668\u7684NoI\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u4f18\u5316\u76ee\u6807\u3002"}}
{"id": "2510.23911", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.23911", "abs": "https://arxiv.org/abs/2510.23911", "authors": ["Arno Uhlig", "Iris Braun", "Matthias W\u00e4hlisch"], "title": "The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing", "comment": "15 pages", "summary": "Allocating resources in a distributed environment is a fundamental challenge.\nIn this paper, we analyze the scheduling and placement of virtual machines\n(VMs) in the cloud platform of SAP, the world's largest enterprise resource\nplanning software vendor. Based on data from roughly 1,800 hypervisors and\n48,000 VMs within a 30-day observation period, we highlight potential\nimprovements for workload management. The data was measured through\nobservability tooling that tracks resource usage and performance metrics across\nthe entire infrastructure. In contrast to existing datasets, ours uniquely\noffers fine-grained time-series telemetry data of fully virtualized\nenterprise-level workloads from both long-running and memory-intensive SAP\nS/4HANA and diverse, general-purpose applications. Our key findings include\nseveral suboptimal scheduling situations, such as CPU resource contention\nexceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced\ncompute hosts with a maximum CPU~utilization on intra-building block hosts of\nup to 99%, and overprovisioned CPU and memory resources resulting into over 80%\nof VMs using less than 70% of the provided resources. Bolstered by these\nfindings, we derive requirements for the design and implementation of novel\nplacement and scheduling algorithms and provide guidance to optimize resource\nallocations. We make the full dataset used in this study publicly available to\nenable data-driven evaluations of scheduling approaches for large-scale cloud\ninfrastructures in future research.", "AI": {"tldr": "\u5206\u6790SAP\u4e91\u5e73\u53f0\u4e2d\u865a\u62df\u673a\u8c03\u5ea6\u548c\u653e\u7f6e\u95ee\u9898\uff0c\u57fa\u4e8e30\u5929\u51851800\u4e2a\u7ba1\u7406\u7a0b\u5e8f\u548c48000\u4e2a\u865a\u62df\u673a\u7684\u6570\u636e\uff0c\u53d1\u73b0\u8d44\u6e90\u8c03\u5ea6\u5b58\u5728\u591a\u79cd\u6b21\u4f18\u60c5\u51b5\uff0c\u5305\u62ecCPU\u8d44\u6e90\u4e89\u7528\u3001\u8d1f\u8f7d\u4e0d\u5747\u8861\u548c\u8d44\u6e90\u8fc7\u5ea6\u914d\u7f6e\u7b49\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u8d44\u6e90\u5206\u914d\u7684\u57fa\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4f01\u4e1a\u7ea7\u4e91\u5e73\u53f0\u4e2d\u4f18\u5316\u865a\u62df\u673a\u8c03\u5ea6\u548c\u8d44\u6e90\u7ba1\u7406\u3002", "method": "\u901a\u8fc7\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\u6536\u96c630\u5929\u51851800\u4e2a\u7ba1\u7406\u7a0b\u5e8f\u548c48000\u4e2a\u865a\u62df\u673a\u7684\u7ec6\u7c92\u5ea6\u65f6\u95f4\u5e8f\u5217\u9065\u6d4b\u6570\u636e\uff0c\u5206\u6790\u8d44\u6e90\u4f7f\u7528\u60c5\u51b5\u548c\u6027\u80fd\u6307\u6807\u3002", "result": "\u53d1\u73b0CPU\u8d44\u6e90\u4e89\u7528\u8d85\u8fc740%\uff0cCPU\u5c31\u7eea\u65f6\u95f4\u9ad8\u8fbe220\u79d2\uff0c\u8ba1\u7b97\u4e3b\u673a\u8d1f\u8f7d\u4e25\u91cd\u4e0d\u5747\u8861\uff08\u6700\u9ad8CPU\u5229\u7528\u7387\u8fbe99%\uff09\uff0c\u8d85\u8fc780%\u7684\u865a\u62df\u673a\u4f7f\u7528\u4e0d\u523070%\u7684\u5206\u914d\u8d44\u6e90\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\u63d0\u51fa\u4e86\u65b0\u578b\u653e\u7f6e\u548c\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bbe\u8ba1\u8981\u6c42\uff0c\u5e76\u4e3a\u4f18\u5316\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u6307\u5bfc\uff0c\u540c\u65f6\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u5927\u89c4\u6a21\u4e91\u57fa\u7840\u8bbe\u65bd\u8c03\u5ea6\u65b9\u6cd5\u7684\u7814\u7a76\u3002"}}
{"id": "2510.23993", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23993", "abs": "https://arxiv.org/abs/2510.23993", "authors": ["Anthony Carreon", "Jagmohan Singh", "Shivank Sharma", "Shuzhi Zhang", "Venkat Raman"], "title": "A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales", "comment": "32 pages, 12 figures", "summary": "High-speed chemically active flows present significant computational\nchallenges due to their disparate space and time scales, where stiff chemistry\noften dominates simulation time. While modern supercomputing scientific codes\nachieve exascale performance by leveraging graphics processing units (GPUs),\nexisting GPU-based compressible combustion solvers face critical limitations in\nmemory management, load balancing, and handling the highly localized nature of\nchemical reactions. To this end, we present a high-performance compressible\nreacting flow solver built on the AMReX framework and optimized for multi-GPU\nsettings. Our approach addresses three GPU performance bottlenecks: memory\naccess patterns through column-major storage optimization, computational\nworkload variability via a bulk-sparse integration strategy for chemical\nkinetics, and multi-GPU load distribution for adaptive mesh refinement\napplications. The solver adapts existing matrix-based chemical kinetics\nformulations to multigrid contexts. Using representative combustion\napplications including hydrogen-air detonations and jet in supersonic crossflow\nconfigurations, we demonstrate $2-5\\times$ performance improvements over\ninitial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA\nH100 GPUs. Roofline analysis reveals substantial improvements in arithmetic\nintensity for both convection ($\\sim 10 \\times$) and chemistry ($\\sim 4\n\\times$) routines, confirming efficient utilization of GPU memory bandwidth and\ncomputational resources.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eAMReX\u6846\u67b6\u7684\u9ad8\u6027\u80fd\u53ef\u538b\u7f29\u53cd\u5e94\u6d41\u6c42\u89e3\u5668\uff0c\u9488\u5bf9\u591aGPU\u73af\u5883\u4f18\u5316\uff0c\u89e3\u51b3\u4e86GPU\u6027\u80fd\u74f6\u9888\uff0c\u5728\u71c3\u70e7\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e862-5\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u9ad8\u901f\u5316\u5b66\u53cd\u5e94\u6d41\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u73b0\u6709GPU\u6c42\u89e3\u5668\u5728\u5185\u5b58\u7ba1\u7406\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u5316\u5b66\u53cd\u5e94\u5c40\u90e8\u6027\u5904\u7406\u65b9\u9762\u5b58\u5728\u5173\u952e\u9650\u5236\u3002", "method": "\u901a\u8fc7\u5217\u4f18\u5148\u5b58\u50a8\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u91c7\u7528\u6279\u91cf\u7a00\u758f\u79ef\u5206\u7b56\u7565\u5904\u7406\u5316\u5b66\u53cd\u5e94\u52a8\u529b\u5b66\u8ba1\u7b97\u8d1f\u8f7d\u53d8\u5316\uff0c\u4ee5\u53ca\u9488\u5bf9\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u7684\u591aGPU\u8d1f\u8f7d\u5206\u914d\u3002", "result": "\u57281-96\u4e2aNVIDIA H100 GPU\u4e0a\u5b9e\u73b0\u4e862-5\u500d\u7684\u6027\u80fd\u63d0\u5347\u548c\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\uff0c\u5bf9\u6d41\u548c\u5316\u5b66\u53cd\u5e94\u7684\u7b97\u672f\u5f3a\u5ea6\u5206\u522b\u63d0\u9ad8\u4e86\u7ea610\u500d\u548c4\u500d\u3002", "conclusion": "\u8be5\u6c42\u89e3\u5668\u6709\u6548\u5229\u7528\u4e86GPU\u5185\u5b58\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e3a\u9ad8\u901f\u5316\u5b66\u53cd\u5e94\u6d41\u7684GPU\u52a0\u901f\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24175", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24175", "abs": "https://arxiv.org/abs/2510.24175", "authors": ["Nitin Shukla", "Alessandro Romeo", "Caterina Caravita", "Michael Redenti", "Radim Vavrik", "Lubomir Riha", "Andrea Mignone", "Marco Rossazza", "Stefano Truzzi", "Luca Tornatore", "Antonio Ragagnin", "Tiago Castro", "Geray S. Karademir", "Klaus Dolag", "Pranab J. Deka", "Fabio Bacchini", "Rostislav-Paul Wilhelm", "Daniele Gregori", "Elisabetta Boella"], "title": "Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System", "comment": null, "summary": "Developing and redesigning astrophysical, cosmological, and space plasma\nnumerical codes for existing and next-generation accelerators is critical for\nenabling large-scale simulations. To address these challenges, the SPACE Center\nof Excellence (SPACE-CoE) fosters collaboration between scientists, code\ndevelopers, and high-performance computing experts to optimize applications for\nthe exascale era. This paper presents our strategy and initial results on the\nLeonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3\nand iPIC3D, using profiling tools to analyze performance on single and multiple\nnodes. Preliminary tests show all three codes scale efficiently, reaching 80%\nscalability up to 1,024 GPUs.", "AI": {"tldr": "SPACE\u4e2d\u5fc3\u901a\u8fc7\u534f\u4f5c\u4f18\u5316\u5929\u4f53\u7269\u7406\u3001\u5b87\u5b99\u5b66\u548c\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6570\u503c\u4ee3\u7801\uff0c\u5728Leonardo\u7cfb\u7edf\u4e0a\u5bf9\u4e09\u4e2a\u65d7\u8230\u4ee3\u7801\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u57281024\u4e2aGPU\u4e0a\u8fbe\u523080%\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4e3a\u73b0\u6709\u548c\u4e0b\u4e00\u4ee3\u52a0\u901f\u5668\u5f00\u53d1\u548c\u91cd\u65b0\u8bbe\u8ba1\u5929\u4f53\u7269\u7406\u3001\u5b87\u5b99\u5b66\u548c\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6570\u503c\u4ee3\u7801\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u6a21\u62df\uff0c\u6ee1\u8db3\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u65f6\u4ee3\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u6027\u80fd\u5206\u6790\u5de5\u5177\u5206\u6790\u4e09\u4e2a\u65d7\u8230\u4ee3\u7801\uff08gPLUTO\u3001OpenGadget3\u548ciPIC3D\uff09\u5728\u5355\u8282\u70b9\u548c\u591a\u8282\u70b9\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u6240\u6709\u4e09\u4e2a\u4ee3\u7801\u90fd\u80fd\u9ad8\u6548\u6269\u5c55\uff0c\u57281024\u4e2aGPU\u4e0a\u8fbe\u523080%\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "SPACE\u4e2d\u5fc3\u7684\u534f\u4f5c\u7b56\u7565\u6210\u529f\u4f18\u5316\u4e86\u4ee3\u7801\u6027\u80fd\uff0c\u4e3a\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u65f6\u4ee3\u7684\u5927\u89c4\u6a21\u6a21\u62df\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24205", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24205", "abs": "https://arxiv.org/abs/2510.24205", "authors": ["Telmo Ribeiro", "Jos\u00e9 Proen\u00e7a", "M\u00e1rio Florido"], "title": "CoMPSeT: A Framework for Comparing Multiparty Session Types", "comment": "In Proceedings EXPRESS/SOS 2025, arXiv:2510.23211", "summary": "Concurrent systems are often complex and difficult to design. Choreographic\nlanguages, such as Multiparty Session Types (MPST), allow the description of\nglobal protocols of interactions by capturing valid patterns of interactions\nbetween participants. Many variations of MPST exist, each one with its rather\nspecific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that\nprovides clearer insights over different features in existing MPST. We select a\nrepresentative set of MPST examples and provide mechanisms to combine different\nfeatures and to animate and compare the semantics of concrete examples. CoMPSeT\nis open-source, compiled into JavaScript, and can be directly executed from any\nbrowser, becoming useful both for researchers who want to better understand the\nlandscape of MPST and for teachers who want to explain global choreographies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCoMPSeT\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u548c\u6bd4\u8f83\u4e0d\u540c\u591a\u4f1a\u8bdd\u7c7b\u578b(MPST)\u7684\u7279\u6027\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u6559\u5e08\u66f4\u597d\u5730\u7406\u89e3\u5168\u5c40\u7f16\u6392\u534f\u8bae\u3002", "motivation": "\u5e76\u53d1\u7cfb\u7edf\u8bbe\u8ba1\u590d\u6742\uff0c\u73b0\u6709\u7684\u591a\u4f1a\u8bdd\u7c7b\u578b(MPST)\u5b58\u5728\u591a\u79cd\u53d8\u4f53\uff0c\u5404\u6709\u7279\u5b9a\u529f\u80fd\u548c\u7279\u6027\uff0c\u9700\u8981\u4e00\u4e2a\u5de5\u5177\u6765\u6e05\u6670\u5c55\u793a\u548c\u6bd4\u8f83\u8fd9\u4e9b\u7279\u6027\u3002", "method": "\u9009\u62e9\u4ee3\u8868\u6027MPST\u793a\u4f8b\uff0c\u63d0\u4f9b\u673a\u5236\u6765\u7ec4\u5408\u4e0d\u540c\u7279\u6027\uff0c\u5e76\u52a8\u753b\u5316\u6bd4\u8f83\u5177\u4f53\u793a\u4f8b\u7684\u8bed\u4e49\u3002\u5de5\u5177\u5f00\u6e90\uff0c\u7f16\u8bd1\u4e3aJavaScript\uff0c\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u76f4\u63a5\u8fd0\u884c\u3002", "result": "\u5f00\u53d1\u4e86CoMPSeT\u5de5\u5177\uff0c\u80fd\u591f\u5c55\u793a\u4e0d\u540cMPST\u7279\u6027\u7684\u7ec4\u5408\u6548\u679c\uff0c\u652f\u6301\u8bed\u4e49\u52a8\u753b\u548c\u6bd4\u8f83\u3002", "conclusion": "CoMPSeT\u4e3a\u7814\u7a76\u4eba\u5458\u7406\u89e3MPST\u9886\u57df\u548c\u6559\u5e08\u8bb2\u89e3\u5168\u5c40\u7f16\u6392\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u638c\u63e1\u591a\u4f1a\u8bdd\u7c7b\u578b\u7684\u4e0d\u540c\u7279\u6027\u3002"}}
{"id": "2510.24452", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24452", "abs": "https://arxiv.org/abs/2510.24452", "authors": ["Xi Cheng", "Weijie Shen", "Haoming Chen", "Chaoyi Shen", "Jean Ortega", "Jiashang Liu", "Steve Thomas", "Honglin Zheng", "Haoyun Wu", "Yuxiang Li", "Casey Lichtendahl", "Jenny Ortiz", "Gang Liu", "Haiyang Qi", "Omid Fatemieh", "Chris Fry", "Jing Jing Long"], "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "comment": null, "summary": "Time series forecasting and anomaly detection are common tasks for\npractitioners in industries such as retail, manufacturing, advertising and\nenergy. Two unique challenges stand out: (1) efficiently and accurately\nforecasting time series or detecting anomalies in large volumes automatically;\nand (2) ensuring interpretability of results to effectively incorporate\nbusiness insights. We present ARIMA_PLUS, a novel framework to overcome these\ntwo challenges by a unique combination of (a) accurate and interpretable time\nseries models and (b) scalable and fully managed system infrastructure. The\nmodel has a sequential and modular structure to handle different components of\nthe time series, including holiday effects, seasonality, trend, and anomalies,\nwhich enables high interpretability of the results. Novel enhancements are made\nto each module, and a unified framework is established to address both\nforecasting and anomaly detection tasks simultaneously. In terms of accuracy,\nits comprehensive benchmark on the 42 public datasets in the Monash forecasting\nrepository shows superior performance over not only well-established\nstatistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer\nneural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms\nof infrastructure, it is directly built into the query engine of BigQuery in\nGoogle Cloud. It uses a simple SQL interface and automates tedious\ntechnicalities such as data cleaning and model selection. It automatically\nscales with managed cloud computational and storage resources, making it\npossible to forecast 100 million time series using only 1.5 hours with a\nthroughput of more than 18000 time series per second. In terms of\ninterpretability, we present several case studies to demonstrate time series\ninsights it generates and customizability it offers.", "AI": {"tldr": "ARIMA_PLUS\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u51c6\u786e\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u4e0e\u53ef\u6269\u5c55\u7684\u4e91\u57fa\u7840\u8bbe\u65bd\uff0c\u572842\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u7edf\u8ba1\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a(1)\u9ad8\u6548\u51c6\u786e\u5730\u5904\u7406\u5927\u91cf\u65f6\u95f4\u5e8f\u5217\uff1b(2)\u786e\u4fdd\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u4ee5\u878d\u5165\u4e1a\u52a1\u6d1e\u5bdf\u3002", "method": "\u91c7\u7528\u987a\u5e8f\u6a21\u5757\u5316\u7ed3\u6784\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u7684\u4e0d\u540c\u7ec4\u4ef6\uff08\u8282\u5047\u65e5\u6548\u5e94\u3001\u5b63\u8282\u6027\u3001\u8d8b\u52bf\u3001\u5f02\u5e38\uff09\uff0c\u6bcf\u4e2a\u6a21\u5757\u90fd\u6709\u65b0\u9896\u589e\u5f3a\uff0c\u5e76\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u540c\u65f6\u5904\u7406\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u3002", "result": "\u5728Monash\u9884\u6d4b\u5e93\u768442\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u7edf\u8ba1\u65b9\u6cd5\uff08ETS\u3001ARIMA\u3001TBATS\u3001Prophet\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08DeepAR\u3001N-BEATS\u3001PatchTST\u3001TimeMixer\uff09\uff1b\u5728Google Cloud BigQuery\u4e2d\u5b9e\u73b0\u6bcf\u79d218000+\u65f6\u95f4\u5e8f\u5217\u7684\u541e\u5410\u91cf\uff0c1.5\u5c0f\u65f6\u53ef\u9884\u6d4b1\u4ebf\u4e2a\u65f6\u95f4\u5e8f\u5217\u3002", "conclusion": "ARIMA_PLUS\u901a\u8fc7\u7ed3\u5408\u51c6\u786e\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u4e0e\u53ef\u6269\u5c55\u4e91\u57fa\u7840\u8bbe\u65bd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u4e3a\u884c\u4e1a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002"}}
