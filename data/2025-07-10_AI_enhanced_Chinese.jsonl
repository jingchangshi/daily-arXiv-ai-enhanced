{"id": "2507.06376", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.06376", "abs": "https://arxiv.org/abs/2507.06376", "authors": ["Elisavet Lydia Alvanaki", "Kevin Lee", "Luca P. Carloni"], "title": "SLDB: An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design", "comment": null, "summary": "Over the last few years, Large Language Models (LLMs) have emerged as a\nvaluable tool for Electronic Design Automation (EDA). State-of-the-art research\nin LLM-aided design has demonstrated the ability of LLMs to generate\nsyntactically correct RTL code, showcasing encouraging prospects for\nintegrating AI into the hardware design process. A key enabler of these\nadvancements is the availability of high-quality benchmarks to evaluate new\napproaches. However, existing datasets and benchmarks fall short of\nsystem-level design, as they focus primarily on component-level information and\nlow-complexity designs. To address this gap, we introduce the System-Level\nDesign Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level\nintegration and configuration tasks. SLDB includes a curated benchmark suite of\n10 baseline SoC designs, whose components can be combined into an exponential\nnumber of distinct tile-based SoCs through a synthetic library. The dataset\nprovides full SoC configurations, accelerator integration code, communication\nparameters, and accelerator-aware system configurations, along with\ntesting-application code, compatible with the ESP platform[1].", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86System-Level Design Benchmark\uff08SLDB\uff09\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cfb\u7edf\u7ea7\u96c6\u6210\u548c\u914d\u7f6e\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7ec4\u4ef6\u7ea7\u4fe1\u606f\u548c\u4f4e\u590d\u6742\u5ea6\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u7684\u652f\u6301\uff0c\u56e0\u6b64\u9700\u8981SLDB\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "SLDB\u5305\u542b10\u4e2a\u57fa\u7ebfSoC\u8bbe\u8ba1\u7684\u57fa\u51c6\u5957\u4ef6\uff0c\u901a\u8fc7\u5408\u6210\u5e93\u5c06\u5176\u7ec4\u4ef6\u7ec4\u5408\u6210\u591a\u79cd\u4e0d\u540c\u7684\u57fa\u4e8e\u74e6\u7247\u7684SoC\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684SoC\u914d\u7f6e\u3001\u52a0\u901f\u5668\u96c6\u6210\u4ee3\u7801\u7b49\u3002", "result": "SLDB\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u8bc4\u4f30\u5de5\u5177\uff0c\u652f\u6301\u52a0\u901f\u5668\u96c6\u6210\u548c\u7cfb\u7edf\u914d\u7f6e\uff0c\u5e76\u4e0eESP\u5e73\u53f0\u517c\u5bb9\u3002", "conclusion": "SLDB\u4e3a\u8bc4\u4f30LLM\u5728\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86AI\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.06512", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06512", "abs": "https://arxiv.org/abs/2507.06512", "authors": ["Siyu Qiu", "Muzhi Wang", "Raheel Afsharmazayejani", "Mohammad Moradi Shahmiri", "Benjamin Tan", "Hammond Pearce"], "title": "Towards LLM-based Root Cause Analysis of Hardware Design Failures", "comment": "6 pages. Accepted for publication in IEEE COINS 2025 Special Session\n  on LLMs for EDA and Security", "summary": "With advances in large language models (LLMs), new opportunities have emerged\nto develop tools that support the digital hardware design process. In this\nwork, we explore how LLMs can assist with explaining the root cause of design\nissues and bugs that are revealed during synthesis and simulation, a necessary\nmilestone on the pathway towards widespread use of LLMs in the hardware design\nprocess and for hardware security analysis. We find promising results: for our\ncorpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model\nreached a correct determination 100% of the time under pass@5 scoring, with\nother state of the art models and configurations usually achieving more than\n80% performance and more than 90% when assisted with retrieval-augmented\ngeneration.", "AI": {"tldr": "LLMs\u5728\u6570\u5b57\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7528\u4e8e\u89e3\u91ca\u5408\u6210\u548c\u4eff\u771f\u9636\u6bb5\u7684\u8bbe\u8ba1\u95ee\u9898\u548c\u9519\u8bef\u6839\u6e90\uff0c\u5c55\u793a\u4e86\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u786c\u4ef6\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u9519\u8bef\u5206\u6790\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u65b9\u9762\u3002", "method": "\u4f7f\u7528OpenAI\u7684o3-mini\u63a8\u7406\u6a21\u578b\u53ca\u5176\u4ed6\u5148\u8fdb\u6a21\u578b\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u6d4b\u8bd534\u79cd\u9519\u8bef\u573a\u666f\u3002", "result": "o3-mini\u6a21\u578b\u5728pass@5\u8bc4\u5206\u4e0b\u8fbe\u5230100%\u51c6\u786e\u7387\uff0c\u5176\u4ed6\u6a21\u578b\u548c\u914d\u7f6e\u901a\u5e38\u8d85\u8fc780%\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0b\u8d85\u8fc790%\u3002", "conclusion": "LLMs\u5728\u786c\u4ef6\u8bbe\u8ba1\u9519\u8bef\u5206\u6790\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.07044", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.07044", "abs": "https://arxiv.org/abs/2507.07044", "authors": ["Mehrdad Morsali", "Chengwei Zhou", "Deniz Najafi", "Sreetama Sarkar", "Pietro Mercati", "Navid Khoshavi", "Peter Beerel", "Mahdi Nikdast", "Gourav Datta", "Shaahin Angizi"], "title": "Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics", "comment": null, "summary": "Vision Transformers (ViTs) have emerged as a powerful architecture for\ncomputer vision tasks due to their ability to model long-range dependencies and\nglobal contextual relationships. However, their substantial compute and memory\ndemands hinder efficient deployment in scenarios with strict energy and\nbandwidth limitations. In this work, we propose OptoViT, the first near-sensor,\nregion-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time\nand energy-efficient vision processing. Opto-ViT features a hybrid\nelectronic-photonic architecture, where the optical core handles\ncompute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting\nLasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and\nnormalization are executed electronically. To reduce redundant computation and\npatch processing, we introduce a lightweight Mask Generation Network (MGNet)\nthat identifies regions of interest in the current frame and prunes irrelevant\npatches before ViT encoding. We further co-optimize the ViT backbone using\nquantization-aware training and matrix decomposition tailored for photonic\nconstraints. Experiments across device fabrication, circuit and architecture\nco-design, to classification, detection, and video tasks demonstrate that\nOptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6%\naccuracy loss, while enabling scalable and efficient ViT deployment at the\nedge.", "AI": {"tldr": "OptoViT\u662f\u4e00\u79cd\u57fa\u4e8e\u7845\u5149\u5b50\u5b66\u7684\u8fd1\u4f20\u611f\u5668ViT\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u6df7\u5408\u7535\u5b50-\u5149\u5b50\u67b6\u6784\u548c\u533a\u57df\u611f\u77e5\u4f18\u5316\uff0c\u5b9e\u73b0\u9ad8\u6548\u80fd\u89c6\u89c9\u5904\u7406\u3002", "motivation": "Vision Transformers\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u4e0a\u8f83\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e25\u683c\u80fd\u6e90\u548c\u5e26\u5bbd\u9650\u5236\u573a\u666f\u4e0b\u7684\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7535\u5b50-\u5149\u5b50\u67b6\u6784\uff0c\u5149\u5b66\u6838\u5fc3\u5904\u7406\u77e9\u9635\u4e58\u6cd5\uff0c\u7535\u5b50\u90e8\u5206\u5904\u7406\u975e\u7ebf\u6027\u51fd\u6570\uff1b\u5f15\u5165\u8f7b\u91cf\u7ea7MGNet\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff1b\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u548c\u77e9\u9635\u5206\u89e3\u4f18\u5316ViT\u3002", "result": "\u5b9e\u9a8c\u663e\u793aOptoViT\u8fbe\u5230100.4 KFPS/W\uff0c\u8282\u80fd84%\uff0c\u51c6\u786e\u7387\u635f\u5931\u5c0f\u4e8e1.6%\u3002", "conclusion": "OptoViT\u4e3a\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684ViT\u90e8\u7f72\u65b9\u6848\u3002"}}
{"id": "2507.06360", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.06360", "abs": "https://arxiv.org/abs/2507.06360", "authors": ["Dustin Jamner", "Gabriel Kammer", "Ritam Nag", "Adam Chlipala"], "title": "Pyrosome: Verified Compilation for Modular Metatheory", "comment": null, "summary": "We present Pyrosome, a generic framework for modular language metatheory that\nembodies a novel approach to extensible semantics and compilation, implemented\nin Coq. Common techniques for semantic reasoning are often tied to the specific\nstructures of the languages and compilers that they support. In Pyrosome,\nverified compilers are fully extensible, meaning that to extend a language\n(even with a new kind of effect) simply requires defining and verifying the\ncompilation of the new feature, reusing the old correctness theorem for all\nother cases. The novel enabling idea is an inductive formulation of equivalence\npreservation that supports the addition of new rules to the source language,\ntarget language, and compiler.\n  Pyrosome defines a formal, deeply embedded notion of programming languages\nwith semantics given by dependently sorted equational theories, so all\ncompiler-correctness proofs boil down to type-checking and equational\nreasoning. We support vertical composition of any compilers expressed in our\nframework in addition to feature extension. As a case study, we present a\nmultipass compiler from System F with simple references, through CPS\ntranslation and closure conversion. Specifically, we demonstrate how we can\nbuild such a compiler incrementally by starting with a compiler for simply\ntyped lambda-calculus and adding natural numbers, the unit type, recursive\nfunctions, and a global heap, then extending judgments with a type environment\nand adding type abstraction, all while reusing the original theorems. We also\npresent a linear version of the simply typed CPS pass and compile a small\nimperative language to the simply typed target to show how Pyrosome handles\nsubstructural typing and imperative features.", "AI": {"tldr": "Pyrosome\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u8bed\u8a00\u5143\u7406\u8bba\u7684\u901a\u7528\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6269\u5c55\u8bed\u4e49\u548c\u7f16\u8bd1\uff0c\u901a\u8fc7Coq\u5b9e\u73b0\u3002\u5176\u6838\u5fc3\u521b\u65b0\u662f\u652f\u6301\u8bed\u8a00\u3001\u76ee\u6807\u8bed\u8a00\u548c\u7f16\u8bd1\u5668\u7684\u65b0\u89c4\u5219\u6dfb\u52a0\uff0c\u540c\u65f6\u4fdd\u6301\u7b49\u4ef7\u6027\u3002", "motivation": "\u4f20\u7edf\u8bed\u4e49\u63a8\u7406\u6280\u672f\u901a\u5e38\u4e0e\u7279\u5b9a\u8bed\u8a00\u548c\u7f16\u8bd1\u5668\u7ed3\u6784\u7ed1\u5b9a\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002Pyrosome\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u9a8c\u8bc1\u7f16\u8bd1\u5668\u6846\u67b6\u3002", "method": "Pyrosome\u901a\u8fc7\u4f9d\u8d56\u6392\u5e8f\u7684\u7b49\u5f0f\u7406\u8bba\u5b9a\u4e49\u7f16\u7a0b\u8bed\u8a00\u8bed\u4e49\uff0c\u7f16\u8bd1\u5668\u6b63\u786e\u6027\u8bc1\u660e\u7b80\u5316\u4e3a\u7c7b\u578b\u68c0\u67e5\u548c\u7b49\u5f0f\u63a8\u7406\u3002\u652f\u6301\u5782\u76f4\u7ec4\u5408\u548c\u529f\u80fd\u6269\u5c55\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u4eceSystem F\u5230CPS\u7ffb\u8bd1\u548c\u95ed\u5305\u8f6c\u6362\u7684\u591a\u9636\u6bb5\u7f16\u8bd1\u5668\uff0c\u652f\u6301\u9010\u6b65\u6269\u5c55\u529f\u80fd\u5e76\u91cd\u7528\u539f\u6709\u5b9a\u7406\u3002", "conclusion": "Pyrosome\u4e3a\u8bed\u8a00\u8bbe\u8ba1\u548c\u7f16\u8bd1\u5668\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8bed\u8a00\u7279\u6027\u548c\u7f16\u8bd1\u573a\u666f\u3002"}}
{"id": "2507.06471", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.06471", "abs": "https://arxiv.org/abs/2507.06471", "authors": ["Fuhuan Li", "Zhihui Du", "David A. Bader"], "title": "Designing Parallel Algorithms for Community Detection using Arachne", "comment": null, "summary": "The rise of graph data in various fields calls for efficient and scalable\ncommunity detection algorithms. In this paper, we present parallel\nimplementations of two widely used algorithms: Label Propagation and Louvain,\nspecifically designed to leverage the capabilities of Arachne which is a\nPython-accessible, open-source framework for large-scale graph analysis. Our\nimplementations achieve substantial speedups over existing Python-based tools\nlike NetworkX and igraph, which lack efficient parallelization, and are\ncompetitive with parallel frameworks such as NetworKit. Experimental results\nshow that Arachne-based methods outperform these baselines, achieving speedups\nof up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit.\nAdditionally, we analyze the scalability of our implementation under varying\nthread counts, demonstrating how different phases contribute to overall\nperformance gains of the parallel Louvain algorithm. Arachne, including our\ncommunity detection implementation, is open-source and available at\nhttps://github.com/Bears-R-Us/arkouda-njit .", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8eArachne\u6846\u67b6\u7684\u5e76\u884c\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\uff08Label Propagation\u548cLouvain\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u56fe\u6570\u636e\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u3002", "method": "\u5728Arachne\u6846\u67b6\u4e2d\u5e76\u884c\u5b9e\u73b0Label Propagation\u548cLouvain\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cArachne\u65b9\u6cd5\u6bd4NetworkX\u5feb710\u500d\uff0c\u6bd4igraph\u5feb75\u500d\uff0c\u6bd4NetworKit\u5feb12\u500d\u3002", "conclusion": "Arachne\u6846\u67b6\u7684\u5e76\u884c\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u4e86\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u4e14\u5f00\u6e90\u53ef\u7528\u3002"}}
{"id": "2507.06456", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.06456", "abs": "https://arxiv.org/abs/2507.06456", "authors": ["Scott Kovach", "Praneeth Kolichala", "Kyle A. Miller", "David Broman", "Fredrik Kjolstad"], "title": "Fast Collection Operations from Indexed Stream Fusion", "comment": null, "summary": "We present a system of efficient methods for traversing and combining\nassociative collection data structures. A distinguishing feature of the system\nis that, like traditional sequential iterator libraries, it does not require\nspecialized compiler infrastructure or staged compilation for efficiency and\ncomposability. By using a representation based on indexed streams, the library\ncan express complex joins over input collections while using no intermediate\nallocations. We implement the library for the Lean, Morphic, and Rust\nprogramming languages and provide a mechanized proof of functional correctness\nin Lean.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u904d\u5386\u548c\u7ec4\u5408\u5173\u8054\u96c6\u5408\u6570\u636e\u7ed3\u6784\u7684\u7cfb\u7edf\uff0c\u65e0\u9700\u4e13\u7528\u7f16\u8bd1\u5668\u6216\u5206\u9636\u6bb5\u7f16\u8bd1\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u6027\u548c\u53ef\u7ec4\u5408\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8fed\u4ee3\u5668\u5e93\u5728\u6548\u7387\u548c\u53ef\u7ec4\u5408\u6027\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u907f\u514d\u4f9d\u8d56\u4e13\u7528\u7f16\u8bd1\u5668\u3002", "method": "\u57fa\u4e8e\u7d22\u5f15\u6d41\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u5b9e\u73b0\u65e0\u4e2d\u95f4\u5206\u914d\u7684\u590d\u6742\u8fde\u63a5\u64cd\u4f5c\u3002", "result": "\u5728Lean\u3001Morphic\u548cRust\u4e2d\u5b9e\u73b0\u8be5\u5e93\uff0c\u5e76\u5728Lean\u4e2d\u63d0\u4f9b\u4e86\u529f\u80fd\u6b63\u786e\u6027\u7684\u673a\u68b0\u5316\u8bc1\u660e\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u4fdd\u6301\u9ad8\u6548\u548c\u53ef\u7ec4\u5408\u7684\u540c\u65f6\uff0c\u65e0\u9700\u4f9d\u8d56\u4e13\u7528\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2507.06608", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06608", "abs": "https://arxiv.org/abs/2507.06608", "authors": ["Xiaoxiang Shi", "Colin Cai", "Junjia Du", "Zhanda Zhu", "Xingda Wei", "Zhihao Jia"], "title": "Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing", "comment": null, "summary": "Current prefill-decode (PD) disaggregation is typically deployed at the level\nof entire serving engines, assigning separate GPUs to handle prefill and decode\nphases. While effective at reducing latency, this approach demands more\nhardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode\nrequests within the same batch, but introduces phase interference between\nprefill and decode.\n  While existing PD disaggregation solutions separate the phases across GPUs,\nwe ask: can the same decoupling be achieved within a single serving engine? The\nkey challenge lies in managing the conflicting resource requirements of prefill\nand decode when they share the same hardware. In this paper, we first show that\nchunked prefill requests cause interference with decode requests due to their\ndistinct requirements for GPU resources. Second, we find that GPU resources\nexhibit diminishing returns. Beyond a saturation point, increasing GPU\nallocation yields negligible latency improvements. This insight enables us to\nsplit a single GPU's resources and dynamically allocate them to prefill and\ndecode on the fly, effectively disaggregating the two phases within the same\nGPU.\n  Across a range of models and workloads, our system Nexus achieves up to 2.2x\nhigher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also\noutperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x\nlower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using\nonly half the number of GPUs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u540c\u4e00GPU\u5185\u52a8\u6001\u5206\u914d\u8d44\u6e90\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u7684\u8d44\u6e90\u51b2\u7a81\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u548c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7684\u9884\u586b\u5145-\u89e3\u7801\uff08PD\uff09\u89e3\u8026\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u591a\u4e2aGPU\uff0c\u786c\u4ef6\u9700\u6c42\u9ad8\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u80fd\u5728\u5355\u4e2aGPU\u5185\u5b9e\u73b0\u89e3\u8026\uff0c\u4ee5\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u901a\u8fc7\u5206\u6790GPU\u8d44\u6e90\u7684\u8fb9\u9645\u6548\u76ca\uff0c\u52a8\u6001\u5206\u914d\u540c\u4e00GPU\u7684\u8d44\u6e90\u7ed9\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\uff0c\u907f\u514d\u5e72\u6270\u3002", "result": "Nexus\u7cfb\u7edf\u5728\u591a\u79cd\u6a21\u578b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.2\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u300120\u500d\u7684TTFT\u964d\u4f4e\u548c2.5\u500d\u7684TBT\u964d\u4f4e\u3002", "conclusion": "\u5728\u540c\u4e00GPU\u5185\u52a8\u6001\u5206\u914d\u8d44\u6e90\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u786c\u4ef6\u9700\u6c42\u3002"}}
{"id": "2507.06584", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06584", "abs": "https://arxiv.org/abs/2507.06584", "authors": ["Qiong Feng", "Xiaotian Ma", "Ziyuan Feng", "Marat Akhin", "Wei Song", "Peng Liang"], "title": "Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing", "comment": "The 40th ACM SIGPLAN International Conference on Object-Oriented\n  Programming, Systems, Languages, and Applications (OOPSLA)", "summary": "Compilers play a central role in translating high-level code into executable\nprograms, making their correctness essential for ensuring code safety and\nreliability. While extensive research has focused on verifying the correctness\nof compilers for single-language compilation, the correctness of cross-language\ncompilation - which involves the interaction between two languages and their\nrespective compilers - remains largely unexplored. To fill this research gap,\nwe propose CrossLangFuzzer, a novel framework that introduces a universal\nintermediate representation (IR) for JVM-based languages and automatically\ngenerates cross-language test programs with diverse type parameters and complex\ninheritance structures. After generating the initial IR, CrossLangFuzzer\napplies three mutation techniques - LangShuffler, FunctionRemoval, and\nTypeChanger - to enhance program diversity. By evaluating both the original and\nmutated programs across multiple compiler versions, CrossLangFuzzer\nsuccessfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed\nbugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2\nconfirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java\ncompiler. Among all mutators, TypeChanger is the most effective, detecting 11\nof the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes\nof cross-compilation bugs, examining the respective responsibilities of\nlanguage compilers when incorrect behavior occurs during cross-language\ncompilation. To the best of our knowledge, this is the firstwork specifically\nfocused on identifying and diagnosing compiler bugs in cross-language\ncompilation scenarios. Our research helps to understand these challenges and\ncontributes to improving compiler correctness in multi-language environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CrossLangFuzzer\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u8de8\u8bed\u8a00\u7f16\u8bd1\u4e2d\u7684\u7f16\u8bd1\u5668\u9519\u8bef\uff0c\u6210\u529f\u53d1\u73b0\u591a\u4e2a\u7f16\u8bd1\u5668\u4e2d\u7684\u9519\u8bef\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6839\u672c\u539f\u56e0\u3002", "motivation": "\u8de8\u8bed\u8a00\u7f16\u8bd1\u7684\u6b63\u786e\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u5de5\u4f5c\u591a\u96c6\u4e2d\u4e8e\u5355\u8bed\u8a00\u7f16\u8bd1\u9a8c\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faCrossLangFuzzer\u6846\u67b6\uff0c\u4f7f\u7528\u901a\u7528\u4e2d\u95f4\u8868\u793a\uff08IR\uff09\u751f\u6210\u8de8\u8bed\u8a00\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u5e76\u5e94\u7528\u4e09\u79cd\u53d8\u5f02\u6280\u672f\u589e\u5f3a\u591a\u6837\u6027\u3002", "result": "\u53d1\u73b0\u4e86\u591a\u4e2a\u7f16\u8bd1\u5668\u4e2d\u768424\u4e2a\u9519\u8bef\uff0c\u5176\u4e2dTypeChanger\u53d8\u5f02\u6280\u672f\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u4e13\u6ce8\u4e8e\u8de8\u8bed\u8a00\u7f16\u8bd1\u9519\u8bef\u7684\u68c0\u6d4b\u4e0e\u8bca\u65ad\uff0c\u4e3a\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u7f16\u8bd1\u5668\u6b63\u786e\u6027\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.06653", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.06653", "abs": "https://arxiv.org/abs/2507.06653", "authors": ["Xiangyu Zhi", "Meng Chen", "Xiao Yan", "Baotong Lu", "Hui Li", "Qianxi Zhang", "Qi Chen", "James Cheng"], "title": "Towards Efficient and Scalable Distributed Vector Search with RDMA", "comment": null, "summary": "Similarity-based vector search facilitates many important applications such\nas search and recommendation but is limited by the memory capacity and\nbandwidth of a single machine due to large datasets and intensive data read. In\nthis paper, we present CoTra, a system that scales up vector search for\ndistributed execution. We observe a tension between computation and\ncommunication efficiency, which is the main challenge for good scalability,\ni.e., handling the local vectors on each machine independently blows up\ncomputation as the pruning power of vector index is not fully utilized, while\nrunning a global index over all machines introduces rich data dependencies and\nthus extensive communication. To resolve such tension, we leverage the fact\nthat vector search is approximate in nature and robust to asynchronous\nexecution. In particular, we run collaborative vector search over the machines\nwith algorithm-system co-designs including clustering-based data partitioning\nto reduce communication, asynchronous execution to avoid communication stall,\nand task push to reduce network traffic. To make collaborative search\nefficient, we introduce a suite of system optimizations including task\nscheduling, communication batching, and storage format. We evaluate CoTra on\nreal datasets and compare with four baselines. The results show that when using\n16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single\nmachine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.", "AI": {"tldr": "CoTra\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u7b97\u6cd5\u4e0e\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u8ba1\u7b97\u4e0e\u901a\u4fe1\u6548\u7387\u7684\u51b2\u7a81\uff0c\u663e\u8457\u63d0\u5347\u67e5\u8be2\u541e\u5410\u91cf\u3002", "motivation": "\u5927\u89c4\u6a21\u5411\u91cf\u641c\u7d22\u53d7\u9650\u4e8e\u5355\u673a\u5185\u5b58\u548c\u5e26\u5bbd\uff0c\u9700\u5206\u5e03\u5f0f\u6267\u884c\u4ee5\u6269\u5c55\u6027\u80fd\u3002", "method": "\u91c7\u7528\u805a\u7c7b\u6570\u636e\u5206\u533a\u3001\u5f02\u6b65\u6267\u884c\u548c\u4efb\u52a1\u63a8\u9001\u7b49\u6280\u672f\uff0c\u7ed3\u5408\u7cfb\u7edf\u4f18\u5316\uff08\u5982\u4efb\u52a1\u8c03\u5ea6\u3001\u901a\u4fe1\u6279\u5904\u7406\uff09\u3002", "result": "\u572816\u53f0\u673a\u5668\u4e0a\uff0cCoTra\u7684\u67e5\u8be2\u541e\u5410\u91cf\u63d0\u5347\u81f3\u5355\u673a\u76849.8-13.4\u500d\uff0c\u4f18\u4e8e\u57fa\u7ebf2.12-3.58\u500d\u3002", "conclusion": "CoTra\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u4e0e\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5411\u91cf\u641c\u7d22\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2507.06939", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.06939", "abs": "https://arxiv.org/abs/2507.06939", "authors": ["Guilherme Espada", "Alcides Fonseca"], "title": "Sound Interval-Based Synthesis for Probabilistic Programs", "comment": null, "summary": "Probabilistic programming has become a standard practice to model stochastic\nevents and learn about the behavior of nature in different scientific contexts,\nranging from Genetics and Ecology to Linguistics and Psychology. However,\ndomain practitioners (such as biologists) also need to be experts in statistics\nin order to select which probabilistic model is suitable for a given particular\nproblem, relying then on probabilistic inference engines such as Stan, Pyro or\nEdward to fine-tune the parameters of that particular model. Probabilistic\nProgramming would be more useful if the model selection is made automatic,\nwithout requiring statistics expertise from the end user. Automatically\nselecting the model is challenging because of the large search space of\nprobabilistic programs needed to be explored, because the fact that most of\nthat search space contains invalid programs, and because invalid programs may\nonly be detected in some executions, due to its probabilistic nature. We\npropose a type system to statically reject invalid probabilistic programs, a\ntype-directed synthesis algorithm that guarantees that generated programs are\ntype-safe by construction, and an heuristic search procedure to handle the vast\nsearch space. We collect a number of probabilistic programs from the\nliterature, and use them to compare our method with both a type-agnostic random\nsearch, and a data-guided method from the literature (DaPPer). Our results show\nthat our technique both outperforms random search and DaPPer, specially on more\ncomplex programs. This drastic performance difference in synthesis allows for\nfast sampling of programs and enables techniques that previously suffered from\nthe complexity of synthesis, such as Genetic Programming, to be applied.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7c7b\u578b\u7cfb\u7edf\u548c\u7c7b\u578b\u5bfc\u5411\u7684\u5408\u6210\u7b97\u6cd5\uff0c\u81ea\u52a8\u9009\u62e9\u6982\u7387\u7a0b\u5e8f\u6a21\u578b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u4e13\u5bb6\u7684\u95ee\u9898\u3002", "motivation": "\u6982\u7387\u7f16\u7a0b\u9700\u7edf\u8ba1\u4e13\u5bb6\u624b\u52a8\u9009\u62e9\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u7c7b\u578b\u7cfb\u7edf\u9759\u6001\u62d2\u7edd\u65e0\u6548\u7a0b\u5e8f\uff0c\u7ed3\u5408\u7c7b\u578b\u5bfc\u5411\u5408\u6210\u7b97\u6cd5\u548c\u542f\u53d1\u5f0f\u641c\u7d22\u5904\u7406\u5927\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u65b9\u6cd5\u4f18\u4e8e\u968f\u673a\u641c\u7d22\u548cDaPPer\uff0c\u7279\u522b\u5728\u590d\u6742\u7a0b\u5e8f\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u8be5\u6280\u672f\u663e\u8457\u63d0\u5347\u5408\u6210\u6548\u7387\uff0c\u652f\u6301\u5982\u9057\u4f20\u7f16\u7a0b\u7b49\u590d\u6742\u5e94\u7528\u3002"}}
