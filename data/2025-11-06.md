<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 6]
- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project](https://arxiv.org/abs/2511.03029)
*Kajol Kulkarni,Samuel Kemmler,Anna Schwarz,Gulcin Gedik,Yanxiang Chen,Dimitrios Papageorgiou,Ioannis Kavroulakis,Roman Iakymchuk*

Main category: cs.DC

TL;DR: 该论文总结了欧洲高性能计算中心在CFD应用中的能源效率优化经验，通过案例研究评估了不同架构下的能耗表现，强调了加速器和混合精度技术在降低能耗方面的优势。


<details>
  <summary>Details</summary>
Motivation: 随着高性能计算系统计算需求增长和架构复杂性增加，能源效率已成为核心挑战，需要测量、分析和优化能源消耗以实现可持续的百亿亿次计算。

Method: 使用代表性CFD应用（waLBerla、FLEXI/GAL{\AE}XI、Neko、NekRS）在多种架构上进行案例研究，评估能耗与时间指标，包括CPU和GPU分区。

Result: 结果显示加速器和混合精度技术在保持计算精度的同时能显著降低能耗，证明了这些技术在能源效率方面的优势。

Conclusion: 需要促进HPC系统的能源测量，提高社区意识，教育用户，并采取行动实现更可持续的百亿亿次计算。

Abstract: Energy efficiency has emerged as a central challenge for modern
high-performance computing (HPC) systems, where escalating computational
demands and architectural complexity have led to significant energy footprints.
This paper presents the collective experience of the EuroHPC JU Center of
Excellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing
energy consumption across major European HPC systems. We briefly review key
methodologies and tools for energy measurement as well as define metrics for
reporting results. Through case studies using representative CFD applications
(waLBerla, FLEXI/GAL{\AE}XI, Neko, and NekRS), we evaluate energy-to-solution
and time-to-solution metrics on diverse architectures, including CPU- and
GPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our
results highlight the advantages of accelerators and mixed-precision techniques
for reducing energy consumption while maintaining computational accuracy.
Finally, we advocate the need to facilitate energy measurements on HPC systems
in order to raise awareness, teach the community, and take actions toward more
sustainable exascale computing.

</details>


### [2] [Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots](https://arxiv.org/abs/2511.03286)
*Ehud Shapiro*

Main category: cs.DC

TL;DR: 该论文提出了一个基于原子事务的多智能体转换系统框架，用于分类全球数字平台。通过引入"基本智能体"概念，将平台分为集中式、去中心化、联邦式和草根式四类，并提供了形式化规范。


<details>
  <summary>Details</summary>
Motivation: 为全球数字平台（如社交网络、货币系统等）提供一个统一的数学框架，以便系统性地分类和分析不同类型的平台架构。

Method: 使用基于原子事务的多智能体转换系统和协议作为形式化框架，引入基本智能体概念（移除后无法通信的最小智能体集），根据基本智能体的基数对平台进行分类。

Result: 成功将全球平台分为四类：1）集中式（1个基本智能体）；2）去中心化（有限个>1基本智能体）；3）联邦式（无限但非全体基本智能体）；4）草根式（全体智能体都是基本智能体）。

Conclusion: 该工作提供了首个数学框架，可通过多智能体原子事务规范和基本智能体基数来分类任何现有或想象的全球平台。

Abstract: Global digital platforms are software systems designed to serve entire
populations, with some already serving billions of people. We propose atomic
transactions-based multiagent transition systems and protocols as a formal
framework to study them; introduce essential agents -- minimal sets of agents
the removal of which makes communication impossible; and show that the
cardinality of essential agents partitions all global platforms into four
classes:
  1. Centralised -- one (the server)
  2. Decentralised -- finite $>1$ (bootstrap nodes)
  3. Federated -- infinite but not universal (all servers)
  4. Grassroots -- universal (all agents)
  Our illustrative formal example is a global social network, for which we
provide centralised, decentralised, federated, and grassroots specifications
via multiagent atomic transactions, and prove they satisfy basic correctness
properties. We discuss informally additional global platforms -- currencies,
``sharing economy'' apps, AI, and more. While this may be the first
characterisation of centralised, decentralised, and federated global platforms,
grassroots platforms have been formally defined previously, but using different
notions. Here, we prove that their original definition implies that all agents
are essential, placing grassroots platforms in a distinct class within the
broader formal context that includes all global platforms. This work provides
the first mathematical framework for classifying any global platform --
existing or imagined -- by providing a multiagent atomic-transactions
specification of it and determining the cardinality of the minimal set of
essential agents in the ensuing multiagent protocol. It thus

</details>


### [3] [UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM](https://arxiv.org/abs/2511.03293)
*Hai Huang,Xuhong Qiang,Weisheng Zhao,Chenchen Liu*

Main category: cs.DC

TL;DR: UMDAM提出了一种统一的内存亲和性数据布局和DRAM地址映射方案，专门针对NPU-PIM协同执行优化，显著提升边缘设备上LLM推理效率。


<details>
  <summary>Details</summary>
Motivation: LLM在边缘设备NPU上部署时，解码阶段内存密集性限制了性能。NPU-PIM协同执行面临数据布局不匹配、带宽损失和冗余存储等挑战。

Method: 采用列优先、基于分块的数据布局和可配置的DRAM映射策略，确保与NPU计算的兼容性同时最大化PIM效率，不引入额外内存开销或带宽损失。

Result: 在OPT模型上的评估显示，UMDAM将首token时间(TTFT)最多减少3.0倍，末token时间(TTTLT)减少2.18倍。

Conclusion: UMDAM显著提升了边缘设备上端到端LLM推理效率，解决了NPU-PIM协同执行的关键挑战。

Abstract: Large Language Models (LLMs) are increasingly deployed on edge devices with
Neural Processing Units (NPUs), yet the decode phase remains memory-intensive,
limiting performance. Processing-in-Memory (PIM) offers a promising solution,
but co-executing NPU-PIM systems face challenges such as data layout
mismatches, bandwidth loss, and redundant storage. To address these issues, we
propose UMDAM, a unified memory-affinity data layout and DRAM address mapping
scheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,
tile-based layout and a configurable DRAM mapping strategy to ensure
compatibility with NPU computation while maximizing PIM efficiency -- without
introducing extra memory overhead or bandwidth loss. Comprehensive evaluations
on OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up
to 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving
end-to-end LLM inference efficiency on edge devices.

</details>


### [4] [Investigating the Impact of Isolation on Synchronized Benchmarks](https://arxiv.org/abs/2511.03533)
*Nils Japke,Furat Hamdan,Diana Baumann,David Bermbach*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Benchmarking in cloud environments suffers from performance variability from
multi-tenant resource contention. Duet benchmarking mitigates this by running
two workload versions concurrently on the same VM, exposing them to identical
external interference. However, intra-VM contention between synchronized
workloads necessitates additional isolation mechanisms.
  This work evaluates three such strategies: cgroups and CPU pinning, Docker
containers, and Firecracker MicroVMs. We compare all strategies with an
unisolated baseline experiment, by running benchmarks with a duet setup
alongside a noise generator. This noise generator "steals" compute resources to
degrade performance measurements.
  All experiments showed different latency distributions while under the
effects of noise generation, but results show that process isolation generally
lowered false positives, except for our experiments with Docker containers.
Even though Docker containers rely internally on cgroups and CPU pinning, they
were more susceptible to performance degradation due to noise influence.
Therefore, we recommend to use process isolation for synchronized workloads,
with the exception of Docker containers.

</details>


### [5] [Stone Duality Proofs for Colorless Distributed Computability Theorems](https://arxiv.org/abs/2511.03609)
*Cameron Calk,Emmanuel Godard*

Main category: cs.DC

TL;DR: 提出了一种基于谱空间的拓扑编码方法，用于分析分布式计算中对抗模型下的无色任务可解性，通过Stone对偶性建立了通用的分布式可计算性定理。


<details>
  <summary>Details</summary>
Motivation: 统一分布式计算中的拓扑方法，为对抗模型下的无色任务提供通用的可解性判据，解释彩色和非彩色模型具有相同计算能力的原因。

Method: 使用谱空间对分布式协议执行进行拓扑编码，考虑面偏序集上的Alexandrov拓扑，通过投影极限定义极限对象，应用Stone对偶性建立可计算性定理。

Result: 得到了无色任务可解性的充要条件：存在与Δ兼容的谱映射f:Π∞_M(I)→O。证明了彩色和非彩色模型具有相同的计算能力。

Conclusion: 该工作为分布式计算中的拓扑方法提供了统一框架，解释了不同模型间的等价性，并推导出多个已知的可计算性定理。

Abstract: We introduce a new topological encoding by spectral spaces of executions of
  round-based full-information adversaries, a model of distributed computations
that is functorially presented and that
  contains many message adversaries. We give a characterization of the
solvability of colorless tasks against compact adversaries.
  Message adversaries are distributed
  models that are known to be very expressive despite being
  round-based and crash-free. Colorless tasks are
  an important class of distributed tasks. For a colorless task, the
  specification does not depend upon the multiplicity of input or
  output values, like the ubiquitous agreement tasks.
  Therefore, our result is a significant
  step toward unifying topological methods in distributed computing.
  The main insight is to consider global states obtained after finite
executions of a distributed protocol
  not as abstract
  simplicial complexes as previously done, but as spectral
  spaces, considering the Alexandrov topology on the faces poset. Given
  an adversary $\mathcal M$ with a set of inputs $\mathcal I$,
  we define a limit object $\Pi^\infty_\mathcal M(\mathcal I)$
  by projective limit in the category of spectral spaces. We derive a new
general distributed computability
  theorem using Stone duality: there exists an algorithm solving a colorless
task $(\mathcal I,\mathcal O,\Delta)$
  against the compact adversary $\mathcal M$ if and only if there exists a
spectral
  map $f:\Pi^\infty_\mathcal M(\mathcal I)\longrightarrow\mathcal O$ compatible
with $\Delta$.
  From this general characterization are derived many known colorless
computability
  theorems.
  Quite surprisingly, colored and uncolored models have the same
  computability power (they solve the same tasks). Our new proofs give
  topological reasons for this equivalence, previously known through
  algorithmic reductions.

</details>


### [6] [A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries](https://arxiv.org/abs/2511.03662)
*Yannis Coutouly,Emmanuel Godard*

Main category: cs.DC

TL;DR: 本文扩展了分布式计算中任务可解性的几何特征化方法，将其推广到输入依赖型对手模型，并给出了k-集合协议在条件基核心依赖对手下的充要条件。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要针对固定对手模型，本文旨在研究输入配置依赖的对手模型，特别是条件基对手在k-集合协议中的可解性问题。

Method: 使用拓扑几何方法，将CG-24的特征化推广到输入依赖对手，分析核心弹性对手的计算能力等价性，并建立结构性质简化证明。

Result: 证明了输入依赖对手的可解性特征化，核心弹性对手的等价性，以及k-集合协议在条件基核心依赖对手下的充要条件。

Conclusion: 通过几何构造简化了分布式计算任务的证明，为输入依赖对手模型提供了完整的可解性理论框架。

Abstract: Distributed computing tasks can be presented with a triple $(\I,\Ou,\Delta)$.
The solvability of a colorless task on the Iterated Immediate Snapshot model
(IIS) has been characterized by the Colorless Computability Theorem
\cite[Th.4.3.1]{HKRbook}. A recent paper~\cite{CG-24} generalizes this theorem
for any message adversaries $\ma \subseteq IIS$ by geometric methods. In 2001,
Most\'efaoui, Rajsbaum, Raynal, and Roy \cite{condbased} introduced
\emph{condition-based adversaries}. This setting considers a particular
adversary that will be applied only to a subset of input configurations. In
this setting, they studied the $k$-set agreement task with condition-based
$t$-resilient adversaries and obtained a sufficient condition on the conditions
that make $k$-Set Agreement solvable. In this paper we have three
contributions:
  -We generalize the characterization of~\cite{CG-24} to \emph{input-dependent}
adversaries, which means that the adversaries can change depending on the input
configuration.
  - We show that core-resilient adversaries of $IIS_n$ have the same
computability power as the core-resilient adversaries of $IIS_n$ where crashes
only happen at the start.
  - Using the two previous contributions, we provide a necessary and sufficient
characterization of the condition-based, core-dependent adversaries that can
solve $k$-Set Agreement. We also distinguish four settings that may appear when
presenting a distributed task as $(\I,\Ou,\Delta)$. Finally, in a later
section, we present structural properties on the carrier map $\Delta$. Such
properties allow simpler proof, without changing the computability power of the
task. Most of the proofs in this article leverage the topological framework
used in distributed computing by using simple geometric constructions.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [7] [LogicSparse: Enabling Engine-Free Unstructured Sparsity for Quantised Deep-learning Accelerators](https://arxiv.org/abs/2511.03079)
*Changhong Li,Biswajit Basu,Shreejith Shanker*

Main category: cs.AR

TL;DR: 提出了一个将非结构化稀疏嵌入数据流加速器的框架，无需专用稀疏引擎即可保持并行性，在LeNet-5上实现51.6倍压缩和1.23倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: FPGA在部署量化神经网络方面表现出色，但现代深度学习模型复杂度限制了资源受限边缘设备的性能。非结构化稀疏因内存访问不规则而未被充分利用。

Method: 开发了将非结构化稀疏嵌入数据流加速器的框架，引入硬件感知剪枝策略，无需专用稀疏引擎即可保持并行性。

Result: 在LeNet-5上实现了51.6倍压缩比和1.23倍吞吐量提升，仅使用5.12%的LUT资源。

Conclusion: 该框架有效利用了非结构化稀疏来加速QNN，为资源受限的边缘设备提供了高效的推理解决方案。

Abstract: FPGAs have been shown to be a promising platform for deploying Quantised
Neural Networks (QNNs) with high-speed, low-latency, and energy-efficient
inference. However, the complexity of modern deep-learning models limits the
performance on resource-constrained edge devices. While quantisation and
pruning alleviate these challenges, unstructured sparsity remains
underexploited due to irregular memory access. This work introduces a framework
that embeds unstructured sparsity into dataflow accelerators, eliminating the
need for dedicated sparse engines and preserving parallelism. A hardware-aware
pruning strategy is introduced to improve efficiency and design flow further.
On LeNet-5, the framework attains 51.6 x compression and 1.23 x throughput
improvement using only 5.12% of LUTs, effectively exploiting unstructured
sparsity for QNN acceleration.

</details>


### [8] [An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM](https://arxiv.org/abs/2511.03203)
*Deyang Yu,Chenchen Liu,Chuanjie Zhang,Xiao Fang,Weisheng Zhao*

Main category: cs.AR

TL;DR: 提出了一种基于自旋轨道转矩MRAM的事件驱动脉冲处理计算内存宏，采用混合串并联单元结构实现高效矩阵向量乘法，峰值能效达243.6 TOPS/W。


<details>
  <summary>Details</summary>
Motivation: 现有MRAM计算内存设计因依赖复杂模拟电路而导致能耗过高，需要更高效的解决方案。

Method: 采用SOT-MRAM交叉阵列，结合混合串并联单元结构，使用轻量级电路将信号编码为脉冲，避免传统模拟电路。

Result: 在28nm工艺下实现，峰值能效达到243.6 TOPS/W，显著优于现有设计。

Conclusion: 该事件驱动脉冲处理方法有效解决了MRAM计算内存的高能耗问题，实现了优异的能效表现。

Abstract: The application of Magnetic Random-Access Memory (MRAM) in
computing-in-memory (CIM) has gained significant attention. However, existing
designs often suffer from high energy consumption due to their reliance on
complex analog circuits for computation. In this work, we present a Spin-Orbit-
Torque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking
processing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid
series-parallel cell structure to efficiently support matrix-vector
multiplication (MVM). Signal information is (en) decoded as spikes using
lightweight circuits, eliminating the need for conventional area- and
powerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in
28nm technology, and experimental results show that it achieves a peak energy
efficiency of 243.6 TOPS/W, significantly outperforming existing designs.

</details>


### [9] [Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics](https://arxiv.org/abs/2511.03427)
*Florentia Afentaki,Maha Shatta,Konstantinos Balaskas,Georgios Panagopoulos,Georgios Zervakis,Mehdi B. Tahoori*

Main category: cs.AR

TL;DR: 提出了首个柔性电子中的混合核混合信号SVM设计，结合线性和RBF核的优势，通过协同优化方法在保持精度的同时显著降低硬件成本。


<details>
  <summary>Details</summary>
Motivation: 柔性电子技术受限于大特征尺寸，限制了集成密度和功耗，难以实现机器学习电路。现有SVM设计在线性核和RBF核之间存在硬件成本与精度的权衡问题。

Method: 采用混合核混合信号SVM设计，结合线性和RBF核，通过协同优化方法训练混合核SVM并将二元分类器映射到合适的核（线性/RBF）和域（数字/模拟）。

Result: 相比最先进的单核线性SVM，精度提高7.7%；相比数字RBF实现，面积和功耗分别平均降低108倍和17倍。

Conclusion: 混合核混合信号SVM设计成功平衡了柔性电子中硬件成本与精度的权衡，为近传感器应用提供了可行的机器学习解决方案。

Abstract: Flexible Electronics (FE) have emerged as a promising alternative to
silicon-based technologies, offering on-demand low-cost fabrication,
conformality, and sustainability. However, their large feature sizes severely
limit integration density, imposing strict area and power constraints, thus
prohibiting the realization of Machine Learning (ML) circuits, which can
significantly enhance the capabilities of relevant near-sensor applications.
Support Vector Machines (SVMs) offer high accuracy in such applications at
relatively low computational complexity, satisfying FE technologies'
constraints. Existing SVM designs rely solely on linear or Radial Basis
Function (RBF) kernels, forcing a trade-off between hardware costs and
accuracy. Linear kernels, implemented digitally, minimize overhead but
sacrifice performance, while the more accurate RBF kernels are prohibitively
large in digital, and their analog realization contains inherent functional
approximation. In this work, we propose the first mixed-kernel and mixed-signal
SVM design in FE, which unifies the advantages of both implementations and
balances the cost/accuracy trade-off. To that end, we introduce a
co-optimization approach that trains our mixed-kernel SVMs and maps binary SVM
classifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),
aiming to maximize accuracy whilst reducing the number of costly RBF
classifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art
single-kernel linear SVMs, and reduce area and power by 108x and 17x on average
compared to digital RBF implementations.

</details>
