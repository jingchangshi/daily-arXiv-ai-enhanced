{"id": "2510.00183", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00183", "abs": "https://arxiv.org/abs/2510.00183", "authors": ["Ween Yang", "Jason Liu", "Suli Wang", "Xinyuan Song", "Lynn Ai", "Eric Yang", "Tianyu Shi"], "title": "Lattica: A Decentralized Cross-NAT Communication Framework for Scalable AI Inference and Training", "comment": null, "summary": "The rapid expansion of distributed Artificial Intelligence (AI) workloads\nbeyond centralized data centers creates a demand for new communication\nsubstrates. These substrates must operate reliably in heterogeneous and\npermissionless environments, where Network Address Translators (NATs) and\nfirewalls impose significant constraints. Existing solutions, however, are\neither designed for controlled data center deployments or implemented as\nmonolithic systems that tightly couple machine learning logic with networking\ncode. To address these limitations, we present Lattica, a decentralized\ncross-NAT communication framework designed to support distributed AI systems.\nLattica integrates three core components. First, it employs a robust suite of\nNAT traversal mechanisms to establish a globally addressable peer-to-peer mesh.\nSecond, it provides a decentralized data store based on Conflict-free\nReplicated Data Types (CRDTs), ensuring verifiable and eventually consistent\nstate replication. Third, it incorporates a content discovery layer that\nleverages distributed hash tables (DHTs) together with an optimized RPC\nprotocol for efficient model synchronization. By integrating these components,\nLattica delivers a complete protocol stack for sovereign, resilient, and\nscalable AI systems that operate independently of centralized intermediaries.\nIt is directly applicable to edge intelligence, collaborative reinforcement\nlearning, and other large-scale distributed machine learning scenarios.", "AI": {"tldr": "Lattica\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u8de8NAT\u901a\u4fe1\u6846\u67b6\uff0c\u4e13\u95e8\u4e3a\u5206\u5e03\u5f0fAI\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u901a\u8fc7NAT\u7a7f\u8d8a\u3001CRDT\u6570\u636e\u5b58\u50a8\u548cDHT\u5185\u5bb9\u53d1\u73b0\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u4e3b\u6743\u3001\u5f39\u6027\u548c\u53ef\u6269\u5c55\u7684AI\u7cfb\u7edf\u534f\u8bae\u6808\u3002", "motivation": "\u5206\u5e03\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\u6269\u5c55\u5230\u96c6\u4e2d\u5f0f\u6570\u636e\u4e2d\u5fc3\u4e4b\u5916\uff0c\u9700\u8981\u5728\u5f02\u6784\u548c\u65e0\u8bb8\u53ef\u73af\u5883\u4e2d\u53ef\u9760\u8fd0\u884c\u7684\u901a\u4fe1\u57fa\u7840\u67b6\u6784\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u8bbe\u8ba1\u7528\u4e8e\u53d7\u63a7\u6570\u636e\u4e2d\u5fc3\u90e8\u7f72\uff0c\u8981\u4e48\u662f\u7d27\u8026\u5408\u7684\u5355\u4e00\u7cfb\u7edf\u3002", "method": "\u96c6\u6210\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u5f3a\u5927\u7684NAT\u7a7f\u8d8a\u673a\u5236\u5efa\u7acb\u5168\u5c40\u53ef\u5bfb\u5740\u7684P2P\u7f51\u7edc\uff1b2) \u57fa\u4e8eCRDT\u7684\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u5b58\u50a8\u786e\u4fdd\u53ef\u9a8c\u8bc1\u548c\u6700\u7ec8\u4e00\u81f4\u7684\u72b6\u6001\u590d\u5236\uff1b3) \u5229\u7528DHT\u548c\u4f18\u5316RPC\u534f\u8bae\u7684\u5185\u5bb9\u53d1\u73b0\u5c42\u5b9e\u73b0\u9ad8\u6548\u6a21\u578b\u540c\u6b65\u3002", "result": "Lattica\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u534f\u8bae\u6808\uff0c\u652f\u6301\u4e3b\u6743\u3001\u5f39\u6027\u548c\u53ef\u6269\u5c55\u7684AI\u7cfb\u7edf\uff0c\u65e0\u9700\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u4e2d\u4ecb\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u667a\u80fd\u3001\u534f\u4f5c\u5f3a\u5316\u5b66\u4e60\u7b49\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u573a\u666f\u3002", "conclusion": "Lattica\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u5206\u5e03\u5f0fAI\u7cfb\u7edf\u5728\u5f02\u6784\u73af\u5883\u4e2d\u7684\u901a\u4fe1\u6311\u6218\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u548c\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00207", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00207", "abs": "https://arxiv.org/abs/2510.00207", "authors": ["Yunqi Gao", "Bing Hu", "Mahdi Boloursaz Mashhadi", "A-Long Jin", "Yanfeng Zhang", "Pei Xiao", "Rahim Tafazolli", "Merouane Debbah"], "title": "FlowMoE: A Scalable Pipeline Scheduling Framework for Distributed Mixture-of-Experts Training", "comment": null, "summary": "The parameter size of modern large language models (LLMs) can be scaled up\nvia the sparsely-activated Mixture-of-Experts (MoE) technique to avoid\nexcessive increase of the computational costs. To further improve training\nefficiency, pipelining computation and communication has become a promising\nsolution for distributed MoE training. However, existing work primarily focuses\non scheduling tasks within the MoE layer, such as expert computing and\nall-to-all (A2A) communication, while neglecting other key operations including\nmulti-head attention (MHA) computing, gating, and all-reduce communication. In\nthis paper, we propose FlowMoE, a scalable framework for scheduling multi-type\ntask pipelines. First, FlowMoE constructs a unified pipeline to consistently\nscheduling MHA computing, gating, expert computing, and A2A communication.\nSecond, FlowMoE introduces a tensor chunk-based priority scheduling mechanism\nto overlap the all-reduce communication with all computing tasks. We implement\nFlowMoE as an adaptive and generic framework atop PyTorch. Extensive\nexperiments with 675 typical MoE layers and four real-world MoE models across\ntwo GPU clusters demonstrate that our proposed FlowMoE framework outperforms\nstate-of-the-art MoE training frameworks, reducing training time by 13%-57%,\nenergy consumption by 10%-39%, and memory usage by 7%-32%.", "AI": {"tldr": "FlowMoE\u662f\u4e00\u4e2a\u7528\u4e8e\u7a00\u758f\u6fc0\u6d3b\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u6d41\u6c34\u7ebf\u548c\u5f20\u91cf\u5206\u5757\u4f18\u5148\u7ea7\u8c03\u5ea6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684MoE\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e13\u5bb6\u8ba1\u7b97\u548call-to-all\u901a\u4fe1\u7684\u8c03\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u591a\u5934\u6ce8\u610f\u529b\u8ba1\u7b97\u3001\u95e8\u63a7\u548call-reduce\u901a\u4fe1\u7b49\u5176\u4ed6\u5173\u952e\u64cd\u4f5c\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6548\u7387\u4e0d\u9ad8\u3002", "method": "1. \u6784\u5efa\u7edf\u4e00\u6d41\u6c34\u7ebf\u6765\u4e00\u81f4\u8c03\u5ea6MHA\u8ba1\u7b97\u3001\u95e8\u63a7\u3001\u4e13\u5bb6\u8ba1\u7b97\u548cA2A\u901a\u4fe1\uff1b2. \u5f15\u5165\u57fa\u4e8e\u5f20\u91cf\u5206\u5757\u7684\u4f18\u5148\u7ea7\u8c03\u5ea6\u673a\u5236\uff0c\u5c06all-reduce\u901a\u4fe1\u4e0e\u6240\u6709\u8ba1\u7b97\u4efb\u52a1\u91cd\u53e0\u3002", "result": "\u5728675\u4e2a\u5178\u578bMoE\u5c42\u548c4\u4e2a\u771f\u5b9eMoE\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFlowMoE\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u6846\u67b6\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f413%-57%\uff0c\u80fd\u801710%-39%\uff0c\u5185\u5b58\u4f7f\u75287%-32%\u3002", "conclusion": "FlowMoE\u4f5c\u4e3a\u4e00\u4e2a\u81ea\u9002\u5e94\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347MoE\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u6548\u7387\uff0c\u5728\u591a\u4e2a\u5173\u952e\u6307\u6807\u4e0a\u90fd\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2510.00306", "categories": ["cs.DC", "C.2.2; C.2.1; C.2.6; C.2.3; C.4"], "pdf": "https://arxiv.org/pdf/2510.00306", "abs": "https://arxiv.org/abs/2510.00306", "authors": ["Wenyang Jia", "Jingjing Wang", "Kai Lei"], "title": "BlockSDN-VC: A SDN-Based Virtual Coordinate-Enhanced Transaction Broadcast Framework for High-Performance Blockchains", "comment": "Accepted to IFIP International Conference on Network and Parallel\n  Computing (NPC 2025), LNCS format. Preprint. 12 pages", "summary": "Modern blockchains need fast, reliable propagation to balance security and\nthroughput. Virtual-coordinate methods speed dissemination but rely on slow\niterative updates, leaving nodes out of sync. We present BlockSDN-VC, a\ntransaction-broadcast protocol that centralises coordinate computation and\nforwarding control in an SDN controller, delivering global consistency, minimal\npath stretch and rapid response to churn or congestion. In geo-distributed\nsimulations, BlockSDN-VC cuts median latency by up to 62% and accelerates\nconvergence fourfold over state-of-the-art schemes with under 3% control-plane\noverhead. In a real blockchain environment, BlockSDN-VC boosts\nconfirmed-transaction throughput by 17% under adversarial workloads, requiring\nno modifications to existing clients.", "AI": {"tldr": "BlockSDN-VC\u662f\u4e00\u79cd\u57fa\u4e8eSDN\u63a7\u5236\u5668\u7684\u4ea4\u6613\u5e7f\u64ad\u534f\u8bae\uff0c\u901a\u8fc7\u96c6\u4e2d\u5316\u5750\u6807\u8ba1\u7b97\u548c\u8f6c\u53d1\u63a7\u5236\uff0c\u663e\u8457\u964d\u4f4e\u533a\u5757\u94fe\u4f20\u64ad\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u4ee3\u533a\u5757\u94fe\u9700\u8981\u5feb\u901f\u53ef\u9760\u7684\u4f20\u64ad\u6765\u5e73\u8861\u5b89\u5168\u6027\u548c\u541e\u5410\u91cf\u3002\u73b0\u6709\u7684\u865a\u62df\u5750\u6807\u65b9\u6cd5\u4f9d\u8d56\u7f13\u6162\u7684\u8fed\u4ee3\u66f4\u65b0\uff0c\u5bfc\u81f4\u8282\u70b9\u4e0d\u540c\u6b65\u3002", "method": "\u5c06\u5750\u6807\u8ba1\u7b97\u548c\u8f6c\u53d1\u63a7\u5236\u96c6\u4e2d\u5230SDN\u63a7\u5236\u5668\u4e2d\uff0c\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\u3001\u6700\u5c0f\u8def\u5f84\u62c9\u4f38\uff0c\u5e76\u80fd\u5feb\u901f\u54cd\u5e94\u8282\u70b9\u53d8\u52a8\u6216\u62e5\u585e\u3002", "result": "\u5728\u5730\u7406\u5206\u5e03\u5f0f\u6a21\u62df\u4e2d\uff0cBlockSDN-VC\u5c06\u4e2d\u4f4d\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe62%\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u9ad84\u500d\uff0c\u63a7\u5236\u5e73\u9762\u5f00\u9500\u4f4e\u4e8e3%\u3002\u5728\u5b9e\u9645\u533a\u5757\u94fe\u73af\u5883\u4e2d\uff0c\u5728\u5bf9\u6297\u6027\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5c06\u786e\u8ba4\u4ea4\u6613\u541e\u5410\u91cf\u63d0\u9ad817%\u3002", "conclusion": "BlockSDN-VC\u65e0\u9700\u4fee\u6539\u73b0\u6709\u5ba2\u6237\u7aef\u5373\u53ef\u663e\u8457\u63d0\u5347\u533a\u5757\u94fe\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u4ea4\u6613\u4f20\u64ad\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00471", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00471", "abs": "https://arxiv.org/abs/2510.00471", "authors": ["Yankai Jiang", "Raghavendra Kanakagiri", "Rohan Basu Roy", "Devesh Tiwari"], "title": "ThirstyFLOPS: Water Footprint Modeling and Analysis Toward Sustainable HPC Systems", "comment": null, "summary": "High-performance computing (HPC) systems are becoming increasingly\nwater-intensive due to their reliance on water-based cooling and the energy\nused in power generation. However, the water footprint of HPC remains\nrelatively underexplored-especially in contrast to the growing focus on carbon\nemissions. In this paper, we present ThirstyFLOPS - a comprehensive water\nfootprint analysis framework for HPC systems. Our approach incorporates\nregion-specific metrics, including Water Usage Effectiveness, Power Usage\nEffectiveness, and Energy Water Factor, to quantify water consumption using\nreal-world data. Using four representative HPC systems - Marconi, Fugaku,\nPolaris, and Frontier - as examples, we provide implications for HPC system\nplanning and management. We explore the impact of regional water scarcity and\nnuclear-based energy strategies on HPC sustainability. Our findings aim to\nadvance the development of water-aware, environmentally responsible computing\ninfrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e86ThirstyFLOPS\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u7684\u6c34\u8db3\u8ff9\uff0c\u7ed3\u5408\u533a\u57df\u7279\u5b9a\u6307\u6807\u8bc4\u4f30\u6c34\u6d88\u8017\uff0c\u5e76\u4ee5\u56db\u4e2a\u4ee3\u8868\u6027HPC\u7cfb\u7edf\u4e3a\u4f8b\u63d0\u4f9b\u7ba1\u7406\u542f\u793a\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u56e0\u4f9d\u8d56\u6c34\u51b7\u548c\u53d1\u7535\u80fd\u8017\u800c\u65e5\u76ca\u8017\u6c34\uff0c\u4f46\u6c34\u8db3\u8ff9\u7814\u7a76\u76f8\u5bf9\u4e0d\u8db3\uff0c\u4e0e\u78b3\u6392\u5173\u6ce8\u5ea6\u5f62\u6210\u5bf9\u6bd4\u3002", "method": "\u5f00\u53d1ThirstyFLOPS\u6846\u67b6\uff0c\u6574\u5408\u533a\u57df\u7279\u5b9a\u6307\u6807\uff08\u6c34\u5229\u7528\u6548\u7387\u3001\u529f\u7387\u5229\u7528\u6548\u7387\u3001\u80fd\u6e90\u6c34\u56e0\u5b50\uff09\uff0c\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u91cf\u5316\u6c34\u6d88\u8017\u3002", "result": "\u4ee5Marconi\u3001Fugaku\u3001Polaris\u548cFrontier\u56db\u4e2aHPC\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u5206\u6790\u4e86\u533a\u57df\u6c34\u8d44\u6e90\u77ed\u7f3a\u548c\u6838\u80fd\u7b56\u7565\u5bf9\u53ef\u6301\u7eed\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u63a8\u52a8\u5f00\u53d1\u5177\u6709\u6c34\u610f\u8bc6\u3001\u73af\u5883\u53cb\u597d\u7684\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2510.00541", "categories": ["cs.DC", "68M20 (Performance evaluation, queueing, and scheduling), 90C59\n  (Approximation methods and heuristics)"], "pdf": "https://arxiv.org/pdf/2510.00541", "abs": "https://arxiv.org/abs/2510.00541", "authors": ["Ali M. Baydoun", "Ahmed S. Zekri"], "title": "Towards Efficient VM Placement: A Two-Stage ACO-PSO Approach for Green Cloud Infrastructure", "comment": "20 pages, 7 figures. Published in International Journal of Computer\n  Networks & Communications (IJCNC), Vol. 17, No. 5, 2025", "summary": "Datacenters consume a growing share of energy, prompting the need for\nsustainable resource management. This paper presents a Hybrid ACO-PSO (HAPSO)\nalgorithm for energy-aware virtual machine (VM) placement and migration in\ngreen cloud datacenters. In the first stage, Ant Colony Optimization (ACO)\nperforms energy-efficient initial placement across physical hosts, ensuring\nglobal feasibility. In the second stage, a discrete Particle Swarm Optimization\n(PSO) refines allocations by migrating VMs from overloaded or underutilized\nhosts. HAPSO introduces several innovations: sequential hybridization of\nmetaheuristics, system-informed particle initialization using ACO output,\nheuristic-guided discretization for constraint handling, and a multi-objective\nfitness function that minimizes active servers and resource wastage.\nImplemented in CloudSimPlus, extensive simulations demonstrate that HAPSO\nconsistently outperforms classical heuristics (BFD, FFD), Unified Ant Colony\nSystem (UACS), and ACO-only. Notably, HAPSO achieves up to 25% lower energy\nconsumption and 18% fewer SLA violations compared to UACS at large-scale\nworkloads, while sustaining stable cost and carbon emissions. These results\nhighlight the effectiveness of two-stage bio-inspired hybridization in\naddressing the dynamic and multi-objective nature of cloud resource management.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408ACO-PSO\u7b97\u6cd5(HAPSO)\uff0c\u7528\u4e8e\u7eff\u8272\u4e91\u6570\u636e\u4e2d\u5fc3\u4e2d\u8282\u80fd\u7684\u865a\u62df\u673a\u653e\u7f6e\u548c\u8fc1\u79fb\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u548cSLA\u8fdd\u89c4\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u6301\u7eed\u589e\u957f\uff0c\u9700\u8981\u53ef\u6301\u7eed\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u6765\u89e3\u51b3\u865a\u62df\u673a\u653e\u7f6e\u548c\u8fc1\u79fb\u7684\u8282\u80fd\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u8681\u7fa4\u4f18\u5316(ACO)\u8fdb\u884c\u8282\u80fd\u7684\u521d\u59cb\u865a\u62df\u673a\u653e\u7f6e\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u79bb\u6563\u7c92\u5b50\u7fa4\u4f18\u5316(PSO)\u901a\u8fc7\u8fc1\u79fb\u8fc7\u8f7d\u6216\u5229\u7528\u7387\u4e0d\u8db3\u4e3b\u673a\u4e0a\u7684\u865a\u62df\u673a\u6765\u4f18\u5316\u5206\u914d\u3002", "result": "\u5728CloudSimPlus\u4e2d\u7684\u4eff\u771f\u663e\u793a\uff0cHAPSO\u76f8\u6bd4\u4f20\u7edf\u542f\u53d1\u5f0f\u7b97\u6cd5(BFD\u3001FFD)\u3001\u7edf\u4e00\u8681\u7fa4\u7cfb\u7edf(UACS)\u548c\u7eafACO\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u8017\u964d\u4f4e\u8fbe25%\uff0cSLA\u8fdd\u89c4\u51cf\u5c1118%\u3002", "conclusion": "\u4e24\u9636\u6bb5\u751f\u7269\u542f\u53d1\u5f0f\u6df7\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u4e91\u8d44\u6e90\u7ba1\u7406\u7684\u52a8\u6001\u548c\u591a\u76ee\u6807\u7279\u6027\uff0c\u5728\u4fdd\u6301\u6210\u672c\u548c\u78b3\u6392\u653e\u7a33\u5b9a\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\u3002"}}
{"id": "2510.00606", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00606", "abs": "https://arxiv.org/abs/2510.00606", "authors": ["Xueze Kang", "Guangyu Xiang", "Yuxin Wang", "Hao Zhang", "Yuchu Fang", "Yuhang Zhou", "Zhenheng Tang", "Youhui Lv", "Eliran Maman", "Mark Wasserman", "Alon Zameret", "Zhipeng Bian", "Shushu Chen", "Zhiyou Yu", "Jin Wang", "Xiaoyu Wu", "Yang Zheng", "Chen Tian", "Xiaowen Chu"], "title": "ElasWave: An Elastic-Native System for Scalable Hybrid-Parallel Training", "comment": null, "summary": "Large-scale LLM pretraining today spans $10^{5}$--$10^{6}$ accelerators,\nmaking failures commonplace and elasticity no longer optional. We posit that an\nelastic-native training system must simultaneously ensure (i) Parameter\nConsistency, (ii) low Mean Time to Recovery (MTTR), (iii) high post-change\nThroughput, and (iv) Computation Consistency. This objective set not has never\nbeen jointly attained by prior work. To achieve these goals, we present\nElasWave, which provides per-step fault tolerance via multi-dimensional\nscheduling across Graph, Dataflow, Frequency, and Random Number Generation.\nElasWave resizes and reshards micro-batch workloads while preserving the global\nbatch size and gradient scale; it performs online pipeline resharding with\nasynchronous parameter migration, interleaving ZeRO partitions so recovery\nreduces to disjoint rank-to-rank transfers. It further uses DVFS to absorb\npipeline bubbles and reshards RNG to keep consistent computations. A dynamic\ncommunicator enables in-place communication group edits, while per-step\nin-memory snapshots support online verification and redistribution. We\nevaluated ElasWave on 96 NPUs and benchmarked against state-of-the-art\nbaselines: throughput improves by $1.35\\times$ over ReCycle and $1.60\\times$\nover TorchFT; communicator recovery completes within one second (up to\n$82\\times/3.6\\times$ faster than full/partial rebuilds); migration MTTR drops\nby as much as $51\\%$; and convergence deviation is reduced by approximately\n$78\\%$.", "AI": {"tldr": "ElasWave\u662f\u4e00\u4e2a\u5f39\u6027\u539f\u751f\u7684\u5927\u89c4\u6a21LLM\u9884\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u7ef4\u8c03\u5ea6\u5b9e\u73b0\u6545\u969c\u5bb9\u9519\uff0c\u572896\u4e2aNPU\u4e0a\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u541e\u5410\u91cf1.35-1.60\u500d\uff0c\u6062\u590d\u65f6\u95f4\u51cf\u5c1151%\uff0c\u6536\u655b\u504f\u5dee\u964d\u4f4e78%\u3002", "motivation": "\u5927\u89c4\u6a21LLM\u9884\u8bad\u7ec3\u6d89\u53ca10^5-10^6\u4e2a\u52a0\u901f\u5668\uff0c\u6545\u969c\u9891\u53d1\u4e14\u5f39\u6027\u4e0d\u518d\u53ef\u9009\u3002\u73b0\u6709\u7cfb\u7edf\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u53c2\u6570\u4e00\u81f4\u6027\u3001\u4f4e\u6062\u590d\u65f6\u95f4\u3001\u9ad8\u541e\u5410\u91cf\u548c\u8ba1\u7b97\u4e00\u81f4\u6027\u7684\u8981\u6c42\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u8c03\u5ea6\uff08\u56fe\u3001\u6570\u636e\u6d41\u3001\u9891\u7387\u3001\u968f\u673a\u6570\u751f\u6210\uff09\uff0c\u5b9e\u73b0\u6bcf\u6b65\u6545\u969c\u5bb9\u9519\u3002\u901a\u8fc7\u5728\u7ebf\u6d41\u6c34\u7ebf\u91cd\u5206\u7247\u3001\u5f02\u6b65\u53c2\u6570\u8fc1\u79fb\u3001ZeRO\u5206\u533a\u4ea4\u9519\u3001DVFS\u5438\u6536\u6d41\u6c34\u7ebf\u6c14\u6ce1\u3001RNG\u91cd\u5206\u7247\u7b49\u6280\u672f\u3002", "result": "\u572896\u4e2aNPU\u4e0a\u6d4b\u8bd5\uff1a\u541e\u5410\u91cf\u6bd4ReCycle\u63d0\u53471.35\u500d\uff0c\u6bd4TorchFT\u63d0\u53471.60\u500d\uff1b\u901a\u4fe1\u5668\u6062\u590d\u57281\u79d2\u5185\u5b8c\u6210\uff08\u6bd4\u5b8c\u5168/\u90e8\u5206\u91cd\u5efa\u5feb82\u500d/3.6\u500d\uff09\uff1b\u8fc1\u79fb\u6062\u590d\u65f6\u95f4\u51cf\u5c1151%\uff1b\u6536\u655b\u504f\u5dee\u964d\u4f4e\u7ea678%\u3002", "conclusion": "ElasWave\u6210\u529f\u5b9e\u73b0\u4e86\u5f39\u6027\u539f\u751f\u8bad\u7ec3\u7cfb\u7edf\u7684\u56db\u4e2a\u5173\u952e\u76ee\u6807\uff0c\u4e3a\u5927\u89c4\u6a21LLM\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u5f39\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00678", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00678", "abs": "https://arxiv.org/abs/2510.00678", "authors": ["Muhammad Ali Jamshed", "Malik Muhammad Saad", "Muhammad Ahmed Mohsin", "Dongkyun Kim", "Octavia A. Dobre", "Halim Yanikomeroglu", "Lina Mohjazi"], "title": "Net-Zero 6G from Earth to Orbit: Sustainable Design of Integrated Terrestrial and Non-Terrestrial Networks", "comment": "Submitted to IEEE Communications Magazine", "summary": "The integration of Terrestrial Networks (TN) and Non-Terrestrial Networks\n(NTN) plays a crucial role in bridging the digital divide and enabling Sixth\nGeneration (6G) and beyond to achieve truly ubiquitous connectivity. However,\ncombining TN and NTN introduces significant energy challenges due to the\ndiverse characteristics and operational environments of these systems. In this\npaper, we present for the first time a comprehensive overview of the design\nchallenges associated with achieving Net-Zero energy targets in integrated TN\nand NTN systems. We outline a set of key enabling technologies that can support\nthe energy demands of such networks while aligning with Net-Zero objectives. To\nenhance the Energy Efficiency (EE) of integrated TN and NTN systems, we provide\na use case analysis that leverages Artificial Intelligence (AI) to deliver\nadaptable solutions across diverse deployment scenarios. Finally, we highlight\npromising research directions that can guide the sustainable evolution of\nintegrated TN and NTN.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u6982\u8ff0\u4e86\u5728\u96c6\u6210\u5730\u9762\u7f51\u7edc\u548c\u975e\u5730\u9762\u7f51\u7edc\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u51c0\u96f6\u80fd\u8017\u76ee\u6807\u7684\u8bbe\u8ba1\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u652f\u6301\u6b64\u7c7b\u7f51\u7edc\u80fd\u6e90\u9700\u6c42\u7684\u5173\u952e\u4f7f\u80fd\u6280\u672f\uff0c\u5e76\u901a\u8fc7AI\u7528\u4f8b\u5206\u6790\u63d0\u5347\u80fd\u6e90\u6548\u7387\uff0c\u6700\u540e\u6307\u51fa\u4e86\u53ef\u6301\u7eed\u6f14\u8fdb\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5730\u9762\u7f51\u7edc\u548c\u975e\u5730\u9762\u7f51\u7edc\u7684\u96c6\u6210\u5bf9\u4e8e\u5f25\u5408\u6570\u5b57\u9e3f\u6c9f\u548c\u5b9e\u73b06G\u53ca\u66f4\u5148\u8fdb\u901a\u4fe1\u7684\u6cdb\u5728\u8fde\u63a5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u79cd\u96c6\u6210\u7531\u4e8e\u7cfb\u7edf\u7279\u6027\u548c\u8fd0\u884c\u73af\u5883\u7684\u591a\u6837\u6027\u5e26\u6765\u4e86\u663e\u8457\u7684\u80fd\u6e90\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u652f\u6301\u51c0\u96f6\u80fd\u8017\u76ee\u6807\u7684\u5173\u952e\u4f7f\u80fd\u6280\u672f\uff0c\u5e76\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u7528\u4f8b\u5206\u6790\uff0c\u4e3a\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u63d0\u4f9b\u9002\u5e94\u6027\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u63d0\u4f9b\u4e86\u96c6\u6210TN\u548cNTN\u7cfb\u7edf\u80fd\u6e90\u6548\u7387\u63d0\u5347\u7684\u5168\u9762\u6846\u67b6\uff0c\u5305\u62ec\u6280\u672f\u8def\u7ebf\u548cAI\u9a71\u52a8\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "\u6307\u51fa\u4e86\u96c6\u6210TN\u548cNTN\u7cfb\u7edf\u53ef\u6301\u7eed\u6f14\u8fdb\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u5b9e\u73b0\u51c0\u96f6\u80fd\u8017\u76ee\u6807\u63d0\u4f9b\u4e86\u6307\u5bfc\u6027\u5efa\u8bae\u3002"}}
{"id": "2510.00758", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00758", "abs": "https://arxiv.org/abs/2510.00758", "authors": ["Davide Rucci", "Emanuele Carlini", "Patrizio Dazzi", "Hanna Kavalionak", "Matteo Mordacchini"], "title": "Decentralized and Self-adaptive Core Maintenance on Temporal Graphs", "comment": null, "summary": "Key graph-based problems play a central role in understanding network\ntopology and uncovering patterns of similarity in homogeneous and temporal\ndata. Such patterns can be revealed by analyzing communities formed by nodes,\nwhich in turn can be effectively modeled through temporal $k$-cores. This paper\nintroduces a novel decentralized and incremental algorithm for computing the\ncore decomposition of temporal networks. Decentralized solutions leverage the\nability of network nodes to communicate and coordinate locally, addressing\ncomplex problems in a scalable, adaptive, and timely manner. By leveraging\npreviously computed coreness values, our approach significantly reduces the\nactivation of nodes and the volume of message exchanges when the network\nchanges over time. This enables scalability with only a minimal trade-off in\nprecision. Experimental evaluations on large real-world networks under varying\nlevels of dynamism demonstrate the efficiency of our solution compared to a\nstate-of-the-art approach, particularly in terms of active nodes, communication\noverhead, and convergence speed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53bb\u4e2d\u5fc3\u5316\u589e\u91cf\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u65f6\u5e8f\u7f51\u7edc\u7684\u6838\u5206\u89e3\uff0c\u901a\u8fc7\u5229\u7528\u5148\u524d\u8ba1\u7b97\u7684\u6838\u5ea6\u503c\u6765\u51cf\u5c11\u8282\u70b9\u6fc0\u6d3b\u548c\u6d88\u606f\u4ea4\u6362\u91cf\uff0c\u5728\u7cbe\u5ea6\u635f\u5931\u6700\u5c0f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u56fe\u57fa\u95ee\u9898\u5728\u7406\u89e3\u7f51\u7edc\u62d3\u6251\u548c\u53d1\u73b0\u540c\u8d28\u53ca\u65f6\u5e8f\u6570\u636e\u4e2d\u7684\u76f8\u4f3c\u6a21\u5f0f\u65b9\u9762\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u53ef\u4ee5\u901a\u8fc7\u5206\u6790\u8282\u70b9\u5f62\u6210\u7684\u793e\u533a\u6765\u63ed\u793a\uff0c\u800c\u65f6\u5e8fk-\u6838\u53ef\u4ee5\u6709\u6548\u5efa\u6a21\u8fd9\u4e9b\u793e\u533a\u3002\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u65b9\u6848\u5229\u7528\u7f51\u7edc\u8282\u70b9\u672c\u5730\u901a\u4fe1\u548c\u534f\u8c03\u80fd\u529b\uff0c\u4ee5\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u53ca\u65f6\u7684\u65b9\u5f0f\u89e3\u51b3\u590d\u6742\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u589e\u91cf\u7b97\u6cd5\uff0c\u5229\u7528\u5148\u524d\u8ba1\u7b97\u7684\u6838\u5ea6\u503c\uff0c\u5728\u7f51\u7edc\u968f\u65f6\u95f4\u53d8\u5316\u65f6\u663e\u8457\u51cf\u5c11\u8282\u70b9\u6fc0\u6d3b\u548c\u6d88\u606f\u4ea4\u6362\u91cf\u3002", "result": "\u5728\u5927\u578b\u771f\u5b9e\u4e16\u754c\u7f51\u7edc\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u89e3\u51b3\u65b9\u6848\u5728\u8282\u70b9\u6fc0\u6d3b\u3001\u901a\u4fe1\u5f00\u9500\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u52a8\u6001\u6c34\u5e73\u4e0b\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u7cbe\u5ea6\u635f\u5931\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u65f6\u5e8f\u7f51\u7edc\u6838\u5206\u89e3\u8ba1\u7b97\uff0c\u4e3a\u5927\u89c4\u6a21\u52a8\u6001\u7f51\u7edc\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00822", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.00822", "abs": "https://arxiv.org/abs/2510.00822", "authors": ["Sairam Sri Vatsavai", "Raees Khan", "Kuan-Chieh Hsu", "Ozgur O. Kilic", "Paul Nilsson", "Tatiana Korchuganova", "David K. Park", "Sankha Dutta", "Yihui Ren", "Joseph Boudreau", "Tasnuva Chowdhury", "Shengyu Feng", "Jaehyung Kim", "Scott Klasky", "Tadashi Maeno", "Verena Ingrid Martinez", "Norbert Podhorszki", "Fr\u00e9d\u00e9ric Suter", "Wei Yang", "Yiming Yang", "Shinjae Yoo", "Alexei Klimentov", "Adolfy Hoisie"], "title": "CGSim: A Simulation Framework for Large Scale Distributed Computing Environment", "comment": "The paper has been accepted at PMBS workshop SC25", "summary": "Large-scale distributed computing infrastructures such as the Worldwide LHC\nComputing Grid (WLCG) require comprehensive simulation tools for evaluating\nperformance, testing new algorithms, and optimizing resource allocation\nstrategies. However, existing simulators suffer from limited scalability,\nhardwired algorithms, lack of real-time monitoring, and inability to generate\ndatasets suitable for modern machine learning approaches. We present CGSim, a\nsimulation framework for large-scale distributed computing environments that\naddresses these limitations. Built upon the validated SimGrid simulation\nframework, CGSim provides high-level abstractions for modeling heterogeneous\ngrid environments while maintaining accuracy and scalability. Key features\ninclude a modular plugin mechanism for testing custom workflow scheduling and\ndata movement policies, interactive real-time visualization dashboards, and\nautomatic generation of event-level datasets suitable for AI-assisted\nperformance modeling. We demonstrate CGSim's capabilities through a\ncomprehensive evaluation using production ATLAS PanDA workloads, showing\nsignificant calibration accuracy improvements across WLCG computing sites.\nScalability experiments show near-linear scaling for multi-site simulations,\nwith distributed workloads achieving 6x better performance compared to\nsingle-site execution. The framework enables researchers to simulate WLCG-scale\ninfrastructures with hundreds of sites and thousands of concurrent jobs within\npractical time budget constraints on commodity hardware.", "AI": {"tldr": "CGSim\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u7684\u4eff\u771f\u6846\u67b6\uff0c\u57fa\u4e8eSimGrid\u6784\u5efa\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4eff\u771f\u5de5\u5177\u5728\u53ef\u6269\u5c55\u6027\u3001\u7b97\u6cd5\u7075\u6d3b\u6027\u3001\u5b9e\u65f6\u76d1\u63a7\u548c\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u751f\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u4eff\u771f\u5de5\u5177\u5b58\u5728\u53ef\u6269\u5c55\u6027\u6709\u9650\u3001\u7b97\u6cd5\u56fa\u5316\u3001\u7f3a\u4e4f\u5b9e\u65f6\u76d1\u63a7\u4ee5\u53ca\u65e0\u6cd5\u751f\u6210\u9002\u5408\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u6570\u636e\u96c6\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u7ecf\u8fc7\u9a8c\u8bc1\u7684SimGrid\u4eff\u771f\u6846\u67b6\uff0cCGSim\u63d0\u4f9b\u9ad8\u5c42\u62bd\u8c61\u6765\u5efa\u6a21\u5f02\u6784\u7f51\u683c\u73af\u5883\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u5173\u952e\u7279\u6027\u5305\u62ec\u6a21\u5757\u5316\u63d2\u4ef6\u673a\u5236\u3001\u4ea4\u4e92\u5f0f\u5b9e\u65f6\u53ef\u89c6\u5316\u4eea\u8868\u677f\u4ee5\u53ca\u81ea\u52a8\u751f\u6210\u4e8b\u4ef6\u7ea7\u6570\u636e\u96c6\u3002", "result": "\u4f7f\u7528\u751f\u4ea7ATLAS PanDA\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u7684\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff0c\u5728WLCG\u8ba1\u7b97\u7ad9\u70b9\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6821\u51c6\u7cbe\u5ea6\u6539\u8fdb\u3002\u53ef\u6269\u5c55\u6027\u5b9e\u9a8c\u663e\u793a\u591a\u7ad9\u70b9\u4eff\u771f\u5177\u6709\u63a5\u8fd1\u7ebf\u6027\u7684\u6269\u5c55\u6027\uff0c\u5206\u5e03\u5f0f\u5de5\u4f5c\u8d1f\u8f7d\u76f8\u6bd4\u5355\u7ad9\u70b9\u6267\u884c\u6027\u80fd\u63d0\u53476\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5728\u5546\u54c1\u786c\u4ef6\u4e0a\uff0c\u5728\u5b9e\u7528\u65f6\u95f4\u9884\u7b97\u7ea6\u675f\u5185\uff0c\u4eff\u771f\u5177\u6709\u6570\u767e\u4e2a\u7ad9\u70b9\u548c\u6570\u5343\u4e2a\u5e76\u53d1\u4f5c\u4e1a\u7684WLCG\u89c4\u6a21\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2510.00828", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00828", "abs": "https://arxiv.org/abs/2510.00828", "authors": ["Kuan-Chieh Hsu", "Sairam Sri Vatsavai", "Ozgur O. Kilic", "Tatiana Korchuganova", "Paul Nilsson", "Sankha Dutta", "Yihui Ren", "David K. Park", "Joseph Boudreau", "Tasnuva Chowdhury", "Shengyu Feng", "Raees Khan", "Jaehyung Kim", "Scott Klasky", "Tadashi Maeno", "Verena Ingrid Martinez Outschoorn", "Norbert Podhorszki", "Fr\u00e9d\u00e9ric Suter", "Wei Yang", "Yiming Yang", "Shinjae Yoo", "Alexei Klimentov", "Adolfy Hoisie"], "title": "Data Management System Analysis for Distributed Computing Workloads", "comment": "10 pages, 12 figures, to be presented in SC25 DRBSD Workshop", "summary": "Large-scale international collaborations such as ATLAS rely on globally\ndistributed workflows and data management to process, move, and store vast\nvolumes of data. ATLAS's Production and Distributed Analysis (PanDA) workflow\nsystem and the Rucio data management system are each highly optimized for their\nrespective design goals. However, operating them together at global scale\nexposes systemic inefficiencies, including underutilized resources, redundant\nor unnecessary transfers, and altered error distributions. Moreover, PanDA and\nRucio currently lack shared performance awareness and coordinated, adaptive\nstrategies.\n  This work charts a path toward co-optimizing the two systems by diagnosing\ndata-management pitfalls and prioritizing end-to-end improvements. With the\nobservation of spatially and temporally imbalanced transfer activities, we\ndevelop a metadata-matching algorithm that links PanDA jobs and Rucio datasets\nat the file level, yielding a complete, fine-grained view of data access and\nmovement. Using this linkage, we identify anomalous transfer patterns that\nviolate PanDA's data-centric job-allocation principle. We then outline\nmitigation strategies for these patterns and highlight opportunities for\ntighter PanDA-Rucio coordination to improve resource utilization, reduce\nunnecessary data movement, and enhance overall system resilience.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86ATLAS\u5b9e\u9a8c\u4e2dPanDA\u5de5\u4f5c\u6d41\u7cfb\u7edf\u548cRucio\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u5728\u534f\u540c\u8fd0\u884c\u65f6\u51fa\u73b0\u7684\u7cfb\u7edf\u6548\u7387\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u5143\u6570\u636e\u5339\u914d\u7b97\u6cd5\u8fde\u63a5\u4e24\u4e2a\u7cfb\u7edf\uff0c\u8bc6\u522b\u5f02\u5e38\u4f20\u8f93\u6a21\u5f0f\uff0c\u5e76\u5236\u5b9a\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "ATLAS\u5b9e\u9a8c\u4e2d\u7684PanDA\u5de5\u4f5c\u6d41\u7cfb\u7edf\u548cRucio\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u5404\u81ea\u4f18\u5316\u4f46\u534f\u540c\u8fd0\u884c\u65f6\u5b58\u5728\u7cfb\u7edf\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u5305\u62ec\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u3001\u5197\u4f59\u4f20\u8f93\u548c\u9519\u8bef\u5206\u5e03\u6539\u53d8\u7b49\uff0c\u9700\u8981\u7aef\u5230\u7aef\u7684\u6539\u8fdb\u3002", "method": "\u5f00\u53d1\u5143\u6570\u636e\u5339\u914d\u7b97\u6cd5\uff0c\u5728\u6587\u4ef6\u7ea7\u522b\u8fde\u63a5PanDA\u4f5c\u4e1a\u548cRucio\u6570\u636e\u96c6\uff0c\u83b7\u5f97\u5b8c\u6574\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u8bbf\u95ee\u548c\u79fb\u52a8\u89c6\u56fe\uff0c\u8bc6\u522b\u8fdd\u53cdPanDA\u6570\u636e\u4e2d\u5fc3\u4f5c\u4e1a\u5206\u914d\u539f\u5219\u7684\u5f02\u5e38\u4f20\u8f93\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u51fa\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u4e0d\u5e73\u8861\u7684\u4f20\u8f93\u6d3b\u52a8\uff0c\u53d1\u73b0\u4e86\u8fdd\u53cd\u6570\u636e\u4e2d\u5fc3\u4f5c\u4e1a\u5206\u914d\u539f\u5219\u7684\u5f02\u5e38\u4f20\u8f93\u6a21\u5f0f\uff0c\u4e3a\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u6570\u636e\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7f13\u89e3\u8fd9\u4e9b\u6a21\u5f0f\u7684\u7b56\u7565\uff0c\u5e76\u5f3a\u8c03\u4e86\u52a0\u5f3aPanDA-Rucio\u534f\u8c03\u7684\u673a\u4f1a\uff0c\u4ee5\u6539\u5584\u8d44\u6e90\u5229\u7528\u3001\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u6570\u636e\u79fb\u52a8\u5e76\u589e\u5f3a\u6574\u4f53\u7cfb\u7edf\u5f39\u6027\u3002"}}
{"id": "2510.00833", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00833", "abs": "https://arxiv.org/abs/2510.00833", "authors": ["Thanh Linh Nguyen", "Marcela Tuler de Oliveira", "An Braeken", "Aaron Yi Ding", "Quoc-Viet Pham"], "title": "Towards Verifiable Federated Unlearning: Framework, Challenges, and The Road Ahead", "comment": "Journal submission", "summary": "Federated unlearning (FUL) enables removing the data influence from the model\ntrained across distributed clients, upholding the right to be forgotten as\nmandated by privacy regulations. FUL facilitates a value exchange where clients\ngain privacy-preserving control over their data contributions, while service\nproviders leverage decentralized computing and data freshness. However, this\nentire proposition is undermined because clients have no reliable way to verify\nthat their data influence has been provably removed, as current metrics and\nsimple notifications offer insufficient assurance. We envision unlearning\nverification becoming a pivotal and trust-by-design part of the FUL life-cycle\ndevelopment, essential for highly regulated and data-sensitive services and\napplications like healthcare. This article introduces veriFUL, a reference\nframework for verifiable FUL that formalizes verification entities, goals,\napproaches, and metrics. Specifically, we consolidate existing efforts and\ncontribute new insights, concepts, and metrics to this domain. Finally, we\nhighlight research challenges and identify potential applications and\ndevelopments for verifiable FUL and veriFUL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86veriFUL\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u9057\u5fd8\u7684\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u5ba2\u6237\u6570\u636e\u5f71\u54cd\u80fd\u88ab\u53ef\u9760\u5730\u9a8c\u8bc1\u79fb\u9664\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u9760\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u5ba2\u6237\u65e0\u6cd5\u786e\u8ba4\u5176\u6570\u636e\u5f71\u54cd\u662f\u5426\u771f\u6b63\u88ab\u79fb\u9664\uff0c\u8fd9\u524a\u5f31\u4e86\u9690\u79c1\u4fdd\u62a4\u627f\u8bfa\u3002", "method": "\u63d0\u51faveriFUL\u53c2\u8003\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5b9e\u4f53\u3001\u76ee\u6807\u3001\u65b9\u6cd5\u548c\u6307\u6807\uff0c\u6574\u5408\u73b0\u6709\u5de5\u4f5c\u5e76\u8d21\u732e\u65b0\u89c1\u89e3\u548c\u6982\u5ff5\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u9a8c\u8bc1\u8054\u90a6\u9057\u5fd8\u7684\u7406\u8bba\u6846\u67b6\uff0c\u660e\u786e\u4e86\u9a8c\u8bc1\u9700\u6c42\u548c\u5b9e\u73b0\u8def\u5f84\u3002", "conclusion": "\u53ef\u9a8c\u8bc1\u9057\u5fd8\u5e94\u6210\u4e3a\u8054\u90a6\u5b66\u4e60\u751f\u547d\u5468\u671f\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u7b49\u9ad8\u5ea6\u76d1\u7ba1\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.00991", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00991", "abs": "https://arxiv.org/abs/2510.00991", "authors": ["Ziteng Chen", "Xiaohe Hu", "Menghao Zhang", "Yanmin Jia", "Yan Zhang", "Mingjun Zhang", "Da Liu", "Fangzheng Jiao", "Jun Chen", "He Liu", "Aohan Zeng", "Shuaixing Duan", "Ruya Gu", "Yang Jing", "Bowen Han", "Jiahao Cao", "Wei Chen", "Wenqi Xie", "Jinlong Hou", "Yuan Cheng", "Bohua Xu", "Mingwei Xu", "Chunming Hu"], "title": "An Efficient, Reliable and Observable Collective Communication Library in Large-scale GPU Training Clusters", "comment": "15 pages, 16 figures", "summary": "Large-scale LLM training requires collective communication libraries to\nexchange data among distributed GPUs. As a company dedicated to building and\noperating large-scale GPU training clusters, we encounter several challenges\nwhen using NCCL in production, including 1) limited efficiency with costly and\ncumbersome P2P communication, 2) poor tolerance to frequent RNIC port failures,\nand 3) insufficient observability of transient collective communication\nanomalies. To address these issues, we propose ICCL, an efficient, reliable,\nand observable collective communication library in large-scale GPU training\nclusters. ICCL offloads the P2P communication from GPU kernels to CPU threads\nfor minimal SM consumption, and removes the redundant memory copies irrelevant\nto the actual communicating process. ICCL also introduces a primary-backup QP\nmechanism to tolerate frequent NIC port failures, and designs a window-based\nmonitor to observe network anomalies at O(us) level. We open-source ICCL and\ndeploy it in production training clusters for several months, with results\nshowing that compared to NCCL, ICCL achieves a 23.4%/28.5% improvement in P2P\nthroughput/latency as well as a 6.02% increase in training throughput. We also\nshare the operating experience of ICCL in large-scale clusters, hoping to give\nthe communities more insights on production-level collective communication\nlibraries in LLM training.", "AI": {"tldr": "ICCL\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u7684\u9ad8\u6548\u3001\u53ef\u9760\u3001\u53ef\u89c2\u6d4b\u7684\u96c6\u4f53\u901a\u4fe1\u5e93\uff0c\u89e3\u51b3\u4e86NCCL\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u9047\u5230\u7684P2P\u901a\u4fe1\u6548\u7387\u4f4e\u3001RNIC\u7aef\u53e3\u6545\u969c\u5bb9\u5fcd\u5dee\u548c\u901a\u4fe1\u5f02\u5e38\u89c2\u6d4b\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u5728\u5927\u89c4\u6a21GPU\u8bad\u7ec3\u96c6\u7fa4\u4e2d\u4f7f\u7528NCCL\u65f6\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1\uff09P2P\u901a\u4fe1\u6548\u7387\u4f4e\u4e14\u590d\u6742\uff1b2\uff09\u5bf9\u9891\u7e41\u7684RNIC\u7aef\u53e3\u6545\u969c\u5bb9\u5fcd\u6027\u5dee\uff1b3\uff09\u5bf9\u77ac\u6001\u96c6\u4f53\u901a\u4fe1\u5f02\u5e38\u7684\u53ef\u89c2\u6d4b\u6027\u4e0d\u8db3\u3002", "method": "ICCL\u5c06P2P\u901a\u4fe1\u4eceGPU\u5185\u6838\u5378\u8f7d\u5230CPU\u7ebf\u7a0b\u4ee5\u51cf\u5c11SM\u6d88\u8017\uff0c\u6d88\u9664\u4e0e\u901a\u4fe1\u8fc7\u7a0b\u65e0\u5173\u7684\u5197\u4f59\u5185\u5b58\u62f7\u8d1d\uff0c\u5f15\u5165\u4e3b\u5907QP\u673a\u5236\u5bb9\u5fcdNIC\u7aef\u53e3\u6545\u969c\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u7a97\u53e3\u7684\u76d1\u63a7\u5668\u5728\u5fae\u79d2\u7ea7\u522b\u89c2\u6d4b\u7f51\u7edc\u5f02\u5e38\u3002", "result": "\u4e0eNCCL\u76f8\u6bd4\uff0cICCL\u5728P2P\u541e\u5410\u91cf/\u5ef6\u8fdf\u65b9\u9762\u5206\u522b\u63d0\u534723.4%/28.5%\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53476.02%\uff0c\u5df2\u5728\u751f\u4ea7\u8bad\u7ec3\u96c6\u7fa4\u4e2d\u90e8\u7f72\u6570\u6708\u3002", "conclusion": "ICCL\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u4e2d\u96c6\u4f53\u901a\u4fe1\u7684\u5173\u952e\u95ee\u9898\uff0c\u5e76\u5206\u4eab\u4e86\u5728\u5927\u89c4\u6a21\u96c6\u7fa4\u4e2d\u7684\u8fd0\u7ef4\u7ecf\u9a8c\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u751f\u4ea7\u7ea7\u96c6\u4f53\u901a\u4fe1\u5e93\u7684\u5b9e\u8df5\u6d1e\u5bdf\u3002"}}
