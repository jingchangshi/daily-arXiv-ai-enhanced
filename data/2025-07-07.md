<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AR](#cs.AR) [Total: 5]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
*Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 论文提出了一种名为DecoRTL的新解码策略，用于改进大型语言模型（LLM）在RTL代码生成中的表现，解决了传统解码策略在结构和语义上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统LLM解码策略在RTL代码生成中常导致无效或重复的输出，无法区分语法关键区域和设计关键区域的需求。

Method: DecoRTL结合了自一致性采样和语法感知温度调整，前者通过多候选生成和重排序提升正确性，后者根据语法角色调整采样温度。

Result: 在VerilogEval基准测试中，DecoRTL显著提升了语法有效性、功能正确性和输出多样性，且性能开销可忽略。

Conclusion: DecoRTL无需额外微调即可在推理时显著改善RTL代码生成质量。

Abstract: As one of their many applications, large language models (LLMs) have recently
shown promise in automating register transfer level (RTL) code generation.
However, conventional LLM decoding strategies, originally designed for natural
language, often fail to meet the structural and semantic demands of RTL,
leading to hallucinated, repetitive, or invalid code outputs. In this paper, we
first investigate the root causes of these decoding failures through an
empirical analysis of token-level entropy during RTL generation. Our findings
reveal that LLMs exhibit low confidence in regions of structural ambiguity or
semantic complexity, showing that standard decoding strategies fail to
differentiate between regions requiring determinism (syntax-critical regions)
and those that benefit from creative exploratory variability (design-critical
regions). Then, to overcome this, we introduce DecoRTL, a novel run-time
decoding strategy, that is both syntax-aware and contrastive for RTL code
generation. DecoRTL integrates two complementary components: (i)
self-consistency sampling, which generates multiple candidates and re-ranks
them based on token-level agreement to promote correctness while maintaining
diversity; and (ii) syntax-aware temperature adaptation, which classifies
tokens by their syntactical and functional roles and adjusts the sampling
temperature accordingly, enforcing low temperature for syntax-critical tokens
and higher temperature for exploratory ones. Our approach operates entirely at
inference time without requiring any additional model fine-tuning. Through
evaluations on multiple open-source LLMs using the VerilogEval benchmark, we
demonstrate significant improvements in syntactic validity, functional
correctness, and output diversity, while the execution overhead (performance
overhead) is imperceptible.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [SAKURAONE: Empowering Transparent and Open AI Platforms through Private-Sector HPC Investment in Japan](https://arxiv.org/abs/2507.02124)
*Fumikazu Konishi*

Main category: cs.DC

TL;DR: SAKURAONE是一个高性能计算集群，采用开放网络技术，在全球TOP500中排名49，展示了其在AI和大规模HPC任务中的竞争力。


<details>
  <summary>Details</summary>
Motivation: 开发一个基于开放和供应商中立技术的高性能计算集群，以支持先进工作负载，如大语言模型训练。

Method: 采用800 GbE和SONiC操作系统构建开放网络堆栈，结合NVIDIA H100 GPU和全闪存存储子系统。

Result: 在HPL、HPCG和HPL-MxP基准测试中表现优异，分别达到33.95 PFLOP/s、396.295 TFLOP/s和339.86 PFLOP/s。

Conclusion: SAKURAONE证明了开放网络技术在大规模HPC基础设施中的可行性，并展示了高性能计算和AI应用的潜力。

Abstract: SAKURAONE is a managed high performance computing (HPC) cluster developed and
operated by the SAKURA Internet Research Center. It reinforces the ``KOKARYOKU
PHY'' configuration of bare-metal GPU servers and is designed as a cluster
computing resource optimized for advanced workloads, including large language
model (LLM) training.
  In the ISC 2025 edition of the TOP500 list, SAKURAONE was ranked
\textbf{49th} in the world based on its High Performance Linpack (HPL) score,
demonstrating its global competitiveness. In particular, it is the \textbf{only
system within the top 100} that employs a fully open networking stack based on
\textbf{800~GbE (Gigabit Ethernet)} and the \textbf{SONiC (Software for Open
Networking in the Cloud)} operating system, highlighting the viability of open
and vendor-neutral technologies in large-scale HPC infrastructure.
  SAKURAONE achieved a sustained performance of 33.95~PFLOP/s on the HPL
benchmark (Rmax), and 396.295~TFLOP/s on the High Performance Conjugate
Gradient (HPCG) benchmark. For the HPL-MxP benchmark, which targets
low-precision workloads representative of AI applications, SAKURAONE delivered
an impressive 339.86~PFLOP/s using FP8 precision.
  The system comprises 100 compute nodes, each equipped with eight NVIDIA H100
GPUs. It is supported by an all-flash Lustre storage subsystem with a total
physical capacity of 2~petabytes, providing high-throughput and low-latency
data access. Internode communication is enabled by a full-bisection bandwidth
interconnect based on a Rail-Optimized topology, where the Leaf and Spine
layers are interconnected via 800~GbE links. This topology, in combination with
RoCEv2 (RDMA over Converged Ethernet version 2), enables high-speed, lossless
data transfers and mitigates communication bottlenecks in large-scale parallel
workloads.

</details>


### [3] [Signalling Health for Improved Kubernetes Microservice Availability](https://arxiv.org/abs/2507.02158)
*Jacob Roberts,Blair Archibald,Phil Trinder*

Main category: cs.DC

TL;DR: 论文比较了基于轮询（PCM）和基于信号（SCM）的容器监控方法，发现SCM在Kubernetes中检测容器故障更快且无需调优，提升了服务可用性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决PCM方法在容器监控中存在的调优困难、服务可用性降低和故障检测慢的问题。

Method: 设计并实现了基于信号的容器监控（SCM）方法，并通过数学模型和实验（使用SockShop基准）与PCM进行比较。

Result: SCM比PCM检测容器故障快86%，且无需调优，同时减少了错误检测，提升了服务可用性4%。

Conclusion: 建议容器编排器支持SCM功能，以实现更快、更准确的故障检测，无需复杂调优。

Abstract: Microservices are often deployed and managed by a container orchestrator that
can detect and fix failures to maintain the service availability critical in
many applications. In Poll-based Container Monitoring (PCM), the orchestrator
periodically checks container health. While a common approach, PCM requires
careful tuning, may degrade service availability, and can be slow to detect
container health changes. An alternative is Signal-based Container Monitoring
(SCM), where the container signals the orchestrator when its status changes. We
present the design, implementation, and evaluation of an SCM approach for
Kubernetes and empirically show that it has benefits over PCM, as predicted by
a new mathematical model. We compare the service availability of SCM and PCM
over six experiments using the SockShop benchmark. SCM does not require that
polling intervals are tuned, and yet detects container failure 86\% faster than
PCM and container readiness in a comparable time with limited resource
overheads. We find PCM can erroneously detect failures, and this reduces
service availability by 4\%. We propose that orchestrators offer SCM features
for faster failure detection than PCM without erroneous detections or careful
tuning.

</details>


### [4] [Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems](https://arxiv.org/abs/2507.02233)
*Bruce Fang,Danyi Gao*

Main category: cs.DC

TL;DR: 提出一种基于迁移学习的智能算法，用于解决云计算环境中故障根因识别的挑战，通过共享特征提取和域对抗机制提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 云计算环境中故障根因识别因系统复杂、服务耦合度高和故障信息有限而困难。

Method: 采用迁移学习，引入共享特征提取模块和域对抗机制，结合伪标签选择策略增强模型泛化能力。

Result: 实验表明，该方法在准确性、F1-Score和AUC等关键指标上优于主流方法，尤其在类别不平衡和目标域结构差异大的情况下表现优异。

Conclusion: 验证了所提机制在复杂云计算系统中的有效性和实用价值。

Abstract: This paper addresses the challenge of fault root cause identification in
cloud computing environments. The difficulty arises from complex system
structures, dense service coupling, and limited fault information. To solve
this problem, an intelligent identification algorithm based on transfer
learning is proposed. The method introduces a shared feature extraction module
and a domain adversarial mechanism to enable effective knowledge transfer from
the source domain to the target domain. This improves the model's
discriminative ability and generalization performance in the target domain. The
model incorporates a pseudo-label selection strategy. When labeled samples are
lacking in the target domain, high-confidence predictions are used in training.
This enhances the model's ability to recognize minority classes. To evaluate
the stability and adaptability of the method in real-world scenarios,
experiments are designed under three conditions: label scarcity, class
imbalance, and heterogeneous node environments. Experimental results show that
the proposed method outperforms existing mainstream approaches in several key
metrics, including accuracy, F1-Score, and AUC. The model demonstrates stronger
discriminative power and robustness. Notably, under extreme class imbalance and
significant structural differences in the target domain, the model still
maintains high performance. This validates the effectiveness and practical
value of the proposed mechanisms in complex cloud computing systems.

</details>


### [5] [Flotilla: A scalable, modular and resilient federated learning framework for heterogeneous resources](https://arxiv.org/abs/2507.02295)
*Roopkatha Banerjee,Prince Modi,Jinal Vyas,Chunduru Sri Abhijit,Tejus Chandrashekar,Harsha Varun Marisetty,Manik Gupta,Yogesh Simmhan*

Main category: cs.DC

TL;DR: Flotilla是一个轻量级、可扩展的联邦学习框架，支持同步和异步策略，具备容错能力，并在边缘设备上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着移动和边缘计算的发展及数据隐私问题的关注，联邦学习（FL）作为一种隐私保护的分布式机器学习方法受到欢迎。然而，现有框架多用于伪分布式模拟，缺乏对真实边缘硬件的支持，且不支持异步聚合和容错。

Method: Flotilla采用模块化设计，支持多种同步和异步FL策略，独立于DNN架构，使用无状态客户端和分离会话状态的服务器设计，并具备容错能力。

Result: Flotilla在200+客户端上展示了容错能力，并在边缘设备上资源使用优于或媲美现有框架（Flower、OpenFL、FedML），且能扩展到1000+客户端。

Conclusion: Flotilla是一个高效的FL框架，适合构建新策略、快速部署及系统优化研究。

Abstract: With the recent improvements in mobile and edge computing and rising concerns
of data privacy, Federated Learning(FL) has rapidly gained popularity as a
privacy-preserving, distributed machine learning methodology. Several FL
frameworks have been built for testing novel FL strategies. However, most focus
on validating the learning aspects of FL through pseudo-distributed simulation
but not for deploying on real edge hardware in a distributed manner to
meaningfully evaluate the federated aspects from a systems perspective. Current
frameworks are also inherently not designed to support asynchronous
aggregation, which is gaining popularity, and have limited resilience to client
and server failures. We introduce Flotilla, a scalable and lightweight FL
framework. It adopts a ``user-first'' modular design to help rapidly compose
various synchronous and asynchronous FL strategies while being agnostic to the
DNN architecture. It uses stateless clients and a server design that separates
out the session state, which are periodically or incrementally checkpointed. We
demonstrate the modularity of Flotilla by evaluating five different FL
strategies for training five DNN models. We also evaluate the client and
server-side fault tolerance on 200+ clients, and showcase its ability to
rapidly failover within seconds. Finally, we show that Flotilla's resource
usage on Raspberry Pis and Nvidia Jetson edge accelerators are comparable to or
better than three state-of-the-art FL frameworks, Flower, OpenFL and FedML. It
also scales significantly better compared to Flower for 1000+ clients. This
positions Flotilla as a competitive candidate to build novel FL strategies on,
compare them uniformly, rapidly deploy them, and perform systems research and
optimizations.

</details>


### [6] [Alps, a versatile research infrastructure](https://arxiv.org/abs/2507.02404)
*Maxime Martinasso,Mark Klein,Thomas C. Schulthess*

Main category: cs.DC

TL;DR: CSCS开发了Alps，一种新型高性能计算基础设施，通过独立端点资源和高速网络设计，满足多样化的科学需求。


<details>
  <summary>Details</summary>
Motivation: 传统垂直集成的HPC架构缺乏灵活性和可组合性，无法适应日益多样化的科学需求。

Method: Alps采用异构硬件（CPU和GPU）和高性能Slingshot网络，结合模块化存储系统和软件定义的vCluster技术。

Result: Alps支持多种科学领域，如数值天气预报和AI研究，提供定制化平台。

Conclusion: Alps通过创新的架构和技术，成功解决了传统HPC的局限性，为科学计算提供了更灵活和可扩展的解决方案。

Abstract: The Swiss National Supercomputing Centre (CSCS) has a long-standing tradition
of delivering top-tier high-performance computing systems, exemplified by the
Piz Daint supercomputer. However, the increasing diversity of scientific needs
has exposed limitations in traditional vertically integrated HPC architectures,
which often lack flexibility and composability. To address these challenges,
CSCS developed Alps, a next-generation HPC infrastructure designed with a
transformative principle: resources operate as independent endpoints within a
high-speed network. This architecture enables the creation of independent
tenant-specific and platform-specific services, tailored to diverse scientific
requirements.
  Alps incorporates heterogeneous hardware, including CPUs and GPUs,
interconnected by a high-performance Slingshot network, and offers a modular
storage system. A key innovation is the versatile software-defined cluster
(vCluster) technology, which bridges cloud and HPC paradigms. By abstracting
infrastructure, service management, and user environments into distinct layers,
vClusters allow for customized platforms that support diverse workloads.
Current platforms on Alps serve various scientific domains, including numerical
weather prediction, and AI research.

</details>


### [7] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
*Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang*

Main category: cs.DC

TL;DR: FlowSpec是一个基于流水线并行和树状推测解码的框架，旨在提高边缘网络中大型语言模型（LLM）的分布式推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有流水线方法在边缘网络请求稀疏时利用率低，导致推理延迟减少效果不佳。

Method: FlowSpec采用三种机制：基于分数的逐步验证、高效草稿管理和动态草稿扩展策略。

Result: 实验表明，FlowSpec在多种模型和配置下显著提升推理速度，速度比基线快1.36×-1.77×。

Conclusion: FlowSpec通过优化流水线利用率和推测效率，有效提升了边缘网络中LLM的分布式推理性能。

Abstract: Distributed inference serves as a promising approach to enabling the
inference of large language models (LLMs) at the network edge. It distributes
the inference process to multiple devices to ensure that the LLMs can fit into
the device memory. Recent pipeline-based approaches have the potential to
parallelize communication and computation, which helps reduce inference
latency. However, the benefit diminishes when the inference request at the
network edge is sparse, where pipeline is typically at low utilization. To
enable efficient distributed LLM inference at the edge, we propose
\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding
framework. FlowSpec incorporates three key mechanisms to improve decoding
efficiency: 1) score-based step-wise verification prioritizes more important
draft tokens to bring earlier accpeted tokens; 2) efficient draft management to
prune invalid tokens while maintaining correct causal relationship during
verification; 3) dynamic draft expansion strategies to supply high-quality
speculative inputs. These techniques work in concert to enhance both pipeline
utilization and speculative efficiency. We evaluate FlowSpec on a real-world
testbed with other baselines. Experimental results demonstrate that our
proposed framework significantly improves inference speed across diverse models
and configurations, achieving speedup ratios 1.36$\times$-1.77$\times$ compared
to baselines. Our code is publicly available at
\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\#}

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [8] [Advanced Printed Sensors for Environmental Applications: A Path Towards Sustainable Monitoring Solutions](https://arxiv.org/abs/2507.02067)
*Nikolaos Papanikolaou,Doha Touhafi,Jurgen Vandendriessche,Danial Karimi,Sohail Fatimi,Gianluca Cornetta,Abdellah Touhafi*

Main category: cs.AR

TL;DR: 印刷传感器通过创新印刷技术实现灵活、低成本、高度可定制的传感设备，广泛应用于环境监测等领域。


<details>
  <summary>Details</summary>
Motivation: 推动传感器技术的革新，提供更灵活、经济的解决方案，以满足多样化的环境监测需求。

Method: 采用创新的印刷技术制造传感器，使其具备高灵敏度和准确性。

Result: 传感器能够高效检测污染物、温湿度变化等关键环境参数。

Conclusion: 印刷传感器在环境监测和保护中展现出巨大潜力，是未来传感器技术的重要发展方向。

Abstract: Printed sensors represent a transformative advancement in sensor technology,
utilizing innovative printing techniques to create flexible, cost-effective,
and highly customizable sensing devices. Their versatility allows integration
into numerous applications across diverse fields such as monitoring a wide
range of environmental factors e.g. air and water quality, soil conditions, and
atmospheric changes among others. These sensors demonstrate high sensitivity
and accuracy in detecting pollutants, temperature variations, humidity levels,
and other critical parameters essential for environmental assessment and
protection.

</details>


### [9] [Hardware-Accelerated Algorithm for Complex Function Roots Density Graph Plotting](https://arxiv.org/abs/2507.02164)
*Ruibai Tang,Chengbin Quan*

Main category: cs.AR

TL;DR: 提出了一种基于FPGA硬件加速的算法，用于绘制复函数根的密度图，通过多项式逼近和单位移QR迭代求解根，显著提高了能效。


<details>
  <summary>Details</summary>
Motivation: 复函数根的求解和可视化在理论和应用领域都很重要，但计算成本高，需要更高效的解决方案。

Method: 利用伴随矩阵的Hessenberg结构和Givens旋转优化QR分解，设计了流水线FPGA架构，处理大量多项式。

Result: 相比CPU方法，能效提升高达65倍，但性能仍落后于现代GPU。

Conclusion: 该算法在能效方面表现优异，适合需要高效计算的应用场景。

Abstract: Solving and visualizing the potential roots of complex functions is essential
in both theoretical and applied domains, yet often computationally intensive.
We present a hardware-accelerated algorithm for complex function roots density
graph plotting by approximating functions with polynomials and solving their
roots using single-shift QR iteration. By leveraging the Hessenberg structure
of companion matrices and optimizing QR decomposition with Givens rotations, we
design a pipelined FPGA architecture capable of processing a large amount of
polynomials with high throughput. Our implementation achieves up to 65x higher
energy efficiency than CPU-based approaches, and while it trails modern GPUs in
performance due to differences in fabrication technique.

</details>


### [10] [System-performance and cost modeling of Large Language Model training and inference](https://arxiv.org/abs/2507.02456)
*Wenzhe Guo,Joyjit Kundu,Uras Tos,Weijiang Kong,Giuliano Sisto,Timon Evenblij,Manu Perumkunnil*

Main category: cs.AR

TL;DR: 本文提出了一种针对大型语言模型（LLM）训练和推理的性能-成本建模方法，结合了先进的计算技术、内存优化和通信技术，以解决分布式系统中的可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模和复杂性的指数增长，计算能力、内存带宽、网络性能和成本效率的提升未能跟上，导致分布式系统上的可扩展性问题。

Method: 提出了一种性能-成本建模方法，整合了闪存注意力技术和专家混合模型，并考虑了不同网络拓扑和通信算法的影响。

Result: 该方法能够分析不同系统架构配置的性能-成本权衡，为未来计算系统设计提供指导。

Conclusion: 该建模方法为硬件-软件协同开发提供了有价值的见解，特别是在性能与成本之间的权衡分析方面。

Abstract: Large language models (LLMs), based on transformer architectures, have
revolutionized numerous domains within artificial intelligence, science, and
engineering due to their exceptional scalability and adaptability. However, the
exponential growth in LLM size and complexity has outpaced advancements in
compute capacity, memory bandwidth, network performance, and cost efficiency,
posing significant challenges to their scalability on distributed systems. To
address these limitations, alternative model architectures, optimization
strategies, communication-aware network topologies, and novel system design
approaches have been proposed in literature. This paper introduces a
performance-cost modeling methodology for LLM training and inference that
integrates state-of-the-art compute techniques with memory optimizations, and
latest communication techniques. Building on an analytical performance model,
our approach incorporates recent innovations such as the flash attention
technique and mixture of experts models to address the memory bandwidth and
compute bottlenecks. It also considers the impact of different network
topologies and topology-specific communication algorithms with 5D parallellism.
The framework also integrates a chiplet cost model. The proposed modeling
methodology provides valuable insights to guide future compute system design
and facilitates hardware-software co-development, in particular due to its
ability to analyze performance-cost trade-offs for various system architectural
configurations.

</details>


### [11] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
*Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun*

Main category: cs.AR

TL;DR: AC-Refiner是一种基于条件扩散模型的算术电路优化框架，通过将电路合成重新定义为条件图像生成任务，显著提升设计质量。


<details>
  <summary>Details</summary>
Motivation: 算术电路优化面临设计空间大和物理约束复杂的挑战，现有深度学习方法难以高效探索高潜力设计变体。

Method: 采用条件扩散模型，将电路合成视为条件图像生成任务，并结合目标质量结果（QoR）进行优化。

Result: AC-Refiner生成的电路设计在帕累托最优性上优于现有方法，并在实际应用中验证了性能提升。

Conclusion: AC-Refiner通过扩散模型有效优化算术电路设计，展示了在复杂设计空间中的高效探索能力。

Abstract: Arithmetic circuits, such as adders and multipliers, are fundamental
components of digital systems, directly impacting the performance, power
efficiency, and area footprint. However, optimizing these circuits remains
challenging due to the vast design space and complex physical constraints.
While recent deep learning-based approaches have shown promise, they struggle
to consistently explore high-potential design variants, limiting their
optimization efficiency. To address this challenge, we propose AC-Refiner, a
novel arithmetic circuit optimization framework leveraging conditional
diffusion models. Our key insight is to reframe arithmetic circuit synthesis as
a conditional image generation task. By carefully conditioning the denoising
diffusion process on target quality-of-results (QoRs), AC-Refiner consistently
produces high-quality circuit designs. Furthermore, the explored designs are
used to fine-tune the diffusion model, which focuses the exploration near the
Pareto frontier. Experimental results demonstrate that AC-Refiner generates
designs with superior Pareto optimality, outperforming state-of-the-art
baselines. The performance gain is further validated by integrating AC-Refiner
into practical applications.

</details>


### [12] [Breaking the HBM Bit Cost Barrier: Domain-Specific ECC for AI Inference Infrastructure](https://arxiv.org/abs/2507.02654)
*Rui Xie,Asad Ul Haq,Yunhua Fang,Linsen Ma,Sanchari Sen,Swagath Venkataramani,Liu Liu,Tong Zhang*

Main category: cs.AR

TL;DR: 通过系统级方法降低HBM成本，将故障管理移至内存控制器，结合RS纠错与CRC检测，保持高吞吐和模型精度。


<details>
  <summary>Details</summary>
Motivation: HBM的高成本限制了其在AI中的可扩展部署，需探索降低成本的方案。

Method: 采用域特定ECC框架，结合RS纠错、CRC检测、差分奇偶更新和可调保护。

Result: 在10^-3误码率下，系统保持78%吞吐和97%模型精度。

Conclusion: 将可靠性作为可调参数，为低成本高性能HBM部署提供新路径。

Abstract: High-Bandwidth Memory (HBM) delivers exceptional bandwidth and energy
efficiency for AI workloads, but its high cost per bit, driven in part by
stringent on-die reliability requirements, poses a growing barrier to scalable
deployment. This work explores a system-level approach to cost reduction by
eliminating on-die ECC and shifting all fault management to the memory
controller. We introduce a domain-specific ECC framework combining
large-codeword Reed--Solomon~(RS) correction with lightweight fine-grained CRC
detection, differential parity updates to mitigate write amplification, and
tunable protection based on data importance. Our evaluation using LLM inference
workloads shows that, even under raw HBM bit error rates up to $10^{-3}$, the
system retains over 78\% of throughput and 97\% of model accuracy compared with
systems equipped with ideal error-free HBM. By treating reliability as a
tunable system parameter rather than a fixed hardware constraint, our design
opens a new path toward low-cost, high-performance HBM deployment in AI
infrastructure.

</details>
