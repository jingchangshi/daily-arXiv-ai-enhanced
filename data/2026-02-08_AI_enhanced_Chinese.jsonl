{"id": "2602.04892", "categories": ["cs.PL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04892", "abs": "https://arxiv.org/abs/2602.04892", "authors": ["Shihao Xia", "Mengting He", "Haomin Jia", "Linhai Song"], "title": "Doc2Spec: Synthesizing Formal Programming Specifications from Natural Language via Grammar Induction", "comment": null, "summary": "Ensuring that API implementations and usage comply with natural language programming rules is critical for software correctness, security, and reliability. Formal verification can provide strong guarantees but requires precise specifications, which are difficult and costly to write manually. To address this challenge, we present Doc2Spec, a multi-agent framework that uses LLMs to automatically induce a specification grammar from natural-language rules and then generates formal specifications guided by the induced grammar. The grammar captures essential domain knowledge, constrains the specification space, and enforces consistent representations, thereby improving the reliability and quality of generated specifications. Evaluated on seven benchmarks across three programming languages, Doc2Spec outperforms a baseline without grammar induction and achieves competitive results against a technique with a manually crafted grammar, demonstrating the effectiveness of automated grammar induction for formalizing natural-language rules.", "AI": {"tldr": "Doc2Spec\uff1a\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548cLLM\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u81ea\u52a8\u63a8\u5bfc\u89c4\u8303\u8bed\u6cd5\uff0c\u7136\u540e\u751f\u6210\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u63d0\u9ad8API\u5b9e\u73b0\u548c\u4f7f\u7528\u7684\u5408\u89c4\u6027\u9a8c\u8bc1\u6548\u7387\u3002", "motivation": "\u786e\u4fddAPI\u5b9e\u73b0\u548c\u4f7f\u7528\u7b26\u5408\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u89c4\u5219\u5bf9\u8f6f\u4ef6\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u63d0\u4f9b\u5f3a\u4fdd\u8bc1\u4f46\u9700\u8981\u7cbe\u786e\u89c4\u8303\uff0c\u800c\u624b\u52a8\u7f16\u5199\u89c4\u8303\u65e2\u56f0\u96be\u53c8\u6602\u8d35\u3002", "method": "\u63d0\u51faDoc2Spec\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4f7f\u7528LLM\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u81ea\u52a8\u63a8\u5bfc\u89c4\u8303\u8bed\u6cd5\uff0c\u7136\u540e\u57fa\u4e8e\u63a8\u5bfc\u51fa\u7684\u8bed\u6cd5\u751f\u6210\u5f62\u5f0f\u5316\u89c4\u8303\u3002\u8bed\u6cd5\u6355\u83b7\u5173\u952e\u9886\u57df\u77e5\u8bc6\uff0c\u7ea6\u675f\u89c4\u8303\u7a7a\u95f4\uff0c\u5e76\u786e\u4fdd\u8868\u793a\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e09\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\uff0cDoc2Spec\u4f18\u4e8e\u65e0\u8bed\u6cd5\u63a8\u5bfc\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4f7f\u7528\u624b\u52a8\u6784\u5efa\u8bed\u6cd5\u7684\u6280\u672f\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u8bed\u6cd5\u63a8\u5bfc\u5728\u5f62\u5f0f\u5316\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "Doc2Spec\u901a\u8fc7\u81ea\u52a8\u63a8\u5bfc\u89c4\u8303\u8bed\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u751f\u6210\u8d28\u91cf\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u89e3\u51b3\u624b\u52a8\u7f16\u5199\u89c4\u8303\u7684\u6210\u672c\u548c\u96be\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.05528", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.05528", "abs": "https://arxiv.org/abs/2602.05528", "authors": ["Danel Ahman", "Ilja Sobolev"], "title": "Strong Normalisation for Asynchronous Effects", "comment": "FSCD 2026 submission", "summary": "Asynchronous effects of Ahman and Pretnar complement the conventional synchronous treatment of algebraic computational effects with asynchrony based on decoupling the execution of algebraic operation calls into signalling that an operation's implementation needs to be executed, and into interrupting a running computation with the operation's result, to which the computation can react by installing matching interrupt handlers. Beyond providing asynchrony for algebraic effects, the resulting core calculus also naturally models examples such as pre-emptive multi-threading, (cancellable) remote function calls, multi-party applications, and even a parallel variant of runners of algebraic effects. In this paper, we study the normalisation properties of this calculus. We prove that if one removes general recursion from the original calculus, then the remaining calculus is strongly normalising, including both its sequential and parallel parts. However, this only guarantees termination for very simple asynchronous examples. To improve on this result, we also prove that the sequential fragment of the calculus remains strongly normalising when a controlled amount of interrupt-driven recursive behaviour is reintroduced. Our strong normalisation proofs are structured compositionally as a natural extension of Lindley and Stark's $\\top\\top$-lifting based approach for proving strong normalisation of effectful languages. All our results are also formalised in Agda.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Ahman\u548cPretnar\u63d0\u51fa\u7684\u5f02\u6b65\u6548\u5e94\u6f14\u7b97\u7684\u89c4\u8303\u5316\u6027\u8d28\uff0c\u8bc1\u660e\u4e86\u79fb\u9664\u4e00\u822c\u9012\u5f52\u540e\u6574\u4e2a\u6f14\u7b97\uff08\u5305\u62ec\u987a\u5e8f\u548c\u5e76\u884c\u90e8\u5206\uff09\u662f\u5f3a\u89c4\u8303\u5316\u7684\uff0c\u5e76\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5728\u91cd\u65b0\u5f15\u5165\u53d7\u63a7\u7684\u4e2d\u65ad\u9a71\u52a8\u9012\u5f52\u884c\u4e3a\u540e\uff0c\u987a\u5e8f\u7247\u6bb5\u4ecd\u4fdd\u6301\u5f3a\u89c4\u8303\u5316\u3002", "motivation": "Ahman\u548cPretnar\u7684\u5f02\u6b65\u6548\u5e94\u6f14\u7b97\u6269\u5c55\u4e86\u4f20\u7edf\u7684\u540c\u6b65\u4ee3\u6570\u8ba1\u7b97\u6548\u5e94\uff0c\u4e3a\u4ee3\u6570\u64cd\u4f5c\u8c03\u7528\u63d0\u4f9b\u4e86\u5f02\u6b65\u5904\u7406\u80fd\u529b\uff0c\u80fd\u591f\u81ea\u7136\u5efa\u6a21\u62a2\u5360\u5f0f\u591a\u7ebf\u7a0b\u3001\u53ef\u53d6\u6d88\u8fdc\u7a0b\u51fd\u6570\u8c03\u7528\u3001\u591a\u65b9\u5e94\u7528\u7b49\u573a\u666f\u3002\u7136\u800c\uff0c\u539f\u6f14\u7b97\u5305\u542b\u4e00\u822c\u9012\u5f52\uff0c\u5176\u89c4\u8303\u5316\u6027\u8d28\u5c1a\u672a\u5f97\u5230\u7814\u7a76\u3002", "method": "\u91c7\u7528Lindley\u548cStark\u57fa\u4e8e\u22a4\u22a4\u63d0\u5347\u7684\u65b9\u6cd5\u6765\u8bc1\u660e\u5f3a\u89c4\u8303\u5316\u6027\u8d28\uff0c\u9996\u5148\u8bc1\u660e\u79fb\u9664\u4e00\u822c\u9012\u5f52\u540e\u6574\u4e2a\u6f14\u7b97\u7684\u5f3a\u89c4\u8303\u5316\uff0c\u7136\u540e\u8bc1\u660e\u5728\u987a\u5e8f\u7247\u6bb5\u4e2d\u91cd\u65b0\u5f15\u5165\u53d7\u63a7\u7684\u4e2d\u65ad\u9a71\u52a8\u9012\u5f52\u884c\u4e3a\u540e\u4ecd\u4fdd\u6301\u5f3a\u89c4\u8303\u5316\u3002\u6240\u6709\u8bc1\u660e\u90fd\u5728Agda\u4e2d\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "1. \u79fb\u9664\u4e00\u822c\u9012\u5f52\u540e\uff0c\u6574\u4e2a\u5f02\u6b65\u6548\u5e94\u6f14\u7b97\uff08\u5305\u62ec\u987a\u5e8f\u548c\u5e76\u884c\u90e8\u5206\uff09\u662f\u5f3a\u89c4\u8303\u5316\u7684\uff1b2. \u5728\u987a\u5e8f\u7247\u6bb5\u4e2d\u91cd\u65b0\u5f15\u5165\u53d7\u63a7\u7684\u4e2d\u65ad\u9a71\u52a8\u9012\u5f52\u884c\u4e3a\u540e\uff0c\u8be5\u7247\u6bb5\u4ecd\u4fdd\u6301\u5f3a\u89c4\u8303\u5316\uff1b3. \u6240\u6709\u7ed3\u679c\u90fd\u5728Agda\u4e2d\u5f97\u5230\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f02\u6b65\u6548\u5e94\u6f14\u7b97\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c4\u8303\u5316\u4fdd\u8bc1\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u9650\u5236\u9012\u5f52\u884c\u4e3a\u7684\u60c5\u51b5\u4e0b\uff0c\u5f02\u6b65\u6548\u5e94\u6f14\u7b97\u53ef\u4ee5\u4fdd\u6301\u5f3a\u89c4\u8303\u5316\u6027\u8d28\uff0c\u8fd9\u4e3a\u5f02\u6b65\u6548\u5e94\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u9884\u6d4b\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.05850", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.05850", "abs": "https://arxiv.org/abs/2602.05850", "authors": ["Ohad Kammar", "Jack Liell-Cock", "Sam Lindley", "Cristina Matache", "Sam Staton"], "title": "An Equational Axiomatization of Dynamic Threads via Algebraic Effects: Presheaves on Finite Relations, Labelled Posets, and Parameterized Algebraic Theories", "comment": "Published at POPL 2026", "summary": "We use the theory of algebraic effects to give a complete equational axiomatization for dynamic threads. Our method is based on parameterized algebraic theories, which give a concrete syntax for strong monads on functor categories, and are a convenient framework for names and binding. Our programs are built from the key primitives `fork' and `wait'. `Fork' creates a child thread and passes its name (thread ID) to the parent thread. `Wait' allows us to wait for given child threads to finish. We provide a parameterized algebraic theory built from fork and wait, together with basic atomic actions and laws such as associativity of `fork'. Our equational axiomatization is complete in two senses. First, for closed expressions, it completely captures equality of labelled posets (pomsets), an established model of concurrency: model complete. Second, any two open expressions are provably equal if they are equal under all closing substitutions: syntactically complete. The benefit of algebraic effects is that the semantic analysis can focus on the algebraic operations of fork and wait. We then extend the analysis to a simple concurrent programming language by giving operational and denotational semantics. The denotational semantics is built using the methods of parameterized algebraic theories and we show that it is sound, adequate, and fully abstract at first order for labelled-poset observations.", "AI": {"tldr": "\u4f7f\u7528\u4ee3\u6570\u6548\u5e94\u7406\u8bba\u4e3a\u52a8\u6001\u7ebf\u7a0b\u63d0\u4f9b\u5b8c\u6574\u7684\u7b49\u5f0f\u516c\u7406\u5316\uff0c\u57fa\u4e8e\u53c2\u6570\u5316\u4ee3\u6570\u7406\u8bba\uff0c\u4ee5fork\u548cwait\u4e3a\u57fa\u672c\u539f\u8bed\uff0c\u5b9e\u73b0\u6a21\u578b\u5b8c\u5907\u6027\u548c\u8bed\u6cd5\u5b8c\u5907\u6027\u3002", "motivation": "\u4e3a\u52a8\u6001\u7ebf\u7a0b\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u7b49\u5f0f\u516c\u7406\u5316\uff0c\u4f7f\u7528\u4ee3\u6570\u6548\u5e94\u7406\u8bba\u6765\u7b80\u5316\u5e76\u53d1\u7a0b\u5e8f\u7684\u8bed\u4e49\u5206\u6790\uff0c\u4e13\u6ce8\u4e8efork\u548cwait\u7b49\u4ee3\u6570\u64cd\u4f5c\u3002", "method": "\u57fa\u4e8e\u53c2\u6570\u5316\u4ee3\u6570\u7406\u8bba\uff0c\u6784\u5efa\u4ee5fork\u548cwait\u4e3a\u57fa\u672c\u539f\u8bed\u7684\u4ee3\u6570\u7406\u8bba\uff0c\u5305\u542b\u57fa\u672c\u539f\u5b50\u64cd\u4f5c\u548c\u7ed3\u5408\u5f8b\u7b49\u5b9a\u5f8b\uff0c\u4e3a\u5e76\u53d1\u7f16\u7a0b\u8bed\u8a00\u63d0\u4f9b\u64cd\u4f5c\u8bed\u4e49\u548c\u6307\u79f0\u8bed\u4e49\u3002", "result": "\u5b9e\u73b0\u4e86\u4e24\u4e2a\u5b8c\u5907\u6027\uff1a1) \u6a21\u578b\u5b8c\u5907\u6027\uff1a\u95ed\u8868\u8fbe\u5f0f\u5b8c\u5168\u6355\u83b7\u6807\u8bb0\u504f\u5e8f\u96c6(pomsets)\u7684\u76f8\u7b49\u6027\uff1b2) \u8bed\u6cd5\u5b8c\u5907\u6027\uff1a\u5f00\u8868\u8fbe\u5f0f\u5728\u6240\u6709\u95ed\u5316\u66ff\u6362\u4e0b\u76f8\u7b49\u65f6\u53ef\u8bc1\u660e\u76f8\u7b49\u3002\u6307\u79f0\u8bed\u4e49\u5728\u6807\u8bb0\u504f\u5e8f\u96c6\u89c2\u5bdf\u4e0b\u662f\u5065\u5168\u3001\u5145\u5206\u4e14\u4e00\u9636\u5b8c\u5168\u62bd\u8c61\u7684\u3002", "conclusion": "\u4ee3\u6570\u6548\u5e94\u7406\u8bba\u4e3a\u52a8\u6001\u7ebf\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b49\u5f0f\u516c\u7406\u5316\u6846\u67b6\uff0c\u53c2\u6570\u5316\u4ee3\u6570\u7406\u8bba\u662f\u5904\u7406\u540d\u79f0\u548c\u7ed1\u5b9a\u7684\u4fbf\u6377\u5de5\u5177\uff0c\u80fd\u591f\u4e3a\u5e76\u53d1\u7f16\u7a0b\u8bed\u8a00\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u8bed\u4e49\u57fa\u7840\u3002"}}
{"id": "2602.04991", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04991", "abs": "https://arxiv.org/abs/2602.04991", "authors": ["Simone Manoni", "Emanuele Parisi", "Riccardo Tedeschi", "Davide Rossi", "Andrea Acquaviva", "Andrea Bartolini"], "title": "CVA6-CFI: A First Glance at RISC-V Control-Flow Integrity Extensions", "comment": "Accepted as a lecture at the 2026 IEEE International Symposium on Circuits and Systems. Preprint version", "summary": "This work presents the first design, integration, and evaluation of the standard RISC-V extensions for Control-Flow Integrity (CFI). The Zicfiss and Zicfilp extensions aim at protecting the execution of a vulnerable program from control-flow hijacking attacks through the implementation of security mechanisms based on shadow stack and landing pad primitives. We introduce two independent and configurable hardware units implementing forward-edge and backward-edge control-flow protection, fully integrated into the open-source CVA6 core. Our design incurs in only 1.0% area overhead when synthesized in 22 nm FDX technology, and up to 15.6% performance overhead based on evaluation with the MiBench automotive benchmark subset. We release the complete implementation as open source.", "AI": {"tldr": "\u9996\u6b21\u8bbe\u8ba1\u3001\u96c6\u6210\u5e76\u8bc4\u4f30\u4e86RISC-V\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u6269\u5c55\u6807\u51c6Zicfiss\u548cZicfilp\uff0c\u901a\u8fc7\u786c\u4ef6\u5b9e\u73b0\u5f71\u5b50\u6808\u548c\u7740\u9646\u57ab\u673a\u5236\u4fdd\u62a4\u7a0b\u5e8f\u514d\u53d7\u63a7\u5236\u6d41\u52ab\u6301\u653b\u51fb\uff0c\u5728CVA6\u6838\u5fc3\u4e2d\u96c6\u6210\u4ec5\u5e26\u67651.0%\u9762\u79ef\u5f00\u9500\u548c\u6700\u9ad815.6%\u6027\u80fd\u5f00\u9500\u3002", "motivation": "\u4fdd\u62a4\u6613\u53d7\u653b\u51fb\u7a0b\u5e8f\u514d\u53d7\u63a7\u5236\u6d41\u52ab\u6301\u653b\u51fb\uff0c\u901a\u8fc7\u786c\u4ef6\u5b9e\u73b0\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u673a\u5236\uff0c\u4e3aRISC-V\u67b6\u6784\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u5b89\u5168\u6269\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u72ec\u7acb\u53ef\u914d\u7f6e\u7684\u786c\u4ef6\u5355\u5143\uff1aZicfiss\uff08\u5f71\u5b50\u6808\uff09\u7528\u4e8e\u540e\u5411\u8fb9\u4fdd\u62a4\uff0cZicfilp\uff08\u7740\u9646\u57ab\uff09\u7528\u4e8e\u524d\u5411\u8fb9\u4fdd\u62a4\uff0c\u5b8c\u5168\u96c6\u6210\u5230\u5f00\u6e90CVA6\u6838\u5fc3\u4e2d\u3002", "result": "\u572822nm FDX\u5de5\u827a\u4e0b\u4ec5\u589e\u52a01.0%\u7684\u9762\u79ef\u5f00\u9500\uff0c\u4f7f\u7528MiBench\u6c7d\u8f66\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u8bc4\u4f30\u663e\u793a\u6700\u9ad815.6%\u7684\u6027\u80fd\u5f00\u9500\uff0c\u5b8c\u6574\u5b9e\u73b0\u5df2\u5f00\u6e90\u3002", "conclusion": "\u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2aRISC-V\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u6269\u5c55\u6807\u51c6\uff0c\u4ee5\u8f83\u5c0f\u7684\u786c\u4ef6\u5f00\u9500\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a7\u5236\u6d41\u4fdd\u62a4\uff0c\u4e3aRISC-V\u751f\u6001\u7cfb\u7edf\u8d21\u732e\u4e86\u91cd\u8981\u7684\u5b89\u5168\u589e\u5f3a\u3002"}}
{"id": "2602.05017", "categories": ["cs.DC", "q-bio.CB"], "pdf": "https://arxiv.org/pdf/2602.05017", "abs": "https://arxiv.org/abs/2602.05017", "authors": ["Jose-Luis Estragues-Mu\u00f1oz", "Carlos Alvarez", "Arnau Montagud", "Daniel Jimenez-Gonzalez", "Alfonso Valencia"], "title": "A novel scalable high performance diffusion solver for multiscale cell simulations", "comment": "14 pages, 9 figures", "summary": "Agent-based cellular models simulate tissue evolution by capturing the behavior of individual cells, their interactions with neighboring cells, and their responses to the surrounding microenvironment. An important challenge in the field is scaling cellular resolution models to real-scale tumor simulations, which is critical for the development of digital twin models of diseases and requires the use of High-Performance Computing (HPC) since every time step involves trillions of operations. We hereby present a scalable HPC solution for the molecular diffusion modeling using an efficient implementation of state-of-the-art Finite Volume Method (FVM) frameworks. The paper systematically evaluates a novel scalable Biological Finite Volume Method (BioFVM) library and presents an extensive performance analysis of the available solutions. Results shows that our HPC proposal reach almost 200x speedup and up to 36% reduction in memory usage over the current state-of-the-art solutions, paving the way to efficiently compute the next generation of biological problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848BioFVM\uff0c\u7528\u4e8e\u5206\u5b50\u6269\u6563\u5efa\u6a21\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8fd1200\u500d\u52a0\u901f\u548c36%\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002", "motivation": "\u57fa\u4e8e\u4ee3\u7406\u7684\u7ec6\u80de\u6a21\u578b\u5728\u6a21\u62df\u7ec4\u7ec7\u6f14\u5316\u65f6\u9700\u8981\u5904\u7406\u4e2a\u4f53\u7ec6\u80de\u884c\u4e3a\u3001\u7ec6\u80de\u95f4\u76f8\u4e92\u4f5c\u7528\u548c\u5fae\u73af\u5883\u54cd\u5e94\u3002\u5c06\u7ec6\u80de\u5206\u8fa8\u7387\u6a21\u578b\u6269\u5c55\u5230\u771f\u5b9e\u89c4\u6a21\u7684\u80bf\u7624\u6a21\u62df\u662f\u6570\u5b57\u5b6a\u751f\u75be\u75c5\u6a21\u578b\u53d1\u5c55\u7684\u5173\u952e\u6311\u6218\uff0c\u8fd9\u9700\u8981\u9ad8\u6027\u80fd\u8ba1\u7b97\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6d89\u53ca\u6570\u4e07\u4ebf\u6b21\u64cd\u4f5c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u91c7\u7528\u6709\u9650\u4f53\u79ef\u6cd5\u6846\u67b6\u7684\u9ad8\u6548\u5b9e\u73b0\uff0c\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u65b0\u578b\u53ef\u6269\u5c55\u751f\u7269\u6709\u9650\u4f53\u79ef\u6cd5\u5e93BioFVM\uff0c\u5e76\u5bf9\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6027\u80fd\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u65b9\u6848\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e86\u8fd1200\u500d\u7684\u52a0\u901f\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u4e86\u9ad8\u8fbe36%\uff0c\u4e3a\u9ad8\u6548\u8ba1\u7b97\u4e0b\u4e00\u4ee3\u751f\u7269\u95ee\u9898\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "BioFVM\u5e93\u4e3a\u5927\u89c4\u6a21\u751f\u7269\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6027\u80fd\u548c\u5185\u5b58\u6548\u7387\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u6570\u5b57\u5b6a\u751f\u75be\u75c5\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.05018", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.05018", "abs": "https://arxiv.org/abs/2602.05018", "authors": ["Hongbang Wu", "Xuesi Chen", "Shubham Jadhav", "Amit Lal", "Lillian Pentecost", "Udit Gupta"], "title": "COFFEE: A Carbon-Modeling and Optimization Framework for HZO-based FeFET eNVMs", "comment": null, "summary": "Information and communication technologies account for a growing portion of global environmental impacts. While emerging technologies, such as emerging non-volatile memories (eNVM), offer a promising solution to energy efficient computing, their end-to-end footprint is not well understood. Understanding the environmental impact of hardware systems over their life cycle is the first step to realizing sustainable computing. This work conducts a detailed study of one example eNVM device: hafnium-zirconium-oxide (HZO)-based ferroelectric field-effect transistors (FeFETs). We present COFFEE, the first carbon modeling framework for HZO-based FeFET eNVMs across life cycle, from hardware manufacturing (embodied carbon) to use (operational carbon). COFFEE builds on data gathered from a real semiconductor fab and device fabrication recipes to estimate embodied carbon, and architecture level eNVM design space exploration tools to quantify use-phase performance and energy. Our evaluation shows that, at 2 MB capacity, the embodied carbon per unit area overhead of HZO-FeFETs can be up to 11% higher than the CMOS baseline, while the embodied carbon per MB remains consistently about 4.3x lower than SRAM across different memory capacity. A further case study applies COFFEE to an edge ML accelerator, showing that replacing the SRAM-based weight buffer with HZO-based FeFET eNVMs reduces embodied carbon by 42.3% and operational carbon by up to 70%.", "AI": {"tldr": "COFFEE\u662f\u9996\u4e2a\u9488\u5bf9HZO\u57faFeFET eNVM\u7684\u78b3\u5efa\u6a21\u6846\u67b6\uff0c\u6db5\u76d6\u786c\u4ef6\u5236\u9020\uff08\u4f53\u73b0\u78b3\uff09\u5230\u4f7f\u7528\u9636\u6bb5\uff08\u8fd0\u8425\u78b3\uff09\u7684\u5168\u751f\u547d\u5468\u671f\u5206\u6790\uff0c\u663e\u793a\u76f8\u6bd4SRAM\u53ef\u663e\u8457\u964d\u4f4e\u78b3\u8db3\u8ff9\u3002", "motivation": "\u4fe1\u606f\u548c\u901a\u4fe1\u6280\u672f\u5bf9\u5168\u7403\u73af\u5883\u5f71\u54cd\u65e5\u76ca\u589e\u957f\uff0c\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\uff08eNVM\uff09\u867d\u80fd\u63d0\u9ad8\u80fd\u6548\uff0c\u4f46\u5176\u7aef\u5230\u7aef\u78b3\u8db3\u8ff9\u5c1a\u4e0d\u660e\u786e\u3002\u7406\u89e3\u786c\u4ef6\u7cfb\u7edf\u5168\u751f\u547d\u5468\u671f\u73af\u5883\u5f71\u54cd\u662f\u5b9e\u73b0\u53ef\u6301\u7eed\u8ba1\u7b97\u7684\u7b2c\u4e00\u6b65\u3002", "method": "\u63d0\u51faCOFFEE\u6846\u67b6\uff0c\u57fa\u4e8e\u771f\u5b9e\u534a\u5bfc\u4f53\u5de5\u5382\u6570\u636e\u548c\u5668\u4ef6\u5236\u9020\u5de5\u827a\u4f30\u7b97\u4f53\u73b0\u78b3\uff0c\u5229\u7528\u67b6\u6784\u7ea7eNVM\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u5de5\u5177\u91cf\u5316\u4f7f\u7528\u9636\u6bb5\u6027\u80fd\u548c\u80fd\u8017\uff0c\u4ee5HZO\u57faFeFET\u4e3a\u4f8b\u8fdb\u884c\u8be6\u7ec6\u7814\u7a76\u3002", "result": "2MB\u5bb9\u91cf\u4e0b\uff0cHZO-FeFET\u7684\u5355\u4f4d\u9762\u79ef\u4f53\u73b0\u78b3\u6bd4CMOS\u57fa\u7ebf\u9ad811%\uff0c\u4f46\u6bcfMB\u4f53\u73b0\u78b3\u59cb\u7ec8\u6bd4SRAM\u4f4e4.3\u500d\u3002\u8fb9\u7f18ML\u52a0\u901f\u5668\u6848\u4f8b\u4e2d\uff0c\u7528HZO-FeFET eNVM\u66ff\u6362SRAM\u6743\u91cd\u7f13\u51b2\u5668\uff0c\u4f53\u73b0\u78b3\u51cf\u5c1142.3%\uff0c\u8fd0\u8425\u78b3\u6700\u591a\u51cf\u5c1170%\u3002", "conclusion": "COFFEE\u6846\u67b6\u4e3aeNVM\u78b3\u8db3\u8ff9\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u8bc1\u660eHZO\u57faFeFET eNVM\u5728\u964d\u4f4e\u78b3\u8db3\u8ff9\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u53ef\u6301\u7eed\u8ba1\u7b97\u53d1\u5c55\u3002"}}
{"id": "2602.05131", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05131", "abs": "https://arxiv.org/abs/2602.05131", "authors": ["Irene Bonati", "Silvina Caino-Lores", "Tain\u00e3 Coleman", "Sagar Dolas", "Sandro Fiore", "Venkatesh Kannan", "Marco Verdicchio", "Sean R. Wilkinson", "Rafael Ferreira da Silva"], "title": "Towards Advancing Research with Workflows: A perspective from the Workflows Community Summit -- Amsterdam, 2025", "comment": null, "summary": "Scientific workflows have become essential for orchestrating complex computational processes across distributed resources, managing large datasets, and ensuring reproducibility in modern research. The Workflows Community Summit 2025, held in Amsterdam on June 6th, 2025, convened international experts to examine emerging challenges and opportunities in this domain. Participants identified key barriers to workflow adoption, including tensions between system generality and domain-specific utility, concerns over long-term sustainability of workflow systems and services, insufficient recognition for those who develop and maintain reproducible workflows, and gaps in standardization, funding, training, and cross-disciplinary collaboration. To address these challenges, the summit proposed action lines spanning technology, policy, and community dimensions: shifting evaluation metrics from raw computational performance toward measuring genuine scientific impact; formalizing workflow patterns and community-driven benchmarks to improve transparency, reproducibility, and usability; cultivating a cohesive international workflows community that engages funding bodies and research stakeholders; and investing in human capital through dedicated workflow engineering roles, career pathways, and integration of workflow concepts into educational curricula and long-term training initiatives. This document presents the summit's findings, beginning with an overview of the current computing ecosystem and the rationale for workflow-centric approaches, followed by a discussion of identified challenges and recommended action lines for advancing scientific discovery through workflows.", "AI": {"tldr": "2025\u5e74\u79d1\u5b66\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\u8bc6\u522b\u4e86\u5de5\u4f5c\u6d41\u91c7\u7528\u7684\u5173\u952e\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u6280\u672f\u3001\u653f\u7b56\u548c\u793e\u533a\u5c42\u9762\u7684\u884c\u52a8\u65b9\u6848\uff0c\u4ee5\u63a8\u52a8\u5de5\u4f5c\u6d41\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u79d1\u5b66\u5de5\u4f5c\u6d41\u5728\u73b0\u4ee3\u7814\u7a76\u4e2d\u5bf9\u4e8e\u534f\u8c03\u5206\u5e03\u5f0f\u8ba1\u7b97\u3001\u7ba1\u7406\u5927\u6570\u636e\u548c\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u91c7\u7528\u969c\u788d\u30022025\u5e74\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\u65e8\u5728\u8bc6\u522b\u8fd9\u4e9b\u6311\u6218\u5e76\u5236\u5b9a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc72025\u5e746\u67086\u65e5\u5728\u963f\u59c6\u65af\u7279\u4e39\u4e3e\u884c\u7684\u56fd\u9645\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\uff0c\u6c47\u96c6\u4e13\u5bb6\u8ba8\u8bba\u65b0\u5174\u6311\u6218\u548c\u673a\u9047\uff0c\u8bc6\u522b\u5173\u952e\u969c\u788d\u5e76\u63d0\u51fa\u884c\u52a8\u65b9\u6848\u3002", "result": "\u8bc6\u522b\u4e86\u56db\u5927\u5173\u952e\u969c\u788d\uff1a\u7cfb\u7edf\u901a\u7528\u6027\u4e0e\u9886\u57df\u7279\u5b9a\u6027\u4e4b\u95f4\u7684\u5f20\u529b\u3001\u5de5\u4f5c\u6d41\u7cfb\u7edf\u957f\u671f\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3001\u5de5\u4f5c\u6d41\u5f00\u53d1\u8005\u7f3a\u4e4f\u8ba4\u53ef\u3001\u6807\u51c6\u5316/\u8d44\u91d1/\u57f9\u8bad/\u8de8\u5b66\u79d1\u5408\u4f5c\u4e0d\u8db3\u3002\u63d0\u51fa\u4e86\u6280\u672f\u3001\u653f\u7b56\u548c\u793e\u533a\u5c42\u9762\u7684\u884c\u52a8\u65b9\u6848\u3002", "conclusion": "\u9700\u8981\u4ece\u5355\u7eaf\u8ba1\u7b97\u6027\u80fd\u8bc4\u4f30\u8f6c\u5411\u79d1\u5b66\u5f71\u54cd\u529b\u8861\u91cf\uff0c\u5efa\u7acb\u6b63\u5f0f\u5de5\u4f5c\u6d41\u6a21\u5f0f\u548c\u793e\u533a\u57fa\u51c6\uff0c\u57f9\u517b\u56fd\u9645\u5de5\u4f5c\u6d41\u793e\u533a\uff0c\u6295\u8d44\u4eba\u529b\u8d44\u672c\uff0c\u4ee5\u901a\u8fc7\u5de5\u4f5c\u6d41\u63a8\u52a8\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2602.05743", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.05743", "abs": "https://arxiv.org/abs/2602.05743", "authors": ["Liang Zhao", "Kunming Shao", "Zhipeng Liao", "Xijie Huang", "Tim Kwang-Ting Cheng", "Chi-Ying Tsui", "Yi Zou"], "title": "Balancing FP8 Computation Accuracy and Efficiency on Digital CIM via Shift-Aware On-the-fly Aligned-Mantissa Bitwidth Prediction", "comment": "This paper is under review by IEEE Transactions On Very Large Scale Integration Systems (TVLSI-00144-2026)", "summary": "FP8 low-precision formats have gained significant adoption in Transformer inference and training. However, existing digital compute-in-memory (DCIM) architectures face challenges in supporting variable FP8 aligned-mantissa bitwidths, as unified alignment strategies and fixed-precision multiply-accumulate (MAC) units struggle to handle input data with diverse distributions. This work presents a flexible FP8 DCIM accelerator with three innovations: (1) a dynamic shift-aware bitwidth prediction (DSBP) with on-the-fly input prediction that adaptively adjusts weight (2/4/6/8b) and input (2$\\sim$12b) aligned-mantissa precision; (2) a FIFO-based input alignment unit (FIAU) replacing complex barrel shifters with pointer-based control; and (3) a precision-scalable INT MAC array achieving flexible weight precision with minimal overhead. Implemented in 28nm CMOS with a 64$\\times$96 CIM array, the design achieves 20.4 TFLOPS/W for fixed E5M7, demonstrating 2.8$\\times$ higher FP8 efficiency than previous work while supporting all FP8 formats. Results on Llama-7b show that the DSBP achieves higher efficiency than fixed bitwidth mode at the same accuracy level on both BoolQ and Winogrande datasets, with configurable parameters enabling flexible accuracy-efficiency trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7075\u6d3b\u7684FP8\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u52a8\u6001\u4f4d\u5bbd\u9884\u6d4b\u3001FIFO\u5bf9\u9f50\u5355\u5143\u548c\u53ef\u6269\u5c55INT MAC\u9635\u5217\uff0c\u652f\u6301\u6240\u6709FP8\u683c\u5f0f\uff0c\u572828nm\u5de5\u827a\u4e0b\u5b9e\u73b020.4 TFLOPS/W\u80fd\u6548\uff0c\u6bd4\u73b0\u6709\u5de5\u4f5c\u9ad82.8\u500d\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\u96be\u4ee5\u652f\u6301\u53ef\u53d8FP8\u5bf9\u9f50\u5c3e\u6570\u4f4d\u5bbd\uff0c\u7edf\u4e00\u5bf9\u9f50\u7b56\u7565\u548c\u56fa\u5b9a\u7cbe\u5ea6\u4e58\u7d2f\u52a0\u5355\u5143\u65e0\u6cd5\u5904\u7406\u5206\u5e03\u591a\u6837\u7684\u8f93\u5165\u6570\u636e\uff0c\u9650\u5236\u4e86FP8\u683c\u5f0f\u5728Transformer\u63a8\u7406\u548c\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u3002", "method": "1) \u52a8\u6001\u79fb\u4f4d\u611f\u77e5\u4f4d\u5bbd\u9884\u6d4b(DSBP)\uff1a\u5728\u7ebf\u9884\u6d4b\u8f93\u5165\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u6743\u91cd(2/4/6/8b)\u548c\u8f93\u5165(2~12b)\u5bf9\u9f50\u5c3e\u6570\u7cbe\u5ea6\uff1b2) FIFO\u8f93\u5165\u5bf9\u9f50\u5355\u5143(FIAU)\uff1a\u7528\u57fa\u4e8e\u6307\u9488\u7684\u63a7\u5236\u66ff\u4ee3\u590d\u6742\u6876\u5f62\u79fb\u4f4d\u5668\uff1b3) \u7cbe\u5ea6\u53ef\u6269\u5c55INT MAC\u9635\u5217\uff1a\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\u7075\u6d3b\u6743\u91cd\u7cbe\u5ea6\u3002", "result": "28nm CMOS\u5de5\u827a\u4e0b\u5b9e\u73b064\u00d796\u5b58\u5185\u8ba1\u7b97\u9635\u5217\uff0c\u56fa\u5b9aE5M7\u683c\u5f0f\u8fbe\u523020.4 TFLOPS/W\u80fd\u6548\uff0cFP8\u6548\u7387\u6bd4\u5148\u524d\u5de5\u4f5c\u9ad82.8\u500d\uff0c\u652f\u6301\u6240\u6709FP8\u683c\u5f0f\u3002\u5728Llama-7b\u6a21\u578b\u4e0a\uff0cDSBP\u5728BoolQ\u548cWinogrande\u6570\u636e\u96c6\u4e0a\u6bd4\u56fa\u5b9a\u4f4d\u5bbd\u6a21\u5f0f\u5728\u76f8\u540c\u7cbe\u5ea6\u6c34\u5e73\u4e0b\u83b7\u5f97\u66f4\u9ad8\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u7075\u6d3bFP8\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u52a0\u901f\u5668\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u6001\u4f4d\u5bbd\u9884\u6d4b\u3001\u9ad8\u6548\u5bf9\u9f50\u5355\u5143\u548c\u53ef\u6269\u5c55\u8ba1\u7b97\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u53ef\u53d8FP8\u683c\u5f0f\u652f\u6301\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u80fd\u6548\u63d0\u5347\u548c\u7075\u6d3b\u7684\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\u3002"}}
{"id": "2602.05292", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05292", "abs": "https://arxiv.org/abs/2602.05292", "authors": ["Haoyu Bai", "Muhammed Tawfiqul Islam", "Minxian Xu", "Rajkumar Buyya"], "title": "ORACL: Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices", "comment": null, "summary": "Applications are moving away from monolithic designs to microservice and serverless architectures, where fleets of lightweight and independently deployable components run on public clouds. Autoscaling serves as the primary control mechanism for balancing resource utilization and quality of service, yet existing policies are either opaque learned models that require substantial per-deployment training or brittle hand-tuned rules that fail to generalize. We investigate whether large language models can act as universal few-shot resource allocators that adapt across rapidly evolving microservice deployments.\n  We propose ORACL, Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices, a framework that leverages prior knowledge and chain-of-thought reasoning to diagnose performance regressions and recommend resource allocations. ORACL transforms runtime telemetry, including pods, replicas, CPU and memory usage, latency, service-level objectives, and fault signals, into semantic natural-language state descriptions and invokes an LLM to produce an interpretable intermediate reasoning trace. This reasoning identifies likely root causes, prunes the action space, and issues safe allocation decisions under policy constraints. Experiments on representative open-source microservice workloads show that ORACL improves root-cause identification accuracy by 15 percent, accelerates training by up to 24x, and improves quality of service by 6 percent in short-term scenarios, without deployment-specific retraining.", "AI": {"tldr": "ORACL\u662f\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u670d\u52a1\u8d44\u6e90\u81ea\u52a8\u6269\u7f29\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u8bca\u65ad\u6027\u80fd\u95ee\u9898\u5e76\u63a8\u8350\u8d44\u6e90\u5206\u914d\uff0c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u90e8\u7f72\u8fdb\u884c\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u5fae\u670d\u52a1\u548cServerless\u67b6\u6784\u4e2d\uff0c\u81ea\u52a8\u6269\u7f29\u7b56\u7565\u8981\u4e48\u662f\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u7684\u4e0d\u900f\u660e\u5b66\u4e60\u6a21\u578b\uff0c\u8981\u4e48\u662f\u96be\u4ee5\u6cdb\u5316\u7684\u624b\u5de5\u8c03\u4f18\u89c4\u5219\uff0c\u7f3a\u4e4f\u80fd\u591f\u5feb\u901f\u9002\u5e94\u4e0d\u65ad\u6f14\u5316\u7684\u5fae\u670d\u52a1\u90e8\u7f72\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "ORACL\u5c06\u8fd0\u884c\u65f6\u9065\u6d4b\u6570\u636e\uff08pod\u3001\u526f\u672c\u3001CPU/\u5185\u5b58\u4f7f\u7528\u7387\u3001\u5ef6\u8fdf\u3001SLO\u3001\u6545\u969c\u4fe1\u53f7\uff09\u8f6c\u6362\u4e3a\u8bed\u4e49\u81ea\u7136\u8bed\u8a00\u72b6\u6001\u63cf\u8ff0\uff0c\u5229\u7528LLM\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u751f\u6210\u53ef\u89e3\u91ca\u7684\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\uff0c\u8bc6\u522b\u6839\u672c\u539f\u56e0\u3001\u526a\u679d\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u5728\u7b56\u7565\u7ea6\u675f\u4e0b\u505a\u51fa\u5b89\u5168\u7684\u5206\u914d\u51b3\u7b56\u3002", "result": "\u5728\u4ee3\u8868\u6027\u5f00\u6e90\u5fae\u670d\u52a1\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cORACL\u5c06\u6839\u672c\u539f\u56e0\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad815%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe24\u500d\uff0c\u77ed\u671f\u573a\u666f\u4e0b\u670d\u52a1\u8d28\u91cf\u6539\u55846%\uff0c\u4e14\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u90e8\u7f72\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u901a\u7528\u7684\u5c11\u6837\u672c\u8d44\u6e90\u5206\u914d\u5668\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u9002\u5e94\u5feb\u901f\u6f14\u5316\u7684\u5fae\u670d\u52a1\u90e8\u7f72\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u9ad8\u6548\u7684\u81ea\u52a8\u6269\u7f29\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05346", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05346", "abs": "https://arxiv.org/abs/2602.05346", "authors": ["Shubham Mishra", "Jo\u00e3o Gon\u00e7alves", "Chawinphat Tankuranand", "Neil Giridharan", "Natacha Crooks", "Heidi Howard", "Chris Jensen"], "title": "Proteus: Append-Only Ledgers for (Mostly) Trusted Execution Environments", "comment": null, "summary": "Distributed ledgers are increasingly relied upon by industry to provide trustworthy accountability, strong integrity protection, and high availability for critical data without centralizing trust. Recently, distributed append-only logs are opting for a layered approach, combining crash-fault-tolerant (CFT) consensus with hardware-based Trusted Execution Environments (TEEs) for greater resiliency. Unfortunately, hardware TEEs can be subject to (rare) attacks, undermining the very guarantees that distributed ledgers are carefully designed to achieve. In response, we present Proteus, a new distributed consensus protocol that cautiously trusts the guarantees of TEEs. Proteus carefully embeds a Byzantine fault-tolerant (BFT) protocol inside of a CFT protocol with no additional messages. This is made possible through careful refactoring of both the CFT and BFT protocols such that their structure aligns. Proteus achieves performance in line with regular TEE-enabled consensus protocols, while guaranteeing integrity in the face of TEE platform compromises.", "AI": {"tldr": "Proteus\u662f\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u5c06BFT\u534f\u8bae\u5d4c\u5165\u5230CFT\u534f\u8bae\u4e2d\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u5bf9TEE\u786c\u4ef6\u653b\u51fb\u7684\u62b5\u5fa1\u80fd\u529b\u3002", "motivation": "\u5206\u5e03\u5f0f\u8d26\u672c\u4f9d\u8d56\u786c\u4ef6\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEEs)\u63d0\u4f9b\u9ad8\u53ef\u7528\u6027\uff0c\u4f46TEEs\u53ef\u80fd\u53d7\u5230\u653b\u51fb\uff0c\u8fd9\u4f1a\u7834\u574f\u5206\u5e03\u5f0f\u8d26\u672c\u7684\u8bbe\u8ba1\u4fdd\u8bc1\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5229\u7528TEEs\u4f18\u52bf\u53c8\u80fd\u62b5\u5fa1\u5176\u6f5c\u5728\u653b\u51fb\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Proteus\u534f\u8bae\u8c28\u614e\u5730\u4fe1\u4efbTEEs\u4fdd\u8bc1\uff0c\u901a\u8fc7\u91cd\u6784CFT\u548cBFT\u534f\u8bae\u4f7f\u5b83\u4eec\u7684\u7ed3\u6784\u5bf9\u9f50\uff0c\u5c06BFT\u534f\u8bae\u5d4c\u5165\u5230CFT\u534f\u8bae\u4e2d\uff0c\u65e0\u9700\u989d\u5916\u6d88\u606f\u3002", "result": "Proteus\u5728\u4fdd\u6301\u4e0e\u5e38\u89c4TEE\u589e\u5f3a\u5171\u8bc6\u534f\u8bae\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5728TEE\u5e73\u53f0\u88ab\u653b\u7834\u65f6\u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u3002", "conclusion": "Proteus\u63d0\u4f9b\u4e86\u4e00\u79cd\u5e73\u8861\u65b9\u6cd5\uff0c\u65e2\u5229\u7528TEEs\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u53c8\u901a\u8fc7BFT\u673a\u5236\u589e\u5f3a\u5bf9\u786c\u4ef6\u653b\u51fb\u7684\u62b5\u5fa1\u80fd\u529b\uff0c\u4e3a\u5206\u5e03\u5f0f\u8d26\u672c\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2602.05356", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05356", "abs": "https://arxiv.org/abs/2602.05356", "authors": ["Andrew Lewis-Pye"], "title": "Reaching Univalency with Subquadratic Communication", "comment": null, "summary": "The Dolev-Reischuk lower bound establishes that any deterministic Byzantine Agreement (BA) protocol for $n$ processors tolerating $f$ faults requires $\u03a9(f^2+n)$ messages. But what exactly does this quadratic cost pay for? Even the minimal requirement that every correct processor \\emph{receive at least one message} already necessitates $\u03a9(f^2 + n)$ messages. This raises a fundamental question: is the Dolev-Reischuk bound about the difficulty of \\emph{reaching univalency} -- the point at which the protocol's outcome is determined -- or merely about \\emph{disseminating} the outcome to all processors afterward?\n  We resolve this question by showing that reaching univalency does \\emph{not} require quadratic communication. Specifically, we introduce $\u03b5$-BA, a relaxation allowing an $\u03b5$-fraction of correct processors to output incorrectly, and prove it can be solved deterministically with $O(n \\log n)$ communication complexity when $f < n(1/3 - \u03b5)$. Crucially, any $\u03b5$-BA protocol can serve as the first phase of a full BA protocol: after $\u03b5$-BA, a single all-to-all exchange and majority vote completes BA. Since the outcome is already determined after $\u03b5$-BA, this demonstrates that the quadratic cost in Dolev-Reischuk stems entirely from dissemination, rather than from reaching univalency. We also define Extractable BA for authenticated settings, capturing when processors collectively hold enough signed messages to determine the agreed value, and show it can be solved with communication complexity $O(f \\log f)$.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86Dolev-Reischuk\u4e0b\u754c\u4e2d\u7684\u4e8c\u6b21\u901a\u4fe1\u6210\u672c\u4e3b\u8981\u6765\u81ea\u7ed3\u679c\u4f20\u64ad\u9636\u6bb5\uff0c\u800c\u975e\u8fbe\u6210\u4e00\u81f4\u6027\u51b3\u7b56\u9636\u6bb5\u3002\u901a\u8fc7\u5f15\u5165\u03b5-BA\u677e\u5f1b\u534f\u8bae\uff0c\u5c55\u793a\u4e86\u5728\u8fbe\u6210\u4e00\u81f4\u6027\u51b3\u7b56\u9636\u6bb5\u53ea\u9700O(n log n)\u901a\u4fe1\u590d\u6742\u5ea6\u3002", "motivation": "Dolev-Reischuk\u4e0b\u754c\u8868\u660e\u62dc\u5360\u5ead\u5bb9\u9519\u534f\u8bae\u9700\u8981\u03a9(f\u00b2+n)\u6d88\u606f\uff0c\u4f46\u8fd9\u4e00\u4e8c\u6b21\u6210\u672c\u7684\u5177\u4f53\u6765\u6e90\u4e0d\u660e\u786e\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7a76\u8fd9\u4e00\u6210\u672c\u662f\u6765\u81ea\u8fbe\u6210\u4e00\u81f4\u6027\u51b3\u7b56\u7684\u56f0\u96be\uff0c\u8fd8\u662f\u4ec5\u4ec5\u6765\u81ea\u5c06\u7ed3\u679c\u4f20\u64ad\u7ed9\u6240\u6709\u5904\u7406\u5668\u7684\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u03b5-BA\u677e\u5f1b\u534f\u8bae\uff0c\u5141\u8bb8\u03b5\u6bd4\u4f8b\u7684\u6b63\u786e\u5904\u7406\u5668\u8f93\u51fa\u9519\u8bef\u7ed3\u679c\u3002\u8bc1\u660e\u5f53f < n(1/3 - \u03b5)\u65f6\uff0c\u03b5-BA\u53ef\u4ee5\u7528O(n log n)\u901a\u4fe1\u590d\u6742\u5ea6\u786e\u5b9a\u6027\u89e3\u51b3\u3002\u4efb\u4f55\u03b5-BA\u534f\u8bae\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u5b8c\u6574BA\u534f\u8bae\u7684\u7b2c\u4e00\u9636\u6bb5\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5355\u6b21\u5168\u4ea4\u6362\u548c\u591a\u6570\u6295\u7968\u5b8c\u6210BA\u3002", "result": "\u8fbe\u6210\u4e00\u81f4\u6027\u51b3\u7b56\uff08univalency\uff09\u4e0d\u9700\u8981\u4e8c\u6b21\u901a\u4fe1\uff0c\u03b5-BA\u53ef\u4ee5\u5728O(n log n)\u901a\u4fe1\u590d\u6742\u5ea6\u4e0b\u89e3\u51b3\u3002\u5b8c\u6574\u7684BA\u534f\u8bae\u4e2d\uff0c\u4e8c\u6b21\u6210\u672c\u5b8c\u5168\u6765\u81ea\u7ed3\u679c\u4f20\u64ad\u9636\u6bb5\uff0c\u800c\u975e\u51b3\u7b56\u9636\u6bb5\u3002\u5728\u8ba4\u8bc1\u8bbe\u7f6e\u4e2d\uff0cExtractable BA\u53ef\u4ee5\u7528O(f log f)\u901a\u4fe1\u590d\u6742\u5ea6\u89e3\u51b3\u3002", "conclusion": "Dolev-Reischuk\u4e0b\u754c\u4e2d\u7684\u4e8c\u6b21\u901a\u4fe1\u6210\u672c\u5b8c\u5168\u6765\u81ea\u7ed3\u679c\u4f20\u64ad\u9700\u6c42\uff0c\u800c\u975e\u8fbe\u6210\u4e00\u81f4\u6027\u51b3\u7b56\u7684\u96be\u5ea6\u3002\u8fd9\u4e00\u53d1\u73b0\u6f84\u6e05\u4e86\u62dc\u5360\u5ead\u534f\u8bae\u901a\u4fe1\u590d\u6742\u6027\u7684\u672c\u8d28\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u534f\u8bae\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.05754", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05754", "abs": "https://arxiv.org/abs/2602.05754", "authors": ["Seonghye Cho", "Jaemin Han", "Hyunjin Kim", "Euisoo Jung", "Jae-Gil Lee"], "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism", "comment": null, "summary": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.", "AI": {"tldr": "TimelyFreeze\u901a\u8fc7\u5efa\u6a21\u6d41\u6c34\u7ebf\u8c03\u5ea6\u4e3a\u6709\u5411\u65e0\u73af\u56fe\u5e76\u6c42\u89e3\u7ebf\u6027\u89c4\u5212\uff0c\u5728\u7cbe\u5ea6\u7ea6\u675f\u4e0b\u8ba1\u7b97\u6700\u4f18\u51bb\u7ed3\u6bd4\u4f8b\uff0c\u51cf\u5c11\u6d41\u6c34\u7ebf\u6c14\u6ce1\uff0c\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf40%", "motivation": "\u6d41\u6c34\u7ebf\u5e76\u884c\u867d\u7136\u80fd\u8bad\u7ec3\u8d85\u51fa\u5355\u8bbe\u5907\u5185\u5b58\u7684\u6a21\u578b\uff0c\u4f46\u5b9e\u9645\u541e\u5410\u91cf\u53d7\u9650\u4e8e\u6d41\u6c34\u7ebf\u6c14\u6ce1\u3002\u73b0\u6709\u53c2\u6570\u51bb\u7ed3\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u81ea\u9002\u5e94\u8df3\u8fc7\u53cd\u5411\u8ba1\u7b97\u63d0\u9ad8\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u4f46\u5f80\u5f80\u8fc7\u5ea6\u51bb\u7ed3\u53c2\u6570\uff0c\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u5c06\u6d41\u6c34\u7ebf\u8c03\u5ea6\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u901a\u8fc7\u6c42\u89e3\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u6765\u8ba1\u7b97\u6700\u4f18\u7684\u51bb\u7ed3\u6bd4\u4f8b\uff0c\u5728\u6ee1\u8db3\u7cbe\u5ea6\u7ea6\u675f\u7684\u6761\u4ef6\u4e0b\u6700\u5c0f\u5316\u6279\u6b21\u6267\u884c\u65f6\u95f4\u3002", "result": "\u5728LLaMA-8B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe40%\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u7684\u7cbe\u5ea6\u3002\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u6536\u655b\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u79cd\u6d41\u6c34\u7ebf\u5e76\u884c\u8bbe\u7f6e\u3002", "conclusion": "TimelyFreeze\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u51bb\u7ed3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u6c34\u7ebf\u5e76\u884c\u4e2d\u7684\u6c14\u6ce1\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u7684\u663e\u8457\u63d0\u5347\u800c\u4e0d\u635f\u5bb3\u6a21\u578b\u7cbe\u5ea6\uff0c\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05948", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.05948", "abs": "https://arxiv.org/abs/2602.05948", "authors": ["Himani", "Supantha Pandit", "Gokarna Sharma"], "title": "Location-Aware Dispersion on Anonymous Graphs", "comment": "3 tables, 2 figures, 6 pseudo-codes", "summary": "The well-studied DISPERSION problem is a fundamental coordination problem in distributed robotics, where a set of mobile robots must relocate so that each occupies a distinct node of a network. DISPERSION assumes that a robot can settle at any node as long as no other robot settles on that node. In this work, we introduce LOCATION-AWARE DISPERSION, a novel generalization of DISPERSION that incorporates location awareness: Let $G = (V, E)$ be an anonymous, connected, undirected graph with $n = |V|$ nodes, each labeled with a color $\\sf{col}(v) \\in C = \\{c_1, \\dots, c_t\\}, t\\leq n$. A set $R = \\{r_1, \\dots, r_k\\}$ of $k \\leq n$ mobile robots is given, where each robot $r_i$ has an associated color $\\mathsf{col}(r_i) \\in C$. Initially placed arbitrarily on the graph, the goal is to relocate the robots so that each occupies a distinct node of the same color. When $|C|=1$, LOCATION-AWARE DISPERSION reduces to DISPERSION. There is a solution to DISPERSION in graphs with any $k\\leq n$ without knowing $k,n$.\n  Like DISPERSION, the goal is to solve LOCATION-AWARE DISPERSION minimizing both time and memory requirement at each agent. We develop several deterministic algorithms with guaranteed bounds on both time and memory requirement. We also give an impossibility and a lower bound for any deterministic algorithm for LOCATION-AWARE DISPERSION. To the best of our knowledge, the presented results collectively establish the algorithmic feasibility of LOCATION-AWARE DISPERSION in anonymous networks and also highlight the challenges on getting an efficient solution compared to the solutions for DISPERSION.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\uff08LOCATION-AWARE DISPERSION\uff09\uff0c\u8fd9\u662f\u7ecf\u5178\u5206\u6563\u95ee\u9898\u7684\u65b0\u6269\u5c55\uff0c\u8981\u6c42\u673a\u5668\u4eba\u6839\u636e\u989c\u8272\u5339\u914d\u79fb\u52a8\u5230\u76f8\u540c\u989c\u8272\u7684\u8282\u70b9\u4e0a\uff0c\u5f53\u989c\u8272\u96c6\u5927\u5c0f\u4e3a1\u65f6\u9000\u5316\u4e3a\u4f20\u7edf\u5206\u6563\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5206\u6563\u95ee\u9898\u53ea\u8981\u6c42\u673a\u5668\u4eba\u5360\u636e\u4e0d\u540c\u8282\u70b9\uff0c\u4e0d\u8003\u8651\u8282\u70b9\u5c5e\u6027\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u673a\u5668\u4eba\u53ef\u80fd\u9700\u8981\u6839\u636e\u4f4d\u7f6e\u7279\u5f81\uff08\u5982\u989c\u8272\u6807\u7b7e\uff09\u8fdb\u884c\u5206\u914d\u3002\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u5f15\u5165\u4e86\u989c\u8272\u5339\u914d\u7ea6\u675f\uff0c\u4f7f\u95ee\u9898\u66f4\u5177\u5b9e\u9645\u610f\u4e49\u548c\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u51e0\u79cd\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4fdd\u8bc1\u65f6\u95f4\u548c\u5185\u5b58\u9700\u6c42\u7684\u754c\u9650\u3002\u540c\u65f6\u7ed9\u51fa\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u7684\u4e0d\u53ef\u884c\u6027\u8bc1\u660e\u548c\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u4e0b\u754c\u5206\u6790\u3002", "result": "\u5efa\u7acb\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u5728\u533f\u540d\u7f51\u7edc\u4e2d\u7684\u7b97\u6cd5\u53ef\u884c\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u76f8\u6bd4\u4f20\u7edf\u5206\u6563\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u83b7\u5f97\u9ad8\u6548\u89e3\u6240\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u662f\u5206\u6563\u95ee\u9898\u7684\u6709\u610f\u4e49\u6269\u5c55\uff0c\u867d\u7136\u7b97\u6cd5\u4e0a\u53ef\u884c\uff0c\u4f46\u76f8\u6bd4\u4f20\u7edf\u5206\u6563\u95ee\u9898\u9700\u8981\u66f4\u590d\u6742\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\u65b9\u9762\u9762\u4e34\u66f4\u5927\u6311\u6218\u3002"}}
