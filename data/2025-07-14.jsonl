{"id": "2507.08190", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08190", "abs": "https://arxiv.org/abs/2507.08190", "authors": ["Simon Johnson", "Raghunandan Makaram", "Amy Santoni", "Vinnie Scarlata"], "title": "Supporting Intel(r) SGX on Multi-Package Platforms", "comment": "8 pages, 6 figures", "summary": "Intel(r) Software Guard Extensions (SGX) was originally released on client\nplatforms and later extended to single socket server platforms. As developers\nhave become familiar with the capabilities of the technology, the applicability\nof this capability in the cloud has been tested. Various Cloud Service\nProviders (CSPs) are demonstrating the value of using SGX based Trusted\nExecution Environments (TEE) to create a new paradigm of Confidential Cloud\nComputing. This paper describes the additional platform enhancements we believe\nare necessary to deliver a user programmable Trusted Execution Environment that\nscales to cloud usages, performs and is secure on multi-package platforms."}
{"id": "2507.08281", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.08281", "abs": "https://arxiv.org/abs/2507.08281", "authors": ["Ahmad Zaki Akmal", "Azkario Rizky Pratama", "Guntur Dharma Putra"], "title": "Fast and Interactive Byzantine Fault-tolerant Web Services via Session-Based Consensus Decoupling", "comment": "6 pages, 5 figures. Accepted to IEEE MetaCom 2025 as a short paper", "summary": "Byzantine fault-tolerant (BFT) web services provide critical integrity\nguarantees for distributed applications but face significant latency challenges\nthat hinder interactive user experiences. We propose a novel two-layer\narchitecture that addresses this fundamental tension between security and\nresponsiveness in BFT systems. Our approach introduces a session-aware\ntransaction buffer layer (Layer 2) that delivers immediate feedback to users\nthrough consensus simulation, while periodically committing batched operations\nto a fully Byzantine fault-tolerant consensus layer (Layer 1). By separating\ninteractive operations from consensus finalization, our system achieves\nresponsive user experiences of under 200ms, while maintaining strong BFT\nsecurity guarantees. We demonstrate the efficacy of our architecture through a\nsupply chain management implementation, where operators require both immediate\nfeedback during multi-step workflows and tamper-proof record keeping. Our\nevaluation shows that our Layer 2 operations perform four times faster than the\nLayer 1 counterpart, while substantially preserving the end-to-end transaction\nintegrity. Our approach enables BFT applications in domains previously\nconsidered impractical due to latency constraints, such as metaverse\nenvironments, where users require both responsive interaction and guaranteed\nstate consistency."}
{"id": "2507.08348", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.08348", "abs": "https://arxiv.org/abs/2507.08348", "authors": ["Yi-Jun Chang", "Lyuting Chen", "Haoran Zhou"], "title": "Content-Oblivious Leader Election in 2-Edge-Connected Networks", "comment": null, "summary": "Censor-Hillel, Cohen, Gelles, and Sela (PODC 2022 \\& Distributed Computing\n2023) studied fully-defective asynchronous networks, where communication\nchannels may suffer an extreme form of alteration errors, rendering messages\ncompletely corrupted. The model is equivalent to content-oblivious computation,\nwhere nodes communicate solely via pulses. They showed that if the network is\n2-edge-connected, then any algorithm for a noiseless setting can be simulated\nin the fully-defective setting; otherwise, no non-trivial computation is\npossible in the fully-defective setting. However, their simulation requires a\npredesignated leader, which they conjectured to be necessary for any\nnon-trivial content-oblivious task.\n  Recently, Frei, Gelles, Ghazy, and Nolin (DISC 2024) refuted this conjecture\nfor the special case of oriented ring topology. They designed two asynchronous\ncontent-oblivious leader election algorithms with message complexity $O(n \\cdot\n\\mathsf{ID}_{\\max})$, where $n$ is the number of nodes and $\\mathsf{ID}_{\\max}$\nis the maximum $\\mathsf{ID}$. The first algorithm stabilizes in unoriented\nrings without termination detection. The second algorithm quiescently\nterminates in oriented rings, thus enabling the execution of the simulation\nalgorithm after leader election.\n  In this work, we present an asynchronous content-oblivious leader election\nalgorithm that quiescently terminates in any 2-edge connected network with\nmessage complexity $O(m \\cdot N \\cdot \\mathsf{ID}_{\\min})$, where $m$ is the\nnumber of edges, $N$ is a known upper bound on the number of nodes, and\n$\\mathsf{ID}_{\\min}$ is the smallest $\\mathsf{ID}$. Combined with the previous\nsimulation result, our finding implies that any algorithm from the noiseless\nsetting can be simulated in the fully-defective setting without assuming a\npreselected leader, entirely refuting the original conjecture."}
{"id": "2507.08725", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.08725", "abs": "https://arxiv.org/abs/2507.08725", "authors": ["Dominik Schweisgut", "Anne Benoit", "Yves Robert", "Henning Meyerhenke"], "title": "Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint", "comment": "40 pages, 17 figures. Accepted at ICPP 2025. Code available at:\n  https://github.com/KIT-EAE/CaWoSched.git", "summary": "Large data and computing centers consume a significant share of the world's\nenergy consumption. A prominent subset of the workloads in such centers are\nworkflows with interdependent tasks, usually represented as directed acyclic\ngraphs (DAGs). To reduce the carbon emissions resulting from executing such\nworkflows in centers with a mixed (renewable and non-renewable) energy supply,\nit is advisable to move task executions to time intervals with sufficient green\nenergy when possible. To this end, we formalize the above problem as a\nscheduling problem with a given mapping and ordering of the tasks. We show that\nthis problem can be solved in polynomial time in the uniprocessor case. For at\nleast two processors, however, the problem becomes NP-hard. Hence, we propose a\nheuristic framework called CaWoSched that combines several greedy approaches\nwith local search. To assess the 16 heuristics resulting from different\ncombinations, we also devise a simple baseline algorithm and an exact ILP-based\nsolution. Our experimental results show that our heuristics provide significant\nsavings in carbon emissions compared to the baseline."}
{"id": "2507.08406", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.08406", "abs": "https://arxiv.org/abs/2507.08406", "authors": ["Weigang Feng", "Yijia Zhang", "Zekun Wang", "Zhengyang Wang", "Yi Wang", "Peijun Ma", "Ningyi Xu"], "title": "CCSS: Hardware-Accelerated RTL Simulation with Fast Combinational Logic Computing and Sequential Logic Synchronization", "comment": null, "summary": "As transistor counts in a single chip exceed tens of billions, the complexity\nof RTL-level simulation and verification has grown exponentially, often\nextending simulation campaigns to several months. In industry practice, RTL\nsimulation is divided into two phases: functional debug and system validation.\nWhile system validation demands high simulation speed and is typically\naccelerated using FPGAs, functional debug relies on rapid compilation-rendering\nmulti-core CPUs the primary choice. However, the limited simulation speed of\nCPUs has become a major bottleneck. To address this challenge, we propose CCSS,\na scalable multi-core RTL simulation platform that achieves both fast\ncompilation and high simulation throughput. CCSS accelerates combinational\nlogic computation and sequential logic synchronization through specialized\narchitecture and compilation strategies. It employs a balanced DAG partitioning\nmethod and efficient boolean computation cores for combinational logic, and\nadopts a low-latency network-on-chip (NoC) design to synchronize sequential\nstates across cores efficiently. Experimental results show that CCSS delivers\nup to 12.9x speedup over state-of-the-art multi-core simulators."}
{"id": "2507.08759", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.08759", "abs": "https://arxiv.org/abs/2507.08759", "authors": ["Maximilian Dor√©"], "title": "Dependent Multiplicities in Dependent Linear Type Theory", "comment": null, "summary": "We present a novel dependent linear type theory in which the multiplicity of\nsome variable - i.e., the number of times the variable can be used in a program\n- can depend on other variables. This allows us to give precise resource\nannotations to many higher-order functions that cannot be adequately typed in\nany other system. Inspired by the Dialectica translation, our typing discipline\nis obtained by embedding linear logic into dependent type theory and specifying\nhow the embedded logic interacts with the host theory. We can then use a\nstandard natural numbers type to obtain a quantitative typing system with\ndependent multiplicities. We characterise the semantics for our theory as a\ncombination of standard models of dependent type theory and linear logic. Our\nsystem can be added to any dependently typed language, which we demonstrate\nwith an implementation in Agda."}
{"id": "2507.08406", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.08406", "abs": "https://arxiv.org/abs/2507.08406", "authors": ["Weigang Feng", "Yijia Zhang", "Zekun Wang", "Zhengyang Wang", "Yi Wang", "Peijun Ma", "Ningyi Xu"], "title": "CCSS: Hardware-Accelerated RTL Simulation with Fast Combinational Logic Computing and Sequential Logic Synchronization", "comment": null, "summary": "As transistor counts in a single chip exceed tens of billions, the complexity\nof RTL-level simulation and verification has grown exponentially, often\nextending simulation campaigns to several months. In industry practice, RTL\nsimulation is divided into two phases: functional debug and system validation.\nWhile system validation demands high simulation speed and is typically\naccelerated using FPGAs, functional debug relies on rapid compilation-rendering\nmulti-core CPUs the primary choice. However, the limited simulation speed of\nCPUs has become a major bottleneck. To address this challenge, we propose CCSS,\na scalable multi-core RTL simulation platform that achieves both fast\ncompilation and high simulation throughput. CCSS accelerates combinational\nlogic computation and sequential logic synchronization through specialized\narchitecture and compilation strategies. It employs a balanced DAG partitioning\nmethod and efficient boolean computation cores for combinational logic, and\nadopts a low-latency network-on-chip (NoC) design to synchronize sequential\nstates across cores efficiently. Experimental results show that CCSS delivers\nup to 12.9x speedup over state-of-the-art multi-core simulators."}
{"id": "2507.08658", "categories": ["cs.AR", "cs.DS", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.08658", "abs": "https://arxiv.org/abs/2507.08658", "authors": ["Robert B. Kent", "Marios S. Pattichis"], "title": "Fast and Efficient Merge of Sorted Input Lists in Hardware Using List Offset Merge Sorters", "comment": null, "summary": "A new set of hardware merge sort devices are introduced here, which merge\nmultiple sorted input lists into a single sorted output list in a fast and\nefficient manner. In each merge sorter, the values from the sorted input lists\nare arranged in an input 2-D setup array, but with the order of each sorted\ninput list offset from the order of each of the other sorted input lists. In\nthese new devices, called List Offset Merge Sorters (LOMS), a minimal set of\ncolumn sort stages alternating with row sort stages process the input setup\narray into a final output array, now in the defined sorted order. LOMS 2-way\nsorters, which merge 2 sorted input lists, require only 2 merge stages and are\nsignificantly faster than Kenneth Batcher's previous state-of-the-art 2-way\nmerge devices, Bitonic Merge Sorters and Odd-Even Merge Sorters. LOMS 2-way\nsorters utilize the recently-introduced Single-Stage 2-way Merge Sorters (S2MS)\nin their first stage. Both LOMS and S2MS devices can merge any mixture of input\nlist sizes, while Batcher's merge sorters are difficult to design unless the 2\ninput lists are equal, and a power-of-2. By themselves, S2MS devices are the\nfastest 2-way merge sorters when implemented in this study's target FPGA\ndevices, but they tend to use a large number of LUT resources. LOMS 2-way\ndevices use fewer resources than comparable S2MS devices, enabling some large\nLOMS devices to be implemented in a given FPGA when comparable S2MS devices\ncannot fit in that FPGA. A List Offset 2-way sorter merges 2 lists, each with\n32 values, into a sorted output list of those 64 values in 2.24 nS, a speedup\nof 2.63 versus a comparable Batcher device. A LOMS 3-way merge sorter, merging\n3 sorted input lists with 7 values, fully merges the 21 values in 3.4 nS, a\nspeedup of 1.36 versus the comparable state-of-the-art 3-way merge device."}
{"id": "2507.08796", "categories": ["cs.PL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08796", "abs": "https://arxiv.org/abs/2507.08796", "authors": ["Owen Lewis", "Neil Ghani", "Andrew Dudzik", "Christos Perivolaropoulos", "Razvan Pascanu", "Petar Veliƒçkoviƒá"], "title": "Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists", "comment": "18 pages, 2 figures", "summary": "What should a function that extrapolates beyond known input/output examples\nlook like? This is a tricky question to answer in general, as any function\nmatching the outputs on those examples can in principle be a correct\nextrapolant. We argue that a \"good\" extrapolant should follow certain kinds of\nrules, and here we study a particularly appealing criterion for rule-following\nin list functions: that the function should behave predictably even when\ncertain elements are removed. In functional programming, a standard way to\nexpress such removal operations is by using a filter function. Accordingly, our\npaper introduces a new semantic class of functions -- the filter equivariant\nfunctions. We show that this class contains interesting examples, prove some\nbasic theorems about it, and relate it to the well-known class of map\nequivariant functions. We also present a geometric account of filter\nequivariants, showing how they correspond naturally to certain simplicial\nstructures. Our highlight result is the amalgamation algorithm, which\nconstructs any filter-equivariant function's output by first studying how it\nbehaves on sublists of the input, in a way that extrapolates perfectly."}
